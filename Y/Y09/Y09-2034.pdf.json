{"sections":[{"title":"  Word Bou\\bd\\try D\\fcisio\\b with CRF for Chi\\b\\fs\\f Word S\\fgm\\f\\bt\\ttio\\b","paragraphs":["∗ ∗ ∗ ∗ "," Shousha\\b \\ti a\\bd \\fhu-Re\\b Hua\\bg","","Departme\\bt of \\fhi\\bese a\\bd Bili\\bgual Studies The Ho\\bg Ko\\bg Polytech\\bic U\\biversity {shousha\\b.li, chure\\bhua\\bg}@gmail.com Abstr\\tct. \\fhi\\bese word segme\\btatio\\b systems \\becessarily perform both accurately a\\bd quickly for real applicatio\\bs. I\\b this paper, we study o\\b word bou\\bdary decisio\\b (WBD) approach for \\fhi\\bese word segme\\btatio\\b a\\bd impleme\\bt it as a 2-tag character taggi\\bg with co\\bditio\\bal ra\\bdom filed (\\fRF). With a help of tag tra\\bsitio\\b features, WBD with \\fRF segme\\btatio\\b approach ca\\b achieve comparative performa\\bces compared to 4-tag character taggi\\bg approach (represe\\bts the state-of-the-art segme\\btatio\\b approach). But it requires o\\bly about half trai\\bi\\bg time a\\bd memory space as much as 4-tag character taggi\\bg approach. These results e\\bcourage that WBD segme\\btatio\\b approach is a good choice for real \\fhi\\bese word segme\\btatio\\b systems. K\\fywords: \\fhi\\bese word segme\\btatio\\b, co\\bditio\\bal ra\\bdom field, word bou\\bdary decisio\\b. \\- \\- ","\\fopyright 2009 by Shousha\\b \\ti a\\bd \\fhu-Re\\b Hua\\bg"]},{"title":"1 I\\btroductio\\b","paragraphs":["\\fhi\\bese word segme\\btatio\\b (\\fWS) is the task of segme\\bti\\bg text of character stri\\bg i\\bto word list as origi\\bal \\fhi\\bese text co\\btai\\bs \\bo explicit bou\\bdaries betwee\\b every two words. This task is a\\b i\\bdispe\\bsible preprocessi\\bg requireme\\bt for ma\\by applicatio\\bs i\\b \\fhi\\bese la\\bguage tech\\bology. A realistic \\fWS system \\becessarily performs well o\\b both segme\\btatio\\b accuracy a\\bd speed.","Segme\\btatio\\b accuracy is esse\\btial for ma\\by applicatio\\bs. For i\\bsta\\bce, i\\b machi\\be tra\\bslatio\\b for \\fhi\\bese to E\\bglish (\\fha\\bg et al., 2008), segme\\btatio\\b errors would cause tra\\bslatio\\b mistakes directly. Tra\\bslatio\\b systems without a wo\\bderful \\fWS model are impossible to offer good results. State-of-the-arts approach called character taggi\\bg (Xue, 2003) has show\\b to be excelle\\bt i\\b segme\\btatio\\b accuracy. This approach mai\\bly aims to detect the character positio\\b i\\b a certai\\b word, e.g., begi\\b\\bi\\bg, middle or e\\bd of a word. It achieves much better performa\\bces tha\\b traditio\\bal word-based (or dictio\\bary) approach, e.g., \\b-gram word maximum probability (Su\\b et al., 2006), because of its appare\\bt adva\\btages o\\b detecti\\bg out-of-vocabulary (OOV) words.","O\\b the other side, the segme\\btatio\\b speed is also very importa\\bt i\\b some applicatio\\bs, such as i\\bformatio\\b retrieval a\\bd o\\bli\\be machi\\be tra\\bslatio\\b systems. Si\\bce \\fWS system is almost always used as a preprocessi\\bg step i\\b the applicatio\\bs, lo\\bg segme\\btatio\\b time would make the applicatio\\bs’ whole ru\\b\\bi\\bg time u\\bacceptable by users. Therefore, it is mea\\bi\\bgful to simplify the complexity of \\fWS approaches so as to reduci\\bg segme\\btatio\\b trai\\bi\\bg a\\bd testi\\bg time. I\\b terms of this view, character taggi\\bg approach (ofte\\b usi\\bg 4-tags (Xue, 2003; Ng a\\bd \\tow, 2004) or eve\\b 6-tags (Zhao et al., 2006)) is \\bot so satisfactory i\\b its trai\\bi\\bg a\\bd testi\\bg time. Especially, give\\b a very huge trai\\bi\\bg data, this approach might \\bot get a trai\\bi\\bg model due to its large time a\\bd memory space dema\\bd.","Rece\\btly, Hua\\bg et al. (2007) propose a\\b i\\bteresti\\bg approach, \\bamed word bou\\bdary decisio\\b (WBD), which tur\\bs from words towards word bou\\bdaries. WBD tries to detect the 726 23rd Pacific Asia Conference on Language, Information and Computation, pages 726–732   \\bature of bou\\bdary betwee\\b two characters, which ca\\b be either a word bou\\bdary or \\bot, i.e. a bou\\bdary betwee\\b two words or a mere character bou\\bdary. This approach performs better tha\\b traditio\\bal word-based (or dictio\\bary) approach but still worse tha\\b character taggi\\bg approach (Hua\\bg et al., 2008). However, this approach takes a big adva\\btage over character taggi\\bg approach i\\b its trai\\bi\\bg a\\bd testi\\bg time.","I\\b this paper, we deeply a\\balyze the relatio\\bship betwee\\b character taggi\\bg approach a\\bd WBD approach a\\bd propose a \\bew impleme\\btatio\\b of WBD approach with co\\bditio\\bal ra\\bdom field (\\fRF) lear\\bi\\bg approach. This impleme\\btatio\\b will make WBD approach achieve competitive performa\\bce compared to character taggi\\bg approach with 4-tags which represe\\bts the state-of-the-art approach i\\b \\fWS studies but \\beed much less trai\\bi\\bg time a\\bd memory space.","I\\b the remai\\bi\\bg part of the paper, we review WBD approach a\\bd study the relatio\\bship betwee\\b this approach a\\bd character taggi\\bg approach i\\b Sectio\\b 2. The\\b, we propose our impleme\\btatio\\b approach of WBD with \\fRF i\\b Sectio\\b 3. Experime\\btal results are give\\b a\\bd discussed i\\b Sectio\\b 4. Fi\\bally, we co\\bclude our co\\btributio\\b o\\b \\fhi\\bese word segme\\btatio\\b i\\b Sectio\\b 5."]},{"title":"2 Word Bou\\bd\\try D\\fcisio\\b 2.1 Appro\\tch R\\fvi\\fwi\\bg","paragraphs":["Hua\\bg et al. (2007) propose a\\b i\\bteresti\\bg approach called WBD which aims at classifyi\\bg bou\\bdaries directly rather tha\\b classifyi\\bg characters. As a result, word segme\\btatio\\b becomes a bi\\bary classificatio\\b problem, which makes the segme\\btatio\\b task easier a\\bd faster.","\\fhi\\bese text ca\\b be formalized as a seque\\bce of characters a\\bd i\\btervals","1 1 2 2 1 1,..., n n n\\b \\t \\b \\t \\b \\t \\b− − where i\\b mea\\bs a character a\\bd i\\t mea\\bs a i\\bterval betwee\\b two characters. There is \\bo i\\bdicatio\\b of word bou\\bdaries i\\b \\fhi\\bese text a\\bd each i\\bterval might be a word bou\\bdary ( 1i\\t= ) or \\bot ( 0i\\t= ). The classificatio\\b problem i\\b WBD is to classify the i\\btervals i\\bto word bou\\bdaries or \\bo\\b-bou\\bdaries.","WBD co\\bsists of two mai\\b steps: ge\\berati\\bg a set of character \\b-gram probabilities a\\bd classifier trai\\bi\\bg a\\bd testi\\bg usi\\bg probability vectors coi\\bed from \\b-gram set.","I\\b the first step, differe\\bt ki\\bds of character \\b-gram probabilities are estimated from trai\\bi\\bg data. Five differe\\bt u\\bigram a\\bd bi-gram probabilities are usually used i\\b WBD. They are u\\bigram probabilities of C\\fP , \\fCP a\\bd bigram probabilities of CC\\fP , C\\fCP , \\fCCP . The defi\\bitio\\b of C\\fP is give\\b as ( , 1) ( 1| ) ( ) i i C\\f i i i","C \\b \\t P \\t \\b","C \\b= = = where i( , 1)iC \\b \\t= is the \\bumber of i\\b which appears before a word bou\\bdary. ( )iC \\bis the total \\bumber of i\\bthat appears i\\b the trai\\bi\\bg data. Similarly, defi\\bitio\\b of CC\\fP is give\\b as 1 1 1 ( , , 1) ( 1| , ) ( , ) i i i CC\\f i i i i i C \\b \\b \\t","P \\t \\b \\b","C \\b \\b − − −","= = = where 1( , , 1)i i iC \\b \\b \\t− = is the \\bumber of bigrams of characters 1,i i\\b \\b− which appear together i\\b fro\\bt of a word bou\\bdary. 1( , )i iC \\b \\b− represe\\bts the total \\bumber of the bi-gram 1,i i\\b \\b− .","After the estimati\\bg process o\\b the trai\\bi\\bg data, all u\\bigrams a\\bd bi-grams will get their bou\\bdary probability i\\bformatio\\b. The probabilities are the\\b applied to ge\\berate the vectors i\\b the seco\\bd step. O\\bce the freque\\bcy a\\bd probability i\\bformatio\\b of all character \\b-grams is obtai\\bed, it ca\\b be easily preserved i\\b a database (\\b-gram database).","I\\b the seco\\bd step, each bou\\bdary i\\t would be represe\\bted as a vector 727  ","( ), ( ), ( ), ( ), ( )CC\\f i C\\f i C\\fC i \\fC i \\fCC iP \\t P \\t P \\t P \\t P \\t< > Both trai\\bi\\bg a\\bd testi\\bg process \\beed to ge\\berate the vectors for each bou\\bdary.","I\\bteresti\\bgly, Hua\\bg et al. (2008) show that 1,000 vectors are e\\bough to optimize a good","classifier.  T\\tbl\\f 1: Example of e\\bcodi\\bg a\\bd labeli\\bg of i\\bterval vectors  CC\\fP C\\fP C\\fCP \\fCCP \\fCP i\\t I\\bter. 0.5 0.60 0.00 0.17 0.02 0 時間 0.98 0.96 1.00 0.99 1.00 1 間: 1.00 1.00 1.00 0.71 0.99 1 :三 0.30 0.54 0.01 0.32 0.05 0 三月 0.96 0.85 1.00 0.43 0.47 1 月十 0.00 0.25 0.07 0.49 0.01 0 十日  Usi\\bg the example from Hua\\bg et al. (2008), to segme\\bt the followi\\bg \\fhi\\bese se\\bte\\bce:","時 1\\t間 2\\t: 3\\t三 4\\t月 5\\t十 6\\t日 The correspo\\bdi\\bg vectors are ge\\berated a\\bd show\\b i\\b Table 1. Note that if a\\b \\b-gram does \\bot appear i\\b the \\b-gram database, the probability is assig\\bed","automatically 0.5, which mea\\bs that it offers \\bo detectio\\b i\\bformatio\\b for word bou\\bdary."]},{"title":"2.2 R\\fl\\ttio\\bship to Ch\\tr\\tct\\fr T\\tggi\\bg Appro\\tch","paragraphs":["\\fharacter taggi\\bg approach models \\fhi\\bese word segme\\btatio\\b as a character-tag classificatio\\b problem. Each character i\\b a\\b u\\btagged text is labeled with a tag that represe\\bts the positio\\b i\\b a word (Xue, 2003). The tag sets usually co\\btai\\bs four labels: '\\f' for a character that begi\\bs a word; 'M' for a character that occurs i\\b the middle of a word; 'E' for a character that e\\bds a word; 'S' for character that occurs as a si\\bgle-character word. Therefore, \\fhi\\bese text with word segme\\btatio\\b i\\bformatio\\b is formulized as follows","1 1 2 2 1 1,..., { , , , }n n n n i\\b T \\b T \\b T \\b T T \\f M E S− − ∈","With respect of classificatio\\b vectors, each character is directly represe\\bted by the characters or character \\b-grams i\\b its surrou\\bdi\\bg, e.g., whether o\\be character appears i\\b its left positio\\b. As a result, the dime\\bsio\\b of the vector is extremely high which make this taggi\\bg approach takes a very lo\\bg trai\\bi\\bg time.","\\fompared to above WBD approach, there seems to be two differe\\bces betwee\\b word bou\\bdary decisio\\b a\\bd character taggi\\bg approach: O\\be is category defi\\bitio\\b (two categories vs. four categories) a\\bd the other is feature represe\\btatio\\b for statistical classificatio\\b (meta-probabilities vs. character prese\\bce).","Actually, the first differe\\bce ca\\b be discarded if we use o\\bly two tags to represe\\bt the character positio\\bs. There are two correspo\\bdi\\bg impleme\\btatio\\bs. O\\be is usi\\bg ‘\\f’ a\\bd ‘M’ tags, where ‘\\f’ mea\\bs the character is a begi\\b\\bi\\bg of a word, otherwise ‘M’. The other is usi\\bg ‘E’ a\\bd ‘M’, where ‘E’ mea\\bs the character is a\\b e\\bd of a word, otherwise ‘M’.","For example, whe\\b we defi\\be that a character is assig\\bed 1 whe\\b a word bou\\bdary is existi\\bg after it, the se\\bte\\bce of “共同 创造 美好 的 新 世纪” ca\\b be represe\\bted as followi\\bg i\\b the WBD approach.","共 0 同 1 创 0 造 1 美 0 好 1 的 1 新 1 世 0 纪 1 Accordi\\bgly, the same represe\\btatio\\b ca\\b be give\\b by usi\\bg character tags of ‘M’ a\\bd ‘E’.","共 M 同 E 创 M 造 E 美 M 好 E 的 E 新 E 世 M 纪 E Mea\\bwhile, whe\\b we defi\\be that a character is assig\\bed 1 whe\\b a word bou\\bdary is existi\\bg","before it, the se\\bte\\bce ca\\b be represe\\bted as followi\\bg i\\b the WBD approach. 728  ","共 1 同 0 创 1 造 0 美 1 好 0 的 1 新 1 世 1 纪 0","Accordi\\bgly, the same represe\\btatio\\b ca\\b be give\\b by usi\\bg character tags of ‘M’ a\\bd ‘\\f’.","共 \\f 同 M 创 \\f 造 M 美 \\f 好 M 的 \\f 新 \\f 世 \\f 纪 M","Therefore, WBD ca\\b certai\\bly be impleme\\bted through character taggi\\bg approach. But there are two differe\\bt impleme\\btatio\\bs. The differe\\bce mai\\bly due to o\\be special case whe\\b the character is a si\\bgle character word, such as ‘的’ a\\bd ‘新’ i\\b the example se\\bte\\bce.","Fortu\\bately, we ca\\b use a special type of features to avoid do both two impleme\\btatio\\bs. The special features are tag tra\\bsitio\\b features which are supposed to i\\bcorporate the si\\bgle character word i\\bformatio\\b. That is to say, we co\\bsider \\bot o\\bly the curre\\bt character but also its previous tag to do the classificatio\\b. For example, whe\\b classifyi\\bg the character ‘新’, we use the character features a\\bd also use the previous tag (the tag of the character ‘的’) i\\b the classificatio\\b features."]},{"title":"3 WBD Impl\\fm\\f\\bt\\ttio\\b with Ch\\tr\\tct\\fr T\\tggi\\bg usi\\bg CRF","paragraphs":["The segme\\btatio\\b task is to classify each character with a tag of '1' or '0', which represe\\bts a word bou\\bdary appears after this character or \\bot. There are several classificatio\\b algorithms which ca\\b be applied to do the segme\\btatio\\b, such as maximum e\\btropy (Xue, 2003), co\\bditio\\bal ra\\bdom field (\\fRF) (Tse\\bg et al., 2005) a\\bd perceptro\\b algorithm (Jia\\bg et al., 2008). We use \\fRF lear\\bi\\bg method as it gives state-of-the-arts performa\\bce for word segme\\btatio\\b a\\bd ca\\b also easily i\\bcorporate differe\\bt types of features (Tse\\bg et al., 2005).","\\fRF is a statistical seque\\bce modeli\\bg framework which aims to compute the followi\\bg probability of a label seque\\bce for a particular of character stri\\bg: 1 1","( | ) exp( ( , , )) ( ) k k t t T kp Y W f y W t","Z Wλ λ − ∈="]},{"title":"\\b \\b","paragraphs":["where { }tY y= is the label seque\\bce for a character stri\\bg. Here, {1, 0}ty ∈ which represe\\bts that whether there is a word bou\\bdary after the curre\\bt character or \\bot. W is the seque\\bce of u\\bsegme\\bted characters. ( )Z W is a \\bormalizatio\\b term. kf is a feature fu\\bctio\\b a\\bd t is the i\\bdex of o\\be character i\\b the stri\\bg.","Specifically, we use a public tool for \\fRF impleme\\btatio\\b: \\fRF++1","by Taku Kudo. The feature template is give\\b i\\b Table 2. The u\\bigram a\\bd bi-gram features follows the character features which are used i\\b WBD approach by (Hua\\bg et al., 2007), i.e., \\fB, B\\f, \\f\\fB, \\fB\\f, a\\bd \\f\\fB. Third type of tra\\bsitio\\b features is i\\bcorporati\\bg the segme\\btatio\\b i\\bformatio\\b from si\\bgle character words. This \\bew type of features has \\bot bee\\b carefully studied i\\b previous work (e.g., i\\b the impleme\\btatio\\b of 2-tag segme\\btatio\\b approach by Zhao et al. (2006)). We believe that usi\\bg this type of features would make the performa\\bce of two tags similar to four tags (i.e., '\\f', 'M', 'E', a\\bd 'S').   T\\tbl\\f 2: Feature template  Type Features Fu\\bctio\\b \\fharacter U\\bigram 0C , 1C The si\\bgle character features \\fharacter Bi-gram 1 0C C− , 0 1C C , 1 2C C The character bi-gram features Tra\\bsitio\\b 1 0 0T C T− , 1 1 0 0C T C T− − , 1 0 0 1T C T C− The character addi\\bg tag tra\\bsitio\\b","features  \\- \\- 1 This tool is available at: http://\\brfpp.sour\\beforge.net/ 729  "]},{"title":"4 Exp\\frim\\f\\bt\\tl Studi\\fs","paragraphs":["I\\b this sectio\\b, we would empirically compare the two impleme\\btatio\\bs: WBD with meta-probability classificatio\\b (Hua\\bg et al., 2007) a\\bd WBD with character taggi\\bg with \\fRF. Furthermore, we would compare the WBD with character taggi\\bg impleme\\bt with traditio\\bal 4-tag character taggi\\bg approach.","We use SIGHAN Bakeoff 2 data (\\tevow, 2006) for experime\\btal studies. The data co\\bsists of four differe\\bt sources: PKU, MSR, \\fityU, a\\bd AS. Their detailed i\\bformatio\\b is give\\b i\\b Table 3. I\\b all experime\\bts, we mai\\bly use F-measure (F1) as the performa\\bce measureme\\bt. F1 is defi\\bed as 1 2 / ( )F PR P R= \\t where P is precisio\\b a\\bd R is recall. A\\bother evaluatio\\b measureme\\bt is out-of-vocabulary (OOV) recall, which is used to evaluate the ability of OOV word recog\\bitio\\b."," T\\tbl\\f 3: \\forpus I\\bformatio\\b ","\\forpus Abbrv. Trai\\bi\\bg Size (Words/Types)","Test Size","(Words/Types) Beiji\\bg U\\biversity PKU 1.1M/55K 104K/13K Microsoft Research MSR 2.37M/88K 107K/13K","\\fity U\\biversity of Ho\\bg Ko\\bg \\fityU 1.46M/69K 41K/9K Academia Si\\bica AS 5.45M/141K 122K/19K","","First of all, WBD approach with differe\\bt impleme\\bts are tested o\\b the four data sets a\\bd the results are show\\b i\\b Table 4. Specifically, \\fRF without tra\\bsitio\\b features mea\\bs usi\\bg the first a\\bd seco\\bd types of features i\\b Table 2 while \\fRF addi\\bg tra\\bsitio\\b features mea\\bs usi\\bg all the three types of features i\\b Table 2. From Table 4, we ca\\b see that WBD with meta-probability (Hua\\bg et al., 2008) appare\\btly performs worse tha\\b WBD with character features. \\fompared the taggi\\bg approach with a\\bd without tra\\bsitio\\b features, we ca\\b fi\\bd that tra\\bsitio\\b features are very effective a\\bd able to make a improveme\\bt of more tha\\b 1% o\\b F1 score i\\b each data set. ","T\\tbl\\f 4: WBD segme\\btatio\\b results with differe\\bt impleme\\btatio\\bs (F1 score) ","Hua\\bg et al. (2008)","\\fRF without tra\\bsitio\\b features","\\fRF addi\\bg","tra\\bsitio\\b features PKU 0.895 0.920 0.937 MSR 0.932 0.951 0.961 \\fityU 0.908 0.932 0.946 AS 0.922 0.942 0.951","","","For further compari\\bg WBD segme\\btatio\\b approach to the state-of-the-arts approaches, we impleme\\bt the 4-tag (i.e., '\\f', 'M', 'E', a\\bd 'S') character taggi\\bg approach with \\fRF usi\\bg the same features show\\b i\\b Table 2. Furthermore, we give some results from most related work Tse\\bg (2005) alo\\bg with the best performa\\bce i\\b Sigha\\b 2005 co\\btest i\\b each data set. All these results are show\\b i\\b Table 5 where WBD with \\fRF mea\\bs WBD approach with \\fRF addi\\bg tra\\bsitio\\b features. \\fompared to 4-tag approach, WBD approach has show\\b comparative performa\\bces (merely a little worse i\\b MSR a\\bd \\fityU data sets). This result is quite differe\\bt from those reported by previous work, e.g., Zhao et al. (2006) which states that 2-tag segme\\btatio\\b performs much worse tha\\b 4-tag segme\\btatio\\b. We thi\\bk this is mai\\bly because we use the tra\\bsitio\\b features which imply the segme\\btatio\\b i\\bformatio\\b of si\\bgle character 730   word. Their impleme\\btatio\\b of 2-tag approach is similar to our WBD impleme\\btatio\\b with \\fRF without tra\\bsitio\\b features. \\fompared to other state-of-the-arts results from Tse\\bg a\\bd Sigha\\b Best, WBD approach with \\fRF provides comparative performa\\bces except i\\b the PKU data set. We thi\\bk the worse performa\\bce i\\b PKU is because the digital character (e.g., 1, 2, 3) e\\bcodi\\bg are differe\\bt i\\b trai\\bi\\bg data a\\bd testi\\bg data (halfwidth vs. fullwidth forms). Tse\\bg a\\bd some Sigha\\b systems co\\bsider the differe\\bces while we do \\bot. We strictly follow the close-test i\\bstructio\\bs. Note that there are some other related work which perhaps prese\\bts better results, e.g., Jia\\bg et al. (2008) a\\bd Zhao et al. (2006). However, they ofte\\b use much more features or some digital a\\bd pu\\bctuatio\\b features. Therefore, the performa\\bce compariso\\b to them becomes quite u\\bfair.","","T\\tbl\\f 5: \\fompariso\\b betwee\\b the performa\\bce of WBD with \\fRF a\\bd state-of-the-arts results (F1 score)","","WBD with \\fRF 4-tag character","taggi\\bg Tse\\bg (2005)","Sigha\\b","Best PKU 0.937 0.938 0.950 0.950 MSR 0.961 0.966 0.964 0.964 \\fityU 0.946 0.951 0.943 0.943 AS 0.951 0.952 0.947 0.952  Table 6 shows the OOV recall results of differe\\bt approaches. Appare\\btly, WBD usi\\bg","character taggi\\bg with \\fRF performs much better tha\\b WBD by Hua\\bg et al. (2008). But it","performs a little worse tha\\b 4-tag character taggi\\bg approach i\\b three data sets. ","T\\tbl\\f 6: OOV recall results of differe\\bt approaches"," WBD by Hua\\bg et al. (2008) WBD with \\fRF 4-tag character taggi\\bg PKU 0.382 0.628 0.596 MSR 0.467 0.615 0.684 \\fityU 0.500 0.692 0.728 AS 0.504 0.652 0.669   Fi\\bally, let's see the time a\\bd space requireme\\bt of WBD approach a\\bd 4-tag character taggi\\bg approach. The trai\\bi\\bg time a\\bd peer memory space is tested i\\b each data set a\\bd the results are give\\b i\\b Table 7. From this table, we ca\\b see that WBD with \\fRF \\beed o\\bly half time a\\bd memory space compared to 4-tag character taggi\\bg. I\\b our work, we impleme\\bt WBD with \\fRF is actually usi\\bg 2-tag character taggi\\bg a\\bd thus the computatio\\bal cost of WBD with \\fRF might be half as much as the cost of 4-tag character taggi\\bg.  ","T\\tbl\\f 7: The time a\\bd space requireme\\bt of WBD approach a\\bd 4-tag character taggi\\bg approach","","WBD with \\fRF 4-tag character taggi\\bg","Trai\\bi\\bg Time Memory Trai\\bi\\bg Time Memory PKU 14mi\\b 0.9G 37mi\\b 1.8G MSR 40mi\\b 1.5G 108mi\\b 3.1G \\fityU 25mi\\b 1.2G 52mi\\b 2.4G AS 150mi\\b 2.6G 350mi\\b 5.7G 731   "]},{"title":"5 Co\\bclusio\\b \\t\\bd Futur\\f Work","paragraphs":["I\\b this work, we a\\balyze the relatio\\bship betwee\\b WBD (Hua\\bg et al., 2007) a\\bd 4-tag character taggi\\bg approach for \\fhi\\bese word segme\\btatio\\b. There are two mai\\b differe\\bces betwee\\b them: O\\be is category defi\\bitio\\b (two categories vs. four categories) a\\bd the other is feature represe\\btatio\\b for statistical classificatio\\b (meta-probabilities vs. character prese\\bce). Experime\\btal results show that character prese\\bce is defi\\bitely more effective tha\\b meta-probabilities. Therefore, we impleme\\bt WBD usi\\bg character taggi\\bg approach (character prese\\bce features) with \\fRF a\\bd fi\\bd that our impleme\\bt ca\\b achieve comparative performa\\bce compared to 4-tag character taggi\\bg approach. This co\\bclusio\\b is quite differe\\bt from most previous work. We thi\\bk this is mai\\bly due to our usage of the tra\\bsitio\\b features which ca\\b imply the segme\\btatio\\b i\\bformatio\\b of si\\bgle character word. Moreover, our WBD impleme\\bt ca\\b save about half trai\\bi\\bg time a\\bd memory space, which makes it more practical for real applicatio\\bs."]},{"title":"R\\ff\\fr\\f\\bc\\fs","paragraphs":["\\fha\\bg, P., M. Galley a\\bd \\f. Ma\\b\\bi\\bg. 2008. Optimizi\\bg \\fhi\\bese Word Segme\\btatio\\b for Machi\\be Tra\\bslatio\\b Performa\\bce. I\\b Pro\\beedings of the 3rd Workshop on Statisti\\bal Ma\\bhine Translation (SMT’08).","Hua\\bg, \\f., P. Šimo\\b, S. Hsieh a\\bd \\t. Prevot. 2007. Rethi\\bki\\bg \\fhi\\bese Word Segme\\btatio\\b: Toke\\bizatio\\b, \\fharacter \\flassificatio\\b, or Wordbreak ide\\btificatio\\b. I\\b Pro\\beedings of the Annual Meeting of the Asso\\biation for Computational Linguisti\\bs (ACL-07).","Hua\\bg, \\f., T. Yo, P. Šimo\\b a\\bd S. Hsieh. 2008. A Realistic a\\bd Robust Model for \\fhi\\bese Word Segme\\btatio\\b. I\\b Pro\\beedings of the Conferen\\be of Computational Linguisti\\bs and Spee\\bh Pro\\bessing (ROCL\\tNG-08).","Jia\\bg, W., \\t. Hua\\bg, Q. \\tiu a\\bd Y. \\tu. 2008. A \\fascaded \\ti\\bear Model for Joi\\bt \\fhi\\bese Word Segme\\btatio\\b a\\bd Part-of-Speech Taggi\\bg. I\\b Pro\\beedings of the Annual Meeting of the Asso\\biation for Computational Linguisti\\bs (ACL-08).","\\tevow, G. 2006. The Third I\\bter\\batio\\bal \\fhi\\bese \\ta\\bguage Processi\\bg Bakeoff: Word Segme\\btatio\\b a\\bd Named E\\btity Recog\\bitio\\b. I\\b Pro\\beedings of the Fifth S\\tGHAN Workshop on Chinese Language Pro\\bessing (S\\tGHAN-06).","Ng, H. a\\bd J. \\tow. 2004. \\fhi\\bese Part-of-speech Taggi\\bg: O\\be-at-a-time or All-at-o\\bce? Word-Based or \\fharacter-based. \\tn Pro\\beedings of the Conferen\\be on Empiri\\bal Methods in Natural Language Pro\\bessing (EMNLP-04).","Su\\b, M., D. Xu, B. Tsou a\\bd H. \\tu. 2006. A\\b I\\btegrated Approach to \\fhi\\bese Word Segme\\btatio\\b a\\bd Part-of-Speech Taggi\\bg. I\\b Pro\\beedings of The \\tnternational Conferen\\be on the Computer Pro\\bessing of Oriental Languages (\\tCCPOL-06).","Tse\\bg, H., P. \\fha\\bg, G. A\\bdrew, D. Jurafsky a\\bd \\f. Ma\\b\\bi\\bg. 2005. A \\fo\\bditio\\bal Ra\\bdom Field Word Segme\\bter for Sigha\\b Bakeoff 2005. I\\b Pro\\beedings of the Fourth S\\tGHAN Workshop on Chinese Language Pro\\bessing (S\\tGHAN-05).","Xue, N. 2003. \\fhi\\bese Word Segme\\btatio\\b as \\fharacter Taggi\\bg. Computational Linguisti\\bs and Chinese Language Pro\\bessing, 8 (1). pages 29-48.","Zhao, H., \\f. Hua\\bg, M. \\ti a\\bd B. \\tu. 2006. Effective Tag Set Selectio\\b i\\b \\fhi\\bese Word Segme\\btatio\\b via \\fo\\bditio\\bal Ra\\bdom Field Modeli\\bg. I\\b Pro\\beedings of the 20th Pa\\bifi\\b Asia Conferen\\be on Language, \\tnformation and Computation (PACL\\tC-06) 732"]}]}