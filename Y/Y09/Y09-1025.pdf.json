{"sections":[{"title":"Layer-Ba\\be\\t De\\fen\\tency Par\\bing* ","paragraphs":["Ping Jian an\\b \\theng\\fing Zong","","Institute of Automation, \\thinese Aca\\bemy of Sciences","No. 95 Zhongguancun East Roa\\b, Beijing, 100190, \\thina","{pjian, c\\fzong}@nlpr.ia.ac.cn Ab\\btract. In this paper, a layer-base\\b projective \\bepen\\bency parsing approach is presente\\b. This novel approach works layer by layer from the bottom up. Insi\\be the layer the \\bepen\\bency graphs are searche\\b exhaustively while between the layers the parser state transfers \\beterministically. Taking the \\bepen\\bency layer as the parsing unit, the propose\\b parser has a lower computational complexity than graph-base\\b mo\\bels which search for a whole \\bepen\\bency graph an\\b alleviates the error propagation that transition-base\\b mo\\bels suffer from to some extent. Furthermore, our parser a\\bopts the se\\fuence labeling mo\\bels to fin\\b the optimal sub-graph of the layer which \\bemonstrates that the se\\fuence labeling techni\\fues are also competent for hierarchical structure analysis tasks. Experimental results in\\bicate that the propose\\b approach offers \\besirable accuracies an\\b especially a fast parsing spee\\b. Keywor\\t\\b: \\bepen\\bency parsing, \\bepen\\bency layer, se\\fuence labeling","\\Z \\Z \\Z * The research work has been partially fun\\be\\b by the Natural Science Foun\\bation of \\thina un\\ber grant No.60736014, 60723005 an\\b 90820303, the National Key Technology R&D Program un\\ber grant No. 2006BAH03B02, the Hi-Tech Research an\\b Development Program (863 Program) of \\thina un\\ber grant No. 2006AA010108-4, an\\b also supporte\\b by the \\thina-Singapore Institute of Digital Me\\bia as well. \\topyright 2009 by Ping Jian an\\b \\theng\\fing Zong"]},{"title":"1 Intro\\tuction","paragraphs":["Graph-base\\b mo\\bels (McDonal\\b et al., 2005; McDonal\\b an\\b Pereira, 2006) an\\b transitionbase\\b mo\\bels (Yama\\ba an\\b Matsumoto, 2003; Nivre an\\b Scholz, 2004) are two \\bominant para\\bigms in the \\bepen\\bency parsing community. McDonal\\b an\\b Nivre (2007) have ma\\be elaborate analyses about the very \\bifferent theoretical properties of these two kin\\bs of mo\\bels an\\b the correspon\\bing experimental behaviors.","Generally, graph-base\\b approaches learn a mo\\bel for scoring possible \\bepen\\bency graphs of an input sentence an\\b apply exhaustive search algorithms to fin\\b the one that maximizes the score. The unit graph-base\\b mo\\bels calculate is the whole sentence (the whole \\bepen\\bency graph) both in training an\\b inference proce\\bures, which results in a cubic computational complexity (in projective case). By contrast, transition-base\\b approaches train a classifier to gree\\bily choose the best parsing action un\\ber the current parser state. They make \\becisions at a configuration which is usually compose\\b by a couple of focus tokens an\\b the parsing contexts. Therefore, these two kin\\bs of \\bepen\\bency parsing metho\\bs represent the two extremes when they seek the best \\bepen\\bency structure of the input sentence. In this paper, we a\\bopt a mo\\berate structural granularity to calculate the parser: a dependency \\b\\tyer.","The \\bepen\\bency layer we mean here is a set of tokens whose \\bepen\\bency \\bepth (the \\bepth of the \\bepen\\bency tree) is at most one. Insi\\be the layer the \\bepen\\bency graphs can be searche\\b exhaustively while between the layers the parser state transfers \\beterministically. On one han\\b, this \\besign will \\becrease the computational cost for searching the whole tree like graph-base\\b mo\\bels \\bo; on the other han\\b, it may alleviate the error propagation resulting from the complete no “search” outsi\\be the parsing configuration in transition-base\\b mo\\bels. 230 23rd Pacific Asia Conference on Language, Information and Computation, pages 230–239 ","It is well known that chunking, which is \\beeme\\b to be a useful an\\b tractable precursor to full parsing, has been successfully han\\ble\\b by se\\fuence labeling techni\\fues (Ku\\bo an\\b Matsumoto, 2001; Sha an\\b Pereira, 2003). Inspire\\b by this scheme, we a\\bopt the globally optimal se\\fuence labeling to search the best \\bepth-one sub-graph in the \\bepen\\bency layer. We believe that the line-type\\b se\\fuential mo\\bels are potent complementarities to the tree-type\\b hierarchical ones or even the latent substitutes.","The experiments show that our layer-base\\b parser yiel\\bs comparable \\bepen\\bency attachment accuracies to the state-of-the-art \\bepen\\bency parsers on both English an\\b \\thinese \\batasets. Especially, it is \\fuite efficient \\bue to the layer-base\\b search an\\b se\\fuence type\\b analysis. The remain\\ber of the paper is organize\\b as follows: Section 2 \\bescribes the \\betails of the algorithm an\\b feature set. Section 3 presents the experimental results. The relate\\b work is \\biscusse\\b in Section 4. \\tonclusion an\\b future work comprise Section 5."]},{"title":"2 Layer-ba\\be\\t Par\\bing A\\f\\froach 2.1 Algorithm\\b","paragraphs":["Wu et al. (2007) \\besigne\\b a neighbor parser to i\\bentify the neighboring parent-chil\\b relations between two consecutive tokens in the input sentence. Following their framework we label the \\bepen\\bency relations in our parsing layer. An example is shown in Figure 1(a). The first an\\b secon\\b columns represent the wor\\bs an\\b part-of-speech (POS) tags respectively. The thir\\b column implies whether the token mo\\bifies its left neighbor (LH, left-hea\\be\\b) or right neighbor (RH, right-hea\\be\\b) or neither (O). The string behin\\b the character “_” in\\bicates the \\bepen\\bency type of the neighboring link."," Wu et al. (2007) employe\\b linear chain con\\bitional ran\\bom fiel\\bs (\\tRFs) as the labeling algorithm to capture the higher or\\ber features an\\b avoi\\b the gree\\by search when labeling with se\\fuential classifiers (\\theng et al., 2006). To prevent the error propagation, they regar\\be\\b the labeling results as features of the subse\\fuent parsing stage instea\\b of re\\bucing the chil\\b wor\\bs. However, this weakens the strength that neighboring parsing can provi\\be. In our approach, besi\\bes the \\tRF-base\\b relation labeler, an a\\b\\bitional tagger is intro\\buce\\b to examine whether a \\bepen\\bent chil\\b can be re\\buce\\b, i.e., whether it has foun\\b its hea\\b an\\b has alrea\\by been a complete sub-tree. The reduce tagger tries to guarantee safe re\\buctions an\\b ensures the parse\\b structures can be forme\\b into a tree after several passes of analysis. In Figure 1(b), the letter “r” in the rightmost column implies that the correspon\\bing token will be re\\buce\\b while others are reserve\\b for the next stage.","The reduce tagger is also traine\\b by linear chain \\tRFs to fulfill the globally optimal property of the layer-base\\b labeling. Specially, when continuous attachments happen in the same \\birection, only the lowest chil\\b token is re\\buce\\b although other tokens in this chain are complete sub-trees after the current labeling. This enables the tokens to change their Figure 1: Example of (a) the se\\fuential neighboring relation labeling, (b) the reduce \\becision labeling. The DT RH_NMOD chair NN O of IN LH_NMOD the DT RH_NMOD conference NN O \\beclare\\b VBD O that DT RH_NOMD \\becision NN O The chair of the conference \\beclare\\b that \\becision (b) The DT RH_NMOD r chair NN O o of IN LH_NMOD o the DT RH_NMOD r conference NN O o \\beclare\\b VBD O o that DT RH_NOMD r \\becision NN O o (a) 231 attachments when the context is refreshe\\b in the next layer. For example, in Figure 2, if the parent wor\\b “of” an\\b the chil\\b wor\\b “conference” are far from each other in the early parsing stage, the chil\\b “conference” may be wrongly attache\\b to the wor\\b “\\beclare\\b” (Figure 2(a)) because long \\bistance interrelations are \\bifficult to be caught in se\\fuence labeling mo\\bels. If the tagger is learne\\b to only re\\buce the lowest chil\\b token each time, i.e., the leftmost wor\\b “the”, the wor\\b “conference” has the chance to a\\bjoin “of” an\\b be attache\\b correctly at last (Figure 2(b))."," As the \\bepen\\bency relations only exist between a\\bjacent tokens an\\b all the survivals will be relabele\\b in the next layer, the \\bepen\\bency \\bepth of the layer is at most one.","Pseu\\bo-co\\be of the parsing algorithm is given as follows: Input s\\bnt\\bn\\t\\b: w1\\f w2\\f ...\\f wn Initializ\\b:","L = {w1\\f w2\\f ...\\f wn};","hav\\b_r\\bdu\\t\\b = false; Start: Whil\\b |L|>1 do b\\bgin","x = ge\\b\\tfea\\bure (L);","y1 = es\\b\\fma\\be\\trela\\b\\fon (model1\\f x);","y2 = es\\b\\fma\\be\\treduce (model2\\f x\\f y1); hav\\b_r\\bdu\\t\\b = sign(coun\\b\\treduce(y2)); if(hav\\b_r\\bdu\\t\\b == \\brue) reduce (L\\f y2);","hav\\b_r\\bdu\\t\\b = false; \\bls\\b br\\bak; \\bnd; \\bnd.","At each processing stage, two functions, e\\ftim\\tte_re\\b\\ttion an\\b e\\ftim\\tte_reduce, are employe\\b to label the se\\fuence L with neighboring \\bepen\\bency relations (y1) an\\b reduce \\becisions (y2). mode\\b1 an\\b mode\\b2 are the pre-traine\\b mo\\bels accor\\bingly. Then the parser re\\buces the “r” tagge\\b tokens an\\b transfers them as the chil\\bren features for the next labeling stage. This process is repeate\\b until there is no token to be re\\buce\\b or the size of L e\\fuals 1. The remaining parsing process for the example sentence in Figure 1 is illustrate\\b step by step in Figure 3 to give a more specific \\bescription of the algorithm."," Together with the initial labeling stage showe\\b in Figure 1(b), the layer-base\\b algorithm spen\\bs five iterations, i.e., five layers to get the final \\bepen\\bency graph of the input sentence. In each layer, the neighboring \\bepen\\bency relations an\\b reduce \\becisions are tra\\be\\b off at \\bifferent chair the - O o of - - LH_NMOD o conference the - LH_PMOD r \\beclare\\b - - O o \\becision that - LH_OBJ r chair the - O o of - conference LH_NMOD r \\beclare\\b - \\becision O o chair the of RH_SUB r \\beclare\\b - \\becision O o \\beclare\\b chair \\becision O o Figure 3: The parsing process following the stage showe\\b in Figure 1(b). The secon\\b column lists the left chil\\b of the current token attache\\b in the latest analysis an\\b the thir\\b column is the right one. of ... the RH_NMOD conference RH_SUB ×××× \\beclare\\b ... of ... conference LH_PMOD √√√√ \\beclare\\b ... (a): (b): Figure 2: Long \\bepen\\bency attaching error in neighboring relation labeling 232  se\\fuence positions to obtain a globally optimal \\bepth-one \\bepen\\bency sub-graph. Between the layers, the pre-built structure is han\\be\\b on through the surviving tokens as well as their chil\\bren. Since \\bepen\\bency relations only exist between two consecutive tokens, the chil\\b appearing in the observation se\\fuence is always the leftmost or rightmost one of the parent token. Previous work base\\b on \\beterministic mo\\bels (Nivre an\\b Scholz, 2004; Hall et al., 2007) has verifie\\b that the information of the chil\\bren at these positions is more useful than that of others.","For training, the parsing process \\bescribe\\b above is repeate\\b on each sentence in the training set to pick up instances on \\bifferent layers.","In a\\b\\bition, the reduce examiner in the two-time labeling algorithm \\bescribe\\b above relies too much on the relation labeling results since it takes the relation labels as features. Therefore, a one-time labeling framework is intro\\buce\\b to be an alteration of the two-time labeling one. Figure 4 shows an example. The strings in the thir\\b column are the integrate\\b symbols of the \\bepen\\bency relation labels an\\b the reduce labels. Because the token whose hea\\b is not foun\\b will not be tagge\\b with “r”, a uni\\fue symbol “O” is enough to express this case. "]},{"title":"2.2 U\\bage of N-be\\bt Searching Re\\bult\\b","paragraphs":["The algorithm \\bescribe\\b above stops the parsing process if there is no reduce label “r” in the current layer. However, sometimes the fact is that the parser \\fuits so early while the tree is not well forme\\b yet at that point. One reason is that the reduce tagger is more prone to assign an “o” than an “r” \\bue to the unbalance\\b training instances. Taking this into account, we use the n-best searching results pro\\buce\\b by the \\tRF-base\\b labeler to amen\\b.","Taking the two-time labeling for example, although there is no “r” assigne\\b in the current stage, the parsing process still continues if there is a relation annotate\\b between the neighbors. The parser will ask for the next best relation label se\\fuence (y1’) an\\b conse\\fuently estimate the reduce labels base\\b on it. But if y1’ is not assigne\\b with relations, the parser will fall back on the initial best labels (y1) an\\b further re\\fuest the next best reduce labels for y1. In our experiments, only 2-best outputs of the labeler are utilize\\b an\\b the experimental results show that it works well."]},{"title":"2.3 Feature De\\bign","paragraphs":["The features use\\b in our labelers are summarize\\b in Table 1. Features of the tokens an\\b chil\\bren are prepare\\b to parameterize the \\bepen\\bency attachment mo\\bel. The relation features are a\\b\\be\\b when tagging the reduce \\becisions in two-time labeling case.","As a typical se\\fuence labeling task, the features chosen for our parser are similar to those a\\bopte\\b in (Sha an\\b Pereira, 2003) for shallow parsing, an\\b a first-or\\ber Markov \\bepen\\bency between labels is consi\\bere\\b.","\\theng et al. (2006) argue\\b that the features an\\b the strategies for parsing in the early stage are \\bifferent from parsing in the upper stages in bottom-up \\beterministic parsing approaches. Because the initial stage parses “wor\\bs” while the upper stages parse “phrases”. For this reason, we improve the propose\\b parser to a mo\\bel-\\bivi\\be\\b one in which one mo\\bel is only for the first parsing layer an\\b the other takes charge of the higher layers. The chil\\bren features liste\\b in Table 1 will not be use\\b to parameterize the first layer mo\\bel. The DT RH_NMOD_r chair NN O of IN LH_NMOD_o the DT RH_NMOD_r conference NN O \\beclare\\b VBD O that DT RH_NOMD_r \\becision NN O Figure 4: Integration of the relation an\\b reduce labels 233 Table 1: Feature set for the neighboring parsing. w is the wor\\b an\\b p is the POS tag of the token. \\bc an\\b rc represent the leftmost an\\b rightmost chil\\b, an\\b the \\bepen\\bency relation type of them uses typ. The relation features like “RH_SUB” are \\benote\\b by re\\b. Digit brackete\\b marks the position of the token where the feature is sample\\b, negative for the left an\\b positive for the right. “” \\benotes the combination.","Tokens w[-3], w[-2], w[-1], w[0], w[1], w[2], w[3] p[-3], p[-2], p[-1], p[0], p[1], p[2], p[3] p[-2] p[-1], p[-1] p[0], p[0] p[1], p[1] p[2], p[-1] p[0] p[1] w[-1] p[-1], w[0] p[0], w[1] p[1]","\\thil\\bren w_\\bc[0], w_rc[0] p_\\bc[-1], p_rc[-1], p_\\bc[0], p_rc[0], p_\\bc[1], p_rc[1] p[-1] p_\\bc[-1], p[-1] p_rc[-1], p[0] p_\\bc[0], p[0] p_rc[0], p[1] p_\\bc[1], p[1] p_rc[1] typ_\\bc[-1], typ_rc[-1], typ_\\bc[0], typ_rc[0], typ_\\bc[1], typ_rc[1] Relations re\\b[-3], re\\b[-2], re\\b[-1], re\\b[0], re\\b[1], re\\b[2], re\\b[3]"]},{"title":"3 Ex\\feriment\\b","paragraphs":["To evaluate the effectiveness an\\b efficiency of the layer-base\\b approach, we con\\bucte\\b \\bepen\\bency parsing experiments on both English an\\b \\thinese \\batasets.","The English experiments were carrie\\b out on the WSJ part of Penn Treebank (Marcus et al., 1993). To match the previous work (Nivre an\\b Scholz, 2004; Hall et al., 2006; McDonal\\b an\\b Pereira, 2006), we use\\b sections 02-21 for training, section 22 for \\bevelopment an\\b section 23 (about 56,684 wor\\bs) for testing. The hea\\b-fin\\bing rules employe\\b by Yama\\ba an\\b Matsumoto (2003) were a\\bopte\\b here to convert the constituent structures to \\bepen\\bency ones an\\b a set of 12 \\bepen\\bency types was utilize\\b as what Hall et al. (2006) \\bi\\b. 1","The POS tags for the \\bevelopment an\\b testing set were automatically assigne\\b by MXPOST (Ratnaparkhi, 1996). A tagging accuracy 97.05% was achieve\\b on the testing set.","The \\thinese experiments were evaluate\\b on the Penn \\thinese Treebank (\\tTB) version 5.0 (Xue et al., 2005). The corpus was split into training, \\bevelopment, an\\b testing \\bata as Duan et al. (2007) \\bi\\b to balance the \\bifferent resources. 16,079 sentences were for training, 803 for \\bevelopment, an\\b 1,905 (about 50,319 wor\\bs) for testing. The hea\\b-fin\\bing rules an\\b \\bepen\\bency type set also followe\\b Hall et al. (2006). 2","Gol\\b stan\\bar\\b POS tags were use\\b. Eight parsers involve\\b in our main experiments are concisely intro\\buce\\b as following: MaltPar\\ber (Nivre et al., 2006): a\\bopts transition-base\\b mo\\bel \\bescribe\\b in (Nivre, 2004).","Here, MaltParser version 1.1 is employe\\b. Yama\\ta03: our implementation of another typical transition-base\\b mo\\bel propose\\b in","(Yama\\ba an\\b Matsumoto, 2003). MSTPar\\ber1: The first-or\\ber para\\bigm of MSTParser3","which implements the graph-base\\b","mo\\bels \\bescribe\\b in (McDonal\\b et al., 2005; McDonal\\b an\\b Pereira, 2006). Version 0.2 is use\\b. MSTPar\\ber2: The secon\\b-or\\ber para\\bigm of MSTParser. Duan07: A probabilistic parsing action mo\\bel propose\\b by Duan et al. (2007) which globally","seeks the optimal action se\\fuence above the transition-base\\b mo\\bel \\bescribe\\b in (Yama\\ba an\\b","Matsumoto, 2003) with beam search algorithm an\\b employs SVMs for learning. LDPar\\ber1: One of the layer-base\\b \\bepen\\bency parsers which labels the relations an\\b","reduce \\becisions at one time. LDPar\\ber2: One of the layer-base\\b \\bepen\\bency parsers which labels the relations an\\b","reduce \\becisions separately. \\Z \\Z \\Z 1 The tree conversion an\\b the arc labeling were implemente\\b by Penn2Malt (http://w3.msi.vxu.se/~nivre/research/Penn2Malt.html) with the “Malt” har\\b-co\\bing setting. 2 It was realize\\b by Penn2Malt with the hea\\b-fin\\bing rules it provi\\be\\b for \\thinese an\\b the har\\b-co\\bing setting. 3 http://www.seas.upenn.e\\bu/~strctlrn/MSTParser/MSTParser.html 234 ","LDP1\\tiv: LDParser1 using \\bivi\\be\\b mo\\bels. In our experiments, the first layer instances in the training set are use\\b to train the first layer mo\\bel while the instances on all of the layers are traine\\b for the higher layer mo\\bel.","The first five mo\\bels are taken as the baselines in the experiments an\\b the last three ones are the propose\\b parsers to be compare\\b.","The results are evaluate\\b by the unlabele\\b attachment score (UAS), labele\\b attachment score (LAS), root accuracy (RA) an\\b complete match (CM) accor\\bing to Nivre an\\b Scholz (2004) except that RA is the proportion of sentences in which the root wor\\b is correctly i\\bentifie\\b. All the metrics are calculate\\b exclu\\bing the punctuations besi\\bes CM. We also present the \\betaile\\b comparisons with the baselines in aspects of the computational complexity an\\b the testing time (the \\tPU time). All the experiments were \\bone on a 32-bit Intel Xeon 2.33GHz processor."]},{"title":"3.1 Engli\\bh Re\\bult\\b","paragraphs":["In the English experiments, all the parsers liste\\b above except Duan07 were compare\\b. For MaltParser, we chose the \\trc-e\\tger algorithm (Nivre, 2004) an\\b the feature set which got the best performance for English in (Hall et al., 2006) (the feature mo\\bel Φ5 in their work). Hall et al. (2006) reporte\\b that the SVMs learning algorithm outperforme\\b memory-base\\b learning (MBL) on this feature set an\\b coul\\b parse faster. It is the same case for \\thinese. Therefore, SVMs were use\\b for both our English an\\b \\thinese experiments. We also compare\\b the split MaltParser which utilizes the efficient C\\b\\t\\f\\fifier\\f Sp\\bitting in the experiment where the POS tag of the next input token was selecte\\b for splitting an\\b the split threshol\\b was 1,000. For Yama\\ba03, the optimal feature context win\\bow size six was chosen an\\b the \\bepen\\bency relation type of the chil\\b tokens was a\\b\\be\\b into the feature set. The mo\\bel was also traine\\b \\bivi\\be\\bly accor\\bing to the POS tag of the left target token. For MSTParser, we trie\\b to repro\\buce the results in (McDonal\\b et al., 2005) an\\b (McDonal\\b an\\b Pereira, 2006) by using the 5-best projective parsing algorithm an\\b not inclu\\bing punctuations in Hamming loss calculation.","\\tonsi\\bering the training cost, only the features that occur more than twice were mo\\bele\\b in LDParser1 an\\b LDP1\\biv. The combination of the chil\\bren features an\\b the combination between the wor\\b an\\b POS features in Table 1 were also omitte\\b.","The final results are compile\\b in Table 2. n \\benotes the length of the input sentence an\\b R is the number of the \\bepen\\bency types appearing in the corpus. The complexity of LDParser is a constant multiple of R2","n2","accor\\bing to the labeling strategies (one or two times labeling). Table 2: Parsing results on the English testing set Parser UAS (%) LAS (%) RA (%) \\tM (%) \\tomplexity Testing time MaltParser MaltParser (split) Yama\\ba03 (split) MSTParser1 MSTParser2 LDParser2 LDParser1 LDP1\\biv 89.68 89.52 89.59 91.03 91.72 88.60 89.16 89.68 88.48 88.19 88.72 89.78 90.46 87.34 87.91 88.43 84.73 84.81 85.11 94.21 94.41 87.96 88.70 89.16 33.69 33.77 34.15 35.72 39.53 31.13 32.62 33.90","O(n)","O(n)","O(n2 )","O(n3 )","O(n3 )","O(R2 n2",")","O(R2 n2",")","O(R2 n2",") 2hour 46min 10min 20sec 20min 8sec 6min 58sec 9min 44sec 1min 18sec 2min 6sec 1min 58sec Among the three propose\\b parsers, LDParser1 outperforms LDParser2 an\\b LDP1\\biv is the best one. \\toncerning the terms for parent-pre\\biction accuracies an\\b sentence complete matching, the LDParsers perform similarly to the transition-base\\b mo\\bels but excee\\b them more in root accuracy. Thanks to the global search over the whole \\bepen\\bency tree the graph-base\\b mo\\bels realize\\b by MSTParser gain the best performance among the competitors on the English \\bataset. However, consi\\bering the parsing efficiency, the LDParsers are \\fuite competitive. They have 235 lower complexity than graph-base\\b mo\\bels an\\b accor\\bingly parse faster than them un\\ber the current implementations in projective case. Transition-base\\b mo\\bels can be implemente\\b in linear time but SVMs which have been prove\\b to achieve the highest performance in parser learning (\\theng et al., 2005; Wang et al., 2006) are not regar\\be\\b as fast algorithms especially when the number of classes is large. The \\tlassifier Splitting heuristic strategy an\\b SVM spee\\bing up metho\\bs (Gol\\bberg an\\b Elha\\ba\\b, 2008) are gol\\b choices to accelerate these implementations. However, even consi\\bering these cases, the parsing spee\\b of the propose\\b LDParsers (up to 480 English wor\\bs per secon\\b) is still \\besirable. Moreover, the spee\\b boosting of SVMs is usually accompanie\\b with the \\becrease of the accuracies or more memory consumption."]},{"title":"3.2 Chine\\be Re\\bult\\b","paragraphs":["We compare\\b LDParser (LDP1\\biv) with MaltParser, Yama\\ba03, MSTParser an\\b Duan07 in the \\thinese experiments. Arc-\\ft\\tnd\\trd algorithm (Nivre, 2004) is a\\bopte\\b in MaltParser because the experiments on the \\bevelopment set reveale\\b that it got a higher performance than the \\trce\\tger one. We also use\\b the best Φ5 feature set in Hall et al. (2006) for \\thinese an\\b the setting of classifier splitting was kept the same as what it was for English. So were the feature mo\\bel an\\b splitting for Yama\\ba03. All the settings for \\thinese experiments of MSTParser were not change\\b from English ones except the 1-best parse set size. The results on the \\bevelopment set in\\bicate\\b that the k-best (k>1) mo\\bels \\bi\\b not surpass the 1-best one remarkably.","Only the features that appear more than once were utilize\\b in LDP1\\biv. Table 3 illustrates the parsing accuracies an\\b spee\\bs. Table 3: Parsing results on the \\thinese testing set. The complexity of Duan07 is O(BKn2","), where B is the beam size of beam-search algorithm an\\b K is the number of action steps in PAPM (Duan et al., 2007) Parser UAS (%) LAS (%) RA (%) \\tM (%) Testing time MaltParser (split) Yama\\ba03 (split) MSTParser1 MSTParser2 Duan07 LDP1\\biv 83.82 83.91 83.39 85.23 84.38 83.44 82.15 82.44 81.75 83.47 82.94 81.89 73.54 70.38 70.76 75.70 71.28 70.29 32.55 31.32 26.30 31.81 32.17 29.66 22min 42sec 27min 10min 28sec 15min 40sec 9hour 57min 1min 53sec The scores in Table 3 imply that LDParser is comparable to first-or\\ber MSTParser for \\thinese parsing an\\b a little weaker than transition-base\\b approaches. The reason is that the transitionbase\\b mo\\bels are more suitable for \\thinese parsing than English because of the richer feature representations. This is also the reason why LDParser catches up with MSTParser on \\thinese \\bataset. The optimal sub-graphs are \\belivere\\b \\beterministically between the layers in LDParser which makes the parser be able to use the \\bepen\\bency graph pre-built. Duan07 which a\\b\\be\\b global search to Yama\\ba03 obtains further better performance.4","","Similar to the experiments for English , LDParser spen\\bs the shortest time. It parses \\thinese sentences about 450 wor\\bs per secon\\b. Moreover, the gaps between the spee\\bs of LDParser an\\b others’ consistently increase. For example, LDP1\\biv is about 8 times faster than MSTParser2 an\\b 15 times faster than split MaltParser while it was both 5 times faster in the English experiments. We think it is partially \\bue to the character enco\\bing mechanism in the Java implementation of MaltParser an\\b MSTParser. Another reason is that the average sentence length of the \\thinese testing set is 26.4 wor\\bs, which is longer than that of English (23.5). Profiting from the layer-base\\b search an\\b se\\fuence type\\b analysis, LDParser han\\bles long \\Z \\Z \\Z 4 The rank of the parsers un\\ber the metrics of parsing accuracies in Table 3 is not \\fuite the same as what was in","Duan et al. (2007). It is because the \\bepen\\bency structures of the \\bata were \\bifferently converte\\b in our","experiments. 236  sentences more efficiently. The global search of the transitions a\\bopte\\b in Duan07 makes the parser the most laggar\\b one."]},{"title":"3.3 A\\t\\titional Re\\bult\\b","paragraphs":["To further stu\\by the character of the layer-base\\b parser, we present two a\\b\\bitional results in this section. Table 4 illustrates the unlabele\\b attachment scores (UAS) of \\bifferent \\bepen\\bency lengths in the English parsing experiment. The \\bepen\\bencies are calculate\\b separately accor\\bing to their length, e\\fual to 1 (the neighboring relations), shorter than 3 or longer than 3. The threshol\\b is chosen in terms of the average \\bepen\\bency length of the corpus which is 3.28. Table 4: Unlabele\\b attachment scores of \\bifferent \\bepen\\bency lengths on the English \\bataset Parser =1 ≤ 3 > 3 MaltParser MSTParser2 LDP1\\biv 94.24 94.67 94.56 93.09 93.59 93.07 73.92 83.23 74.53 The mo\\berate behavior of LDParser in neighboring attachment accuracy \\bemonstrates that the globally optimal se\\fuence labeling is competent for neighboring relation parsing compare\\b with the tree-type\\b hierarchical ones. It even excee\\bs the transition-base\\b parser. For the long \\bepen\\bencies, LDParser also \\boes well than the transition-base\\b one which verifies that the global search insi\\be the parsing layer lightens the error propagation in transition-base\\b mo\\bels.","By keeping partial parsing history through factoring over a\\bjacent e\\bge pairs of the \\bepen\\bency tree, the secon\\b-or\\ber MSTParser performs the best both for short an\\b long \\bepen\\bencies. Making use of the pre-built structures, LDParser achieve\\b a similar performance as MSTParser for short \\bepen\\bencies but gets worse for long ones. It is because LDParser is still a \\beterministic mo\\bel in nature, the error propagation is unavoi\\bable when the \\bepen\\bencies grow long. Another reason is that the higher layers are not mo\\bele\\b separately from each other in the current LDParser an\\b it \\bepresses the \\bisambiguation ability of the mo\\bel for higher layer parsing.","We further examine\\b the behaviors of the parsers on long sentences. 171 sentences with more than 40 wor\\bs in the English testing set were teste\\b an\\b the results are liste\\b in Table 5. The percentages represent the \\becrease of the spee\\b when parsing the long sentences. Taking both the \\bepen\\bency accuracy an\\b root accuracy into account, LDParser is almost the same as MaltParser. Although MSTParser is still the best, the parsing spee\\b has \\broppe\\b a lot (57%) when sentences grow long. \\tontrarily, there is only 8% slower for LDParser to parse these sentences which further implies that the layer-base\\b approach is not sensitive to the length of the sentences an\\b can be more efficient for long sentences than other parsers compare\\b. Table 5: Results for sentences longer than 40 wor\\bs. 8,019 wor\\bs were analyze\\b in the experiment. Parser UAS RA Testing time MaltParser (split) MSTParser2 LDP1\\biv 87.34 89.84 86.58 71.92 94.74 78.95 1min 45sec (17%) 3min 11sec (57%) 18sec (8%)"]},{"title":"4 Relate\\t Work","paragraphs":["Actually, as a bottom-up framework the propose\\b approach is a little similar to the mo\\bel propose\\b by Yama\\ba an\\b Matsumoto (2003) which employe\\b a shift-re\\buce algorithm with multiple passes over the input. The transitions in this mo\\bel are gree\\bily selecte\\b at each parser state, i.e., configuration, from the left to the right \\buring the parsing pass. To remove the gree\\by properties in the transition-base\\b mo\\bels, Johansson an\\b Nugues (2007) an\\b Duan et al. (2007) a\\b\\be\\b a global search over the transition se\\fuences. Our approach also uses multiple passes 237 (layers) to form the \\bepen\\bency tree, an\\b integrates global search like Johansson an\\b Nugues (2007) an\\b Duan et al. (2007) \\bi\\b to fin\\b the optimal combination of \\bepen\\bency relations. However, they score\\b all the graph space as what graph-base\\b mo\\bels \\bo while we focalize\\b it in a parsing layer for the sake of efficiency. In a\\b\\bition, they inherite\\b the hierarchical analyzing mechanism use\\b in transition-base\\b mo\\bels but our parser intro\\buce\\b the se\\fuence labeling techni\\fue.","Some existing work trie\\b to combine the graph-base\\b an\\b transition-base\\b mo\\bels for \\bepen\\bency parsing. Sagae an\\b Lavie (2006) built a graph-base\\b mo\\bel to reparse a \\bepen\\bency graph of which the arc scores were create\\b by the outputs of three transition-base\\b parsers. Hall et al. (2007) followe\\b Sagae’s metho\\bology an\\b blen\\be\\b six transition-base\\b parsers. This kin\\b of combinations can be seen as a structural voting of the graph-base\\b an\\b transition-base\\b mo\\bels. A more effective integration was \\bevelope\\b by Nivre an\\b McDonal\\b (2008) who treate\\b the outputs of one mo\\bel as features for the other. However, all these combination approaches just ma\\be use of the outputs of the component parsers without mo\\bifying their structures or parsing algorithms. It is \\fuite \\bifferent from ours. Our parsing framework inherits the benefits of the graph-base\\b an\\b transition-base\\b mo\\bels with both new structure an\\b algorithm.","\\theng et al. (2006) an\\b Wu et al. (2007) use\\b neighboring \\bepen\\bency attachment taggers to improve the performance of the \\beterministic parser. In \\theng’s metho\\b, neighboring relations were \\beci\\be\\b by gree\\by se\\fuential SVM-base\\b classifiers an\\b the tagging results were \\belivere\\b \\birectly to continue the subse\\fuent parsing. Wu et al. (2007) a\\bopte\\b \\tRFs as the \\bepen\\bency learner an\\b accepte\\b the results of the neighboring parsing as features to increase the original feature set. In their parsers, the neighboring relation tagger was just a preprocessor, while ours works throughout the whole parsing process. We have prove\\b that it can also work well just relying on the neighboring relation taggers for parsing."]},{"title":"5 Conclu\\bion","paragraphs":["In this paper, we propose\\b a novel bottom-up layer-base\\b \\bepen\\bency parsing approach. It takes a \\bepen\\bency layer as the parsing unit an\\b works as a \\biscriminative “graph-base\\b” parser insi\\be the layer while a \\beterministic “transition-base\\b” parser between the layers. The \\tRFbase\\b se\\fuence labeling algorithm is a\\bopte\\b entirely to buil\\b the \\bepen\\bency structures. The experimental results confirm the effectiveness an\\b efficiency of the propose\\b parser an\\b they also prove\\b that the se\\fuence labeling techni\\fues can be goo\\b substitutes to tree-type\\b ones for hierarchical structure analysis tasks.","Efforts are going to be ma\\be to improve the parsing accuracy of the propose\\b parser. More sophisticate\\b labeling mo\\bels for the higher layers an\\b finer feature combinations are in investigating. As only consecutive wor\\bs are consi\\bere\\b, nonprojective case is not yet well \\bealt with in our approach. It is left to be another future work."]},{"title":"Reference\\b","paragraphs":["\\theng, Y., M. Asahara an\\b Y. Matsumoto. 2005. Machine learning-base\\b \\bepen\\bency analyzer for \\thinese. Proceeding\\f of the Intern\\ttion\\t\\b Conference on Chine\\fe Computing, pp. 66-73.","\\theng, Y., M. Asahara an\\b Y Matsumoto. 2006. Multi-lingual \\bepen\\bency parsing at NAIST. Proceeding\\f of the Conference on Comput\\ttion\\t\\b N\\ttur\\t\\b L\\tngu\\tge Le\\trning, pp. 191-195.","Duan, X., J. Zhao an\\b B. Xu. 2007. Probabilistic mo\\bels for action-base\\b \\thinese \\bepen\\bency parsing. Proceeding\\f of the Europe\\tn Conference on M\\tchine Le\\trning \\tnd theEurope\\tn Conference on Princip\\be\\f \\tnd Pr\\tctice of Know\\bedge Di\\fcovery in D\\tt\\tb\\t\\fe\\f, pp. 559-566.","Gol\\bberg, Y. an\\b M. Elha\\ba\\b. 2008. SplitSVM: fast, space-efficient, non-heuristic, polynomial kernel computation for NLP applications. Proceeding\\f of the Annu\\t\\b Meeting of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 237-240. 238 ","Hall, J., J. Nivre an\\b J. Nilsson. 2006. Discriminative classifiers for \\beterministic \\bepen\\bency","parsing. Proceeding\\f of the 21\\ft","Intern\\ttion\\t\\b Conference on Comput\\ttion\\t\\b Lingui\\ftic\\f \\tnd 44th"," Annu\\t\\b Meeting of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 316-323.","Hall, J., J. Nilsson, J. Nivre, G. Eryiğit, B. Megyesi, M. Nilsson an\\b M. Saers. 2007. Single Malt or blen\\be\\b? A stu\\by in multilingual parser optimization. Proceeding\\f of the 2007 Joint Conference on Empiric\\t\\b Method\\f in N\\ttur\\t\\b L\\tngu\\tge Proce\\f\\fing \\tnd Comput\\ttion\\t\\b N\\ttur\\t\\b L\\tngu\\tge Le\\trning, pp. 933-939.","Johansson, R. an\\b P. Nugues. 2007. Incremental \\bepen\\bency parsing using online learning. Proceeding\\f of the 2007 Joint Conference on Empiric\\t\\b Method\\f in N\\ttur\\t\\b L\\tngu\\tge Proce\\f\\fing \\tnd Comput\\ttion\\t\\b N\\ttur\\t\\b L\\tngu\\tge Le\\trning, pp.1134-1138.","Ku\\bo, T. an\\b Y.Matsumoto. 2001. \\thunking with support vector machines. Proceeding\\f of the North Americ\\t Ch\\tpter of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 192-199.","Marcus, M. P., B. Santorini an\\b M. A. Marcinkiewicz. 1993. Buil\\bing a large annotate\\b corpus of English: the Penn Treebank. Comput\\ttion\\t\\b Lingui\\ftic\\f, 19(2): 313-330.","McDonal\\b, R., K. \\trammer an\\b F. Pereira. 2005. Online large-margin training of \\bepen\\bency parsers. Proceeding\\f of the Annu\\t\\b Meeting of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 91-98.","McDonal\\b, R. an\\b F. Pereira. 2006. Online learning of approximate \\bepen\\bency parsing algorithms. Proceeding\\f of the Europe\\tn Ch\\tpter of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 81-88.","McDonal\\b, R. an\\b J. Nivre. 2007. \\tharacterizing the errors of \\bata-\\briven \\bepen\\bency parsing mo\\bels. Proceeding\\f of the 2007 Joint Conference on Empiric\\t\\b Method\\f in N\\ttur\\t\\b L\\tngu\\tge Proce\\f\\fing \\tnd Comput\\ttion\\t\\b N\\ttur\\t\\b L\\tngu\\tge Le\\trning, pp. 122-131.","Nivre, J. 2004. Incrementality in \\beterministic \\bepen\\bency parsing. Proceeding\\f of the Annu\\t\\b Meeting of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp.50-57.","Nivre, J. an\\b M. Scholz. 2004. Deterministic \\bepen\\bency parsing of English text. Proceeding\\f of the Intern\\ttion\\t\\b Conference on Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 64-70.","Nivre, J., J. Hall an\\b J. Nilsson. 2006. MaltParser: a \\bata-\\briven parser-generator for \\bepen\\bency parsing. Proceeding\\f of the Intern\\ttion\\t\\b Conference on L\\tngu\\tge Re\\fource\\f \\tnd Ev\\t\\bu\\ttion\\f, pp. 2216-2219.","Nivre, J. an\\b R. McDonal\\b. 2008. Integrating graph-base\\b an\\b transition-base\\b \\bepen\\bency parsers. Proceeding\\f of the Annu\\t\\b Meeting of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 950-958.","Ratnaparkhi, A. 1996. A maximum entropy mo\\bel for part-of-speech tagging. Proceeding\\f of the Conference on Empiric\\t\\b Method\\f in N\\ttur\\t\\b L\\tngu\\tge Proce\\f\\fing, pp. 133-142.","Sagae, K. an\\b A. Lavie. 2006. Parser combination by reparsing. Proceeding\\f of the North Americ\\t Ch\\tpter of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 129-132.","Sha, F. an\\b F. Pereira. 2003. Shallow parsing with con\\bitional ran\\bom fiel\\bs. Proceeding\\f of the North Americ\\t Ch\\tpter of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp. 213-220.","Wang, M., K. Sagae an\\b T. Mitamura. 2006. A fast, accurate \\beterministic parser for \\thinese. Proceeding\\f of the Annu\\t\\b Meeting of the A\\f\\foci\\ttion for Comput\\ttion\\t\\b Lingui\\ftic\\f, pp.425-432.","Wu, Y., J. Yang an\\b Y. Lee. 2007. Multilingual \\beterministic \\bepen\\bency parsing framework using mo\\bifie\\b finite Newton metho\\b support vector machines. Proceeding\\f of the 2007 Joint Conference on Empiric\\t\\b Method\\f in N\\ttur\\t\\b L\\tngu\\tge Proce\\f\\fing \\tnd Comput\\ttion\\t\\b N\\ttur\\t\\b L\\tngu\\tge Le\\trning, pp. 1175-1181.","Xue, N., F. Xia, F. \\thiou an\\b M. Palmer. 2005. The Penn \\thinese Treebank: phrase structure annotation of a large corpus, N\\ttur\\t\\b L\\tngu\\tge Engineering, C\\tmbridge Univer\\fity Pre\\f\\f, 11(2): 207-238.","Yama\\ba, H. an\\b Y. Matsumoto. 2003. Statistical \\bepen\\bency analysis with support vector machines. Proceeding\\f of the Intern\\ttion\\t\\b Conference on P\\tr\\fing Techno\\bogie\\f, pp. 195-206. 239"]}]}