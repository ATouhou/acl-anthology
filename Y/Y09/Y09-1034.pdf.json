{"sections":[{"title":"","paragraphs":["T\\fe framework of o\\br met\\fods is s\\fown in Fig\\bre 1. T\\fe TST is t\\fe test set\\t t\\fe DEV is t\\fe development set\\t and t\\fe New DEV is t\\fe development set we extract from t\\fe DEV base on some similarity meas\\bres. We b\\bild criteria from t\\fe TST\\t assign different weig\\ft to t\\fe basic \\bnit. T\\fen we \\bse t\\fe weig\\ft to meas\\bre t\\fe sentences in t\\fe DEV by giving eac\\f sentence a score. At last\\t we select t\\fe New DEV based on t\\fe score.","T\\fere are two basic met\\fods to calc\\blate t\\fe similarity. One is based on t\\fe s\\brface feat\\bres\\t s\\bc\\f as t\\fe words and p\\frases; t\\fe ot\\fer is based on some deeper feat\\bres\\t s\\bc\\f as t\\fe sentences str\\bct\\bre. We propose similarity meas\\bres to select t\\fe sentences in t\\fese two ways respectively."," "," Figure\\b1: Framework of selecting development set "]},{"title":"3.1 Phrase-based\\bMe\\thod\\b","paragraphs":["For t\\fe p\\frase-based statistical mac\\fine translation model\\t t\\fe basic translate \\bnit is p\\frase\\t t\\fat is to say\\t a contin\\bo\\bs word seq\\bence (Koe\\fn et al.\\t 2003). It is a nat\\bral idea t\\fat \\bsing t\\fe p\\frase to meas\\bre t\\fe similarity between t\\fe test set and t\\fe development set. If t\\fe sentences w\\fic\\f we selected contain more p\\frases in t\\fe test set\\t t\\fe sentences are more similar to t\\fe test set. T\\fen we try to select sentences from t\\fe development set w\\fic\\f can cover more p\\frases of t\\fe test set corp\\bs.","In t\\fis met\\fod\\t t\\fe p\\frases in test set play a vital role. So\\t firstly we extract all t\\fe p\\frases from t\\fe test set and assign t\\fem different weig\\fts. We take two aspects into acco\\bnt to estimate t\\fe weig\\ft of p\\frase: t\\fe information it contained and t\\fe lengt\\f of t\\fe p\\frase. In information t\\feory (Cover and T\\fomas\\t 1991; Lin\\t 1998)\\t t\\fe information contained in a statement is meas\\bred by t\\fe negative logarit\\fm of t\\fe probability of t\\fe statement. So we s\\fo\\bld estimate t\\fe probability of eac\\f p\\frase first. We class t\\fe p\\frases wit\\f t\\feir lengt\\fs and only \\bse t\\fe p\\frases w\\fic\\f lengt\\f is not longer t\\fan fo\\br in order to avoid t\\fe sparse data problem. We calc\\blate t\\fe probabilities of t\\fe p\\frases based on t\\feir lengt\\fs respectively. For a p\\frase f \\t its lengt\\f f is \\b and t\\fe probability"]},{"title":"( )","paragraphs":["\\t f is estimated by following form\\bla: "]},{"title":"( ) ( ) ( )","paragraphs":["| |i if \\b c\\fu\\bt f \\t f c\\fu\\bt f= ="]},{"title":"∑ ","paragraphs":["(1)  W\\fere t\\fe n\\bmerator"]},{"title":"( )","paragraphs":["c\\fu\\bt f is t\\fe total n\\bmber of p\\frase f appears in t\\fe test set\\t and t\\fe denominator is t\\fe total n\\bmber of t\\fe p\\frases w\\fic\\f lengt\\f is eq\\bal to\\b. T\\fen t\\fe information contained in p\\frase f is calc\\blate by form\\bla (2), 317 23rd Pacific Asia Conference on Language, Information and Computation, pages 317–324  "]},{"title":"( )","paragraphs":["( ) logI f \\t f= − (2)  In t\\fis way\\t we get t\\fe information contained in eac\\f p\\frase. Beca\\bse t\\fe translation model is based on p\\frase\\t t\\fe longer p\\frase will lead to better translation. So we take \\b\\t t\\fe lengt\\f of p\\frase\\t into acco\\bnt. We \\bse t\\fe sq\\bare root of lengt\\f\\t b\\bt not t\\fe lengt\\f directly beca\\bse of t\\fe data smoot\\fing. And t\\fe form\\bla to calc\\blate t\\fe weig\\ft of eac\\f p\\frase is s\\fown below. "]},{"title":"( ) ( )","paragraphs":["w f \\b I f= ⋅ (3) ","Now\\t we get t\\fe weig\\ft for eac\\f p\\frase in t\\fe test set base on t\\fe lengt\\f of t\\fe p\\frase and t\\fe information it contains. T\\fen we can estimate t\\fe weig\\ft of sentence in t\\fe development set by t\\fe p\\frase weig\\ft. For a sentence"]},{"title":"s","paragraphs":["in t\\fe development set\\t if more p\\frases it contains appear in t\\fe test set\\t we assign it a larger score. T\\fe score of t\\fe sentence is calc\\blated by t\\fe following form\\bla: "]},{"title":"( ) ( )","paragraphs":["Sc\\fre s w f="]},{"title":"∑","paragraphs":["(4)","","We extract all t\\fe p\\frases w\\fose lengt\\f is not longer t\\fan fo\\br in sentence s \\t and we add all t\\fe weig\\fts of p\\frases toget\\fer. If a p\\frase does not appear in t\\fe test set\\t t\\fe weig\\ft of t\\fe p\\frase is set to zero. T\\fe sentences are sorted by t\\feir score in a descending order. We c\\foose \\fig\\fer score sentences to combine new development set. We r\\bn MERT on different scale development set to get system parameters. At last\\t t\\fe test set is translated \\bsing t\\fis gro\\bp of parameters\\t and t\\fe res\\blts will be presented in Section 4."]},{"title":"3.2 S\\truc\\ture-based\\bMe\\thod\\b","paragraphs":["T\\fe p\\frase-based met\\fod only \\bses p\\frase\\t a s\\brface feat\\bre\\t to estimate t\\fe weig\\ft of sentences. And it doesn’t contain any deep feat\\bres\\t s\\bc\\f as t\\fe sentence str\\bct\\bre. So we try to \\bse some of deep feat\\bres to \\felp c\\foosing t\\fe development set.","As we do in t\\fe p\\frase-based met\\fod\\t we want to find sentences w\\fic\\f \\fave t\\fe str\\bct\\bres can cover t\\fe great mass of t\\fe test set. So we firstly parse all t\\fe so\\brce lang\\bage sentences (incl\\bding t\\fe development set and t\\fe test set) \\bsing Stanford lexicalized parser version 1.61",". Eac\\f sentence is parsed into a p\\frase-str\\bct\\bre tree. If we \\bse t\\fe entire tree to calc\\blate similarity\\t t\\fe sparse data will become an ins\\bperable problem. So we \\bse t\\fe s\\bbtree of t\\fe p\\frase-str\\bct\\bre tree as t\\fe basic \\bnit. We only \\bse t\\fe str\\bct\\bre information\\t so t\\fe s\\bbtree doesn’t contain any word. T\\fe range of s\\bbtree dept\\f is limited to from two to fo\\br in order to avoid t\\fe sparse data problem. An example of p\\frase-str\\bct\\bre tree and s\\bbtrees is s\\fown in Fig\\bre 2.","We consider two aspects to estimate t\\fe weig\\ft of t\\fe s\\bbtree: dept\\f and information\\t as same as t\\fe p\\frased-based met\\fod. For a s\\bbtree t \\t and its dept\\f is d \\t let’s ass\\bme its probability is"]},{"title":"( )","paragraphs":["\\t t\\t w\\fic\\f is estimated from t\\fe test set\\t and t\\fe information contained in it is","calc\\blate by form\\bla (5).     \\o \\o 1 \\fttp://nlp.stanford.ed\\b/software/lex-parser.s\\ftml 318 Root IP NPNP VP","NPNP VV QP","... NP QP NP","...","..."," (a) \\o \\o \\o \\o (b)","Figure\\b2:\\b(a) a p\\frase-str\\bct\\bre tree; (b) s\\bbtrees w\\fic\\f dept\\fs are 2 contained in t\\fe p\\frase-str\\bct\\bre tree.\\b "]},{"title":"( ) ( )","paragraphs":["logI t \\t t= − (5)  T\\fen t\\fe weig\\ft of eac\\f s\\bbtree in t\\fe test set is calc\\blated by t\\fe following form\\bla. "]},{"title":"( ) ( )","paragraphs":["w t d I t= ⋅ (6)","","Now we can meas\\bre t\\fe weig\\ft of eac\\f sentence in t\\fe development set by all t\\fe s\\bbtrees it contained. If a s\\bbtree does not appear in t\\fe test set\\t t\\fe weig\\ft of t\\fe s\\bbtree is assigned to zero. For a sentence s in t\\fe development set\\t t\\fe score is calc\\blated by following form\\bla: "]},{"title":"( )","paragraphs":["( )Sc\\fre s w t="]},{"title":"∑","paragraphs":["(7) ","T\\fen we sort t\\fe sentences according to t\\feir scores\\t and select t\\fe sentences in a descending order. We r\\bn MERT on different scale of development set\\t and \\bsing t\\fe parameters to translate t\\fe test set. T\\fe experimental res\\blts are presented in Section 4."]},{"title":"4 Experimen\\ts\\band\\bResu\\f\\ts\\b","paragraphs":["We did o\\br experiments on C\\finese to Englis\\f translation task. T\\fe translation model is b\\bilt on NIST corp\\bs\\t \\bsing abo\\bt 300\\t000 sentences to extract p\\frases and b\\bild lang\\bage model. And we \\bse newswire portion of NIST MT05\\t MT06 and MT08 test set as o\\br development set\\t and \\bse CWMT 2008 (C\\fina Works\\fop on Mac\\fine Translation)2","test set as o\\br test set. T\\fe development set \\fas 4103 sentences\\t eac\\f one \\fas fo\\br reference translations; and t\\fe test set \\fas 1006 sentences. We \\bse MOSES3","as o\\br translation system."]},{"title":"4.1 Base\\fine\\b","paragraphs":["Before t\\fe experimental res\\blts are presented\\t we wonder w\\fat kind of performance we will get if we only \\bse a part of t\\fe development set in t\\feir initial order. So we \\bse a part of t\\fe development set in t\\feir initial order\\t and r\\bn MERT on t\\fem to get translation system parameters. After t\\fe MERT finis\\fed\\t we \\bse t\\fe parameters to translate t\\fe test set. And we \\bse t\\fe res\\blts as o\\br baseline. T\\fe experimental res\\blts are presented in Fig\\bre 3.","In Fig\\bre 3\\t t\\fe x axis is t\\fe ratio of t\\fe total n\\bmber of development set sentences divides t\\fe total n\\bmber of t\\fe sentences in t\\fe test set. T\\fe left vertical axis is t\\fe BLEU score (BLEU-4) and t\\fe rig\\ft vertical axis is t\\fe average sentence lengt\\f of t\\fe development. T\\fe sq\\bare point is t\\fe BLEU score on t\\fe test set; t\\fe triangle point is t\\fe average sentence lengt\\f of t\\fe new development set. \\o \\o 2 \\fttp://nlpr-web.ia.ac.cn/cwmt-2008/ 3 \\fttp://www.statmt.org/moses/ 319 ","W\\fen t\\fe scale of t\\fe development set is small\\t t\\fe q\\bantity of sentences \\fas a great infl\\bence on t\\fe performance of SMT system. T\\fe BLEU score of t\\fe translation res\\blts contin\\be rising wit\\f t\\fe increasing of t\\fe development set. W\\fen x is eq\\bal to 0.5\\t i.e. t\\fe development set is only \\falf of t\\fe test set\\t t\\fe BLEU score is only 0.0909. W\\fen t\\fe q\\bantity of t\\fe development set increases to as many as t\\fe test set\\t t\\fe BLEU score rapidly increase to 0.1359. T\\fen t\\fe performance contin\\bes improving w\\fen we add more sentences to t\\fe development set. W\\fen t\\fe development set is t\\free times as many as t\\fe test set\\t t\\fe BLEU \\fas a little decline. W\\fen we add more sentences to t\\fe development set\\t t\\fe performance is relatively stable and only a little c\\fange occ\\brred.","From Fig\\bre 3\\t it is clear t\\fat t\\fe performance of t\\fe translation system is greatly infl\\benced by t\\fe development set w\\fen t\\fe development set is in small scale. However\\t w\\fen t\\fe development set increase to a special scale\\t t\\fe performance will keep stable. Adding more sentences to t\\fe development set will not increase t\\fe performance evidently b\\bt cons\\bme more time on translation and adj\\bsting parameters.  0.05 0.07 0.09 0.11 0.13 0.15 0.17 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 B LEU  s c o r e 202530354045505560 S e n t e n c e  l e n g t \\f ","\\b Figure\\b3: Res\\blts of baseline system  Beca\\bse we select t\\fe sentences in t\\feir initial order wit\\fo\\bt any ot\\fer meas\\bres\\t t\\fe average sentence lengt\\f does not c\\fange greatly. T\\fe val\\be is between 25.10 w\\fen x is eq\\bal to 4.0 and 28.03 w\\fen x is eq\\bal to 1.0."]},{"title":"4.2 Resu\\f\\ts\\bof\\bPhrase-based\\bMe\\thod\\b","paragraphs":["We select development set \\bsing two met\\fods we proposed above\\t and r\\bn MERT on t\\fem to get a gro\\bp of optimal parameters. T\\fen we translate t\\fe test set \\bsing t\\fese parameters. T\\fe experimental res\\blts are s\\fown in Table 1. T\\fe first row is t\\fe ratio w\\fic\\f t\\fe total n\\bmber of development set divides to t\\fe total n\\bmber of test set. T\\fe second row is t\\fe res\\blts of baseline system\\t selecting sentences in t\\feir initial order. T\\fe t\\fird row is t\\fe res\\blts of p\\frase-based met\\fod; and t\\fe last row is t\\fe res\\blts of str\\bct\\bre-based met\\fod. T\\fe last col\\bmn is t\\fe average val\\be of eac\\f experiment.","T\\fe average sentence lengt\\f is s\\fown in Table 2. T\\fe first row is as same as t\\fe Table 1. And t\\fe last t\\free rows are t\\fe average sentence lengt\\f of eac\\f development set. We also present t\\fe experimental res\\blts of p\\frase-based met\\fods in Fig\\bre 4. T\\fe \\forizontal axis and vertical axis are as same as Fig\\bre 3. T\\fe sq\\bare point is t\\fe BLEU score of t\\fe test set; and t\\fe triangle point is t\\fe average lengt\\f of t\\fe development set sentences. T\\fe recall ratio of t\\fe p\\frase is presented in Table 3. T\\fe first row is as same as Table 1; t\\fe second to t\\fe fift\\f rows are t\\fe recall ratio of p\\fases wit\\f different lengt\\f; and t\\fe last row is t\\fe average val\\be of fo\\br kinds of recall ratio. 320  Tab\\fe\\b1: BLEU score of experiment res\\blts Ratio 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Avg. Baseline 0.0909 0.1359 0.1380 0.1433 0.1520 0.1510 0.1541 0.1530 0.1398 P\\frase 0.1445 0.1519 0.1538 0.1572 0.1546 0.1545 0.1556 0.1535 0.1532\\b Str\\bct\\bre 0.1397 0.1536 0.1518 0.1523 0.1587 0.1550 0.1576 0.1554 0.1530  Tab\\fe\\b2: T\\fe average lengt\\f of t\\fe development set sentences Ratio 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Baseline 27.83 28.03 26.03 26.34 25.80 25.38 25.53 25.10 P\\frase 50.27 43.46 39.22 35.83 32.88 30.30 27.88 25.50 Str\\bct\\bre 49.69 43.30 39.08 35.65 32.66 30.11 27.79 25.45  Tab\\fe\\b3: T\\fe recall ratio of t\\fe p\\frase-based met\\fod Ratio 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Lengt\\f=1 0.687 0.821 0.890 0.931 0.960 0.979 0.992 1.000 Lengt\\f=2 0.545 0.728 0.825 0.898 0.940 0.973 0.993 1.000 Lengt\\f=3 0.528 0.718 0.839 0.914 0.974 0.995 1.000 1.000 Lengt\\f=4 0.646 0.826 0.910 0.951 0.993 1.000 1.000 1.000 Avg. 0.601 0.773 0.866 0.923 0.967 0.987 0.996 1.000  0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 B LEU  s c o r e 20 25 30 35 40 45 50 55 S e n t e n c e  l e n g t \\f \\b Figure\\b4: Res\\blts of p\\frase-based met\\fod"," From Fig\\bre 4\\t it is clear t\\fat \\bsing t\\fe p\\frase-based met\\fod\\t t\\fe performance of system get a great en\\fancement\\t especially w\\fen t\\fe development set is in small scale. W\\fen x is eq\\bal to 0.5\\t t\\fe BLEU score is 0.1445\\t t\\fere is 5.36% BLEU score improvement compare to t\\fe baseline met\\fod. And wit\\f t\\fe increasing of development set\\t t\\fe performance contin\\bes improving. It reac\\fes t\\fe maxim\\bm val\\be 0.1572 w\\fen x is eq\\bal to 2.0\\t wit\\f average p\\frase recall of 92.3%. Now\\t most of t\\fe common p\\frases \\fave been covered by t\\fe new development set. T\\fen t\\fe BLEU score \\fas a litter drop b\\bt almost keep stable. From now on\\t adding more sentences to t\\fe development will give little increase for t\\fe recall. Comparing to t\\fe baseline met\\fod\\t t\\fe p\\frase-based met\\fod reac\\fes t\\fe maxim\\bm val\\be more q\\bickly\\t \\bsing only two times as many as test set sentences. B\\bt t\\fe baseline met\\fod \\bses 3.5 times as many as t\\fe test set. T\\fis will cons\\bme more time on training process. T\\fe baseline met\\fod takes 59 min for eac\\f iteration in t\\fe MERT process to reac\\f t\\fe best performance\\t w\\file t\\fe p\\frased-based 321  met\\fod only takes 45 min\\t saving time 23.7%. W\\fen \\bse t\\fe same q\\bantity of development set\\t t\\fe performance of p\\frase-based met\\fod is always \\fig\\fer t\\fan t\\fe baseline system. T\\fe average score of p\\frase-based met\\fod is 0.1532\\t and t\\fe average score of baseline system is 0.1398. T\\fe former met\\fod is 1.34% BLEU score \\fig\\fer t\\fan t\\fe latter met\\fod.","In t\\fis met\\fod\\t t\\fe average lengt\\f of t\\fe development set sentence decreases monotonically. It drops from 50.27 to 25.50 wit\\f t\\fe increasing of development sentences. O\\br met\\fod is apt to c\\foose longer sentences. It is easy to \\bnderstand t\\fat longer sentence contains more p\\frases\\t and easy to get \\fig\\fer score.",""]},{"title":"4.3 Resu\\f\\ts\\bof\\bS\\truc\\ture-based\\bMe\\thod\\b","paragraphs":["T\\fe str\\bct\\bre-based met\\fod experiment res\\blts are s\\fown in Fig\\bre 5 and t\\fe recall ratio are presented in Table 4. From Fig\\bre 5\\t it is clear t\\fat t\\fe res\\blts \\fave similar trend wit\\f t\\fe p\\frase-based met\\fod b\\bt not so stable. T\\fe system performs better t\\fan t\\fe baseline w\\fen t\\fe q\\bantity is small. W\\fen x is 0.5\\t t\\fe BLEU score is 0.1397\\t 4.88% BLEU score \\fig\\fer t\\fan t\\fe baseline system. T\\fe corresponding recall ratio is 66.2%\\t less t\\fan two t\\fird of t\\fe common s\\bbtree is been covered. And it reac\\fes t\\fe maxim\\bm val\\be 0.1587 w\\fen x is eq\\bal to 2.5\\t 0.67% BLEU score \\fig\\fer t\\fan t\\fe baseline. And t\\fe recall ratio rises to 94.7%. It takes 49 min for eac\\f iteration\\t saving time 16.9%. T\\fe average score of t\\fe str\\bct\\bre-based met\\fod is 0.1530\\t 1.32% \\fig\\fer t\\fan t\\fe baseline met\\fod. B\\bt t\\fe BLEU score’s fl\\bct\\bation range of t\\fis met\\fod is larger t\\fan t\\fe p\\frase-based met\\fod. T\\fis makes t\\fe average score of t\\fe str\\bct\\bre-based met\\fod is 0.02% lower t\\fan t\\fe p\\frase-based met\\fod."," Tab\\fe\\b4: T\\fe recall ratio of t\\fe str\\bct\\bre-based met\\fod Ratio 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Dept\\f=2 0.750 0.864 0.910 0.937 0.966 0.976 0.994 0.999 Dept\\f=3 0.642 0.785 0.861 0.906 0.939 0.971 0.992 1.000 Dept\\f=4 0.593 0.745 0.840 0.899 0.937 0.973 0.991 0.999 Avg. 0.662 0.798 0.870 0.914 0.947 0.973 0.992 0.999  0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 B LEU  s c o r e 20 25 30 35 40 45 50 55 S e n t e n c e  l e n g t \\f  Figure\\b5: Res\\blts of str\\bct\\bre-based met\\fod"," Comparing to t\\fe p\\frase-based met\\fod\\t t\\fe str\\bct\\bre-based met\\fod is not so stable. T\\fis may beca\\bse t\\fe str\\bct\\bre-based met\\fod is calc\\blated based on t\\fe parsing res\\blts. And it is well known t\\fat t\\fe syntactic analysis is a very diffic\\blt problem\\t and t\\fe precision of parser is not \\fig\\f. T\\fe F1 score (\\farmonic mean of precision and recall) of t\\fe parser is only abo\\bt 80% 322 (Levy and Manning\\t 2003). So t\\fere are many errors in t\\fe parsing res\\blts. T\\fis make t\\fe str\\bct\\bre-based met\\fod is not as stable as t\\fe p\\frase-based met\\fod.","T\\fe str\\bct\\bre-based met\\fod is also prior to t\\fe longer sentences. Beca\\bse longer sentence contains more s\\bbtrees\\t and t\\fis makes t\\fe sentence get a \\fig\\fer score. In Fig\\bre 5\\t t\\fe average sentence lengt\\f decreases monotonically\\t drops from 49.69 to 25.45\\t it is almost as same as t\\fe p\\frase-based met\\fod."]},{"title":"5 Conc\\fusions\\b","paragraphs":["From t\\fe experimental res\\blts\\t we can get some \\bsef\\bl concl\\bsions:","First\\t t\\fe scale of development set is not t\\fe larger t\\fe better. T\\fe BLEU score on t\\fe test set will rapidly increase wit\\f t\\fe increasing of development set scale. However\\t t\\fe increase will become slower if we contin\\be adding sentences to t\\fe development set. And t\\fe performance keeps stable w\\fen t\\fe development set is adeq\\bate\\t as s\\fown in all experiments. W\\fen we add more sentences to t\\fe development set\\t t\\fe BLEU score will not contin\\be increasing b\\bt cons\\bming more training time. According to t\\fe experimental res\\blts\\t we can get optimal parameters w\\fen t\\fe development set is at least two times as many as t\\fe test set.","Second\\t t\\fe met\\fods we proposed to select development sentences are effective. On eac\\f scale of development set\\t t\\fe parameters trained on it will get better performance t\\fan t\\fe baseline system. Especially w\\fen t\\fe development set is less t\\fan two times as many as t\\fe test set. Comparing t\\fe baseline and t\\fe p\\frase-based metric\\t w\\fen t\\fe development set is 0.5\\t 1.0\\t 1.5 and 2.0 times as many as t\\fe test set\\t t\\fe BLEU score improve 58.9%\\t 11.7%\\t 11.4% and 9.6% respectively. After t\\fe development set is twice larger t\\fan t\\fe test set\\t t\\fe scores are still \\fig\\fer t\\fan t\\fe baseline. T\\fe str\\bct\\bre-based met\\fod \\fas t\\fe same trend wit\\f t\\fe p\\frased based met\\fod.","Finally\\t t\\fe p\\frase-based met\\fod is powerf\\bl t\\fan t\\fe str\\bct\\bre-based met\\fod. Two met\\fods \\fave t\\fe same trend\\t b\\bt t\\fe p\\frase-based met\\fod is more stable. T\\fe str\\bct\\bre-based met\\fod is infl\\benced by t\\fe parser errors. From t\\fe res\\blts\\t t\\fe average BLEU score on p\\frase-based met\\fod is 0.1532\\t w\\file t\\fe average score on str\\bct\\bre-based met\\fod is 0.1530. T\\fe p\\frase-based met\\fod is a little \\fig\\fer t\\fan t\\fe str\\bct\\bre-based met\\fod. So bot\\f met\\fods are powerf\\bl t\\fan t\\fe baseline system\\t b\\bt t\\fe p\\frase-based met\\fod is more effective."]},{"title":"References\\b","paragraphs":["Bergsma\\t S. and G. Kondrak. 2007. Alignment-Based Discriminative String Similarity. Pr\\fceedi\\bgs \\ff the 45th A\\b\\bual Meeti\\bg \\ff the Ass\\fciati\\f\\b \\ff C\\fm\\tutati\\f\\bal Li\\bguistics\\t pp. 656-663\\t Prag\\be\\t Czec\\f Rep\\bblic.","B\\bdanitsky\\t A. and G. Hirst. 2006. Eval\\bating WordNet-based Meas\\bres of Lexical Semantic Relatedness. C\\fm\\tutati\\f\\bal Li\\bguistics\\t 32(1)\\t 13-47.","Cover\\t T. M. and J. A. T\\fomas. 1991. Eleme\\bts \\ff I\\bf\\frmati\\f\\b The\\fry. New York: Wiley.","Da\\bmé III\\t H. 2007. Fr\\bstratingly Easy Domain Adaptation. Pr\\fc. \\ff the 45th A\\b\\bual Meeti\\bg \\ff the Ass\\fciati\\f\\b \\ff C\\fm\\tutati\\f\\bal Li\\bguistics\\t pp. 256-263.","Koe\\fn\\t P.\\t F. J. Oc\\f and D. Marc\\b\\t 2003. Statistical P\\frase-Based Translation. Pr\\fceedi\\bgs \\ff NAACL\\t pp. 48-54\\t Edmonton\\t Canada.","Levy\\t R. and C. D. Manning. 2003. Is it Harder to Parse C\\finese\\t or t\\fe C\\finese Treebank? Pr\\fceedi\\bgs \\ff the 41st A\\b\\bual Meeti\\bg \\ff the Ass\\fciati\\f\\b f\\fr C\\fm\\tutati\\f\\bal Li\\bguistics\\t pp. 439-446\\t Sapporo\\t Japan","Li\\t Y.\\t D. McLean\\t Z. A. Bandar\\t J. D. O’S\\fea and K. Crockett. 2006. Sentence Similarity Based on Semantic Nets and Corp\\bs Statistics. IEEE Tra\\bsacti\\f\\bs \\f\\b K\\b\\fwledge a\\bd Data E\\bgi\\beeri\\bg\\t 18(8)\\t 1138-1150. 323 ","Lin\\t D.\\t 1998. An Information-T\\feoretic Definition of Similarity. Pr\\fceedi\\bgs \\ff the 5th I\\bter\\bati\\f\\bal C\\f\\bfere\\bce \\f\\b Machi\\be Lear\\bi\\bg\\t pp. 296-304\\t Madison\\t Wisconsin.","Matso\\bkas\\t S.\\t A.-V. I. Rosti and B. Z\\fang. 2009. Discriminative Corp\\bs Weig\\ft Estimation for Mac\\fine Translation. Pr\\fceedi\\bgs \\ff the 2009 C\\f\\bfere\\bce \\f\\b Em\\tirical Meth\\fds i\\b Natural La\\bguage Pr\\fcessi\\bg\\t pp. 708-717\\t Singapore\\t Association for Comp\\btational Ling\\bistics.","Oc\\f\\t F. J. 2003. Minim\\bm Error Rate Training in Statistical Mac\\fine Translation. Pr\\fceedi\\bgs \\ff the 41st A\\b\\bual Meeti\\bg \\ff the Ass\\fciati\\f\\b f\\fr C\\fm\\tutati\\f\\bal Li\\bguistics\\t pp. 160-167\\t Sapporo\\t Japan.","W\\b\\t H.\\t H. Wang and C. Zong\\t 2008. Domain Adaptation for Statistical Mac\\fine Translation wit\\f Domain Dictionary and Monoling\\bal Corpora. Pr\\fceedi\\bgs \\ff the 22\\bd I\\bter\\bati\\f\\bal C\\f\\bfere\\bce \\f\\b C\\fm\\tutati\\f\\bal Li\\bguistics\\t pp. 993-1000\\t Manc\\fester\\t UK.","Yas\\bda\\t K.\\t R. Z\\fang\\t H. Yamamoto and E. S\\bmita. 2008. Met\\fod of Selecting Training Data to B\\bild a Compact and Efficient Translation Model. Pr\\fceedi\\bgs \\ff the Third I\\bter\\bati\\f\\bal J\\fi\\bt C\\f\\bfere\\bce \\f\\b Natural La\\bguage Pr\\fcessi\\bg\\t pp. 655-660\\t Hyderabad\\t India. 324"]}]}