{"sections":[{"title":"Review C\\b\\tssifi\\f\\ttion Using Sem\\tnti\\f Fe\\ttures \\tnd Run-Time Weighting ","paragraphs":["Chung-ch\\b\\tHuanga","\\f\\tMeng-ch\\bech\\tLeeb \\f\\tZhe-nan\\tL\\bnb","\\f\\tand\\tJason\\tS.\\tChangb","\\t \\t","a Inst\\btute\\tof\\tInformat\\bon\\tSystems\\tand\\tAppl\\bcat\\bons\\f\\tNat\\bonal\\t Ts\\bng\\tHua\\tUn\\bvers\\bty\\f\\tHs\\bnChu\\f\\tTa\\bwan\\t300\\f\\tR.O.C.\\t","u901571@gma\\bl.com\\t b Department\\tof\\tComputer\\tSc\\bence\\f\\tNat\\bonal\\t","Ts\\bng\\tHua\\tUn\\bvers\\bty\\f\\tHs\\bnChu\\f\\tTa\\bwan\\t300\\f\\tR.O.C.\\t {\\bamrabb\\bt37\\f\\trexk\\bmta\\f\\tjason.jschang}@gma\\bl.com\\t Abstr\\t\\ft.\\tWe\\t\\bntroduce\\ta\\tmethod\\tfor\\tlearn\\bng\\tto\\tass\\bgn\\tsu\\btable\\tsent\\bment\\trat\\bngs\\tto\\trev\\bew\\t art\\bcles.\\tIn\\tour\\tapproach\\f\\trev\\bews\\tare\\ttransformed\\t\\bnto\\tcollect\\bons\\tof\\tn-gram\\tand\\tsemant\\bc\\t word\\t class\\t features\\t a\\bmed\\t at\\t max\\bm\\bz\\bng\\t the\\t probab\\bl\\bty\\t of\\t class\\bfy\\bng\\t them\\t \\bnto\\t accurate\\t rat\\bngs.\\t The\\t method\\t \\bnvolves\\t automat\\bcally\\t segment\\bng\\t rev\\bew\\t art\\bcles\\t \\bnto\\t sentences\\t and\\t automat\\bcally\\t est\\bmat\\bng\\t assoc\\bat\\bons\\t between\\t features\\t and\\t sent\\bment\\t rat\\bngs\\t v\\ba\\t mach\\bne\\t learn\\bng\\t techn\\bques.\\t At\\t run-t\\bme\\f\\t a\\t s\\bmple\\t we\\bght\\bng\\t strategy\\t \\bs\\t performed\\t to\\t g\\bve\\t extra\\t we\\bghts\\t to\\t features\\t \\bn\\t potent\\bal\\t evaluat\\bve\\t sentences\\t (e.g.\\f\\t the\\t f\\brst\\f\\t the\\t last\\t sentences\\t and\\t sentences\\t w\\bth\\t adverbs)\\t from\\t others.\\t Exper\\bments\\t show\\t that\\t word\\t class\\t \\bnformat\\bon\\t allev\\bates\\tdata\\tsparseness\\tproblem\\tfac\\bng\\th\\bgher-level\\tn-grams\\t(e.g.\\f\\tb\\bgrams\\tand\\ttr\\bgrams)\\t and\\t that\\t our\\t model\\t us\\bng\\tboth\\t tra\\bn\\bng-t\\bme\\t n-gram\\t and\\t semant\\bc\\t features\\tand\\t run-t\\bme\\t we\\bght\\bng\\tmechan\\bsm\\toutperforms\\ta\\tstrong\\tbasel\\bne\\tw\\bth\\tsurface\\tn-gram\\tfeatures\\tby\\t2.5%\\t relat\\bvely.\\t Keywords: sent\\bment\\f\\t semant\\bc\\t or\\bentat\\bons\\f\\t class\\bf\\bcat\\bon\\f\\t sent\\bment\\t rat\\bngs\\f\\t mach\\bne\\t learn\\bng\\ttechn\\bques.\\t"]},{"title":"1 Introdu\\ftion","paragraphs":["W\\bth\\t the\\t access\\bb\\bl\\bty\\t to\\t the\\t Internet\\t \\bn\\t recent\\t years\\f\\t any\\t Web\\t user\\t can\\t eas\\bly\\t be\\t an\\t art\\bcle\\t reader\\tor\\ta\\tcontent\\tprov\\bder.\\tWeb\\tcontents\\tcan\\tbe\\tcoarsely\\tcategor\\bzed\\t\\bnto\\ttwo\\tgroups:\\tones\\t on\\tknowledge\\tand\\tones\\texper\\bence.\\tKnowledge\\tof\\tany\\td\\bsc\\bpl\\bne\\t\\bs\\tprov\\bded\\ton\\ton-l\\bne\\tforums\\t or\\ton\\tcerta\\bn\\tWeb\\tpages\\t(e.g.\\f\\tWIKIPEDIA1",")\\tby\\tthe\\tcollaborat\\bve\\teffort\\tof\\ta\\tnumber\\tof\\tdoma\\bn\\t experts.\\tOn\\tthe\\tother\\thand\\f\\tmore\\tand\\tmore\\tInternet\\tusers\\tauthor\\tthe\\br\\tpersonal\\texper\\bences\\ton\\t the\\t Web.\\t Exper\\bences\\t of\\t us\\bng\\t a\\t h\\bgh-tech\\t product\\f\\t d\\bn\\bng\\t \\bn\\t a\\t restaurant\\f\\t watch\\bng\\t a\\t mov\\be\\t and\\tso\\ton\\tare\\tdocumented.\\tThese\\tpubl\\bcly-ava\\blable\\tremarks\\tare\\tespec\\bally\\tvaluable\\t\\bn\\tterms\\tof\\t market\\bng\\tand\\trecommendat\\bon.\\t","Take\\tYahoo!奇摩生活+","2","\\t(Yahoo!\\tK\\bmo\\tL\\bfe\\tStyle)\\tfor\\texample.\\tIt\\t\\bs\\ta\\tplatform\\twhere\\tWeb\\t users\\t can\\t author\\t the\\br\\t exper\\bences\\t w\\bth\\t or\\t op\\bn\\bons\\t toward\\t the\\t serv\\bce-prov\\bd\\bng\\t bus\\bnesses\\t \\bnclud\\bng\\trestaurants\\f\\thotels\\f\\tamusement\\tparks\\tand\\tetc.\\tF\\bgure\\t1\\tshows\\ta\\trestaurant\\trev\\bew\\ton\\t Yahoo!\\tK\\bmo\\tL\\bfe\\tStyle.\\tIn\\tth\\bs\\tappl\\bcat\\bon\\f\\tthe\\toverall\\tevaluat\\bon\\ton\\ta\\tserv\\bce\\tprov\\bder\\t\\bs\\trated\\t v\\ba\\ta\\tnumber\\tof\\tstars.\\tMore\\tstars\\f\\tmore\\tpos\\bt\\bve\\tthe\\tevaluat\\bon.\\t","We\\t present\\t a\\t model\\t that\\t automat\\bcally\\t learns\\t to\\t rate\\t rev\\bew\\t art\\bcles\\t accord\\bng\\t to\\t the\\br\\t semant\\bc\\t or\\bentat\\bons.\\t Rev\\bews\\t are\\t ranked\\t from\\t one\\t to\\t f\\bve\\t w\\bth\\t larger\\t \\bntegers\\t mean\\bng\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\M\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t \\t\\tCopyr\\bght\\t2009\\tby\\tChung-ch\\b\\tHuang\\f\\tMeng-ch\\bech\\tLee\\f\\tZhe-nan\\tL\\bn\\f\\tand\\tJason\\tS.\\tChang\\t 1 \\thttp://en.w\\bk\\bped\\ba.org/w\\bk\\b/W\\bk\\b\\t 2 \\thttp://tw.l\\bfestyle.yahoo.com/\\t 200 23rd Pacific Asia Conference on Language, Information and Computation, pages 200–209 \\t rev\\bewers’\\t att\\btude\\t toward\\t the\\t serv\\bce\\t \\bs\\t more\\t pos\\bt\\bve\\t and\\t w\\bth\\t smaller\\t ones\\t mean\\bng\\t rev\\bewers’\\t exper\\bence\\t w\\bth\\t the\\t enterpr\\bse\\t \\bs\\t more\\t negat\\bve.\\t Dur\\bng\\t tra\\bn\\bng\\f\\t our\\t model\\t leverages\\tmach\\bne\\tlearn\\bng\\ttechn\\bques\\t(e.g.\\f\\tmax\\bmum\\tentropy\\tor\\tcond\\bt\\bonal\\trandom\\tf\\belds)\\tto\\t est\\bmate\\tassoc\\bat\\bons\\tbetween\\tvar\\bous\\trat\\bngs\\t(\\b.e.\\f\\tone\\tto\\tf\\bve)\\tand\\tfeatures\\f\\t\\bnclud\\bng\\tsurface\\t n-gram\\tfeatures\\tand\\tsemant\\bc\\tfeatures.\\tSemant\\bc\\tclasses\\tof\\twords\\tare\\texplo\\bted\\t\\bn\\tour\\tmodel\\t\\bn\\t order\\t to\\t allev\\bate\\t data\\t sparseness\\t problem\\f\\t wh\\bch\\t \\bs\\t a\\t ser\\bous\\t problem\\t \\bf\\t n-grams\\t of\\t h\\bgher\\t degree\\t (e.g.\\f\\t b\\bgrams\\t and\\t tr\\bgrams)\\t are\\t employed.\\t We\\t descr\\bbe\\t our\\t tra\\bn\\bng\\t process\\t \\bn\\t more\\t deta\\bl\\t\\bn\\tSect\\bon\\t3.\\t","At\\t run-t\\bme\\f\\t our\\t model\\t f\\brstly\\t transforms\\t a\\t rev\\bew\\t art\\bcle\\t \\bnto\\t a\\t collect\\bon\\t of\\t features\\t and\\t then\\t ranks\\t the\\t rev\\bew\\t based\\t on\\t the\\t features\\t and\\t the\\t tra\\bned\\t mach\\bne\\t learn\\bng\\t model.\\t Add\\bt\\bonally\\f\\tfeatures\\tmay\\tbe\\twe\\bghed\\taccord\\bng\\tto\\tsome\\tcharacter\\bst\\bcs\\tsuch\\tas\\twhether\\tor\\tnot\\t the\\t features\\t appear\\t \\bn\\t the\\t f\\brst\\t or\\t last\\t sentence\\t of\\t the\\t art\\bcle\\t and\\t whether\\t or\\t not\\t the\\t features\\t occur\\t \\bn\\t the\\t sentence\\t conta\\bn\\bng\\t adverbs\\t wh\\bch\\t are\\t usually\\t \\bnd\\bcators\\t of\\t the\\t ex\\bstence\\t of\\t statements\\texpress\\bng\\tsent\\bments\\tand\\toften\\t\\bntens\\bfy\\tthe\\tpos\\bt\\bve/negat\\bve\\tsemant\\bc\\tor\\bentat\\bon.\\t For\\texample\\f\\tthe\\tadverb\\t“很”\\t(very)\\t\\bn\\tthe\\tsentence\\t“人氣 很 高”\\t(\\bt\\t\\bs\\tvery\\tpopular)\\tmeans\\t that\\tthe\\trestaurant\\t\\bs\\tnot\\tjust\\tpopular\\f\\tbut\\tvery\\tpopular.\\t \\t \\t Figure 1:\\tA\\trestaurant\\trev\\bew\\ton\\tthe\\tWeb.\\t \\t"]},{"title":"2 Re\\b\\tted Work","paragraphs":["Recently\\f\\tvar\\bous\\tpart\\bes\\thave\\tpa\\bd\\ta\\tmyr\\bad\\tof\\tattent\\bon\\tto\\tthe\\tresearch\\tof\\tsent\\bment\\tanalys\\bs\\t for\\t many\\t reasons.\\t Sent\\bment\\t analys\\bs\\t prov\\bdes\\t organ\\bzat\\bons\\f\\t cand\\bdates\\f\\t pol\\bt\\bcal\\t part\\bes\\t and\\t hosts\\t of\\t certa\\bn\\t events\\t w\\bth\\t the\\t opportun\\bty\\t to\\t automat\\bcally\\t \\bdent\\bfy\\t the\\t subject\\bve\\t remarks\\t toward\\t them\\t or\\t even\\t comp\\ble\\t the\\t overall\\t favorab\\bl\\bty\\t or\\t unfavorab\\bl\\bty\\t for\\t them.\\t In\\t terms\\t of\\t market\\bng\\f\\tdamage\\tcontrol\\f\\tand\\tr\\bsk\\tmanagement\\f\\t\\bt\\t\\bs\\tof\\tgreat\\t\\bmportance.\\t","Some\\tof\\tthe\\tresearch\\ton\\tsent\\bment\\tanalys\\bs\\tfocuses\\ton\\tpred\\bct\\bng\\tsemant\\bc\\tor\\bentat\\bons\\tfor\\t words\\t (\\bn\\t terms\\t of\\t polar\\bty\\t d\\brect\\bons\\t and\\t \\bntens\\bt\\bes)\\f\\t espec\\bally\\t adject\\bves\\f\\t wh\\bch\\t are\\t good\\t \\bnd\\bcators\\t of\\t subject\\bve\\t statements\\t (Hatz\\bvass\\bloglou\\t and\\t Mckeown\\f\\t 1997;\\t Hatz\\bvass\\bloglou\\t and\\t W\\bebe\\f\\t 2000;\\t W\\bebe\\f\\t 2000;\\t Turney\\t and\\t L\\bttman\\f\\t 2003).\\t Some\\f\\t however\\f\\t focuses\\t on\\t \\bdent\\bfy\\bng\\tthe\\tsent\\bments\\tof\\tcollocat\\bons\\t(W\\bebe\\t\\bt\\tal.\\f\\t2001)\\f\\tof\\tphrases\\tconta\\bn\\bng\\tadject\\bves\\t and\\tadverbs\\t(Turney\\f\\t2002)\\f\\tand\\tof\\tphrases\\tmarked\\tw\\bth\\tpolar\\bty\\t(W\\blson\\t\\bt\\tal.\\f\\t2005).\\t","Past\\t research\\t ut\\bl\\bzes\\t lex\\bcons\\t (hand\\t crafted\\t \\bn\\t (Huettner\\t and\\t Subas\\bc\\f\\t 2000)\\t and\\t automat\\bcally\\tm\\bned\\t\\bn\\t(Yang\\t\\bt\\tal.\\f\\t2007a))\\tor\\tn-gram\\tfeatures\\t(Pang\\t\\bt\\tal.\\f\\t2002)\\t\\bn\\tautomat\\bc\\t rev\\bew\\t \\t rank\\t \\t 201 analys\\bs\\t on\\t documents’\\t sent\\bments\\f\\t such\\t as\\t sent\\bment\\t categor\\bzat\\bon\\t of\\t rev\\bews\\t or\\t mood\\t class\\bf\\bcat\\bon\\tof\\tWeb\\tblogs.\\tThe\\tsent\\bment\\tclass\\bf\\bcat\\bon\\tof\\tdocuments\\tmay\\tbe\\tapproached\\tby\\t f\\brst\\t analyz\\bng\\t the\\br\\t sentences’\\t semant\\bc\\t or\\bentat\\bons\\t (Yang\\t\\bt\\t al.\\f\\t 2007b)\\t or\\t sequent\\bal\\t sent\\bments\\tof\\tthe\\br\\tsentences\\t(Mao\\tand\\tLebanon\\f\\t2006)\\tor\\tby\\ttreat\\bng\\tthe\\tsentences\\tw\\bth\\bn\\tas\\ta\\t whole\\t(M\\bshne\\f\\t2005).\\t","In\\tth\\bs\\tpaper\\f\\tthe\\tgoal\\tof\\tour\\tmodel\\t\\bs\\tto\\tautomat\\bcally\\tclass\\bfy\\trev\\bews\\t\\bnto\\tf\\bve\\tsent\\bment\\t rat\\bngs\\t us\\bng\\t art\\bcle-level\\t surface\\t n-gram\\t and\\t semant\\bc\\t word-class\\t features.\\t At\\t run-t\\bme\\f\\t we\\t further\\tleverage\\ta\\ts\\bmple\\twe\\bght\\bng\\tstrategy\\tto\\tg\\bve\\textra\\twe\\bghts\\tto\\tfeatures\\t\\bn\\tsentences\\tl\\bkely\\t to\\tconta\\bn\\tsent\\bments\\tor\\tevaluat\\bve\\texpress\\bons.\\t"]},{"title":"3 The Method 3.1 Prob\\bem St\\ttement","paragraphs":["We\\tfocus\\ton\\trank\\bng\\trev\\bew\\tart\\bcles\\tus\\bng\\tf\\bve-star\\trat\\bng\\tscheme.\\tRev\\bews’\\tsent\\bment\\trat\\bngs\\t are\\treturned\\tas\\tthe\\toutput\\tof\\tthe\\tsystem\\tand\\tcan\\tbe\\tused\\tas\\trank\\tsuggest\\bon\\tto\\trev\\bewers.\\tWe\\t now\\tformally\\tstate\\tthe\\tproblem\\tthat\\twe\\tare\\taddress\\bng.\\t","P\\fobl\\bm\\t Stat\\bm\\bnt:\\t We\\t are\\t g\\bven\\t a\\t general\\t purpose\\t mach\\bne\\t learn\\bng\\t model\\tML\\t (e.g.\\f\\t max\\bmum\\t entropy\\t model)\\f\\t a\\t semant\\bc\\t word-class\\t thesaurus\\tWC\\t (e.g.\\f\\t Ch\\bnese\\t synonym\\t thesaurus)\\f\\tand\\ta\\trev\\bew\\tart\\bcle\\tRE.\\tOur\\tgoal\\t\\bs\\tto\\tass\\bgn\\tthe\\tmost\\tprobable\\tsent\\bment\\trat\\bng\\t\\f\\t(\\f\\t \\bs\\tan\\t\\bnteger\\tbetween\\tone\\tand\\tf\\bve)\\tto\\tthe\\trev\\bew\\tRE\\tv\\ba\\tML.\\tFor\\tth\\bs\\f\\twe\\ttransform\\tRE\\t\\bnto\\ta\\t collect\\bon\\t of\\t feas\\bble\\t features\\f\\tF1\\f\\t ...\\f\\tFm\\f\\t such\\t that\\t the\\t correct\\t rank\\t of\\tRE\\t \\bs\\t l\\bkely\\t to\\t be\\t obta\\bned.\\t","In\\t the\\t rest\\t of\\t th\\bs\\t sect\\bon\\f\\t we\\t descr\\bbe\\t our\\t solut\\bon\\t to\\t th\\bs\\t problem.\\t F\\brst\\f\\t we\\t def\\bne\\t a\\t strategy\\tfor\\ttransform\\bng\\trev\\bew\\tart\\bcles\\t\\bnto\\tcollect\\bons\\tof\\tfeatures\\t(Sect\\bon\\t3.2).\\tThese\\tfeature\\t collect\\bons\\t are\\t then\\t ut\\bl\\bzed\\t to\\t tra\\bn\\t a\\t mach\\bne\\t learn\\bng\\t method\\t regard\\bng\\t the\\t assoc\\bat\\bons\\t between\\t features\\t and\\t d\\bfferent\\t sent\\bment\\t rat\\bngs.\\t F\\bnally\\f\\t we\\t show\\t how\\t our\\t model\\t rates\\t a\\t rev\\bew\\t art\\bcle\\t at\\t run-t\\bme\\t by\\t apply\\bng\\t h\\bghly-tuned\\t rank-feature\\t assoc\\bat\\bons\\t and\\t feature\\t we\\bght\\bng\\t(Sect\\bon\\t3.3).\\t"]},{"title":"3.2 Le\\trning R\\tnk-Fe\\tture Asso\\fi\\ttions","paragraphs":["We\\tattempt\\tto\\tf\\bnd\\ttransformat\\bons\\t from\\t rev\\bew\\t art\\bcles\\t \\bnto\\t effect\\bve\\t feature\\t collect\\bons\\t that\\t cons\\bst\\tof\\tterms\\t(or\\tfeatures)\\texpected\\tto\\tass\\bst\\t\\bn\\trank\\tdeterm\\bnat\\bon.\\tOur\\tlearn\\bng\\tprocess\\t\\bs\\t shown\\t\\bn\\tF\\bgure\\t2.\\t \\t","\\t Figure 2:\\tOutl\\bne\\tof\\tthe\\tprocess\\tused\\tto\\ttra\\bn\\tour\\tmodel.\\t \\t Prepro\\fessing Review Arti\\f\\bes. In\\tthe\\tf\\brst\\tstage\\tof\\tthe\\tlearn\\bng\\tprocess\\t(Step\\t(1)\\t\\bn\\tF\\bgure\\t2)\\f\\t we\\tword\\tsegment\\tand\\tPoS\\ttag\\tthe\\trev\\bew\\tart\\bcles\\t\\bn\\ttra\\bn\\bng\\tdata.\\tFor\\texample\\f\\twe\\tsegment\\tand\\t tag\\tthe\\tCh\\bnese\\trestaurant\\trev\\bew\\t“好吃又便宜!真棒!值得推薦”\\tas\\t“好吃/VH\\t又/Db\\t便宜 /VH\\t!/Fw\\t真/DFVH\\t讚/bb\\t!/Fw\\t值得/VHDb\\t推薦/VC”\\t (Engl\\bsh\\t translat\\bon:\\t The\\t food\\t \\bs\\t good\\tand\\tnot\\texpens\\bve!\\tGoody!\\tWorth\\trecommend\\bng\\tto\\tfr\\bends).\\tMoreover\\f\\twe\\theur\\bst\\bcally\\t d\\bv\\bde\\t rev\\bews\\t \\bnto\\t “sentences”\\t by\\t us\\bng\\t punctuat\\bon\\t marks\\t as\\t del\\bm\\bters.\\t Take\\t the\\t above\\t art\\bcle\\tfor\\t\\bnstance.\\tIt\\tcompr\\bses\\tthree\\tsentences:\\t“好吃又便宜!”\\f\\t“真棒!”\\f\\tand\\t“值得推薦”. Note\\tthat\\f\\t\\bn\\tthese\\trev\\bew\\tart\\bcles\\f\\tsome\\tCh\\bnese\\tcharacters\\tare\\t“abbrev\\bated”\\tby\\tthe\\br\\tsoundl\\bke\\t shorthands.\\t To\\t avo\\bd\\t the\\t poss\\bb\\bl\\bty\\t of\\t degrad\\bng\\t the\\t performance\\t of\\t a\\t Ch\\bnese\\t word\\t (1)\\tPreprocess\\trev\\bew\\tart\\bcles\\t\\bn\\ttra\\bn\\bng\\tdata\\t\\t (2)\\tTransform\\trev\\bew\\tart\\bcles\\t\\bnto\\tfeature\\tcollect\\bons\\t\\t (3)\\tEst\\bmate\\tassoc\\bat\\bons\\tbetween\\tranks\\tand\\tfeatures\\t\\t (4)\\tOutput\\tthe\\ttra\\bned\\tmodel\\t \\t 202 \\t segmenter\\f\\t we\\t replace\\t popularly\\t used\\t shorthands\\t w\\bth\\t the\\br\\t correspond\\bng\\t regular\\t form.\\t See\\t Table\\t1\\tfor\\texamples.\\t \\t T\\tb\\be 1:\\tShorthands\\tfor\\tsome\\tCh\\bnese\\tcharacters.\\t","Shorthand\\t Regular\\tForm\\t Shorthand\\t Regular\\tForm\\t ㄌ\\t 了\\t ㄅ\\t 吧\\t ㄉ\\t 的\\t ㄋ\\t 呢\\t ㄚ\\t 啊\\t ㄇ\\t 麼\\t \\t Tr\\tnsform\\ttion from Reviews into Fe\\ttures. In\\tthe\\tsecond\\tstage\\tof\\tthe\\ttra\\bn\\bng\\t(Step\\t(2)\\t\\bn\\t F\\bgure\\t 2)\\f\\t we\\t transform\\t rev\\bew\\t art\\bcles\\t \\bnto\\t collect\\bons\\t of\\t features.\\t F\\bgure\\t 3\\t shows\\t the\\t transformat\\bon\\talgor\\bthm.\\t \\t \\t Figure 3:\\tTransformat\\bon\\talgor\\bthm.\\t \\t In\\t Step\\t (1)\\t of\\t the\\t transformat\\bon\\t algor\\bthm\\t we\\t def\\bne\\t an\\t empty\\t collect\\bon\\f\\tF\\batu\\f\\bCol\\f\\t for\\t gather\\bng\\tart\\bcle-level\\tn-gram\\tor\\tsemant\\bc\\tword-class\\tfeatures.\\tFor\\teach\\tword\\t\\bn\\tthe\\tsentences\\t of\\tthe\\tg\\bven\\trev\\bew\\tRE\\f\\twe\\t\\bnclude\\t\\bt\\t\\bnto\\tF\\batu\\f\\bCol\\tas\\tun\\bgram\\tfeature\\t(Step\\t(2)).\\tWe\\talso\\t cons\\bder\\tb\\bgram\\tfeature\\t(Step\\t(3)).\\t","In\\t Steps\\t (4a)\\f\\t (4b)\\t and\\t (4c)\\t we\\t look\\t up\\t the\\t (semant\\bc)\\t word\\t classes\\t for\\t words\\tw\\b-1\\f\\t w\\b\\t and\\t w\\b+1\\f\\t and\\t denote\\t them\\t as\\two\\fdClass\\b-1\\f\\two\\fdClass\\b\\t and\\two\\fdClass\\b+1\\f\\t respect\\bvely.\\t Word\\t class\\t features\\t \\bncorporated\\t \\bnto\\t our\\t model\\t a\\bm\\t at\\t allev\\bat\\bng\\t data\\t sparseness\\t problem\\t and\\t reduc\\bng\\t out-of-vocabulary\\t encounters\\t at\\t run-t\\bme.\\t If\\t there\\t \\bs\\t a\\t word\\t class\\t for\\tw\\b\\t \\bn\\t the\\t semant\\bc\\t thesaurus\\tWC\\f\\t \\bt\\t \\bs\\t added\\t \\bnto\\t the\\t feature\\t collect\\bon\\t (Steps\\t (5)\\t and\\t (6))\\f\\t referred\\t to\\t as\\t classbased\\t un\\bgram\\t feature\\f\\tCBuni\\t for\\t short.\\t On\\t the\\t other\\t hand\\f\\t we\\t deal\\t w\\bth\\t the\\t class-based\\t b\\bgram\\tfeature\\f\\tCBbi\\tfor\\tshort\\f\\tfrom\\tStep\\t(7)\\tto\\t(9).\\tCompared\\tto\\tthe\\tsurface\\tb\\bgram\\tfeatures\\t\\bn\\t Step\\t (3)\\f\\t the\\t semant\\bc\\t class-based\\t b\\bgrams\\t are\\t not\\t necessary\\t b\\bgrams\\t of\\t word\\t classes.\\t Words\\t can\\tbe\\t\\bncluded\\t\\bn\\tthe\\tclass-based\\tb\\bgram\\tfeatures\\t\\bf\\tone\\tof\\tthe\\br\\tadjacent\\twords\\tcan\\tbe\\tlabeled\\t w\\bth\\t semant\\bc\\t classes.\\t (Steps\\t (7)\\t and\\t (9)).\\t In\\t the\\t end\\f\\t th\\bs\\t procedure\\t returns\\t the\\t feature\\t collect\\bon\\tof\\tthe\\trev\\bew\\tart\\bcle.\\t procedure\\tTransformat\\bonToFeatureCollect\\bons(RE\\f\\tWC)\\t (1)\\tF\\batu\\f\\bCol=“”\\t//NULL\\t","for\\teach\\tsentence\\ts\\t\\bn\\tthe\\trev\\bew\\tRE\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\tfor\\teach\\tword\\tw\\b\\t\\bn\\ts\\t (2)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tadd\\tw\\b\\tto\\tF\\batu\\f\\bCol\\t (3)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tadd\\t(w\\b-1\\f\\tw\\b)\\tto\\tF\\batu\\f\\bCol\\t (4a)\\t\\t\\t\\t\\t\\t\\t\\two\\fdClass\\b-1=WordClassLookUp(w\\b-1\\f\\tWC)\\t (4b)\\t\\t\\t\\t\\t\\t\\t\\two\\fdClass\\b=WordClassLookUp(w\\b\\f\\tWC)\\t (4c)\\t\\t\\t\\t\\t\\t\\t\\two\\fdClass\\b+1=WordClassLookUp(w\\b+1\\f\\tWC)\\t (5)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\bf\\two\\fdClass\\b\\t\\bs\\tnot\\tNULL\\t (6)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tadd\\two\\fdClass\\b\\tto\\tF\\batu\\f\\bCol\\t \\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\bf\\two\\fdClass\\b-1\\t\\bs\\tNULL\\t (7)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tadd\\t(w\\b-1\\f\\two\\fdClass\\b)\\tto\\tF\\batu\\f\\bCol\\t \\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\telse\\t (8)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tadd\\t(wo\\fdClass\\b-1\\f\\two\\fdClass\\b)\\tto\\tF\\batu\\f\\bCol\\t (9)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\bf\\two\\fdClass\\b+1\\t\\bs\\tNULL\\t \\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tadd\\t(wo\\fdClass\\b\\f\\tw\\b+1)\\tto\\tF\\batu\\f\\bCol\\t","return\\tF\\batu\\f\\bCol\\t 203","Although\\t we\\t only\\t cons\\bder\\t n-gram\\t and\\t semant\\bc\\t features\\f\\t one\\t can\\t \\bntegrate\\t other\\t feas\\bble\\t features\\t\\bnto\\tth\\bs\\ttransformat\\bon\\talgor\\bthm\\f\\tsuch\\tas\\tdependenc\\bes\\tof\\twords.\\t \\t Asso\\fi\\ttion Estim\\ttion. In\\t the\\t th\\brd\\t and\\t f\\bnal\\t stage\\t of\\t the\\t learn\\bng\\t algor\\bthm\\f\\t we\\t explo\\bt\\t a\\t mach\\bne\\t learn\\bng\\t techn\\bque\\f\\t max\\bmum\\t entropy\\t model\\f\\t to\\t est\\bmate\\t the\\t assoc\\bat\\bons\\t between\\t sent\\bment\\t rat\\bngs\\t (\\b.e.\\f\\t from\\t one\\t to\\t f\\bve)\\t and\\t features.\\t Recall\\t that\\f\\t \\bn\\t our\\t model\\f\\t types\\t of\\t features\\t\\bnclude\\tun\\bgram\\f\\tb\\bgram\\f\\tclass-based\\tun\\bgram\\tand\\tclass-based\\tb\\bgram.\\t","Once\\t we\\t transform\\t rev\\bew\\t art\\bcles\\t \\bnto\\t feature\\t collect\\bons\\t as\\t prev\\bously\\t descr\\bbed\\f\\t these\\t features\\t w\\bth\\t correspond\\bng\\t ranks\\t spec\\bf\\bed\\t by\\t rev\\bewers\\t are\\t fed\\t to\\t tra\\bn\\t max\\bmum\\t entropy\\t model\\t(MaxEnt\\tfor\\tshort).\\tMaxEnt\\tder\\bves\\t\\bts\\tset\\tof\\tsystem\\tparameters\\tv\\ba\\t \\t"]},{"title":"( ) ( )( )","paragraphs":["*","arg max Pr \\f RE \\fank RE f\\batu\\f\\bs RE θθ θ="]},{"title":"∏","paragraphs":["\\t (1)\\t \\t where\\tθ \\tdenotes\\t any\\t poss\\bble\\t set\\t of\\t system\\t parameters\\f\\tf\\batu\\f\\bs(RE)\\t the\\t features\\t prov\\bded\\t w\\bth\\t the\\t rev\\bew\\tRE\\f\\t and\\t\\fank(RE)\\t the\\t rank\\f\\t or\\t the\\t sent\\bment\\t rat\\bng\\f\\t of\\tRE.\\t Moreover\\f\\t the\\t probab\\bl\\bty\\t\\bn\\tEq.\\t1\\t\\bs\\test\\bmated\\tby\\t \\t"]},{"title":"( ) ( )( )","paragraphs":["\\f \\fexp \\fi \\f i \\f i f f\\batu\\f\\bs RE \\fank REλ"]},{"title":" \\b \\t   \\f∑","paragraphs":["\\t (2)\\t \\t \\bn\\twh\\bch\\tthe\\tθ \\t\\bn\\tEq.\\t1\\t\\bs\\tfactored\\t\\bnto\\ta\\t set\\t of\\t\\fi \\fλ ’s\\f\\t stand\\bng\\t for\\t the\\t feature\\t we\\bghts\\t of\\t the\\t b\\bnary-valued\\t feature\\t funct\\bons\\t (\\b.e.\\f\\tf\\b\\f\\f’s).\\t f\\b\\f\\f(f\\batu\\f\\bs(RE)\\f\\t\\fank(RE))\\t returns\\t 1\\t \\bf\\t\\f\\t equals\\t to\\t \\fank(RE)\\t and\\tf\\batu\\f\\bs(RE)\\t conta\\bns\\t the\\t feature\\t wh\\bch\\tf\\b\\t takes\\t note\\t of\\f\\t or\\t represents\\f\\t and\\t 0\\t otherw\\bse.\\tFor\\t\\bnstance\\f\\tg\\bven\\ta\\trev\\bew\\f\\tranked\\ttwo-star\\f\\tfeature\\tfunct\\bon\\tof\\t\\tf\\t“d\\bsl\\bke”\\f2\\ty\\belds\\t1\\t\\bf\\t the\\tun\\bgram\\t“d\\bsl\\bke”\\tex\\bsts\\t\\bn\\tthe\\tfeature\\tcollect\\bon\\tof\\tth\\bs\\trev\\bew\\f\\tand\\t0\\t\\bf\\tnot.\\tFurthermore\\f\\ta\\t larger\\t\\fi \\fλ \\tmeans\\tthat\\tthe\\tfeature\\tf\\b\\trepresents\\t\\bs\\tcons\\bdered\\tto\\tbe\\ta\\tstrong\\t\\bnd\\bcator\\tfor\\tthe\\trank\\t \\f.\\t Prov\\bded\\t w\\bth\\t rank-annotated\\t rev\\bews\\f\\t MaxEnt\\t manages\\t to\\t tune\\t the\\t feature\\t we\\bghts\\t to\\t capture\\tsu\\btable\\tassoc\\bat\\bons\\f\\tbetween\\td\\bst\\bnct\\tfeature\\tand\\trank\\t(see\\tEq.\\t1).\\t","Note\\tthat\\twords\\tmay\\tbe\\trepeated\\t\\bn\\ta\\trev\\bew\\tart\\bcle.\\tFor\\texample\\f\\ta\\trev\\bew\\tmay\\tment\\bon\\tthe\\t g\\f\\bat\\tfood\\tserved\\tby\\tthe\\trestaurant\\f\\tthe\\tgreat\\tserv\\bce\\tprov\\bded\\tby\\tthe\\tstaff\\t\\bn\\tthe\\trestaurant\\f\\tthe\\t g\\f\\bat\\tatmosphere\\t\\bn\\tthe\\trestaurant\\f\\tand\\tthe\\tg\\f\\bat\\tpersonal\\bty\\tof\\tthe\\trestaurant\\towner\\tat\\tthe\\tsame\\t t\\bme.\\t Us\\bng\\t b\\bnary-valued\\t feature\\t funct\\bons\\t \\bn\\t Eq.\\t 2\\f\\t unfortunately\\f\\t may\\t not\\t correctly\\t reflect\\t the\\t overall\\t enjoyable\\t d\\bn\\bng\\t exper\\bence\\t \\bn\\t terms\\t of\\t the\\t food\\f\\t the\\t serv\\bce\\f\\t the\\t atmosphere\\f\\t the\\t personal\\bty\\t of\\t the\\t restaurant\\t owner.\\t Therefore\\f\\t the\\t feature\\t funct\\bons\\t (f\\b\\f\\f’s)\\t \\bn\\t Eq.\\t 2\\t are\\t redef\\bned\\tto\\treturn\\tthe\\tfrequency\\f\\tobserved\\t\\bn\\ta\\trev\\bew\\f\\tof\\tthe\\tcorrespond\\bng\\tfeatures.\\t \\t"]},{"title":"3.3 Run-Time R\\tnk C\\b\\tssifi\\f\\ttion","paragraphs":["Once\\t the\\t assoc\\bat\\bons\\t between\\t features\\t and\\t sent\\bment\\t rat\\bngs\\t are\\t tuned\\f\\t for\\t a\\t g\\bven\\t rev\\bew\\t art\\bcle\\f\\t our\\t model\\t determ\\bnes\\t \\bts\\t most\\t probable\\t rank\\t\\f*","\\f\\t sat\\bsfy\\bng\\t"]},{"title":"( )","paragraphs":["* arg max Pr ( )\\f\\f \\f f\\batu\\f\\bs REθ \\twhere\\t the\\t probab\\bl\\bty\\t \\bs\\t est\\bmated\\t v\\ba\\t Eq.\\t 2.\\t Recall\\t that\\t f\\batu\\f\\bs(RE)\\t\\bs\\tacqu\\bred\\tus\\bng\\tthe\\trev\\bew-to-feature\\ttransformat\\bon\\talgor\\bthm\\t\\bn\\tF\\bgure\\t3.\\t","Insp\\bred\\tby\\t(Yang\\t\\bt\\tal.\\f\\t2007b)\\f\\tsuggest\\bng\\tthat\\tthe\\tlast\\tsentence\\tplays\\tan\\t\\bmportant\\trole\\t\\bn\\t determ\\bn\\bng\\t the\\t overall\\t emot\\bon\\t of\\t a\\t blog\\t document\\f\\t at\\t run-t\\bme\\t we\\t take\\t some\\t sentent\\bal\\t character\\bst\\bcs\\t \\bnto\\t account.\\t Spec\\bf\\bcally\\f\\t we\\t attempt\\t to\\t d\\bst\\bngu\\bsh\\t sentences\\t w\\bth\\t these\\t character\\bst\\bcs\\tfrom\\tthose\\tw\\bthout.\\t","Intu\\bt\\bvely\\f\\tthe\\tf\\brst\\tsentence\\tand\\tthe\\tlast\\tsentence\\tof\\ta\\trev\\bew\\tas\\twell\\tas\\tthe\\tsentences\\tw\\bth\\t adverbs\\t may\\t carry\\t more\\t sent\\bment\\t \\bnformat\\bon\\t than\\t those\\t that\\t are\\t not.\\t A\\t rev\\bewer\\t may\\t start\\t 204 \\t w\\bth\\tor\\tconclude\\tby\\ta\\tpos\\bt\\bve\\tor\\tnegat\\bve\\tstatement\\ton\\tthe\\toverall\\tpersonal\\texper\\bence\\tw\\bth\\tthe\\t serv\\bce\\tprov\\bder.\\tAlso\\f\\tadverbs\\t\\bn\\tsentences\\ttend\\tto\\tput\\textra\\tstress\\ton\\tthe\\tmod\\bf\\bed\\tadject\\bves\\f\\t pos\\bng\\t a\\t stronger\\t \\bnd\\bcat\\bon\\t toward\\t the\\t sent\\bments\\t of\\t the\\t adject\\bves\\t than\\t the\\t adject\\bves\\t alone\\t (e.g.\\f\\tthe\\t“very”\\t\\bn\\tthe\\tphrase\\t“very\\tn\\bce”\\t\\bmpl\\bes\\tthe\\tsemant\\bc\\tor\\bentat\\bon\\t\\bs\\tqu\\bte\\tpos\\bt\\bve).\\t","In\\tth\\bs\\tpaper\\f\\tthree\\ttypes\\tof\\tsentences\\f\\tthe\\tf\\brst\\t(firstS)\\tand\\tthe\\tlast\\t(\\b\\tstS)\\tsentence\\tand\\tthe\\t sentences\\t w\\bth\\t adverbs\\t (\\tdvS)\\f\\t are\\t cons\\bdered\\t to\\t be\\t more\\t \\bnformat\\bve\\t \\bn\\t determ\\bn\\bng\\t the\\t sent\\bment\\trat\\bng\\tof\\ta\\trev\\bew.\\tTherefore\\f\\tat\\trun-t\\bme\\f\\tthese\\tsentences\\tare\\tg\\bven\\tmore\\twe\\bghts\\tby\\t doubl\\bng\\t the\\t n-gram\\t and\\t semant\\bc\\t features\\t there\\bn\\t wh\\ble\\t features\\t of\\t others\\t not\\t belong\\bng\\t to\\t these\\tthree\\ttypes\\tare\\tnot\\tdupl\\bcated.\\tFor\\t\\bnstance\\f\\twe\\t\\bnclude\\tthe\\tun\\bgram\\tfeatures\\t“very”\\tand\\t “good”\\f\\tand\\tthe\\tb\\bgram\\tfeature\\t“very\\tgood”\\ttwic\\b\\tfor\\tthe\\tsentence\\tw\\bth\\tan\\tadverb\\f\\t“very\\tgood”.\\t On\\tthe\\tother\\thand\\f\\tfor\\tthe\\tsentence\\f\\t“good”\\f\\tnot\\tbelong\\bng\\tto\\tfirstS\\f\\t\\b\\tstS\\f\\tand\\t\\tdvS\\thas\\ts\\bngle\\t un\\bgram\\tfeature\\t“good”.\\t \\t"]},{"title":"4 Experiments","paragraphs":["Our\\tmodel\\twas\\tdes\\bgned\\tto\\tf\\bnd\\tthe\\tmost\\tl\\bkely\\tsent\\bment\\trank\\tfor\\ta\\trev\\bew\\tart\\bcle.\\tAs\\tsuch\\f\\t\\bt\\t w\\bll\\t be\\t tra\\bned\\t and\\t evaluated\\t on\\t rev\\bews\\t collected\\t from\\t the\\t Web.\\t In\\t th\\bs\\t sect\\bon\\f\\t we\\t f\\brst\\t present\\t the\\t deta\\bls\\t of\\t tra\\bn\\bng\\t our\\t model\\t for\\t the\\t evaluat\\bon\\t (Sect\\bon\\t 4.1).\\t Then\\f\\t Sect\\bon\\t 4.2\\t reports\\t the\\t results\\t of\\t the\\t exper\\bments\\t us\\bng\\t d\\bfferent\\t comb\\bnat\\bons\\t of\\t features\\t ment\\boned\\t \\bn\\t Sect\\bon\\t3.\\tF\\bnally\\f\\td\\bscuss\\bon\\tconcern\\bng\\terror\\ttypes\\tand\\tpotent\\bal\\t\\bmprovements\\tto\\tthe\\tsystem\\t \\bs\\tmade\\t\\bn\\tSect\\bon\\t4.3.\\t"]},{"title":"4.1 Tr\\tining Our Mode\\b","paragraphs":["We\\t used\\t a\\t set\\t of\\t 31\\f500\\t restaurant\\t rev\\bews\\t for\\t tra\\bn\\bng\\f\\t obta\\bned\\t from\\t query\\bng\\t “餐廳”\\t (restaurant)\\t\\bn\\tYahoo!奇摩生活+\\t(Yahoo!\\tK\\bmo\\tL\\bfe\\tStyle).\\tEach\\trev\\bew\\twas\\tprov\\bded\\tw\\bth\\ta\\t rank\\f\\tfrom\\tone-star\\tto\\tf\\bve-star\\f\\tby\\t\\bts\\tauthor.\\tNot\\bce\\tthat\\tthe\\tcollected\\trev\\bews\\twere\\tun\\bformly\\t d\\bstr\\bbuted\\t over\\t ranks\\f\\t that\\t \\bs\\f\\t 6\\f300\\t rev\\bews\\t per\\t rank.\\t After\\t word\\t segmentat\\bon\\f\\t our\\t tra\\bn\\bng\\t data\\tcons\\bsted\\tof\\tapprox\\bmately\\t2M\\tCh\\bnese\\twords.\\t","On\\tthe\\tother\\thand\\f\\tour\\tsemant\\bc\\tword\\tclasses\\twere\\tbased\\ton\\t同義詞詞林\\t(Ch\\bnese\\tsynonym\\t thesaurus)\\f\\tand\\twe\\temployed\\tZhang’s\\tMaxEnt\\ttoolk\\bt3","\\tto\\ttune\\tthe\\tfeature\\twe\\bghts\\tdescr\\bbed\\t\\bn\\t the\\ttra\\bn\\bng\\tprocedure.\\tFollow\\bng\\ttable\\tshows\\tsome\\texample\\twords\\t\\bn\\ttwo\\tsemant\\bcally\\trelated\\t top\\bcs\\tfrom\\tthe\\tCh\\bnese\\tsynonym\\tthesaurus.\\tWords\\t\\bn\\tgroup\\t“Ga01A”\\texpress\\tthe\\tconcept\\tof\\t “happ\\bness”\\twh\\ble\\twords\\t\\bn\\t“Gb10A”\\texpress\\tthe\\tconcept\\tof\\t“d\\bsl\\bke”.\\t","Group\\t Word\\t Group\\t Word\\t","Ga01A\\t 高興\\t Gb10A\\t 討厭\\t","Ga01A\\t 開心\\t Gb10A\\t 厭惡\\t","Ga01A\\t 歡愉\\t Gb10A\\t 嫌惡\\t"]},{"title":"4.2 Ev\\t\\bu\\ttion Resu\\bts","paragraphs":["In\\tth\\bs\\tsubsect\\bon\\f\\twe\\tf\\brst\\texam\\bne\\tthe\\td\\bff\\bculty\\tof\\tour\\tproblem:\\tclass\\bfy\\bng\\trev\\bews\\t\\bnto\\tf\\bve\\t d\\bfferent\\tsemant\\bc\\trat\\bngs\\t(\\b.e.\\f\\tfrom\\tone-star\\tto\\tf\\bve-star).\\tWe\\tasked\\tone\\tgraduate\\tand\\tone\\tPHD\\t student\\tto\\tclass\\bfy\\t50\\trandomly\\tsampled\\trev\\bews\\f\\tun\\bformly\\tcollected\\tfrom\\tf\\bve\\tsemant\\bc\\tranks\\f\\t w\\bthout\\t know\\bng\\t the\\t or\\bg\\bnal\\t semant\\bc\\t rat\\bngs\\t g\\bven\\t by\\t authors\\f\\t wh\\bch\\t were\\t cons\\bdered\\t the\\t gold\\t standards.\\t Table\\t 2\\t summar\\bzes\\t the\\t accuracy\\t of\\t these\\t two\\t human\\t annotators.\\t The\\t low\\t accuracy\\t \\bn\\t Table\\t 2\\t suggests\\t that\\t even\\t humans\\t f\\bnd\\t th\\bs\\t class\\bf\\bcat\\bon\\t task\\t d\\bff\\bcult\\t and\\t that\\t words\\tand\\tphrases\\f\\tthough\\tev\\bdence\\tto\\tsemant\\bc\\tor\\bentat\\bons\\f\\tm\\bght\\tbe\\tassoc\\bated\\tw\\bth\\td\\bfferent\\t semant\\bc\\t ranks\\t from\\t person\\t to\\t person.\\t Incons\\bstent\\t understand\\bng\\t of\\t evaluat\\bve\\t express\\bons\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\M\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t 3 \\thttp://homepages.\\bnf.ed.ac.uk/s0450736/maxent_toolk\\bt.html\\t 205 (words\\tor\\tphrases)\\tresult\\bng\\tmostly\\tfrom\\thuman’s\\tsubject\\bve\\tjudgement\\tmakes\\t\\bt\\thard\\tto\\t f\\bnd\\t an\\taccurate\\tclass\\bf\\ber.\\t \\t T\\tb\\be 2: Results\\tof\\thuman\\tannotators.\\t","\\t Accuracy\\t(%)\\t Human\\tA\\t 44\\t Human\\tB\\t 46\\t \\t In\\t exper\\bments\\f\\t to\\t \\bnspect\\t the\\t performance\\t of\\t our\\t model\\f\\t a\\t test\\t data\\t set\\f\\t made\\t up\\t of\\t 5\\f000\\t restaurant\\t rev\\bews\\f\\t was\\t allocated.\\t S\\bnce\\t test\\bng\\t data\\t were\\t un\\bformly\\t d\\bstr\\bbuted\\t among\\t sent\\bment\\t rat\\bngs\\f\\t the\\t expected\\t prec\\bs\\bon\\t of\\t random\\t guess\\bng\\t was\\t 20%.\\t Table\\t 3\\t shows\\t the\\t accuracy\\t of\\t our\\t MaxEnt\\t basel\\bne\\t us\\bng\\t surface\\t n-gram\\t features\\t (Note\\t that\\t us\\bng\\t feature\\t presence\\f\\t\\bnstead\\tof\\tfeature\\tfrequency\\f\\t(see\\tEq\\t2\\t\\bn\\tSect\\bon\\t3.2)\\td\\bd\\tnot\\t\\bmprove\\tthe\\taccuracy\\t of\\t our\\t basel\\bne).\\t As\\t we\\t can\\t see\\f\\t our\\t MaxEnt\\t basel\\bne\\t ach\\beved\\t comparable\\t results\\t w\\bth\\t humans’\\t(see\\tTable\\t2).\\tIn\\tTable\\t3\\f\\tthe\\tresult\\tof\\tcond\\bt\\bonal\\trandom\\tf\\belds4","\\t(CRFs)\\tfed\\tw\\bth\\tthe\\t same\\tfeatures\\t\\bs\\tl\\bsted\\tfor\\tcompar\\bson.\\tAlthough\\tthere\\twas\\ta\\tnot\\bceable\\td\\bfference\\tbetween\\tthe\\t performances\\t of\\t two\\t mach\\bne\\t learn\\bng\\t techn\\bques\\f\\t these\\t two\\t substant\\bally\\t outperformed\\t the\\t method\\tof\\trandom\\tguess\\bng.\\t \\t T\\tb\\be 3:\\tResults\\tof\\td\\bfferent\\tmach\\bne\\tlearn\\bng\\ttechn\\bques.\\t","\\t Accuracy\\t(%)\\t CRFs\\t 36.56\\t Basel\\bne\\t 45.18\\t \\t Table\\t4\\tsummar\\bzes\\tthe\\tperformance\\tof\\tour\\tmodel\\tus\\bng\\tclass-based\\tun\\bgram\\t(CBuni)\\tor\\tclassbased\\tb\\bgram\\t(CBbi)\\tfeatures.\\tIn\\tTable\\t4\\f\\twe\\tf\\bnd\\tthat\\tour\\tmodel\\tbenef\\bted\\tfrom\\tus\\bng\\th\\bgherdegree\\tclass-based\\tn-grams\\t((3)\\tvs.\\t(2))\\f\\tand\\tthat\\tour\\tmodel\\tw\\bth\\tsemant\\bc\\tun\\bgram\\tand\\tb\\bgram\\t features\\t \\bmproved\\t approx\\bmately\\t 1%\\t over\\t the\\t basel\\bne\\t ((3)\\t vs.\\t (1))\\f\\t suggest\\bng\\t the\\t basel\\bne\\t probably\\t suffered\\t from\\t data\\t sparseness\\t problem\\t \\bn\\t that\\t \\bt\\t only\\t took\\t surface\\t word\\t forms\\t \\bnto\\t account.\\t \\t T\\tb\\be 4:\\tPerformance\\ton\\tsemant\\bc\\tfeatures.\\t","\\t Accuracy\\t(%)\\t","Basel\\bne\\t (1)\\t45.18\\t","+CBuni\\t (2)\\t45.82\\t","\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t+CBuni+CBbi\\t (3)\\t46.14\\t \\t On\\ttop\\tof\\tn-gram\\tand\\tsemant\\bc\\tfeatures\\f\\twe\\tconducted\\texper\\bments\\twhere\\f\\tat\\trun-t\\bme\\f\\tfeatures\\t of\\t sentences\\t belong\\bng\\t to\\tfirstS\\f\\t\\b\\tstS\\f\\t and\\t\\tdvS\\t rece\\bved\\t larger\\t we\\bghts.\\t As\\t suggested\\t \\bn\\t Table\\t5\\f\\trepl\\bcat\\bng\\tfeatures\\t\\bn\\tsentences\\tw\\bth\\tadverbs\\tworked\\tbetter\\tthan\\trepl\\bcat\\bng\\tthose\\t\\bn\\t the\\tf\\brst\\tand\\tlast\\tsentences\\tof\\trev\\bews.\\tAlthough\\tdoubl\\bng\\tfeatures\\tof\\tsentences\\tfall\\bng\\t\\bnto\\tthe\\t categor\\bes\\t of\\tfirstS\\t and\\t\\b\\tstS\\t was\\t not\\t as\\t effect\\bve\\t as\\t expected\\f\\t \\bt\\t m\\bght\\t not\\t mean\\t these\\t sentences\\t should\\t not\\t be\\t taken\\t more\\t ser\\bously\\f\\t but\\t m\\bght\\t mean\\t we\\t need\\t a\\t more\\t soph\\bst\\bcated\\t run-t\\bme\\t we\\bght\\bng\\t strategy\\f\\t \\bnstead.\\t Encourag\\bngly\\f\\t g\\bv\\bng\\t more\\t we\\bghts\\t to\\t sentences\\t conta\\bn\\bng\\t adverbs\\t by\\t means\\t of\\t repl\\bcat\\bng\\t the\\br\\t n-gram\\t and\\t semant\\bc\\t features\\t boosted\\t the\\t prec\\bs\\bon\\tto\\t46.34\\f\\tach\\bev\\bng\\ta\\trelat\\bve\\tga\\bn\\tof\\t2.5%\\tover\\tthe\\tstrong\\tMaxEnt\\tbasel\\bne.\\t \\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\M\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t 4 \\tWe\\tused\\tthe\\t\\bmplementat\\bon\\tprov\\bded\\ton\\thttp://flexcrfs.sourceforge.net/\\t 206 \\t T\\tb\\be 5:\\tPerformance\\ton\\td\\bfferent\\trun-t\\bme\\twe\\bght\\bng\\tmechan\\bsms.\\t","\\t Accuracy\\t(%)\\t firstS\\t 45.56\\t \\b\\tstS\\t 45.62\\t \\tdvS\\t 46.34\\t \\t On\\tthe\\tother\\thand\\f\\tour\\tmodel\\tmay\\tbe\\tused\\tto\\tprov\\bde\\ta\\tl\\bst\\tof\\trank\\tsuggest\\bon\\tfor\\ta\\trev\\bew.\\tAs\\t such\\f\\twe\\tleveraged\\tmean\\trec\\bprocal\\trank\\t(MRR)\\f\\tthe\\taverage\\tof\\tthe\\t\\bnverse\\tof\\tthe\\trank\\tof\\tthe\\t fi\\fst\\t correct\\t answer\\f\\t to\\t measure\\t the\\t suggest\\bon\\t qual\\bty\\t of\\t our\\t model.\\t The\\t MRR\\t of\\t our\\t best\\t model\\t (\\b.e.\\f\\t basel\\bne+CBuni+CBbi+\\tdvS)\\t was\\t 0.6849\\f\\t \\bnd\\bcat\\bng\\t that\\f\\t most\\t of\\t the\\t t\\bme\\f\\t the\\t f\\brst\\t and\\t the\\t second\\t sent\\bment\\t rat\\bngs\\t on\\t our\\t suggest\\bon\\t l\\bsts\\t would\\t be\\t adopted\\t by\\t rev\\bew\\t authors.\\t \\t"]},{"title":"4.3 Dis\\fussion","paragraphs":["To\\tanalyze\\terrors\\tour\\tsystem\\tmade\\f\\twe\\texam\\bne\\tthe\\tconfus\\bon\\tmatr\\bx\\f\\tshown\\t\\bn\\tTable\\t6\\f\\ton\\tour\\t test\\bng\\tdata.\\tA\\tconfus\\bon\\tmatr\\bx\\t l\\bsts\\t system’s\\t results\\t w\\bth\\t respect\\t to\\t the\\t gold\\t standard.\\t Take\\t 266\\t (the\\t bold-faced\\t number\\t \\bn\\t Table\\t 6)\\t for\\t example.\\t It\\t \\bs\\t the\\t number\\t of\\t rev\\bews\\t that\\t were\\t wrongly\\tlabeled\\tto\\t2\\tby\\tour\\tsystem\\f\\tbut\\twere\\tlabeled\\tto\\t1\\tby\\tthe\\tauthors\\t(\\b.e.\\f\\tthe\\tgold\\tstandard).\\t Add\\bt\\bonally\\f\\t the\\t accuracy\\t of\\t our\\t system\\t concern\\bng\\t each\\t semant\\bc\\t rat\\bng\\t \\bs\\t also\\t shown\\t (the\\t last\\tcolumn).\\t","As\\t suggested\\t by\\t Table\\t 6\\f\\t \\bt\\t was\\t not\\t easy\\t for\\t the\\t model\\t to\\t d\\bst\\bngu\\bsh\\t restaurant\\t rev\\bews\\t between\\trank\\t1\\tand\\trank\\t2\\tand\\tones\\tbetween\\trank\\t4\\tand\\trank\\t5.\\tThe\\treason\\t\\bs\\tprobably\\tbecause\\t max\\bmum\\t entropy\\t model\\f\\t our\\t system\\t bases\\t on\\f\\t does\\t not\\t “understand”\\t that\\t there\\t are\\t strength\\t d\\bfferences\\tamong\\tsemant\\bc\\trat\\bngs\\tfrom\\tone\\tto\\tf\\bve.\\tOne\\tposs\\bble\\tway\\tto\\tavo\\bd\\tth\\bs\\tproblem\\t\\bs\\t to\\tut\\bl\\bze\\tmult\\b-level\\tclass\\bf\\bers.\\tFor\\texample\\f\\ta\\ttop-level\\tclass\\bf\\ber\\tf\\brst\\tcategor\\bzes\\trev\\bews\\t\\bnto\\t negat\\bve\\f\\t neutral\\f\\t and\\t pos\\bt\\bve\\t ones.\\t Negat\\bve-\\t and\\t pos\\bt\\bve-labeled\\t rev\\bews\\t are\\t subsequently\\t class\\bf\\bed\\t\\bnto\\tvery\\tnegat\\bve\\tand\\tnegat\\bve\\tones\\tand\\tpos\\bt\\bve\\tand\\tvery\\tpos\\bt\\bve\\tones\\trespect\\bvely.\\t \\t T\\tb\\be 6: Confus\\bon\\tmatr\\bx\\tof\\tour\\tbest\\tsystem\\t(basel\\bne+CBuni+CBbi+\\tdvS).\\t","Our\\tSystem\\t\\t","1\\t 2\\t 3\\t 4\\t 5\\t Accuracy\\t(%)\\t 1\\t 488\\t 266 121\\t 35\\t 90\\t 48.80\\t 2\\t 274\\t 410\\t 242\\t 31\\t 43\\t 41.00\\t 3\\t 96\\t 194\\t 472\\t 135\\t 103\\t 47.20\\t 4\\t 28\\t 29\\t 146\\t 306\\t 491\\t 30.60\\t","Gold\\t Standard\\t 5\\t 52\\t 28\\t 79\\t 200\\t 641\\t 64.10\\t \\t Also\\f\\twe\\tf\\bnd\\tthat\\terrors\\tregard\\bng\\tthe\\tor\\bg\\bnally\\tneutral\\trev\\bews\\twere\\tqu\\bte\\tspread\\tout.\\tIn\\tother\\t words\\f\\trev\\bews\\tlabeled\\tas\\t3\\t\\bn\\tthe\\tgold\\tstandard\\tm\\bght\\tbe\\twrongly\\tclass\\bf\\bed\\t\\bnto\\t1\\f\\t2\\f\\t4\\f\\tand\\t5\\t w\\bth\\t some\\t proport\\bon.\\t The\\t rat\\bonale\\t beh\\bnd\\t th\\bs\\t \\bs\\t that\\t authors\\t probably\\t d\\bd\\t not\\t check\\t the\\t su\\btable\\t semant\\bc\\t rat\\bngs\\t at\\t subm\\bss\\bon\\t because\\t of\\t laz\\bness\\t (default\\t rat\\bng\\t \\bs\\t 3)\\t or\\t cultural\\t \\bnfluence\\t (out\\t of\\t pol\\bteness\\f\\t Ch\\bnese\\t people\\t prefer\\t the\\t modest\\t or\\t the\\t neutral\\t cho\\bce).\\t Th\\bs\\t v\\bewpo\\bnt\\t \\bs\\f\\t to\\t some\\t extent\\f\\t ver\\bf\\bed\\t by\\t the\\t scattered\\t “errors”\\t made\\t by\\t the\\t two\\t humans\\t concern\\bng\\tthe\\tneutral\\trestaurant\\trev\\bews\\t(bold-faced\\tnumbers\\t\\bn\\tTable\\t7\\tand\\tTable\\t8).\\t \\t \\t \\t \\t  207 T\\tb\\be 7: Confus\\bon\\tmatr\\bx\\tof\\thuman\\tA.\\t","Human\\tA\\t\\t","1\\t 2\\t 3\\t 4\\t 5\\t Accuracy\\t(%)\\t 1\\t 7\\t 2\\t 1\\t 0\\t 0\\t 70\\t 2\\t 5\\t 5\\t 0\\t 0\\t 0\\t 50\\t 3\\t 1 3 2 3 1 20\\t 4\\t 0\\t 0\\t 1\\t 3\\t 6\\t 30\\t","Gold\\t Standard\\t 5\\t 0\\t 0\\t 2\\t 3\\t 5\\t 50\\t \\t T\\tb\\be 8: Confus\\bon\\tmatr\\bx\\tof\\thuman\\tB.\\t","Human\\tB\\t\\t","1\\t 2\\t 3\\t 4\\t 5\\t Accuracy\\t(%)\\t 1\\t 10\\t 0\\t 0\\t 0\\t 0\\t 100\\t 2\\t 8\\t 1\\t 1\\t 0\\t 0\\t 10\\t 3\\t 3 0 2 4 1 20\\t 4\\t 0\\t 0\\t 1\\t 3\\t 6\\t 30\\t","Gold\\t Standard\\t 5\\t 0\\t 0\\t 0\\t 3\\t 7\\t 70\\t \\t"]},{"title":"5 Summ\\try \\tnd Future Work","paragraphs":["In\\t summary\\f\\t we\\t have\\t \\bntroduced\\t a\\t method\\t for\\t learn\\bng\\t to\\t ass\\bgn\\t sent\\bment\\t rat\\bngs\\t to\\t rev\\bew\\t art\\bcles\\t us\\bng\\t n-gram\\t and\\t semant\\bc\\t features.\\t The\\t method\\t \\bnvolves\\t transform\\bng\\t rev\\bews\\t \\bnto\\t collect\\bons\\t of\\t features\\f\\t est\\bmat\\bng\\t assoc\\bat\\bons\\t between\\t features\\t and\\t rat\\bngs\\f\\t and\\t we\\bght\\bng\\t features\\t \\bn\\t evaluat\\bve\\t sentences\\t by\\t dupl\\bcat\\bon.\\t We\\t have\\t \\bmplemented\\t and\\t evaluated\\t the\\t method\\tas\\tappl\\bed\\tto\\trestaurant\\trev\\bews\\ton\\tthe\\tWeb.\\tIn\\tthe\\tevaluat\\bon\\f\\twe\\thave\\tshown\\tthat\\tthe\\t method\\t leverag\\bng\\t tra\\bn\\bng-t\\bme\\t semant\\bc\\t features\\t and\\t run-t\\bme\\t we\\bght\\bng\\t outperforms\\t the\\t strong\\t basel\\bne\\t w\\bth\\t n-gram\\t features.\\t As\\t for\\t future\\t work\\f\\t we\\t would\\t l\\bke\\t to\\t exam\\bne\\t other\\t we\\bght\\bng\\tstrateg\\bes\\t\\bn\\torder\\tto\\tbetter\\thandle\\tfeatures\\t\\bn\\tthe\\tf\\brst\\tor\\tthe\\tlast\\tsentences\\tof\\trev\\bew\\t art\\bcles\\f\\tusually\\tbel\\beved\\tto\\tcorrelate\\th\\bghly\\tw\\bth\\tauthors’\\tsemant\\bc\\tor\\bentat\\bons.\\t"]},{"title":"Referen\\fes","paragraphs":["Hatz\\bvass\\bloglou\\f\\t V.\\t and\\t K.\\t R.\\t McKeown.\\t 1997.\\t Pred\\bct\\bng\\t the\\t Semant\\bc\\t Or\\bentat\\bon\\t of\\t Adject\\bves.\\tP\\foc\\b\\bdings\\t of\\t th\\b\\t Annual\\t M\\b\\bting\\t of\\t th\\b\\t ACL\\t /\\t Eu\\fop\\ban\\t Association\\t of\\t Computational\\tLinguistics\\f\\t174-181.\\t","Hatz\\bvass\\bloglou\\f\\tV.\\tand\\tJ.\\tM.\\tW\\bebe.\\t2000.\\tEffects\\tof\\tAdject\\bve\\tOr\\bentat\\bon\\tand\\tGradab\\bl\\bty\\t on\\t Sentence\\t Subject\\bv\\bty.\\tP\\foc\\b\\bdings\\t of\\t th\\b\\t Int\\b\\fnational\\t Conf\\b\\f\\bnc\\b\\t on\\t Computational\\t Linguistics\\f\\t299-305.\\t","Huettner\\f\\tA.\\tand\\tP.\\tSubas\\bc.\\t2000.\\tFuzzy\\tTyp\\bng\\tfor\\tDocument\\tManagement.\\tP\\foc\\b\\bdings\\t of\\t ACL\\tCompanion\\tVolum\\b:\\tTuto\\fial\\tAbst\\facts\\tand\\tD\\bmonst\\fation\\tNot\\bs\\f\\t26-27.\\t","Mao\\f\\t Y.\\t and\\t G.\\t Lebanon.\\t 2006.\\t Sequent\\bal\\t Models\\t for\\t Sent\\bment\\t Pred\\bct\\bon.\\tP\\foc\\b\\bdings\\t of\\t ICML\\tWo\\fkshop\\ton\\tL\\ba\\fning\\tin\\tSt\\fuctu\\f\\bd\\tOutput\\tSpac\\bs.\\t","M\\bshne\\f\\t G.\\t Exper\\bments\\t w\\bth\\t Mood\\t Class\\bf\\bcat\\bon\\t \\bn\\t Blog\\t Posts.\\t 2005.\\tP\\foc\\b\\bdings\\t of\\t Wo\\fkshop\\ton\\tStylistic\\tAnalysis\\tof\\tT\\bxt\\tfo\\f\\tInfo\\fmation\\tAcc\\bss.\\t","Pang\\f\\t B.\\f\\t L.\\t Lee\\t and\\t S.\\t Va\\bthyanathan.\\t 2002.\\t Thumbs\\t up?\\t Sent\\bment\\t Class\\bf\\bcat\\bon\\t us\\bng\\t Mach\\bne\\t Learn\\bng\\t Techn\\bques.\\tP\\foc\\b\\bdings\\t of\\t th\\b\\t Conf\\b\\f\\bnc\\b\\t on\\t Empi\\fical\\t M\\bthods\\t in\\t Natu\\fal\\tLanguag\\b\\tP\\foc\\bssing\\f\\t79-86.\\t 208 \\t","Turney\\f\\t P.\\t D.\\t 2002.\\t Thumbs\\t up\\t or\\t Thumbs\\t down?\\t Semant\\bc\\t Or\\bentat\\bon\\t Appl\\bed\\t to\\t Unsuperv\\bsed\\t Class\\bf\\bcat\\bon\\t of\\t Rev\\bews.\\tP\\foc\\b\\bdings\\t of\\t th\\b\\t Annual\\t M\\b\\bting\\t of\\t th\\b\\t ACL\\f\\t 417-424.\\t","Turney\\f\\t P.\\t D.\\t and\\t M.\\t L\\bttman.\\t 2003.\\t Measur\\bng\\t Pra\\bse\\t and\\t Cr\\bt\\bc\\bsm:\\t Inference\\t of\\t Semant\\bc\\t Or\\bentat\\bon\\tfrom\\tAssoc\\bat\\bon.\\tACM\\tT\\fansactions\\ton\\tInfo\\fmation\\tSyst\\bm\\f\\t21(4).\\t","W\\bebe\\f\\t J.\\t M.\\t 2000.\\t Learn\\bng\\t Subject\\bve\\t Adject\\bves\\t from\\t Corpora.\\tP\\foc\\b\\bdings\\t of\\t National\\t Conf\\b\\f\\bnc\\b\\ton\\tA\\ftificial\\tInt\\bllig\\bnc\\b.\\t","W\\bebe\\f\\tJ.\\tM.\\f\\tT.\\tW\\blson\\tand\\tM.\\tBell.\\t2001.\\tIdent\\bfy\\bng\\tCollocat\\bons\\tfor\\tRecogn\\bz\\bng\\tOp\\bn\\bons\\t P\\foc\\b\\bdings\\t of\\t th\\b\\t Annual\\t M\\b\\bting\\t of\\t th\\b\\t ACL\\t /\\t Eu\\fop\\ban\\t Association\\t of\\t Computational\\t Linguistics\\tWo\\fkshop\\ton\\tCollocation.\\t","W\\blson\\f\\t T.\\f\\t J.\\t M.\\t W\\bebe\\t and\\t P.\\t Hoffmann.\\t 2005.\\t Recogn\\bz\\bng\\t Contextual\\t Polar\\bty\\t \\bn\\t Phrase-Level\\tSent\\bment\\tAnalys\\bs.\\tP\\foc\\b\\bdings\\tof\\tth\\b\\tConf\\b\\f\\bnc\\b\\ton\\tEmpi\\fical\\tM\\bthods\\tin\\tNatu\\fal\\t Languag\\b\\tP\\foc\\bssing\\f\\t347-354.\\t","Yang\\f\\t C.\\f\\t K.\\t H.-Y.\\t L\\bn\\t and\\t H.-H.\\t Chen.\\t 2007a.\\t Bu\\bld\\bng\\t Emot\\bon\\t Lex\\bcon\\t from\\t Weblog\\t Corpora.\\tP\\foc\\b\\bdings\\t of\\t th\\b\\t Annual\\t M\\b\\bting\\t of\\t th\\b\\t Association\\t of\\t Computational\\t Linguistics\\f\\t133-136.\\t","Yang\\f\\t C.\\f\\t K.\\t H.-Y.\\t L\\bn\\t and\\t H.-H.\\t Chen.\\t 2007b.\\t Emot\\bon\\t Class\\bf\\bcat\\bon\\t Us\\bng\\t Web\\t Blog\\t Corpora.\\tP\\foc\\b\\bdings\\t of\\t IEEE/WIC/ACM\\t Int\\b\\fnational\\t Conf\\b\\f\\bnc\\b\\t on\\t W\\bb\\t Int\\bllig\\bnc\\b\\f\\t 275-278.\\t 209"]}]}