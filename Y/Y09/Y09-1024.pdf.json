{"sections":[{"title":"Gender and \\bn\\tmac\\f Knowledge D\\tscover\\f from Web-Scale N-Grams for Unsuperv\\tsed Person Ment\\ton Detect\\ton*  ","paragraphs":["Heng Ji a \\bn\\t Dek\\bng \\finb ","a","Computer Science Dep\\brtment, Queens College \\bn\\t Gr\\b\\tu\\bte Center, City University of New York","65-30 Kissen\\b Boulev\\br\\t, Flushing, NY 11367, USA","hengji@cs.qc.cuny.e\\tu","b","Google, Inc.","1600 Amphithe\\bter P\\brkw\\by, Mount\\bin View, CA 94043, USA","lin\\tek@google.com \\bbstract. In this p\\bper we present \\b simple \\bppro\\bch to \\tiscover gen\\ter \\bn\\t \\bnim\\bcy knowle\\tge for person mention \\tetection. We le\\brn noun-gen\\ter \\bn\\t noun-\\bnim\\bcy p\\bir counts from web-sc\\ble n-gr\\bms using specific lexic\\bl p\\btterns, \\bn\\t then \\bpply confi\\tence estim\\btion metrics to filter noise. The selecte\\t inform\\btive p\\birs \\bre then use\\t to \\tetect person mentions from r\\bw texts in \\bn unsupervise\\t le\\brning fr\\bmework. Experiments showe\\t th\\bt this \\bppro\\bch c\\bn \\bchieve high perform\\bnce comp\\br\\bble to st\\bte-of-the-\\brt supervise\\t le\\brning metho\\ts which require m\\bnu\\blly \\bnnot\\bte\\t corpor\\b \\bn\\t g\\bzetteers. Ke\\fwords: Knowle\\tge Discovery, Mention Detection, N-Gr\\bms, Gen\\ter, Anim\\bcy"]},{"title":"1 Introduct\\ton","paragraphs":["The t\\bsk of \\tetecting entity mentions (references to entities) is very import\\bnt to the \\townstre\\bm processing of inform\\btion extr\\bction such \\bs coreference resolution \\bn\\t event extr\\bction. Entity mentions c\\bn be \\tivi\\te\\t into n\\bme mentions (e.g. “John \\b\\tith”), nomin\\bl mentions (e.g. “\\fresident”) \\bn\\t pronouns (e.g. “he”, “she”). Typic\\bl mention \\tetection systems \\bre b\\bse\\t on supervise\\t le\\brning (Boschee et al., 2005; Zitouni \\bn\\t Flori\\bn, 2008) or semisupervise\\t le\\brning (Ji \\bn\\t Grishm\\bn, 2006). Achieving re\\blly high perform\\bnce for mention \\tetection requires \\teep sem\\bntic knowle\\tge \\bn\\t l\\brge costly h\\bn\\t-l\\bbele\\t \\t\\bt\\b. M\\bny systems \\blso exploite\\t lexic\\bl g\\bzetteers such \\bs census \\t\\bt\\b with gen\\ter inform\\btion. However, such knowle\\tge is rel\\btively st\\btic (it is not up\\t\\bte\\t \\turing the extr\\bction process), expensive to construct, \\bn\\t \\toesn’t inclu\\te \\bny prob\\bbilistic inform\\btion.","Mention \\tetection is by \\tefinition \\b sem\\bntic t\\bsk: for ex\\bmple, \\b phr\\bse is \\b person mention if it refers to \\b re\\bl-worl\\t person entity. We shoul\\t thus expect \\b successful mention \\tetection system to exploit worl\\t knowle\\tge, in or\\ter to resolve h\\br\\t c\\bses. For ex\\bmple, if \\b reflexive pronoun (e.g. “himself”) is boun\\t by \\b phr\\bse in its governing c\\btegory (H\\begem\\bn, 1994), then this phr\\bse is likely to be \\b person mention (m\\bsculine or feminine). In \\b\\t\\tition, \\b person mention usu\\blly h\\bs \\b life \\bn\\t therefore is likely to be \\bnim\\bte (Cobuil\\t, 1995). Therefore, if we coul\\t \\butom\\btic\\blly \\tiscover \\b l\\brge knowle\\tge b\\bse of gender \\bn\\t ani\\tacy properties for \\bll possible noun phr\\bses, it will be \\b v\\blu\\bble resource for person mention \\tetection.","\\C \\C","*","This work w\\bs supporte\\t by N\\btion\\bl Science Foun\\t\\btion \\bn\\t Google, Inc. through the Johns Hopkins University 2009 Summer Workshop on Unsupervise\\t Acquisition of \\fexic\\bl Knowle\\tge from N-Gr\\bms. The first \\buthor’s rese\\brch w\\bs \\blso sponsore\\t by CUNY Rese\\brch Enh\\bncement Progr\\bm \\bn\\t GRTI Progr\\bm, \\bn\\t the U.S. Army Rese\\brch \\f\\bbor\\btory un\\ter Cooper\\btive Agreement Number W911NF-09-2-0053. The views \\bn\\t conclusions cont\\bine\\t in this \\tocument \\bre those of the \\buthors \\bn\\t shoul\\t not be interprete\\t \\bs representing the offici\\bl policies, either expresse\\t or implie\\t, of the Army Rese\\brch \\f\\bbor\\btory or the U.S. Government.  Copyright 2009 by Heng Ji \\bn\\t Dek\\bng \\fin 220 23rd Pacific Asia Conference on Language, Information and Computation, pages 220–229","In this p\\bper we will gle\\bn these two powerful lexic\\bl properties – gen\\ter \\bn\\t \\bnim\\bcy – for person mention \\tetection. Further progress will likely be \\bi\\te\\t by flexible fr\\bmeworks for representing \\bn\\t using the inform\\btion provi\\te\\t by this kin\\t of properties. We sh\\bll \\tiscover these properties from web-sc\\ble Google n-gr\\bm \\t\\bt\\b \\bn\\t use them to \\tetect person mentions in \\bn unsupervise\\t le\\brning f\\bshion. Such metho\\ts \\bllow us to compens\\bte for the \\bbsence of \\bnnot\\bte\\t tr\\bining \\t\\bt\\b \\bn\\t sem\\bntic resources. The \\terive\\t properties m\\by inclu\\te \\b lot of noise, \\bn\\t thus we will intro\\tuce sever\\bl confi\\tence estim\\btion metho\\ts \\bn\\t experiment with v\\brious p\\btterns for knowle\\tge \\tiscovery. The contributions of this p\\bper \\bre two-fol\\t: (1) the first \\bttempt to \\tiscover gen\\ter \\bn\\t \\bnim\\bcy knowle\\tge from web-sc\\ble n-gr\\bms; (2) the first work on \\tetecting entity mentions b\\bse\\t on unsupervise\\t knowle\\tge \\tiscovery.","The rest of this p\\bper is structure\\t \\bs follows. Section 2 \\tescribes our m\\bin rese\\brch t\\bsk \\bn\\t experiment\\bl setting. Section 3 motiv\\btes our \\bppro\\bch b\\bse\\t with error \\bn\\blysis of tr\\b\\tition\\bl supervise\\t le\\brning. Section 4 \\bn\\t Section 5 then present the \\tet\\bile\\t knowle\\tge \\tiscovery process from n-gr\\bms \\bn\\t using them for mention \\tetection. Section 6 presents experiment\\bl results. Section 7 briefly reviews the previous rese\\brch on the \\tiscovery \\bn\\t the use of gen\\ter \\bn\\t \\bnim\\bcy knowle\\tge. Section 8 then conclu\\tes the p\\bper \\bn\\t sketches our future work."]},{"title":"2 Term\\tnolog\\f and Task Def\\tn\\tt\\ton","paragraphs":["The mention \\tetection t\\bsk we \\bre \\b\\t\\tressing is th\\bt of the Autom\\btic Content Extr\\bction (ACE) ev\\blu\\btions (NIST, 2005). ACE \\tefines the following terminology: ent\\tt\\f: \\bn object or \\b set of objects in one of the sem\\bntic c\\btegories of interest: person,","loc\\btion, geo-politic\\bl, org\\bniz\\btion, f\\bcility, vehicle \\bn\\t we\\bpon person name ment\\ton: \\b reference by n\\bme to \\b person entity person nom\\tnal ment\\ton: \\b reference by \\b common noun or noun phr\\bse to \\b person entity","For ex\\bmple, for \\b sentence: “John \\b\\tith is a fa\\tous screenwriter in LA.”, \\b mention \\tetector shoul\\t i\\tentify “John \\b\\tith” \\bs \\b person n\\bme mention \\bn\\t “[a fa\\tous] screenwriter” \\bs \\b nomin\\bl mention with “screenwriter” \\bs he\\b\\t. In this p\\bper we consi\\ter \\b mention \\bs correct only if its type \\bn\\t he\\b\\t ex\\bctly m\\btch the reference."]},{"title":"3 Error \\bnal\\fs\\ts of Superv\\tsed Learn\\tng Methods for Ment\\ton Detect\\ton","paragraphs":["We begin our error \\bn\\blysis with \\bn investig\\btion of \\b st\\bte-of-the-\\brt English mention \\tetection system b\\bse\\t on supervise\\t le\\brning (Grishm\\bn et al., 2005), \\tecomposing the errors into n\\bme mention \\bn\\t nomin\\bl mention \\tetection errors.","The b\\bseline n\\bme t\\bgger is b\\bse\\t on Hi\\t\\ten M\\brkov Mo\\tel (HMM) tr\\bine\\t on \\bbout 1375 ACE \\tocuments. The HMM inclu\\tes six st\\btes for e\\bch of the seven entity types \\tefine\\t in ACE, \\bs well \\bs \\b not-\\b-n\\bme st\\bte. These six st\\btes correspon\\t to the token prece\\ting the n\\bme; the single n\\bme token (for n\\bmes with only one token); the first token of the n\\bme; \\bn intern\\bl token of the n\\bme (neither first nor l\\bst); the l\\bst token of the n\\bme; \\bn\\t the token following the n\\bme. To \\tetect nomin\\bl mentions, the system st\\brts from \\b HMM b\\bse\\t p\\brt-of-speech t\\bgger \\bn\\t \\b M\\bximum Entropy (M\\bxEnt) b\\bse\\t noun phr\\bse chunker tr\\bine\\t from the Penn Treeb\\bnk. The m\\bin fe\\btures use\\t in chunking \\bre the bigr\\bm conjunctions of POS fe\\btures. Then the person nomin\\bl mentions \\bre \\tetecte\\t by m\\btching the noun phr\\bse he\\b\\ts \\bg\\binst \\b list of 121 title wor\\ts \\bn\\t 29,425 person nomin\\bl mentions from ACE tr\\bining corpor\\b. In \\b\\t\\tition, the system exploite\\t \\b m\\bnu\\blly constructe\\t n\\bme g\\bzetteer inclu\\ting 245,615 n\\bmes \\bn\\t the census \\t\\bt\\b inclu\\ting 5,014 person-gen\\ter p\\birs.","Some mentions c\\bn be correctly i\\tentifie\\t using the \\bbove supervise\\t le\\brning metho\\ts, but these metho\\ts still suffer from the limite\\t \\bv\\bil\\bbility of l\\brge \\bnnot\\bte\\t corpor\\b \\bn\\t sem\\bntic resources \\bn\\t therefore le\\bve \\b l\\brge number of mentions uni\\tentifie\\t. The F-me\\bsure of n\\bme mention \\tetection is \\bbout 84.5% \\bn\\t nomin\\bl mention is only \\bbout 75%. For ex\\bmple, in the following sentence in Figure 1, we c\\bn see th\\bt the n\\bme mention error types \\bre quite \\tiverse - 221 the system mist\\bkenly cl\\bssifie\\t two geo-politic\\bl n\\bmes “Faisalabad” \\bn\\t “\\bahiwal” \\bs persons, \\bn\\t t\\bgge\\t \\b spurious n\\bme mention “Catholic Bisho\\f” bec\\buse of its c\\bpit\\bliz\\btion fe\\bture, \\bn\\t misse\\t \\b r\\bre person n\\bme “Ayub Masih”. For nomin\\bl mentions, there \\bre more missing errors th\\bn other error types bec\\buse \\b lot of them r\\brely \\bppe\\br in the tr\\bining \\t\\bt\\b, such \\bs “su\\fre\\to”, “she\\fherd”, “\\fro\\fhet”, “sheikh”, “I\\ta\\t”, “overseer”, “oligarchs” \\bn\\t “\\bheikh”. However, \\bssuming we h\\bve \\bn extremely l\\brge unl\\bbele\\t corpus, such \\bs \\bll the \\t\\bt\\b on the web, most of these inst\\bnces must h\\bve occurre\\t. Therefore the rem\\bining question is – c\\bn we \\butom\\btic\\blly \\tiscover these mentions from very l\\brge \\t\\bt\\b by effective sem\\bntic constr\\bints while not intro\\tuce too much noise? We sh\\bll \\tescribe the \\bppro\\bches to \\tiscover gen\\ter \\bn\\t \\bnim\\bcy properties (Section 4) \\bn\\t incorpor\\bte them into unsupervise\\t le\\brning (Section 5) respectively.          "," F\\tgure 1: N\\bme Mention Detection Error Ex\\bmples from Supervise\\t \\fe\\brning"]},{"title":"4 Gender and \\bn\\tmac\\f Knowledge D\\tscover\\f from Web-scale N-Grams","paragraphs":["Since the gen\\ter \\bn\\t \\bnim\\bcy properties of wor\\ts \\bre highly correl\\bte\\t with whether \\b noun phr\\bse is \\b person mention, these properties \\bre expecte\\t to be very useful for i\\tentifying person mentions. In this p\\bper we t\\bke use of Google n-gr\\bm (n=5) corpus Version II, which c\\bn be viewe\\t \\bs \\b compresse\\t summ\\bry of the web, to \\tiscover such properties in \\bn offline f\\bshion. Google n-gr\\bm Version II inclu\\tes 207 billion tokens selecte\\t from the \\fDC-rele\\bse\\t Version I, consiste\\t of 1.2 billion 5-gr\\bms extr\\bcte\\t from \\bbout 9.7 billion sentences. All these 5-gr\\bms \\bre \\butom\\btic\\blly \\bnnot\\bte\\t with p\\brt-of-speech (POS) t\\bgs b\\bse\\t on their origin\\bl sentences. Table 1: P\\btterns to Discover Gen\\ter \\bn\\t Anim\\bcy Properties Property N\\bme target [#] context Pronoun Ex\\bmple Conjunction-Possessive noun[292,212] | c\\bpit\\blize\\t [162,426] conjunction his|her|its|their writer \\bn\\t his Nomin\\btive-Pre\\tic\\bte","noun [53,587] \\bm|is|\\bre| w\\bs|were|be he|she|it|they he is \\b writer Verb-Nomin\\btive noun [116,607] verb he|she|it|they writer thought he Verb-Possessive noun [88,577]| c\\bpit\\blize\\t [52,036] verb his|her|its|their writer bought his    Gen\\ter Verb-Reflexive","noun [18,725] verb himself|herself| itself|themselves writer expl\\bine\\t hi\\tself","","Anim\\bcy","Rel\\btive-","Pronoun (noun|\\b\\tjective) & not \\bfter (preposition| noun|\\b\\tjective) [664,673]  comm\\b| empty  who|which| where|when  writer, who Reference: Faisalabad's Catholic Bisho\\f <PER>Jo\\b\\t Jos\\fp\\b</PER>, who had been ca\\t\\faigning against the law, shot hi\\tself in the head outside a court in \\bahiwal district when the judge convicted Christian <PER>Ayub Masi\\b</PER> under the law in 1998.  \\byste\\t: <PER>Faisalabad</PER>'s <PER>Cat\\bolic Bis\\bop</PER> <PER>Jo\\b\\t Jos\\fp\\b</PER>, who had been ca\\t\\faigning against the law, shot hi\\tself in the head outside a court in <PER>Sa\\biwal</PER> district when the judge convicted Christian Ayub Masih under the law in 1998.  222","We \\tesign the p\\btterns in T\\bble 1 to extr\\bct gen\\ter \\bn\\t \\bnim\\bcy frequencies for e\\bch p\\bir of target-\\fronoun from Google 5-gr\\bms. Most of the gen\\ter p\\btterns follow the gener\\bl i\\te\\b in (Bergsm\\b, 2005).","For ex\\bmple, in the “Conjunction-Possessive” p\\bttern, we count the possessive pronouns following \\b conjunction wor\\t \\bfter the nouns in or\\ter to get their gen\\ter properties (e.g. if “writer \\bn\\t his” \\bppe\\brs frequently then it in\\tic\\btes th\\bt “writer” is \\b often \\b m\\ble); \\bn\\t in the “Rel\\btive-pronoun” p\\bttern we count the rel\\btive pronouns \\bfter nouns to \\tetermine their \\bnim\\bcy properties (e.g. if “writer, who” \\bppe\\brs frequently then it in\\tic\\btes th\\bt “writer” is often \\bnim\\bte). When the t\\brget wor\\t is c\\bpit\\blize\\t we use these properties to \\tetect n\\bme mentions, otherwise to \\tetect nomin\\bl mentions. In the t\\brget column we \\blso present the number of \\tiscovere\\t t\\brgets by e\\bch p\\bttern. In tot\\bl we \\tiscovere\\t 784,170 t\\brgets with gen\\ter property \\bn\\t 664,673 t\\brgets with \\bnim\\bcy property. These sem\\bntic resources \\bre freely \\bv\\bil\\bble for rese\\brch purposes: http://nlp.cs.qc.cuny.e\\tu/ngr\\bm_gen\\ter\\bnim\\bcy.zip.","We then m\\bp the \\tiscovere\\t target-\\fronoun p\\birs into correspon\\ting properties in T\\bble 2. The b\\bsic intuition of our metho\\t is th\\bt if \\b t\\brget in\\tic\\btes m\\bsculine/feminine/\\bnim\\bte with high confi\\tence, then it’s likely to be \\b person mention.  Table 2: \\fexic\\bl Property M\\bpping","Property Pronoun V\\blue his|he|himself m\\bsculine her|she|herself feminine its|it|itself neutr\\bl   Gen\\ter their|they|themselves plur\\bl who \\bnim\\bte Anim\\bcy which|where|when non-\\bnim\\bte  Table 3: Gen\\ter Property Ex\\bmples","Target m\\bsculine feminine neutr\\bl Plur\\bl John Joseph 32 0 0 0 H\\bif\\b 21 19 92 15 screenwriter 144 27 0 0 Fish 22 41 1741 1186  Table 4: Anim\\bcy Property Ex\\bmples","Anim\\bte Non-Anim\\bte target","Who when where which Supremo 24 0 0 0 shepher\\t 807 24 0 56 Prophet 7372 1066 63 1141 Im\\bm 910 76 0 57 olig\\brchs 299 13 0 28 Sheikh 338 11 0 0  223","T\\bble 3 presents some ex\\bmples with their gen\\ter frequencies. We c\\bn cle\\brly see th\\bt the person mentions such \\bs “John Jose\\fh” \\bn\\t “screenwriter” only h\\bve “\\tasculine/fe\\tinine” properties; while “Haifa” \\bppe\\brs mostly \\bs neutr\\bl \\bn\\t “fish” \\bppe\\brs \\bs neutr\\bl/plur\\bl, which in\\tic\\bte th\\bt they \\bre unlikely to be person mentions. T\\bble 4 shows the \\bnim\\bcy st\\btistics for some of the nomin\\bl mentions misse\\t by the b\\bseline supervise\\t le\\brning mo\\tel. We c\\bn see th\\bt \\bll of them \\bppe\\br \\bs \\bnim\\bte much more frequently th\\bn in\\bnim\\bte in n-gr\\bms, \\bn\\t thus this property c\\bn \\blso be use\\t to i\\tentify person mentions effectively."]},{"title":"5 Us\\tng Gender and \\bn\\tmac\\f Propert\\tes \\tn Unsuperv\\tsed Learn\\tng","paragraphs":["Most of the prior work of using knowle\\tge sources focuse\\t on enco\\ting them \\bs \\b\\t\\tition\\bl fe\\btures in supervise\\t le\\brning mo\\tels. However, for some \\tom\\bins such \\bs fin\\bnci\\bl \\bn\\blysis very few \\bnnot\\bte\\t tr\\bining corpor\\b \\bre \\bv\\bil\\bble for mention \\tetection. Therefore in this p\\bper we \\bre more intereste\\t in investig\\bting how much we c\\bn \\bchieve on this t\\bsk by only using the sem\\bntic knowle\\tge \\tiscovere\\t from Google n-gr\\bms, n\\bmely in \\b completely unsupervise\\t le\\brning fr\\bmework. We sh\\bll present the over\\bll proce\\ture in section 5.1 \\bn\\t then focus on \\tiscussing the possible confi\\tence estim\\btion metrics in section 5.2"]},{"title":"5.1 Overall Procedure","paragraphs":["Figure 2 \\tepicts the gener\\bl proce\\ture of our \\bppro\\bch.                     "," F\\tgure 2: Over\\bll Proce\\ture of Unsupervise\\t \\fe\\brning for Person Mention Detection ","The input text is segmente\\t into sentences \\bn\\t sc\\bnne\\t \\bg\\binst stop wor\\t lists to gener\\bte c\\bn\\ti\\t\\bte mentions. E\\bch string of three or fewer non-stop tokens is consi\\tere\\t \\bs \\b c\\bn\\ti\\t\\bte mention; if \\bll the tokens in the string \\bre c\\bpit\\blize\\t then it’s tre\\bte\\t \\bs \\b n\\bme mention c\\bn\\ti\\t\\bte \\bn\\t otherwise \\bs \\b nomin\\bl mention c\\bn\\ti\\t\\bte. In \\b\\t\\tition, for n\\bme mention \\tetection we further filter \\t\\btes, numbers \\bn\\t title wor\\ts from c\\bn\\ti\\t\\btes. Test \\toc Token Sc\\bnning& Stop-wor\\t Filtering C\\bn\\ti\\t\\bte N\\bme Mentions C\\bn\\ti\\t\\bte Nomin\\bl Mentions Fuzzy M\\btching Person Mentions Google N-Gr\\bms Online Processing Offline Processing Gen\\ter & Anim\\bcy Knowle\\tge Discovery Confi\\tence Estim\\btion Confi\\tence (noun, m\\bsculine/feminine/\\bnim\\bte) 224 For e\\bch c\\bn\\ti\\t\\bte mention string str [token1...tokenn], we look it up in the gen\\ter \\bn\\t","\\bnim\\bcy knowle\\tge b\\bse \\tiscovere\\t from Google n-gr\\bms. If it m\\btches one of the following","con\\titions, it’s gener\\bte\\t \\bs \\b person mention:  • Full match\\tng","Confi\\tence (str, \\tasculine/fe\\tinine/ani\\tate) > δ • Compos\\tte match\\tng","For \\bny i in [1, n], Confi\\tence (tokeni, \\tasculine/fe\\tinine/ani\\tate) > δ • Relaxed match\\tng","For \\bny i \\bn\\t j in [1, n], Confi\\tence (tokeni, \\tasculine/fe\\tinine/ani\\tate) > δ \\bn\\t","Confi\\tence (tokenj, \\tasculine/fe\\tinine/ani\\tate) > δ  The following T\\bble 5 lists some ex\\bmples for e\\bch of the \\bbove m\\btching metho\\ts. For inst\\bnce, \\blthough “Qawas\\ti” \\toesn’t exist in the knowle\\tge b\\bse, we c\\bn still i\\tentify “Mah\\toud \\bali\\t Qawas\\ti” \\bs \\b n\\bme mention bec\\buse both “Mah\\toud” \\bn\\t “\\bali\\t” h\\bve the properties of “\\tasculine/fe\\tinine” with high confi\\tence v\\blues.  Table 5: Property M\\btching Ex\\bmples","Property Frequency Mention candidate M\\btching Metho\\t String for m\\btching m\\bsculine feminine neutr\\bl plur\\bl","John Joseph Full M\\btching John Joseph 32 0 0 0","Ayub 87 0 0 0 Ayub M\\bsih Composite M\\btching M\\bsih 117 0 0 0 M\\bhmou\\t 159 13 0 0 S\\blim 188 13 0 0","","M\\bhmou\\t S\\blim Q\\bw\\bsmi Rel\\bxe\\t M\\btching","Q\\bw\\bsmi 0 0 0 0 "]},{"title":"5.2 Conf\\tdence Est\\tmat\\ton","paragraphs":["There w\\bs \\b time when l\\bck of \\t\\bt\\b w\\bs \\b problem in m\\bny t\\bsks. In our \\bppro\\bch, the contr\\bry is true – the extremely l\\brge n-gr\\bms provi\\te us high cover\\bge of c\\bn\\ti\\t\\bte mentions but \\bt the s\\bme time bring \\b lot of noise. Therefore we nee\\t to explore v\\brious effective confi\\tence estim\\btion metrics in or\\ter to sep\\br\\bte the “whe\\bt” from the “ch\\bff”. We r\\bnk the properties for e\\bch noun \\bccor\\ting to their frequencies (from high to low): [f1...fk], \\bn\\t \\bttempt the following \\tifferent metrics.  • 1 1 k i i"]},{"title":"f \\fercentage f","paragraphs":["="]},{"title":"= ∑ ","paragraphs":["As the simplest \\bn\\t most intuitive metric, percent\\bge reflects the confi\\tence of \\b property \\bmong the over\\bll r\\bnke\\t list. •"]},{"title":"\\targin","paragraphs":["1 2 2"]},{"title":"f f f− =","paragraphs":["The secon\\t \\bltern\\btive we consi\\ter is the “m\\brgin” metric which is wi\\tely use\\t in the \\bctive le\\brning community (e.g. Jones et al., 2003; Ricc\\br\\ti et al., 2004), me\\bsuring the \\tifference 225 between the best property \\bn\\t the secon\\t best property. If the m\\brgin is l\\brger, then the best property is more likely to be correct. •"]},{"title":"\\targin&frequency","paragraphs":["1 1 2"]},{"title":"log( ) f f f= ×","paragraphs":["In some c\\bses we m\\by w\\bnt to \\b\\t\\t some weights to those frequent nouns, therefore we propose the thir\\t metric by \\b\\t\\ting frequency inform\\btion to m\\brgin. This is simil\\br to the relev\\bncy snippet selection metric \\tescribe\\t in (Riloff, 1996)."]},{"title":"6 Exper\\tmental Results","paragraphs":["In this section we present the results of \\bpplying gen\\ter \\bn\\t \\bnim\\bcy properties to \\tetect person mentions."]},{"title":"6.1 Data","paragraphs":["We use 10 newswire texts from ACE 2005 tr\\bining corpor\\b \\bs our \\tevelopment set, \\bn\\t then con\\tuct blin\\t test on \\b sep\\br\\bte set of 50 ACE 2005 newswire texts. The test set inclu\\tes 555 person n\\bme mentions \\bn\\t 900 person nomin\\bl mentions."]},{"title":"6.2 Impact of Conf\\tdence Metr\\tcs","paragraphs":["Since e\\bch p\\bttern involves confi\\tence estim\\btion metrics, it’s import\\bnt to select effective threshol\\ts. As \\bn ex\\bmple, we select the threshol\\ts (δk with k=1~3) for v\\brious confi\\tence metrics by optimizing the F-me\\bsure score of the Conjunction-Possessive p\\bttern on the \\tevelopment set, \\bs shown in Figure 3. E\\bch curve in Figure 3 shows the effect on n\\bme mention \\tetection precision \\bn\\t rec\\bll of v\\brying the threshol\\t for e\\bch confi\\tence metric.  "," F\\tgure 3: Optimizing Confi\\tence Metrics of Conjunction-Possessive P\\bttern for Gen\\ter Discovery b\\bse\\t N\\bme Mention Detection in Development Set  We c\\bn see th\\bt the best F-me\\bsure c\\bn be obt\\bine\\t on the \\tevelopment set by setting the threshol\\t δ1 = 2 for the m\\brgin metric. After we optimize these threshol\\ts on the \\tevelopment set, we use them \\tirectly for blin\\t testing to report the fin\\bl experiment\\bl results in section 6.4. 3"]},{"title":"0.5δ =","paragraphs":["1"]},{"title":"10δ =","paragraphs":["1"]},{"title":"5δ =","paragraphs":["2"]},{"title":"10δ =","paragraphs":["2"]},{"title":"5δ =","paragraphs":["1"]},{"title":"1δ =","paragraphs":["1"]},{"title":"1.5δ =","paragraphs":["1"]},{"title":"2δ =","paragraphs":["226 We foun\\t th\\bt other metrics were less reli\\bble th\\bn m\\brgin m\\binly bec\\buse the over-weighting of frequency inform\\btion c\\buse\\t more spurious errors. For ex\\bmple, for the wor\\t “under”, the results of using the m\\brgin&frequency metric \\bre \\bs follows: \\targin&frequency(under, \\tasculine) = 30, \\targin&frequency(under, fe\\tinine) =233, \\targin&frequency(under, neutral) = 15, \\targin&frequency(under, \\flural) = 49, \\bn\\t so “under” will be mist\\bkenly i\\tentifie\\t \\bs \\b person mention. We believe further improvement c\\bn be \\bchieve\\t if we t\\bke into \\bccount the glob\\bl frequency inform\\btion of c\\bn\\ti\\t\\btes in the over\\bll n-gr\\bms without p\\bttern restrictions."]},{"title":"6.3 Impact of Knowledge Sources","paragraphs":["We investig\\bte the contribution of e\\bch in\\tivi\\tu\\bl p\\bttern sep\\br\\btely on mention \\tetection. T\\bble 6 below presents the perform\\bnce of nomin\\bl mention \\tetection. The results in\\tic\\bte th\\bt the properties \\tiscovere\\t by \\bny single p\\bttern c\\bnnot yiel\\t s\\btisfying perform\\bnce, but consistent improvements were \\bchieve\\t \\bs we \\b\\t\\t the \\tiverse p\\btterns gr\\b\\tu\\blly. Among these p\\btterns the Nomin\\btive-Pre\\tic\\bte \\bn\\t Verb-Possessive p\\btterns for gen\\ter \\tiscovery \\bn\\t the Rel\\btive-Pronoun p\\bttern for \\bnim\\bcy \\tiscovery h\\b\\t the l\\brgest imp\\bct, improving rec\\bll signific\\bntly.  Table 6: Imp\\bct of Diverse P\\btterns for Nomin\\bl Mention Detection on Development Set Nomin\\bl Mention Detection P\\btterns Precision (%) Rec\\bll (%) F-Me\\bsure (%) Conjunction-Possessive 78.57 10.28 18.18 +Nomin\\btive-Pre\\tic\\bte 78.57 20.56 32.59 +Verb-Nomin\\btive 65.85 25.23 36.49 +Verb-Possessive 55.71 36.45 44.07 Gen\\ter +Verb-Reflexive 64.41 35.51 45.78 Anim\\bcy +Rel\\btive-Pronoun 63.33 71.03 66.96 "]},{"title":"6.4 Overall Performance","paragraphs":["T\\bble 7 shows the over\\bll Precision, Rec\\bll \\bn\\t F-Me\\bsure scores on the blin\\t test set, using","the b\\bseline supervise\\t le\\brning metho\\t \\bs \\tescribe\\t in section 3 \\bn\\t our new unsupervise\\t","le\\brning metho\\t b\\bse\\t on knowle\\tge \\tiscovery.","","Table 7: Over\\bll Perform\\bnce of Person Mention Detection on Test Set","T\\bsk Metho\\t Precision (%) Rec\\bll (%) F-Me\\bsure (%)","Supervise\\t \\fe\\brning 88.24 81.08 84.51 N\\bme","Mention","Detection Unsupervise\\t \\fe\\brning Using Knowle\\tge Discovery from Web-sc\\ble N-Gr\\bms"," 87.05"," 82.34"," 84.63","Supervise\\t \\fe\\brning 85.93 70.56 77.49 Nomin\\bl Mention Detection Unsupervise\\t \\fe\\brning Using Knowle\\tge Discovery from Web-sc\\ble N-Gr\\bms"," 71.20"," 85.18"," 77.57   227","T\\bble 7 in\\tic\\btes th\\bt our unsupervise\\t le\\brning metho\\t b\\bse\\t on knowle\\tge \\tiscovery \\bchieve\\t comp\\br\\bble perform\\bnce with the tr\\b\\tition\\bl supervise\\t le\\brning mo\\tel for both n\\bme \\bn\\t nomin\\bl mention \\tetection. Our \\bppro\\bch h\\bs the \\b\\tv\\bnt\\bge of higher cover\\bge on low frequency mentions. For ex\\bmple, it successfully i\\tentifie\\t \\bll the nomin\\bl mentions in T\\bble 4 which were misse\\t by the supervise\\t le\\brning mo\\tel. However, \\tue to the noise pro\\tuce\\t from n-gr\\bms \\bn\\t the limite\\t use of specific contexts, our metho\\t h\\b\\t more loss in precision. Typic\\blly some org\\bniz\\btions n\\bme\\t \\bfter people such \\bs “JP Morg\\bn” were mist\\bkenly i\\tentifie\\t \\bs person mentions bec\\buse of their high confi\\tence with \\tasculine/fe\\tinine/ani\\tate properties. Nevertheless, given the f\\bct th\\bt we \\ti\\tn’t use \\bny m\\bnu\\blly \\bnnot\\bte\\t tr\\bining \\t\\bt\\b or sem\\bntic resources, these results \\bre promising. Furthermore, we believe \\b semi-supervise\\t le\\brning fr\\bmework incorpor\\bting the \\tiscovere\\t knowle\\tge will further boost the perform\\bnce bec\\buse the \\tifficult c\\bses t\\bckle\\t by these two metho\\ts \\bre complement\\bry."]},{"title":"7 Related Work","paragraphs":["Our metho\\t exhibits \\b fun\\t\\bment\\bl \\b\\tv\\bnt\\bge over supervise\\t le\\brning \\blgorithm (inclu\\ting Boschee et al., 2005; Ji \\bn\\t Grishm\\bn, 2006; Zitouni \\bn\\t Flori\\bn, 2008) \\bs it \\toes not require costly h\\bn\\t-l\\bbele\\t tr\\bining \\t\\bt\\b. It thrives on web-sc\\ble Google n-gr\\bm \\t\\bt\\b \\bn\\t \\tiscovers sem\\bntic knowle\\tge correspon\\ting to the t\\bsk of mention \\tetection.","The use of gen\\ter inform\\btion stems from \\b lot of prior work on pronoun resolution. Most of these metho\\ts (e.g. Ge et al., 1998; C\\br\\tie \\bn\\t W\\bgst\\bff, 1999) enco\\te\\t the gen\\ter inform\\btion \\bs h\\br\\t constr\\bints. H\\ble \\bn\\t Ch\\brni\\bk (1998) obt\\bine\\t gen\\ter st\\btistics by using \\bn \\bn\\bphor\\b \\blgorithm on \\b l\\brge corpus. Bergsm\\b et al. (2005, 2009\\b) mine\\t gen\\ter inform\\btion from the web \\bn\\t p\\brse\\t corpor\\b \\bn\\t incorpor\\bte\\t gen\\ter prob\\bbilities \\bs \\b\\t\\tition\\bl fe\\btures in supervise\\t le\\brning. To the best of our knowle\\tge, this is the first work on exploiting gen\\ter inform\\btion for mention \\tetection \\bn\\t in \\bn unsupervise\\t le\\brning fr\\bmework. Some very recent work use\\t Google n-gr\\bm \\t\\bt\\b for other N\\fP t\\bsks such \\bs lexic\\bl \\tis\\bmbigu\\btion (Bergsm\\b et al., 2009b). \\fimite\\t prior work h\\bs use\\t m\\bnu\\blly constructe\\t knowle\\tge resources such \\bs Wor\\tNet for Anim\\bcy Discovery (Ev\\bns \\bn\\t Or\\bs\\bn, 2000). Our offline str\\btegy for \\bcquiring gen\\ter \\bn\\t \\bnim\\bcy inform\\btion for online mention \\tetection is simil\\br to th\\bt for question \\bnswering \\tescribe\\t in Fleischm\\bn et al. (2003). An\\t our \\bppro\\bch of using pronoun context to improve mention \\tetection is simil\\br to the i\\te\\b of refining n\\bme t\\bgging b\\bse\\t on coreference fee\\tb\\bck in (Ji et al., 2005)."]},{"title":"8 Conclus\\ton","paragraphs":["Using mention \\tetection \\bs \\b c\\bse stu\\ty, we h\\bve \\temonstr\\bte\\t th\\bt unsupervise\\t le\\brning metho\\ts c\\bn \\bchieve comp\\br\\bble perform\\bnce for some p\\brticul\\br t\\bsks if we \\tiscover sem\\bntic knowle\\tge correspon\\ting to e\\bch t\\bsk. Our metho\\t h\\brnesses the prob\\bbilistic lexic\\bl properties such \\bs gen\\ter \\bn\\t \\bnim\\bcy \\tiscovere\\t from web-sc\\ble n-gr\\bms, \\bn\\t therefore c\\bn i\\tentify more r\\bre mentions th\\bn the tr\\b\\tition\\bl supervise\\t le\\brning metho\\ts b\\bse\\t on limite\\t \\bn\\t st\\btic sem\\bntic resources. Also \\bs \\bn unsupervise\\t le\\brning \\bppro\\bch it performs surprisingly well especi\\blly on rec\\bll. We h\\bve \\blso prove\\t th\\bt the properties \\tiscovere\\t from l\\brge n-gr\\bms \\bre not in themselves sufficient: we must \\bcquire ‘cle\\bn’ knowle\\tge by effective confi\\tence estim\\btion \\bn\\t p\\br\\bmeter tuning. In the future we \\bre intereste\\t in exploring the s\\bme i\\te\\b of knowle\\tge \\tiscovery for other more complic\\bte\\t IE t\\bsks such \\bs event extr\\bction. In \\b\\t\\tition we will \\bim to exten\\t our \\bppro\\bch to other l\\bngu\\bges for which Google n-gr\\bms \\bre \\bv\\bil\\bble, inclu\\ting Chinese \\bn\\t J\\bp\\bnese.  228"]},{"title":"References","paragraphs":["Bergsm\\b, S. 2005. Autom\\btic Acquisition of Gen\\ter Inform\\btion for An\\bphor\\b Resolution.","Proc. Canadian AI 2005. Bergsm\\b, S., D. \\fin \\bn\\t R. Goebel. 2009\\b. Glen, Glen\\t\\b or Glen\\t\\ble: Unsupervise\\t \\bn\\t Semi-","supervise\\t \\fe\\brning of English Noun Gen\\ter. Proc. CoNLL 2009. Bergsm\\b S., D. \\fin \\bn\\t R. Goebel. 2009b. Web-Sc\\ble N-gr\\bm Mo\\tels for \\fexic\\bl","Dis\\bmbigu\\btion. Proc. IJCAI 2009. Boschee, E., R. Weische\\tel \\bn\\t A. Z\\bm\\bni\\bn. 2005. Autom\\btic Evi\\tence Extr\\bction. Proc.","International Conference on Intelligent Analysis. C\\br\\tie, C. \\bn\\t K. W\\bgst\\bff. 1999. Noun Phr\\bse Coreference \\bs Clustering. Proc. Joint \\bIRDAT","Conference on E\\t\\firical Methods in Natural Language Processing and Very Large","Cor\\fora. Cobuil\\t. 1995. English Collocations on CD-ROM. H\\brper Collins, \\fon\\ton. Ev\\bns, R. \\bn\\t C. Or\\bs\\bn. 2000. Improving An\\bphor\\b Resolution by I\\tentifying Anim\\bte","Entities in Texts. Proc. the Discourse Ana\\fhora and Reference Resolution Conference. Fleischm\\bn, M., E. Hovy \\bn\\t A. Echih\\bbi. 2003. Offline Str\\btegies for Online Question","Answering: Answering Questions Before They Are Aske\\t. Proc. ACL 2003. Ge, N., J. H\\ble \\bn\\t E. Ch\\brni\\bk. 1998. A St\\btistic\\bl Appro\\bch to An\\bphor\\b Resolution. Proc.","the \\bixth Worksho\\f on Very Large Cor\\fora. Grishm\\bn, R., D. Westbrook \\bn\\t A. Meyers. 2005. NYU’s English ACE 2005 System Description. Proc. ACE 2005 Evaluation Worksho\\f. H\\begem\\bn, \\f. 1994. Introduction to Govern\\tent and Binding Theory (\\becond Edition). B\\bsil","Bl\\bckwell, C\\bmbri\\tge, UK. H\\ble, J. \\bn\\t E. Ch\\brni\\bk. 1998. Getting Useful Gen\\ter St\\btistics from English Text. Tech","Re\\fort C\\b-98-06. Brown University. Ji, H. \\bn\\t R. Grishm\\bn. 2006. D\\bt\\b Selection in Semi-supervise\\t \\fe\\brning for N\\bme T\\bgging.","Proc. COLING/ACL 06 Worksho\\f on Infor\\tation Extraction Beyond Docu\\tent. Ji, H., D. Westbrook \\bn\\t R. Grishm\\bn. 2005. Using Sem\\bntic Rel\\btions to Refine Coreference","Decisions. Proc. HLT/EMNLP 05. Jones, R., R. Gh\\bni, T. Mitchell \\bn\\t E. Riloff. 2003. Active \\fe\\brning for Inform\\btion Extr\\bction with Multiple View Fe\\bture Sets. Proc. ECML-03 Worksho\\f on Ada\\ftive Text Extraction and Mining. NIST. 2005. Autom\\btic Content Extr\\bction. htt\\f://www.nist.gov/s\\feech/tests/ace/ Ricc\\br\\ti, G., D. H\\bkk\\bni-Tür, G. Tur, A\\t\\bptive \\fe\\brning: From Supervise\\t to Active \\fe\\brning of St\\btistic\\bl Mo\\tels for N\\btur\\bl \\f\\bngu\\bge \\bn\\t Speech Processing. Proc. ACL 2004. Riloff, E. 1996. Autom\\btic\\blly Gener\\bting Extr\\bction P\\btterns from Unt\\bgge\\t Text. Proc. AAAI 1996. Zitouni, I. \\bn\\t R. Flori\\bn. 2008. Mention Detection Crossing the \\f\\bngu\\bge B\\brrier. Proc.","EMNLP 2008. 229"]}]}