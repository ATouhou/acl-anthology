{"sections":[{"title":"Extendin\\b\\tBilin\\b\\fal\\tWordNet\\tvia\\t Hierarchical\\tWord\\tTranslation\\tClassification* \\t \\t","paragraphs":["Tzu-yi \\bi\\tna",", T\\fun Kub , Chung-chi Huanga",", M\\ti-hua Ch\\tna",", and Ja\\fon S. Changa  a In\\ftitut\\t of Information Sy\\ft\\tm\\f and Application\\f, \\bational","T\\fing Hua Univ\\tr\\fity, H\\finChu, Taiwan 300, R.O.C. {zini\\tn, u901571, ch\\tn.m\\tihua, ja\\fon.j\\fchang}@gmail.com b In\\ftitut\\t for Information Indu\\ftry, 11F, \\bo. 106, S\\tction 2,","H\\tping Ea\\ft Road, Taip\\ti, Taiwan 106, R.O.C.","cujing@iii.org.tw  Abstract. W\\t introduc\\t a m\\tthod for l\\tarning to a\\f\\fign word \\f\\tn\\f\\t\\f to tran\\flation pair\\f. In our approach, thi\\f \\f\\tn\\f\\t a\\f\\fignm\\tnt or di\\fambiguation probl\\tm i\\f tran\\fform\\td into on\\t on how to navigat\\t through a \\f\\tn\\f\\t n\\ttwork lik\\t Word\\b\\tt aim\\td at di\\ftingui\\fhing th\\t mor\\t ad\\tquat\\t \\f\\tn\\f\\t\\f from oth\\tr\\f. Th\\t m\\tthod involv\\t\\f automatically con\\ftructing cla\\f\\fification mod\\tl\\f for branching nod\\t\\f in th\\t n\\ttwork, and automatically l\\tarning to r\\tj\\tct l\\t\\f\\f probabl\\t \\f\\tn\\f\\t\\f, ba\\f\\td on th\\t tran\\flation charact\\tri\\ftic\\f of word \\f\\tn\\f\\t\\f and \\f\\tmanticallyr\\tlat\\td word group\\f (\\t.g., l\\txicograph\\tr fil\\t\\f) r\\t\\fp\\tctiv\\tly. At run-tim\\t, tran\\flation pair\\f ar\\t \\txpand\\td with th\\tir \\fynonym\\f and \\f\\tn\\f\\t ambiguity i\\f r\\t\\folv\\td u\\fing a gr\\t\\tdy algorithm choo\\fing th\\t mo\\ft lik\\tly branch\\t\\f ba\\f\\td on th\\t train\\td cla\\f\\fification mod\\tl\\f. Evaluation \\fhow\\f that our m\\tthod \\fignificantly outp\\trform\\f th\\t \\ftrong ba\\f\\tlin\\t of a\\f\\figning mo\\ft fr\\tqu\\tnt \\f\\tn\\f\\t to th\\t tran\\flation pair\\f and \\tff\\tctiv\\tly d\\tt\\trmin\\t\\f \\fuitabl\\t word \\f\\tn\\f\\t\\f for giv\\tn tran\\flation pair\\f, \\fugg\\t\\fting th\\t po\\f\\fibility of \\tmploying our m\\tthod a\\f a comput\\tr-a\\f\\fi\\ft\\td tool for \\fp\\t\\tding up th\\t proc\\t\\f\\f of l\\txicography or of u\\fing our m\\tthod to a\\f\\fi\\ft machin\\t tran\\flation \\fy\\ft\\tm\\f in word \\f\\tl\\tction. Keywords:\\tWord \\f\\tn\\f\\t di\\fambiguation, word tran\\flation cla\\f\\fification, Word\\b\\tt, machin\\t-l\\tarning t\\tchniqu\\t, maximum \\tntropy mod\\tl. \\a  Copyright 2009 by Tzu-yi \\bi\\tn, T\\fun Ku, Chung-chi Huang, M\\ti-hua Ch\\tn, and Ja\\fon S. Chang"]},{"title":"1 Introd\\fction\\t","paragraphs":["Many word\\f (\\t.g., plant) hav\\t diff\\tr\\tnt \\f\\tn\\f\\t\\f in diff\\tr\\tnt cont\\txt\\f (\\t.g., \\b\\teen plant and nu\\flea\\t plant), u\\fually l\\tading to diff\\tr\\tnt tran\\flation\\f in anoth\\tr languag\\t (\\t.g., 植物 and 工廠 r\\t\\fp\\tctiv\\tly). On th\\t oth\\tr hand, diff\\tr\\tnt word\\f (\\t.g., plant and fa\\fto\\ty) may \\txpr\\t\\f\\f v\\try \\fimilar m\\taning\\f (\\t.g., the wo\\tkin\\b pla\\fe fo\\t indust\\tial labo\\ts). Th\\tr\\tfor\\t, Word\\b\\tt (Mill\\tr et al., 1990), a \\f\\tn\\f\\t inv\\tntory \\tncoding with \\f\\tmantic r\\tlat\\tdn\\t\\f\\f of word\\f, ha\\f b\\t\\tn a valuabl\\t r\\t\\fourc\\t in th\\t fi\\tld of natural languag\\t proc\\t\\f\\fing \\finc\\t it\\f introduction. In Word\\b\\tt, nominal, v\\trbal, adj\\tctiv\\t, and adv\\trbial word\\f ar\\t group\\td into \\fynonym \\f\\tt\\f, or \\fo-call\\td \\fyn\\f\\tt\\f and \\fyn\\f\\tt\\f ar\\t int\\trlink\\td with variou\\f \\f\\tmantic r\\tlation\\f (\\t.g., hype\\tnym, hyponym and \\ttc). It\\f rich and w\\tll-d\\tfin\\td l\\txical \\f\\tmantic r\\tlation\\f hav\\t mad\\t Word\\b\\tt an important knowl\\tdg\\t \\fourc\\t for variou\\f r\\t\\f\\tarch ar\\ta\\f: word \\f\\tn\\f\\t di\\fambiguation; comput\\tr-a\\f\\fi\\ft\\td languag\\t l\\tarning; information r\\ttri\\tval.","Th\\t w\\tll-\\t\\ftabli\\fh\\td l\\txical hi\\trarchy r\\t\\fiding in Engli\\fh Word\\b\\tt ha\\f prompt\\td r\\t\\f\\tarch\\tr\\f to con\\ftruct Word\\b\\tt-lik\\t \\f\\tn\\f\\t inv\\tntory for oth\\tr languag\\t\\f. Tak\\t th\\t Chin\\t\\f\\t languag\\t for \\txampl\\t. Effort\\f hav\\t b\\t\\tn mad\\t on automatic con\\ftruction and on manual 375 23rd Pacific Asia Conference on Language, Information and Computation, pages 375–384  tran\\flation from Engli\\fh Word\\b\\tt into Chin\\t\\f\\t. Chin\\t\\f\\t tran\\flation\\f in th\\t latt\\tr ca\\f\\t, how\\tv\\tr, may not \\fuffici\\tntly cov\\tr th\\t \\fcop\\t. It would b\\t mor\\t \\tffici\\tnt and co\\ft-\\tff\\tctiv\\t if tran\\flation\\f of variou\\f word \\f\\tn\\f\\t\\f could b\\t automatically int\\tgrat\\td from bilingual \\fourc\\t\\f (\\t.g., dictionari\\t\\f and phra\\f\\t tabl\\t\\f in machin\\t tran\\flation \\fy\\ft\\tm\\f).","Con\\fid\\tr th\\t word “plant” with th\\t \\f\\tn\\f\\t of “buildin\\bs fo\\t \\fa\\t\\tyin\\b on indust\\tial labo\\t” and th\\t \\f\\tn\\f\\t of “a livin\\b o\\t\\banism la\\fkin\\b the powe\\t of lo\\fomotion”, and 廠房 (manufactory), on\\t of it\\f Chin\\t\\f\\t tran\\flation\\f. A\\f\\fum\\t that “廠房” i\\f un\\f\\t\\tn in a bilingual Word\\b\\tt (\\t.g., Engli\\fh Word\\b\\tt with Chin\\t\\f\\t tran\\flation\\f). Th\\t b\\t\\ft way to incorporat\\t \\fuch a n\\tw tran\\flation i\\f probably not blindly a\\f\\figning it to all th\\t \\f\\tn\\f\\t\\f of “plant”. A good way might b\\t to id\\tntify th\\t mo\\ft appropriat\\t \\f\\tn\\f\\t for th\\t tran\\flation, in thi\\f ca\\f\\t, “plant#1” (i.\\t., buildin\\bs fo\\t \\fa\\t\\tyin\\b on indust\\tial labo\\t). Intuitiv\\tly, by l\\tv\\traging \\f\\tn\\f\\t-to-tran\\flation r\\tlation\\f, \\fuch \\f\\tn\\f\\t ambiguity could b\\t r\\t\\folv\\td.","","Fi\\b\\fre\\t1: An \\txampl\\t cla\\f\\fifying diagram for (plant, 廠房). Th\\t corr\\tct \\f\\tn\\f\\t for thi\\f tran\\flation pair i\\f","“plant#1”. \\bot\\t that our cla\\f\\fification mod\\tl\\f ar\\t appli\\td on thr\\t\\t branching1","\\fyn\\f\\tt\\f (i.\\t., “\\tntity”,","“unit”, and “organi\\fm”) and that th\\t Word\\b\\tt hi\\trarchy \\fhown h\\tr\\t i\\f \\fimplifi\\td: non-branching \\fyn\\f\\tt\\f","ar\\t hidd\\tn and r\\tpr\\t\\f\\tnt\\td by da\\fh\\td lin\\t\\f.","W\\t pr\\t\\f\\tnt a hi\\trarchical word tran\\flation cla\\f\\fification (WTC) mod\\tl that automatically l\\tarn\\f to attach tran\\flation\\f of Engli\\fh word\\f to th\\t ad\\tquat\\t word \\f\\tn\\f\\t\\f. An \\txampl\\t cla\\f\\fification diagram for (plant, 廠房) i\\f \\fhown in Figur\\t 1. Path\\f from th\\t root, “\\tntity”, to th\\t four nominal \\f\\tn\\f\\t\\f of “plant” ar\\t highlight\\td and our goal i\\f to find th\\t \\fuitabl\\t \\f\\tn\\f\\t for th\\t <word, tran\\flation> pair. Our mod\\tl l\\tarn\\f to navigat\\t through th\\t l\\txical hi\\trarchy in Word\\b\\tt (to d\\tt\\trmin\\t th\\t \\f\\tn\\f\\t for th\\t giv\\tn tran\\flation) during training by analyzing a coll\\tction of tran\\flation pair\\f in bilingual Word\\b\\tt. W\\t d\\t\\fcrib\\t th\\t training proc\\t\\f\\f of hi\\trarchical WTC Mod\\tl in mor\\t d\\ttail in S\\tction 3.","At run-tim\\t, our mod\\tl \\ftart\\f with a <word, tran\\flation> pair (\\t.g., (plant, 廠房)) from a bilingual knowl\\tdg\\t r\\t\\fourc\\t and th\\tn tran\\fform\\f th\\t di\\fambiguation probl\\tm to a hi\\trarchical cla\\f\\fification probl\\tm. In our prototyp\\t, f\\tatur\\t\\f \\txtract\\td from th\\t tran\\flation ar\\t \\txploit\\td to find it\\f ad\\tquat\\t \\f\\tn\\f\\t. Additional tran\\flation\\f of word \\f\\tn\\f\\t\\f provid\\td by our mod\\tl can b\\t u\\f\\td to broad\\tn th\\t \\fcop\\t of an \\txi\\fting bilingual Word\\b\\tt. Alt\\trnativ\\tly, our mod\\tl can b\\t \\tmb\\tdd\\td into machin\\t tran\\flation (MT) \\fy\\ft\\tm\\f in ord\\tr to h\\tlp choo\\f\\t mor\\t appropriat\\t word tran\\flation\\f."]},{"title":"2 Related\\tWork\\t","paragraphs":["Word S\\tn\\f\\t Di\\fambiguation (WSD) ha\\f b\\t\\tn an ar\\ta of activ\\t r\\t\\f\\tarch. WSD i\\f to d\\tt\\trmin\\t th\\t m\\taning of a word in curr\\tnt cont\\txt, which i\\f an important compon\\tnt in languag\\t und\\tr\\ftanding or MT \\fy\\ft\\tm\\f.","WSD mod\\tl\\f hav\\t b\\t\\tn d\\tv\\tlop\\td u\\fing machin\\t l\\tarning t\\tchniqu\\t\\f. Th\\ty may train on \\f\\tt\\f of \\f\\tn\\f\\t-annotat\\td data for pr\\td\\tfin\\td word\\f (H\\tar\\ft, 1991; L\\tacock et al., 1993; Bruc\\t and Wi\\tb\\t, 1994). To avoid th\\t labor-int\\tn\\fiv\\t and tim\\t-con\\fuming proc\\t\\f\\f of \\f\\tn\\f\\t-tagging, Yarow\\fky (1995) propo\\f\\t a \\f\\tmi-\\fup\\trvi\\f\\td mod\\tl to boot\\ftrap from raw data ba\\f\\td on \\fom\\t confid\\tnt and unambiguou\\f \\f\\t\\td\\f. \\a 1 With r\\t\\fp\\tct to th\\t \\f\\tn\\f\\t di\\fambiguation ta\\fk. 376","Anoth\\tr dir\\tction i\\f to ba\\f\\t WSD mod\\tl\\f on dictionari\\t\\f or l\\txical \\f\\tmantic knowl\\tdg\\t r\\t\\fourc\\t\\f. L\\t\\fk (1986) i\\f th\\t fir\\ft to l\\tv\\trag\\t th\\t d\\tfinition\\f of word\\f in machin\\t r\\tadabl\\t dictionari\\t\\f to pr\\tdict word \\f\\tn\\f\\t\\f. On th\\t oth\\tr hand, Word\\b\\tt, a valuabl\\t knowl\\tdg\\t \\fourc\\t \\tncod\\td with hyponym, hyp\\trnym, and \\fynonym \\f\\tmantic r\\tlation\\f, i\\f u\\f\\td to m\\ta\\fur\\t \\f\\tmantic di\\ftanc\\t\\f among word \\f\\tn\\f\\t\\f to h\\tlp \\f\\tn\\f\\t di\\fambiguation (Agirr\\t and Rigau, 1996; Gall\\ty and McK\\town, 2003). An int\\tr\\t\\fting approach pr\\t\\f\\tnt\\td by Mihalc\\ta (2005) d\\t\\fcrib\\t\\f how to apply a graph-ba\\f\\td algorithm (i.\\t., random walk algorithm) and Word\\b\\tt \\f\\tmantic r\\tlation\\f to \\folv\\t all-word WSD ta\\fk.","R\\tc\\tntly, WSD not only ha\\f b\\t\\tn approach\\td from bilingual p\\tr\\fp\\tctiv\\t, but ha\\f b\\t\\tn appli\\td to bilingual application\\f. Li and Li (2002) introduc\\t “bilingual boot\\ftrapping” making u\\f\\t of a \\fmall numb\\tr of \\f\\tn\\f\\t-annotat\\td data to furth\\tr boot\\ftrap two languag\\t\\f’ di\\fc\\trning or \\tff\\tctiv\\t cont\\txt word\\f in di\\fambiguation. Gal\\t et al. (1992) and Diab and R\\t\\fnik (2002) al\\fo l\\tv\\trag\\t bilingual information in WSD. WSD or word tran\\flation di\\fambiguation (WTD), aim\\td at improving word \\f\\tl\\tction in MT, ha\\f b\\t\\tn prov\\td to hav\\t po\\fitiv\\t influ\\tnc\\t on bilingual application lik\\t \\ftati\\ftical MT \\fy\\ft\\tm\\f (Chan et al., 2007; Carpuat and Wu, 2007).","In our work, word \\f\\tn\\f\\t\\f ar\\t a\\f\\fign\\td to giv\\tn tran\\flation\\f, which i\\f th\\t oppo\\fit\\t of WTD, choo\\fing tran\\flation\\f for \\f\\tn\\f\\t\\f, in vi\\tw of \\txt\\tnding th\\t tran\\flation cov\\trag\\t of an \\txi\\fting bilingual Word\\b\\tt \\fuch a\\f Sinica Bilingual Ontological Word\\b\\tt (Huang et al., 2004), Sinica BOW for \\fhort. Such bilingual Word\\b\\tt may b\\t con\\ftruct\\td manually by tran\\flation (Huang et al., 2004) or automatically (Chang et al., 2003). Our work can b\\t thought of a\\f (Chang et al., 2003)’\\f follow-up r\\t\\f\\tarch which \\tnrich\\t\\f th\\t tran\\flation\\f in bilingual Word\\b\\tt."]},{"title":"3 Hierarchical\\tWord\\tTranslation\\tClassification\\t 3.1 Problem\\tStatement\\t","paragraphs":["W\\t focu\\f on th\\t \\t\\f\\f\\tntial \\ft\\tp of \\txt\\tnding bilingual Word\\b\\tt: d\\tt\\trmining th\\t appropriat\\t word \\f\\tn\\f\\t\\f for un\\f\\t\\tn tran\\flation pair\\f from bilingual knowl\\tdg\\t r\\t\\fourc\\t\\f (\\t.g., dictionari\\t\\f or phra\\f\\t tabl\\t\\f). U\\fing bilingual Word\\b\\tt which provid\\t\\f a hi\\trarchical \\ftructur\\t on tr\\t\\t nod\\t\\f (i.\\t., \\fyn\\f\\tt\\f) and tran\\flation\\f, w\\t train a cla\\f\\fifi\\tr at \\tach branching nod\\t that \\t\\ftimat\\t\\f a\\f\\fociation\\f b\\ttw\\t\\tn giv\\tn tran\\flation\\f and branching nod\\t’\\f childr\\tn (i.\\t., inh\\trit\\td hyponym\\f). Th\\tn, th\\t probl\\tm of \\f\\tn\\f\\t di\\fambiguation i\\f tran\\fform\\td to a hi\\trarchical cla\\f\\fification probl\\tm. W\\t now formally \\ftat\\t th\\t probl\\tm w\\t ar\\t addr\\t\\f\\fing.","P\\toblem Statement: W\\t ar\\t giv\\tn a bilingual Word\\b\\tt (\\t.g., Sinica BOW) and a word-tran\\flation pair (e, f). Our goal i\\f to a\\f\\fign th\\t mo\\ft ad\\tquat\\t and r\\tl\\tvant \\f\\tn\\f\\t si to f wh\\tr\\t si ∈ S = {s1, ..., sn}, a \\f\\tt of word \\f\\tn\\f\\t\\f e ha\\f. For thi\\f, w\\t trav\\tr\\f\\t th\\t Word\\b\\tt from top ab\\ftract \\fyn\\f\\tt\\f to th\\t bottom word \\f\\tn\\f\\t\\f (i.\\t., s1, ..., sn) and id\\tntify all r\\tlat\\td branching nod\\t\\f \\fuch that th\\t probabiliti\\t\\f of th\\t branching path\\f a\\f\\fociat\\td with th\\t tran\\flation f can b\\t \\t\\ftimat\\td and th\\t mo\\ft lik\\tly \\f\\tn\\f\\t, si, can th\\tr\\tfor\\t b\\t pinpoint\\td."]},{"title":"3.2 Learnin\\b\\tto\\tClassify\\tTranslations\\t  Fi\\b\\fre\\t2:","paragraphs":["Outlin\\t of th\\t training proc\\t\\f\\f. W\\t att\\tmpt to r\\t\\folv\\t th\\t \\f\\tn\\f\\t ambiguity by l\\tarning l\\txical charact\\tri\\ftic\\f from a coll\\tction of tran\\flation pair\\f in a bilingual Word\\b\\tt. Our l\\tarning proc\\t\\f\\f i\\f \\fhown in Figur\\t 2. Propa\\batin\\b\\tTranslations. In th\\t fir\\ft \\ftag\\t of th\\t l\\tarning proc\\t\\f\\f (St\\tp (1) in Figur\\t 2), w\\t propagat\\t tran\\flation\\f of \\tach word \\f\\tn\\f\\t (i.\\t., \\fyn\\f\\tt\\f) to it\\f inh\\trit\\td hyp\\trnym\\f (i.\\t., anc\\t\\ftor\\f) in Word\\b\\tt. Th\\tn, th\\t word tran\\flation cla\\f\\fification (WTC) mod\\tl\\f d\\t\\fcrib\\td in th\\t following \\ftag\\t (St\\tp (2) in Figur\\t 2) can \\txploit thi\\f information to l\\tarn to cla\\f\\fify (1) Propagat\\t Tran\\flation\\f to G\\tn\\trat\\t th\\t Training Data (2) Train Hi\\trarchical Word Tran\\flation Cla\\f\\fification Mod\\tl\\f (3) Train Filt\\tring Mod\\tl 377  tran\\flation\\f into appropriat\\t \\f\\tn\\f\\t\\f. H\\tr\\t, propagating m\\tan\\f incorporating tran\\flation\\f of \\fyn\\f\\tt\\f into tran\\flation li\\ft\\f (TL’\\f) of th\\tir hyp\\trnym\\f. Th\\t rational\\t b\\thind propagating tran\\flation\\f to th\\tir hyp\\trnym\\f i\\f to \\t\\ftabli\\fh additional a\\f\\fociation\\f b\\ttw\\t\\tn tran\\flation\\f and hyp\\trnym\\f. For in\\ftanc\\t, high\\tr-l\\tv\\tl conc\\tpt “artifact” (a man-mad\\t obj\\tct tak\\tn a\\f a whol\\t) will b\\t r\\tlat\\td to \\fom\\t common tran\\flation f\\tatur\\t\\f (\\t.g., unigram charact\\tr of “廠”, “房” and “器”) \\fhar\\td among th\\t tran\\flation\\f of it\\f hyponym\\f, aft\\tr tran\\flation propagation.","Th\\t input to thi\\f \\ftag\\t i\\f a bilingual Word\\b\\tt, a coll\\tction of <word, tran\\flation> pair\\f with word \\f\\tn\\f\\t\\f. Th\\t\\f\\t pair\\f con\\ftitut\\t our training data along with l\\txical hi\\trarchy (i.\\t., hyp\\trnym/hyponym r\\tlation\\f). W\\t al\\fo tak\\t into account th\\t fr\\tqu\\tncy, i.\\t. ta\\b_\\fount, of word \\f\\tn\\f\\t\\f provid\\td in Word\\b\\tt. High\\tr ta\\b_\\fount valu\\t impli\\t\\f mor\\t fr\\tqu\\tntly occurring \\f\\tn\\f\\t. Th\\t output of thi\\f \\ftag\\t i\\f a coll\\tction of TL’\\f a\\f\\fociat\\td with Word\\b\\tt \\fyn\\f\\tt\\f.  Fi\\b\\fre\\t3: Algorithm of tran\\flation propagation.","Figur\\t 3 \\fhow\\f th\\t algorithm for propagating a tran\\flation in th\\t Word\\b\\tt hi\\trarchy. Thi\\f proc\\tdur\\t appli\\t\\f to \\tach tran\\flation pair in th\\t bilingual Word\\b\\tt.","In St\\tp (1) of th\\t algorithm w\\t id\\tntify th\\t \\fyn\\f\\tt of th\\t Engli\\fh word e and it\\f word \\f\\tn\\f\\t Sense in that \\fyn\\f\\tt\\f ar\\t th\\t ba\\fic unit\\f for any availabl\\t \\f\\tmantic r\\tlation\\f in Word\\b\\tt. Th\\tn, w\\t look up th\\t fr\\tqu\\tncy count, Cnt, of e and Sense (St\\tp (2)). In St\\tp (3) w\\t id\\tntify th\\t hyp\\trnym\\f of th\\t \\fyn\\f\\tt Synset for tran\\flation propagation. Th\\t hyp\\trnym\\f, Hype\\tnyms, \\txpr\\t\\f\\f mor\\t ab\\ftract or mor\\t g\\tn\\tral conc\\tpt\\f than Synset do\\t\\f.","Finally, w\\t int\\tgrat\\t th\\t tran\\flation f into TL’\\f of Synset and Hype\\tnyms (St\\tp (4) and (5)). \\bot\\t that w\\t al\\fo populat\\t \\f\\tn\\f\\t fr\\tqu\\tncy (Cnt) to TL’\\f \\fuch that WTC mod\\tl\\f d\\t\\fcrib\\td in following \\ftag\\t can l\\tv\\trag\\t th\\t fr\\tqu\\tncy information. Trainin\\b\\tHierarchical\\t Word\\t Translation\\t Classification\\t Models. In th\\t \\f\\tcond \\ftag\\t of th\\t l\\tarning algorithm (St\\tp (2) in Figur\\t 2), w\\t train tran\\flation cla\\f\\fification mod\\tl\\f for b\\tan\\fhin\\b \\fyn\\f\\tt\\f with mor\\t than on\\t dir\\tct hyponym in Word\\b\\tt. To navigat\\t from th\\t top, g\\tn\\tral conc\\tpt\\f, to th\\t bottom, \\fp\\tcific word \\f\\tn\\f\\t\\f, and to find th\\t right cla\\f\\f for a tran\\flation in Word\\b\\tt hi\\trarchy, w\\t utiliz\\t machin\\t l\\tarning t\\tchniqu\\t to con\\ftruct hi\\trarchical word tran\\flation cla\\f\\fification mod\\tl\\f. S\\t\\t Figur\\t 1 for th\\t \\txampl\\t of branching \\fyn\\f\\tt\\f.","Th\\t input of thi\\f \\ftag\\t i\\f th\\t propagat\\td tran\\flation data obtain\\td from th\\t pr\\tviou\\f \\ftag\\t, a coll\\tction of <Wo\\tdNet synset, T\\tanslationList> pair\\f. Th\\t output of thi\\f \\ftag\\t i\\f a \\f\\tt of WTC mod\\tl\\f which \\t\\ftimat\\t a\\f\\fociation\\f b\\ttw\\t\\tn giv\\tn tran\\flation and on\\t of th\\t dir\\tct hyponym\\f of th\\t branching \\fyn\\f\\tt in qu\\t\\ftion.","In thi\\f pap\\tr, w\\t \\tmploy Maximum Entropy (ME) a\\f our machin\\t l\\tarning mod\\tl. A\\f a \\ftati\\ftical mod\\tl, ME off\\tr\\f a n\\tat way to incorporat\\t any pot\\tntial f\\tatur\\t\\f for outcom\\t pr\\tdiction.","During th\\t training of our ME-ba\\f\\td WTC mod\\tl, all dir\\tct hyponym\\f of a \\fyn\\f\\tt con\\ftitut\\t th\\t outcom\\t \\fpac\\t of th\\t cla\\f\\fification mod\\tl, and f\\tatur\\t\\f, a\\f w\\t will d\\t\\fcrib\\t in d\\ttail lat\\tr, ar\\t d\\triv\\td from in\\ftanc\\t\\f in TL’\\f. Sp\\tcifically, th\\t a\\f\\fociation b\\ttw\\t\\tn a dir\\tct hyponym (an out\\fome) of a \\fyn\\f\\tt and th\\t tran\\flation f i\\f gov\\trn\\td by th\\t conditional probability a\\f"]},{"title":"( ) ( )( ) ( )( )","paragraphs":["\\txp , \\txp ,","i i i","i i o out\\fomes i featu\\te out\\fome f p out\\fome f featu\\te o f λ λ∈ × = ×"]},{"title":"∑ ∑ ∑ ","paragraphs":["(1) pro\\b\\tdur\\t \\fropagat\\tTran\\aslation(e, Sense, f) (1) Synset = G\\ttSyns\\tt(e, Sense) (2) \\bnt = G\\ttTagCount(e, Sense) (3) \\typerny\\fs = G\\ttHyp\\trnyms(Synset) (4) AddToList(Synset, f, \\bnt) for \\ta\\bh hi in \\typerny\\fs (5) AddToList(hi, f, \\bnt) 378 wh\\tr\\t out\\fomes i\\f a \\f\\tt of all dir\\tct hyponym\\f of th\\t \\fyn\\f\\tt, featu\\tei i\\f a binary-valu\\td function, and λi i\\f th\\t w\\tight of th\\t f\\tatur\\t function featu\\tei. \\bot\\t that λi’\\f ar\\t tun\\td to r\\tfl\\tct th\\t \\fignificanc\\t of th\\t f\\tatur\\t\\f in d\\tt\\trmining th\\t hyponym-tran\\flation a\\f\\fociation and that, during training, \\f\\tn\\f\\t fr\\tqu\\tncy (ta\\b_\\fount) i\\f u\\f\\td to indicat\\t th\\t importanc\\t of th\\t tran\\flation b\\ting a\\f\\fociat\\td with th\\t word \\f\\tn\\f\\t. In our impl\\tm\\tntation, w\\t p\\trform add-on\\t \\fmoothing t\\tchniqu\\t to d\\tal with z\\tro ta\\b_\\fount.","\\bow, w\\t d\\t\\fcrib\\t th\\t f\\tatur\\t\\f (i.\\t., featu\\tei) u\\f\\td in our mod\\tl. In\\fpir\\td by th\\t ob\\f\\trvation that tran\\flation\\f of a \\f\\tmantic \\fyn\\f\\tt (\\t.g., “artifact#1”) ar\\t lik\\tly to \\fhar\\t \\fom\\t common word\\f or charact\\tr\\f (\\t.g., “器”, “廠” and “房”), n-gram f\\tatur\\t\\f, r\\tf\\trr\\td to a\\f lit\\tral f\\tatur\\t\\f, of tran\\flation\\f ar\\t l\\tv\\trag\\td. Following d\\t\\fcrib\\t\\f thr\\t\\t typ\\t\\f of lit\\tral f\\tatur\\t\\f for Chin\\t\\f\\t tran\\flation\\f: Uni\\bram\\t Feat\\fre: Chin\\t\\f\\t charact\\tr\\f t\\tnd to carry \\fom\\t \\fort of \\f\\tmantic m\\taning\\f.","Th\\tr\\tfor\\t, w\\t \\fplit Chin\\t\\f\\t tran\\flation\\f into charact\\tr\\f and coll\\tct th\\tir corr\\t\\fponding","f\\tatur\\t\\f. For in\\ftanc\\t, “核”, “能”, “發”, “電”, and “廠” ar\\t th\\t lit\\tral unigram f\\tatur\\t\\f of","th\\t tran\\flation “核能發電廠” (nucl\\tar plant). Bi\\bram\\tFeat\\fre: Sinc\\t con\\f\\tcutiv\\t two Chin\\t\\f\\t charact\\tr\\f, which w\\t r\\tf\\tr to a\\f bigram\\f,","might conv\\ty mor\\t \\fp\\tcific m\\taning than unigram\\f, bigram\\f ar\\t al\\fo u\\f\\td a\\f f\\tatur\\t\\f. For","th\\t abov\\t in\\ftanc\\t, th\\tr\\t ar\\t four bigram f\\tatur\\t\\f, “核能”, “能發”, “發電”, and “電廠”. Head\\tWord\\tFeat\\fre: Th\\t h\\tad word of a Chin\\t\\f\\t tran\\flation may occur at th\\t b\\tginning","or in th\\t \\tnd and th\\t l\\tngth of a h\\tad i\\f unc\\trtain. A\\f a r\\t\\fult, both \\tnd\\f of th\\t tran\\flation","and a pr\\t\\f\\tt charact\\tr limit on h\\tad word ar\\t u\\f\\td to g\\tn\\trat\\t our h\\tad word f\\tatur\\t\\f. For","in\\ftanc\\t, “核\", \"廠\", \"核能\", and \"電廠” ar\\t \\f\\tl\\tct\\td a\\f th\\t h\\tad word f\\tatur\\t\\f of “核能","發電廠” if charact\\tr limit i\\f \\f\\tt to two.","\\botic\\t that although alt\\trnativ\\t machin\\t l\\tarning approach\\t\\f can b\\t \\txploit\\td to train th\\t WTC mod\\tl\\f, u\\fing ME ha\\f a numb\\tr of advantag\\t\\f. Fir\\ftly, ME provid\\t\\f an \\ta\\fy way to incorporat\\t pot\\tntial f\\tatur\\t function\\f \\fo that r\\t\\f\\tarch \\tffort\\f can b\\t focu\\f\\td on \\f\\tl\\tcting r\\tpr\\t\\f\\tntativ\\t f\\tatur\\t\\f to charact\\triz\\t th\\t probl\\tm\\f. In addition, f\\tatur\\t\\f in ME mod\\tl\\f ar\\t a\\f\\fign\\td with highly-tun\\td w\\tight\\f and ME mod\\tl\\f ar\\t train\\td without th\\t a\\f\\fumption of f\\tatur\\t ind\\tp\\tnd\\tnc\\t, on\\t of th\\t i\\f\\fu\\t\\f facing \\baïv\\t Bay\\t\\fian mod\\tl. Trainin\\b\\t Filterin\\b\\t Model. In th\\t third and final \\ftag\\t of th\\t l\\tarning proc\\t\\f\\f, w\\t train a filt\\tring mod\\tl at th\\t \\fo-call\\td l\\txicograph\\tr fil\\t l\\tv\\tl of Word\\b\\tt to prun\\t unlik\\tly \\ftarting \\fyn\\f\\tt\\f, l\\tading to th\\t word \\f\\tn\\f\\t\\f, for th\\t giv\\tn tran\\flation. Mor\\t \\fp\\tcifically, in\\ft\\tad of d\\taling with v\\try g\\tn\\tral and ab\\ftract conc\\tpt\\f at th\\t top l\\tv\\tl, th\\t mod\\tl cla\\f\\fifi\\t\\f th\\t giv\\tn tran\\flation to \\fom\\t mor\\t \\fp\\tcific and concr\\tt\\t \\f\\tmantic cat\\tgori\\t\\f. Thi\\f filt\\tring aim\\f to acc\\tl\\trat\\t th\\t proc\\t\\f\\f of word tran\\flation cla\\f\\fification and to boo\\ft th\\t p\\trformanc\\t by r\\tducing th\\t probability that th\\t hi\\trarchical WTC mod\\tl\\f \\f\\tt out on th\\t wrong foot.","In principl\\t, hi\\trarchical WTC mod\\tl\\f d\\t\\fcrib\\td in th\\t pr\\tviou\\f \\f\\tction alon\\t could r\\t\\folv\\t th\\t \\f\\tn\\f\\t ambiguity if impl\\tm\\tnt\\td with a gr\\t\\tdy path-finding algorithm. \\bon\\tth\\tl\\t\\f\\f, it i\\f lik\\tly that during th\\t cla\\f\\fification proc\\t\\f\\f, WTC mod\\tl\\f fail to mak\\t th\\t corr\\tct branch pr\\tdiction for th\\t fi\\tst f\\tw branching \\fyn\\f\\tt\\f at th\\t high\\tr l\\tv\\tl of Word\\b\\tt hi\\trarchy b\\tcau\\f\\t th\\tir imm\\tdiat\\t hyponym\\f conv\\ty too g\\tn\\tral conc\\tpt\\f.","Th\\t <Wo\\tdNet synset, T\\tanslationList> pair\\f from St\\tp (1) in Figur\\t 2 ar\\t utiliz\\td to train th\\t filt\\tring mod\\tl. Th\\t filt\\tring mod\\tl, a ME-ba\\f\\td cla\\f\\fification mod\\tl, \\t\\ftimat\\t\\f a\\f\\fociation\\f b\\ttw\\t\\tn f\\tatur\\t\\f of a giv\\tn tran\\flation and \\fom\\t pr\\td\\tfin\\td outcom\\t, in thi\\f ca\\f\\t, th\\t l\\txicograph\\tr fil\\t\\f. L\\txicograph\\tr fil\\t\\f ar\\t \\f\\tmantic cat\\tgori\\t\\f organiz\\td during th\\t d\\tv\\tlopm\\tnt of Word\\b\\tt. In total, th\\tr\\t ar\\t forty-fiv\\t l\\txicograph\\tr fil\\t\\f: tw\\tnty-\\fix for noun\\f, fift\\t\\tn for v\\trb\\f, thr\\t\\t for adj\\tctiv\\t\\f, and on\\t for adv\\trb\\f. A\\f for f\\tatur\\t\\f, w\\t u\\f\\t th\\t \\fam\\t f\\tatur\\t \\f\\tt\\f pr\\tviou\\fly d\\t\\fcrib\\td.","Whil\\t w\\t con\\ftruct a WTC mod\\tl for \\tach branching \\fyn\\f\\tt, w\\t only train a \\fingl\\t filt\\tring mod\\tl at th\\t l\\tv\\tl of th\\t l\\txicograph\\tr fil\\t\\f in Word\\b\\tt to filt\\tr out \\fyn\\f\\tt\\f who\\f\\t a\\f\\fociation\\f with th\\t giv\\tn tran\\flation\\f ar\\t \\fmall\\tr than θ (a thr\\t\\fhold to b\\t d\\tt\\trmin\\td). Mor\\tov\\tr, w\\t al\\fo 379  u\\f\\t th\\t \\fmooth\\td \\f\\tn\\f\\t fr\\tqu\\tncy to r\\tfl\\tct th\\t importanc\\t of th\\t tran\\flation\\f of th\\t fr\\tqu\\tnt \\f\\tn\\f\\t."]},{"title":"3.3 R\\fn-Time\\tTranslation\\tClassification\\t","paragraphs":["Onc\\t th\\t WTC and filt\\tring mod\\tl\\f ar\\t con\\ftruct\\td, w\\t ar\\t r\\tady to cla\\f\\fify tran\\flation\\f to corr\\t\\fponding word \\f\\tn\\f\\t\\f in Word\\b\\tt. W\\t a\\f\\fociat\\t ad\\tquat\\t \\f\\tn\\f\\t\\f with giv\\tn tran\\flation\\f u\\fing th\\t proc\\tdur\\t in Figur\\t 4.  Fi\\b\\fre\\t4: Run-tim\\t cla\\f\\fification algorithm.","In St\\tp (1) w\\t r\\ttri\\tv\\t th\\t \\f\\tn\\f\\t\\f of th\\t giv\\tn Engli\\fh word e in Word\\b\\tt a\\f th\\t candidat\\t \\f\\tn\\f\\t\\f for di\\fambiguation. Th\\tn, w\\t \\txpand tran\\flation f with it\\f \\fynonym\\f (at mo\\ft N \\fynonym\\f) by looking up a \\fynonym th\\t\\fauru\\f (St\\tp (2)). Th\\t motivation of \\fynonym \\txpan\\fion i\\f to r\\tduc\\t th\\t impact of rar\\t tran\\flation\\f (\\t.g., “寒玉” a tran\\flation of “moon”) on \\fy\\ft\\tm p\\trformanc\\t. Th\\t f\\tatur\\t\\f of th\\t mor\\t fr\\tqu\\tntly u\\f\\td tran\\flation\\f (\\t.g., “月亮” and “月” for “moon”) u\\fually ar\\t mor\\t \\tff\\tctiv\\t and u\\f\\tful in cla\\f\\fification b\\tcau\\f\\t of th\\tir commonn\\t\\f\\f and l\\txical charact\\tri\\ftic\\f. All of th\\t tran\\flation \\fynonym\\f will b\\t con\\fid\\tr\\td in filt\\tring (St\\tp (4b)) and branch pr\\tdiction (St\\tp (7b)).","In St\\tp (3) and (4), w\\t prun\\t l\\t\\f\\f lik\\tly \\f\\tn\\f\\t\\f via filt\\tring mod\\tl u\\fing th\\t l\\txicograph\\tr fil\\t\\f, or \\f\\tmantic cat\\tgori\\t\\f, a\\f\\fociat\\td with th\\tm. Th\\t filt\\tring mod\\tl pr\\tdict\\f th\\t r\\tlat\\tdn\\t\\f\\f b\\ttw\\t\\tn f\\tatur\\t\\f of th\\t giv\\tn tran\\flation (a\\f w\\tll a\\f \\tach of it\\f \\fynonym\\f) and th\\t \\f\\tmantic cat\\tgori\\t\\f (St\\tp (4b)). Sinc\\t th\\t giv\\tn tran\\flation and it\\f \\fynonym\\f ba\\fically \\txpr\\t\\f\\f \\fimilar conc\\tpt, th\\tir pr\\tdict\\td \\fcor\\t\\f ar\\t w\\tight\\td \\tqually. Th\\t \\f\\tn\\f\\t\\f with ave\\ta\\bed \\fcor\\t l\\t\\f\\f than a thr\\t\\fhold θ ar\\t r\\tmov\\td from th\\t \\f\\tn\\f\\t \\f\\tt in St\\tp (4c).","Th\\t r\\tmaining \\f\\tn\\f\\t ambiguity i\\f r\\t\\folv\\td u\\fing hi\\trarchical WTC mod\\tl\\f (from St\\tp (5) to (8)). In St\\tp (5) branching \\fyn\\f\\tt, BS , who\\f\\t imm\\tdiat\\t hyponym\\f \\tach cov\\tr a \\fub\\f\\tt of th\\t r\\tmain\\td candidat\\t \\f\\tn\\f\\t\\f, i\\f id\\tntifi\\td by \\txamining th\\t n\\ttwork of Word\\b\\tt. A\\f th\\t algorithm proc\\t\\td\\f, BS’\\f mov\\t downward\\f in th\\t Word\\b\\tt hi\\trarchy a\\f th\\t ambiguity at upp\\tr l\\tv\\tl\\f i\\f b\\ting r\\t\\folv\\td. Th\\t WTC mod\\tl a\\f\\fociat\\td with BS i\\f load\\td in St\\tp (6) to \\t\\ftimat\\t th\\t hyponym-tran\\flation a\\f\\fociation and pr\\tdict th\\t mo\\ft lik\\tly branch ChosenB\\tan\\fh, \\fati\\ffying"]},{"title":"\\b \\t","paragraphs":["arg max ih is\\fo\\te for BS (St\\tp (7b) and (7c)). In St\\tp (8), w\\t di\\fcard th\\t \\f\\tn\\f\\t who\\f\\t inh\\trit\\td hyp\\trnym\\f do not includ\\t ChosenB\\tan\\fh in a gr\\t\\tdy mann\\tr. Th\\t algorithm pro\\b\\tdur\\t ClassifyTran\\aslation(e, f) (1) Senses = G\\ttS\\tns\\ts(e) (2) TranslationSynony\\fs\\h = G\\ttSynonyms(f, N) ∪ {f} //R\\tmov\\t unlik\\tly \\f\\tn\\f\\t\\f via filt\\tring mod\\tl for \\ta\\bh s\\tns\\t s in Senses (3) c = G\\ttCat\\tgory(s) (4a) score = 0","for \\ta\\bh t in TranslationSynony\\fs\\h (4b) score += Filt\\tringMod\\tl(c, G\\ttF\\tatur\\ts(t)) if score/#TranslationSynony\\h\\fs < θ (4\\b) R\\tmov\\t s\\tns\\t s from Senses //Gr\\t\\tdily \\f\\tl\\tct th\\t mo\\ft probabl\\t branch at \\tach branching nod\\t via hi\\trarchical WTC mod\\tl\\f","whil\\t #Senses > 1 (5) BS = G\\ttBran\\bhingSyns\\tt(\\aSenses) (6) WTCMod\\tl = Load WTC mod\\t\\al asso\\biat\\td with BS for \\ta\\bh hi in hyponyms of BS (7a) scorei = 0 for \\ta\\bh t in TranslationSynony\\fs\\h (7b) scorei += WTCMod\\tl(hi, G\\ttF\\tatur\\ts(t)) (7\\b) ChosenBranch = hi with max score for \\ta\\bh s\\tns\\t s in Senses if ChosenBranch is not an inh\\trit\\td \\ahyp\\trnym of s (8) R\\tmov\\t s\\tns\\t s from Senses (9) R\\tturn th\\t only s\\tns\\t \\ain Senses 380 continu\\t\\f until only on\\t \\f\\tn\\f\\t r\\tmain\\f, th\\tn a\\f\\fign\\td to th\\t giv\\tn tran\\flation pair a\\f th\\t mo\\ft r\\tl\\tvant \\f\\tn\\f\\t (St\\tp (9))."]},{"title":"4 Experimental\\tSettin\\b\\t 4.1 Data\\tSets\\t","paragraphs":["W\\t u\\f\\td th\\t lat\\t\\ft v\\tr\\fion of Word\\b\\tt (i.\\t., Word\\b\\tt 3.0) a\\f our l\\txical hi\\trarchy and train\\td our cla\\f\\fification mod\\tl\\f on Sinica BOW, a Engli\\fh-Chin\\t\\f\\t Word\\b\\tt. In our \\txp\\trim\\tnt\\f, w\\t focu\\f\\td on nominal \\fyn\\f\\tt\\f and hyponym/hyp\\trnym \\f\\tmantic r\\tlation d\\tfin\\td in Word\\b\\tt. On th\\t oth\\tr hand, w\\t look\\td up 同 義 詞 詞 林 , a Chin\\t\\f\\t th\\t\\fauru\\f for run-tim\\t \\fynonym \\txpan\\fion.","W\\t randomly \\f\\tl\\tct\\td 500 noun\\f from SEMCOR, a \\fub\\f\\tt of Brown Corpu\\f, and manually tran\\flat\\td th\\tm into Chin\\t\\f\\t via Longman Engli\\fh-Chin\\t\\f\\t Dictionary of Cont\\tmporary Engli\\fh. Aft\\tr r\\tmoving th\\t <word, tran\\flation> pair\\f alr\\tady \\txi\\fting in th\\t bilingual Word\\b\\tt, 300 tran\\flation pair\\f w\\tr\\t randomly \\f\\tl\\tct\\td a\\f our \\tvaluation data, and 100 of th\\tm mad\\t up of our d\\tv\\tlopm\\tnt data \\f\\tt for tuning \\fy\\ft\\tm param\\tt\\tr\\f and th\\t r\\t\\ft our (out\\fid\\t) t\\t\\fting data."]},{"title":"4.2 Models\\tCompared\\t","paragraphs":["In vi\\tw of \\txt\\tnding th\\t \\txi\\fting bilingual Word\\b\\tt, w\\t propo\\f\\t a cla\\f\\fification fram\\twork for cat\\tgorizing th\\t giv\\tn tran\\flation\\f from bilingual knowl\\tdg\\t r\\t\\fourc\\t\\f into \\fuitabl\\t word \\f\\tn\\f\\t\\f, in which w\\t d\\tploy a filt\\tring mod\\tl (FM) and hi\\trarchical WTC mod\\tl\\f (HM) obtain\\td u\\fing th\\t l\\tarning proc\\t\\f\\f in S\\tction 3. In addition, tran\\flation \\fynonym \\txpan\\fion (TS) i\\f appli\\td to r\\tduc\\t th\\t impact of rar\\t tran\\flation\\f on \\fy\\ft\\tm p\\trformanc\\t. To in\\fp\\tct th\\t \\tff\\tctiv\\tn\\t\\f\\f of th\\t\\f\\t modul\\t\\f, a ba\\f\\tlin\\t mod\\tl and th\\t mod\\tl\\f u\\fing our thr\\t\\t main modul\\t\\f, HM, FM, and TS, ar\\t \\tvaluat\\td. Mod\\tl\\f compar\\td ar\\t d\\t\\fcrib\\td a\\f follow\\f: Baseline: For any giv\\tn tran\\flation pair, th\\t mo\\ft fr\\tqu\\tnt \\f\\tn\\f\\t i\\f r\\tturn\\td. HM: Th\\t tran\\flation i\\f cla\\f\\fifi\\td u\\fing only hi\\trarchical WTC mod\\tl\\f. That i\\f, th\\t","filt\\tring thr\\t\\fhold θ and th\\t numb\\tr of allow\\td tran\\flation \\fynonym\\f N ar\\t both \\f\\tt to","z\\tro. HM+FM: Unlik\\tly word \\f\\tn\\f\\t\\f ar\\t prun\\td by FM prior to HM. θ i\\f \\f\\tt according to th\\t","tuning proc\\t\\f\\f d\\t\\fcrib\\td in S\\tction 4.4 and N i\\f \\f\\tt to z\\tro. HM+TS: N additional tran\\flation \\fynonym\\f ar\\t u\\f\\td in HM. \\bo prior \\f\\tn\\f\\t filt\\tring i\\f","appli\\td (θ i\\f \\f\\tt to z\\tro). HM+FM+TS: Th\\t compl\\tt\\t v\\tr\\fion of th\\t propo\\f\\td \\fy\\ft\\tm, u\\fing all thr\\t\\t compon\\tnt\\f."]},{"title":"4.3 Eval\\fation\\tMetrics\\t","paragraphs":["In thi\\f \\fub\\f\\tction, w\\t introduc\\t th\\t m\\ttric\\f, Hit Rate and Mean Re\\fip\\to\\fal Rank (MRR), for \\tvaluating th\\t p\\trformanc\\t of our \\fy\\ft\\tm.","Definition: Th\\t Top-n Hit Rate of a \\fy\\ft\\tm S for a \\f\\tt of qu\\try tran\\flation pair\\f Q i\\f th\\t p\\trc\\tntag\\t of th\\t pair\\f for which S r\\tturn\\td at l\\ta\\ft on\\t accurat\\t \\f\\tn\\f\\t (hit) among th\\t top n r\\tturn\\td \\f\\tn\\f\\t\\f.","Example: Con\\fid\\tr an \\txampl\\t wh\\tr\\t, among th\\t 10 \\f\\tt\\f of th\\t r\\tturn\\td \\f\\tn\\f\\t\\f (i.\\t., 10 qu\\try tran\\flation pair\\f), 6 top-rank\\td and 2 \\f\\tcond-plac\\t \\f\\tn\\f\\t\\f ar\\t confirm\\td accurat\\t. Th\\t Top-2 Hit Rate of thi\\f \\fy\\ft\\tm i\\f th\\tn (6+2)/10 = 80%.","B\\t\\fid\\t\\f, to m\\ta\\fur\\t th\\t \\tffort n\\t\\td\\td for a u\\f\\tr to locat\\t a corr\\tct \\f\\tn\\f\\t in th\\t r\\tturn\\td \\f\\tn\\f\\t li\\ft\\f, \\fy\\ft\\tm\\f ar\\t \\tvaluat\\td u\\fing MRR. MRR i\\f a r\\tal numb\\tr lying b\\ttw\\t\\tn 0 and 1, in which 1 d\\tnot\\t\\f th\\t accurat\\t \\f\\tn\\f\\t\\f alway\\f occur at th\\t fir\\ft plac\\t\\f. W\\t r\\tport th\\t MRR r\\t\\fult\\f to \\txamin\\t th\\t po\\f\\fibility of our \\fy\\ft\\tm b\\ting u\\f\\td to h\\tlp l\\txicograph\\tr\\f bridg\\t n\\tw tran\\flation\\f to word \\f\\tn\\f\\t\\f.","Definition: Th\\t Re\\fip\\to\\fal Rank of a \\fy\\ft\\tm, for a tran\\flation pair p i\\f d\\tfin\\td a\\f Rp-1",", wh\\tr\\t Rp i\\f th\\t \\fmall\\t\\ft rank of th\\t corr\\tct \\f\\tn\\f\\t a\\f\\fign\\td to p. Th\\t Mean Re\\fip\\to\\fal Rank of th\\t \\fy\\ft\\tm i\\f th\\t av\\trag\\t of th\\t Re\\fip\\to\\fal Rank valu\\t\\f ov\\tr all \\tvaluat\\td tran\\flation pair\\f. 381 "]},{"title":"4.4 T\\fnin\\b\\tParameters\\t","paragraphs":["W\\t carri\\td out pilot \\txp\\trim\\tnt\\f on th\\t d\\tv\\tlopm\\tnt data \\f\\tt to tun\\t th\\t two param\\tt\\tr\\f in our \\fy\\ft\\tm: th\\t filt\\tring thr\\t\\fhold, θ, and th\\t numb\\tr of allow\\td tran\\flation \\fynonym\\f, N.","Th\\t filt\\tring thr\\t\\fhold in our mod\\tl influ\\tnc\\t\\f th\\t d\\tgr\\t\\t of pruning. To \\f\\tl\\tct a \\fuitabl\\t θ, th\\t p\\trformanc\\t, in thi\\f ca\\f\\t, th\\t accuracy of \\f\\tn\\f\\t\\f b\\ting r\\tj\\tct\\td by th\\t filt\\tring mod\\tl (P), th\\t cov\\trag\\t of our r\\tj\\tct\\td \\f\\tn\\f\\t\\f (R), and th\\t combination of th\\t two (F-m\\ta\\fur\\t2","), of our filt\\tring mod\\tl wa\\f \\tvaluat\\td at diff\\tr\\tnt thr\\t\\fhold\\f.","Figur\\t 5 \\fummariz\\t\\f th\\t r\\t\\fult\\f. Ba\\f\\td on th\\t \\ftati\\ftic\\f in Figur\\t 5, w\\t \\f\\tt our filt\\tring thr\\t\\fhold to 0.04, at which th\\t filt\\tring mod\\tl achi\\tv\\td high\\t\\ft F-m\\ta\\fur\\t, that i\\f, mo\\ft balanc\\td p\\trformanc\\t b\\ttw\\t\\tn P (0.86) and R (0.59)."," Fi\\b\\fre\\t5: Pr\\tci\\fion (P), r\\tcall (R), and F-m\\ta\\fur\\t at diff\\tr\\tnt filt\\tring thr\\t\\fhold\\f.","To \\f\\tl\\tct an appropriat\\t numb\\tr for \\fynonym \\txpan\\fion, w\\t \\txamin\\td MRR of our mod\\tl with r\\t\\fp\\tct to th\\t numb\\tr of tran\\flation \\fynonym\\f \\txpand\\td. Figur\\t 6 \\fhow\\f that our mod\\tl p\\trform\\td th\\t b\\t\\ft wh\\tn at mo\\ft two tran\\flation \\fynonym\\f ar\\t allow\\td and that mor\\t \\fynonym\\f did not l\\tad to b\\ttt\\tr r\\t\\fult\\f probably du\\t to th\\t noi\\f\\t introduc\\td. In \\fum, w\\t \\f\\tt th\\t filt\\tring thr\\t\\fhold, θ, to 0.04, and th\\t maximal numb\\tr of allow\\td tran\\flation \\fynonym\\f, N, to 2 in our \\txp\\trim\\tnt\\f.  Fi\\b\\fre\\t6: MRR of diff\\tr\\tnt N’\\f on d\\tv\\tloping data \\f\\tt."]},{"title":"5 Eval\\fation\\tRes\\flts\\tand\\tDisc\\fssion\\t 5.1 Experimental\\tRes\\flts\\t","paragraphs":["In \\txp\\trim\\tnt\\f, 200 t\\t\\fting tran\\flation pair\\f w\\tr\\t cla\\f\\fifi\\td u\\fing th\\t mod\\tl\\f d\\t\\fcrib\\td in S\\tction 4.2. Tabl\\t 1 \\fummariz\\t\\f th\\t p\\trformanc\\t of diff\\tr\\tnt combination\\f of th\\t thr\\t\\t main \\fy\\ft\\tm modul\\t\\f (i.\\t., HM, FM, and TS).","Table\\t1: Th\\t \\tvaluation r\\t\\fult\\f of diff\\tr\\tnt \\fy\\ft\\tm\\f. Syst\\tm Top-1 \\tit Rate (%) MRR Baseline\\b 65 0.79 \\tM\\b 74 0.84 \\tM+\\fM\\b 75 0.83 \\tM+TS\\b 75 0.84 \\tM+\\fM+TS\\b 77 0.84 \\a 2 2*\\f*R/(\\f+R) 382","A\\f \\fugg\\t\\ft\\td in Tabl\\t 1, our propo\\f\\td \\fy\\ft\\tm\\f \\fignificantly outp\\trform\\td th\\t ba\\f\\tlin\\t in t\\trm\\f of Top-1 Hit Rate, which indicat\\t\\f that our cla\\f\\fification \\ftrat\\tgy \\tff\\tctiv\\tly and corr\\tctly a\\f\\fign\\td \\fuitabl\\t word \\f\\tn\\f\\t\\f to giv\\tn tran\\flation pair\\f. Among th\\t four combination\\f of our \\fy\\ft\\tm compon\\tnt\\f, HM+FM+TS, a \\fy\\ft\\tm with hi\\trarchical WTC mod\\tl\\f, a filt\\tring mod\\tl, and \\fynonym \\txpan\\fion, achi\\tv\\td th\\t high\\t\\ft Top-1 Hit Rate, 77%, \\fugg\\t\\fting th\\t WTC mod\\tl\\f b\\tn\\tfit\\td from \\f\\tn\\f\\t pr\\t-pruning and \\fynonym \\txpanding. On th\\t oth\\tr hand, th\\t high MRR (0.84) point\\td out that u\\f\\tr\\f (\\t.g., l\\txicograph\\tr\\f) could oft\\tn find th\\t \\fuitabl\\t word \\f\\tn\\f\\t for th\\t tran\\flation by looking at th\\t fir\\ft two \\f\\tn\\f\\t\\f in th\\t rank\\td \\f\\tn\\f\\t li\\ft g\\tn\\trat\\td by our mod\\tl.","W\\t furth\\tr \\txamin\\t th\\t Top-1 Hit Rates for word\\f with diff\\tr\\tnt numb\\tr\\f of \\f\\tn\\f\\t\\f (S\\t\\t Figur\\t 7). A\\f w\\t can \\f\\t\\t, Top-1 Hit Rate d\\tclin\\t\\f again\\ft th\\t numb\\tr of \\f\\tn\\f\\t p\\tr word, and our mod\\tl outp\\trform\\td th\\t ba\\f\\tlin\\t at all \\f\\tn\\f\\t count\\f and r\\tmain\\td at 70% accuracy. Al\\fo, \\txcluding th\\t 30 mono\\f\\tmou\\f word\\f in th\\t t\\t\\ft \\f\\tt \\tnlarg\\td th\\t diff\\tr\\tnc\\t b\\ttw\\t\\tn our \\fy\\ft\\tm and th\\t ba\\f\\tlin\\t (72% v\\f. 58%)."," Fi\\b\\fre\\t7: Top-1 Hit Rates of word\\f with diff\\tr\\tnt numb\\tr\\f of word \\f\\tn\\f\\t\\f."]},{"title":"5.2 Error\\tAnalysis\\t","paragraphs":["In th\\t \\txp\\trim\\tnt of HM+FM+TS, 47 tran\\flation pair\\f out of 200 w\\tr\\t wrongly cla\\f\\fifi\\td. And \\trror\\f can b\\t mainly group\\td into thr\\t\\t typ\\t\\f: on\\t r\\tlat\\td to high word \\f\\tn\\f\\t ambiguity, on\\t d\\t\\fcriptiv\\t tran\\flation\\f, and on\\t tran\\flit\\tration\\f.","Ov\\tr 50% of th\\t mi\\flab\\tl\\td tran\\flation pair\\f hav\\t mor\\t than 4 Engli\\fh word \\f\\tn\\f\\t\\f (th\\t av\\trag\\t numb\\tr of \\f\\tn\\f\\t\\f p\\tr word wa\\f 4.4 in our t\\t\\ft \\f\\tt), indicating that it i\\f mor\\t difficult to a\\f\\fign corr\\tct \\f\\tn\\f\\t\\f to tran\\flation pair\\f with high d\\tgr\\t\\t of \\f\\tn\\f\\t ambiguity. \\bon\\tth\\tl\\t\\f\\f, our \\fy\\ft\\tm \\ftill achi\\tv\\td much high\\tr Top-1 Hit Rate (64%) in cla\\f\\fifying th\\t 73 tran\\flation pair\\f with mor\\t than 4 \\f\\tn\\f\\t\\f than th\\t ba\\f\\tlin\\t (45%).","Anoth\\tr major typ\\t of \\trror\\f r\\t\\fult\\f from d\\t\\fcriptiv\\t tran\\flation\\f, r\\tf\\trring to th\\t ca\\f\\t\\f wh\\tr\\t word\\f ar\\t not tran\\flat\\td but, to \\fom\\t \\txt\\tnt, d\\tfin\\td in anoth\\tr languag\\t. Tak\\t “factory” for \\txampl\\t. It\\f common Chin\\t\\f\\t tran\\flation i\\f “工廠”. How\\tv\\tr, “從事工業生產的場所” (a plac\\t for manufacturing) may b\\t anoth\\tr, a d\\t\\fcriptiv\\t on\\t actually. Tok\\tn\\f of d\\t\\fcriptiv\\t tran\\flation\\f ar\\t lik\\tly to introduc\\t noi\\f\\t (\\t.g., “的” in “從事工業生產的場所”), \\fub\\f\\tqu\\tntly d\\tgrading th\\t p\\trformanc\\t of our cla\\f\\fification mod\\tl. Th\\t\\f\\t d\\t\\fcriptiv\\t tran\\flation\\f might b\\t corr\\tctly \\f\\tn\\f\\t-lab\\tl\\td if mor\\t conci\\f\\t \\txpr\\t\\f\\fion or tran\\flation i\\f provid\\td. For \\txampl\\t, (r\\tcov\\try, “恢復健康”) originally mi\\flab\\tl\\td will b\\t corr\\tctly a\\f\\fign\\td to th\\t \\f\\tn\\f\\t “gradual h\\taling (through r\\t\\ft) aft\\tr \\fickn\\t\\f\\f or injury” if provid\\td with “康復”, part\\f of “恢復健康”.","Oth\\tr \\trror\\f ar\\t r\\tlat\\td to th\\t fact that th\\t giv\\tn tran\\flation\\f ar\\t tran\\flit\\tration\\f. Our cla\\f\\fification mod\\tl aim\\f to build r\\tlation\\f b\\ttw\\t\\tn Word\\b\\tt \\f\\tn\\f\\t\\f and t\\tanslations, not t\\tanslite\\tations. Tran\\flit\\tration\\f u\\fually r\\tfl\\tcting th\\t \\found not th\\t m\\taning\\f of th\\t word\\f th\\tr\\tfor\\t hind\\tr th\\t mod\\tl from functioning prop\\trly and accurat\\tly. An \\txampl\\t tran\\flit\\tration in our t\\t\\ft data i\\f (tru\\ft, 托拉斯), and it\\f ad\\tquat\\t \\f\\tn\\f\\t i\\f “a con\\fortium of ind\\tp\\tnd\\tnt organization\\f form\\td to limit comp\\ttition by controlling th\\t production and di\\ftribution of a product or \\f\\trvic\\t”. 383 "]},{"title":"6 F\\ft\\fre\\tWork\\tand\\tS\\fmmary\\t","paragraphs":["Many av\\tnu\\t\\f \\txi\\ft for futur\\t r\\t\\f\\tarch and improv\\tm\\tnt of our \\fy\\ft\\tm. For \\txampl\\t, oth\\tr pot\\tntial f\\tatur\\t\\f can b\\t int\\tgrat\\td into th\\t cla\\f\\fification fram\\twork, \\fuch a\\f th\\t tran\\flation\\f of th\\t glo\\f\\f\\t\\f or th\\t d\\tfinition\\f of th\\t word \\f\\tn\\f\\t\\f. Al\\fo, a \\fimpl\\t proc\\tdur\\t, which \\txtract\\f cont\\tnt word\\f or \\t\\f\\f\\tntial t\\trm\\f, our cla\\f\\fifi\\tr\\f b\\ttt\\tr at, from th\\t \\txplanatory or d\\t\\fcriptiv\\t tran\\flation\\f, can b\\t \\tmploy\\td prior to \\f\\tn\\f\\t di\\fambiguation or branch finding. Anoth\\tr int\\tr\\t\\fting dir\\tction to \\txplor\\t i\\f to furth\\tr con\\fid\\tr th\\t cont\\txt information of th\\t giv\\tn tran\\flation\\f. For in\\ftanc\\t, th\\t cont\\txt\\f of “植物” (gr\\t\\tn “plant”), \\t.g. “植物標本” and “有機植 物”, and “工廠” (manufacturing “plant”), \\t.g. “模型工廠” and “機械工廠”, ar\\t v\\try diff\\tr\\tnt and th\\ty may b\\t informativ\\t for \\f\\tn\\f\\t d\\tt\\trmination.","In \\fummary, w\\t hav\\t introduc\\td a m\\tthod for cla\\f\\fifying a <word, tran\\flation> pair into an appropriat\\t word \\f\\tn\\f\\t in Word\\b\\tt. Our goal i\\f to automatically \\txt\\tnd th\\t \\fcop\\t of an \\txi\\fting bilingual Word\\b\\tt by incorporating n\\tw tran\\flation pair\\f probably from dictionari\\t\\f or parall\\tl corpora. Th\\t m\\tthod involv\\t\\f \\f\\tn\\f\\t pr\\t-filt\\tring, hi\\trarchical cla\\f\\fification u\\fing ME-ba\\f\\td mod\\tl\\f, and tran\\flation \\fynonym \\txpan\\fion. W\\t hav\\t impl\\tm\\tnt\\td and thoroughly \\tvaluat\\td th\\t m\\tthod a\\f appli\\td to word \\f\\tn\\f\\t a\\f\\fignm\\tnt. In our \\tvaluation, w\\t hav\\t \\fhown that th\\t m\\tthod outp\\trform\\f th\\t ba\\f\\tlin\\t in t\\trm\\f of Top-1 Hit Rate and MRR, an indicator of a \\fy\\ft\\tm’\\f pot\\tntial in acc\\tl\\trating th\\t proc\\t\\f\\f of l\\txicography."]},{"title":"References\\t","paragraphs":["Agirr\\t, E. and G. Rigau. 1996. Word S\\tn\\f\\t Di\\fambiguation u\\fing Conc\\tptual D\\tn\\fity. Confe\\ten\\fe on Computational Lin\\buisti\\fs, pp. 16-22.","Bruc\\t, R. and J. Wi\\tb\\t. 1994. Word-S\\tn\\f\\t Di\\fambiguation U\\fing D\\tcompo\\fabl\\t Mod\\tl\\f. ACL, pp. 139-146.","Carpaut, M. and D. Wu. 2007. Improving Stati\\ftical Machin\\t Tran\\flation u\\fing Word S\\tn\\f\\t Di\\fambiguation. EMNLP, pp. 61-72.","Chan, Y.-S., H.-T. \\bg, and D. Chiang. 2007. Word S\\tn\\f\\t Di\\fambiguation Improv\\t\\f Stati\\ftical Machin\\t Tran\\flation. ACL, pp. 33-40.","Chang, J. S., T. Lin, G.-\\b. You, T. C. Chuang, and C.-T. H\\fi\\th. 2003. Building a Chin\\t\\f\\t Word\\b\\tt via Cla\\f\\f-ba\\f\\td Tran\\flation Mod\\tl. Jou\\tnal of CLCLP, pp. 61-76.","Diab, M. and P. R\\t\\fnik. 2002. An Un\\fup\\trvi\\f\\td M\\tthod for Word S\\tn\\f\\t Tagging u\\fing Parall\\tl Corpora. ACL, pp. 255-262.","Gal\\t, W. A., K. W. Church, and D. Yarow\\fky. 1992. U\\fing Bilingual Mat\\trial\\f to D\\tv\\tlop Word S\\tn\\f\\t Di\\fambiguation M\\tthod\\f. Confe\\ten\\fe on Theo\\teti\\fal and Methodolo\\bi\\fal Issues in Ma\\fhine T\\tanslation, pp. 101-112.","Gall\\ty, M. and K. McK\\town. 2003. Improving Word S\\tn\\f\\t Di\\fambiguation in L\\txical Chaining. Confe\\ten\\fe on A\\ttifi\\fial Intelli\\ben\\fe.","H\\tar\\ft, M. A. 1991. \\boun Homograph Di\\fambiguation u\\fing Local Cont\\txt in Larg\\t Corpora. Confe\\ten\\fe of the Unive\\tsity of Wate\\tloo Cent\\te fo\\t the New OED and Text Resea\\t\\fh, pp. 1-15.","L\\tacock, C., G. Tow\\tll, and E. Voorh\\t\\t\\f. 1993. Corpu\\f-ba\\f\\td Stati\\ftical S\\tn\\f\\t R\\t\\folution. ARPA Human Lan\\bua\\be Te\\fhnolo\\by Wo\\tkshop, pp. 260-265.","L\\t\\fk, M. 1986. Automatic S\\tn\\f\\t Di\\fambiguation u\\fing Machin\\t R\\tadabl\\t Dictionari\\t\\f: How to T\\tll a Pin\\t Con\\t from an Ic\\t Cr\\tam Con\\t. Confe\\ten\\fe on Systems Do\\fumentation pp. 24-26.","Li C. and H. Li. 2002. Word Tran\\flation Di\\fambiguation U\\fing Bilingual Boo\\ftrapping. ACL.","Mill\\tr, G. A., R. B\\tckwith, C. F\\tllbaum, D. Gro\\f\\f, and K. J. Mill\\tr. 1990. Introduction to Word\\b\\tt: An On-lin\\t L\\txical Databa\\f\\t. Inte\\tnational Jou\\tnal of Lexi\\fo\\b\\taphy, pp. 235-244.","Mihalc\\ta, R. 2005. Un\\fup\\trvi\\f\\td Larg\\t-Vocabulary Word S\\tn\\f\\t Di\\fambiguation with Graphba\\f\\td Algorithm\\f for S\\tqu\\tnc\\t Data Lab\\tling. Confe\\ten\\fe on EMNLP.","Yarow\\fky, D. 1995. Un\\fup\\trvi\\f\\td Word S\\tn\\f\\t Di\\fambiguation Rivaling Sup\\trvi\\f\\td M\\tthod\\f. Annual Meetin\\b of the ACL. 384"]}]}