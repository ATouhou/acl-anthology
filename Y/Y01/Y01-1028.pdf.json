{"sections":[{"title":"An HPSG Account of the Hierarchical Clause Formation in Japanese —HPSG-Based Japanese Grammar for Practical Parsing Takashi MIYATA*\\tAkira OHTANI* t\\tYuji MATSUMOTO* Graduate School of Information Science, \\tFaculty of Informatics, Nara Institute of Science and Technology \\tOsaka Gakuin University, 8916-5, Takayama-cho,\\t2-36-1, Kishibe-minami, Ikoma, Nara 630-0101, JAPAN \\tSuita, Osaka 564-8511, JAPAN {takashi,akira-o,matsu} @is.aist-nara.ac.jp * \\tohtani@utc.osaka-gu.ac.jp t Abstract","paragraphs":["The most perspicuous phenomenon that demonstrates the head-final property of Japanese is the sentence-final clusters of auxiliary verbs such as (s)ase and conjunctive particles nagara. Although they are related to the hierarchical clause structure that has been discussed in the literature of Japanese linguistics, the hierarchical complexities have also been one of the major causes of the failure of long sentence parsing in the field of natural language processing. To overcome this parsing problem, we develop Japanese Phrase Structure Grammar, NAIST JPSG, which is a partial implementation of ideas from not only recent developments in Head-driven Phrase Structure Grammar but also Minami's four-level syntactic/semantic hierarchy. We devote our discussion to the analysis of hierarchical clause formation, pseudo-lexical treatment of causatives and regulation of co-occurrence of subordinate clauses, with main focus on their specific lexical information of the sentence-final clusters. Causative constructions exhibit properties of simple/complex thematic relation in spite of their morphologically simple status. A clause can be embedded as subordinate clause if and only if the clause is a member of the same or lower level in Minami's sense than the main clause belongs to. These hierarchical clause phenomena can be explained by introducing lexical description and general mechanism assumed in JPSG."]},{"title":"1 Introduction","paragraphs":["Hierarchical clause formation (HCF) in Japanese is a phenomenon that has reflexes in syntax and semantics. Although there is a large body of descriptive work on this topic (see Minami (1974) and references cited there), there has been little attempt to give a formal analysis of the phenomenon.","This study concentrates on two types of relations for HCF: head-head relation and head-modifier relation headed by sentence-final clusters of auxiliary verbs and conjunctive particles, which are exemplified in some kind of complex predicate and subordinate clause, respectively. These hierarchical complexities make sentence to be long and not simple, so many linguists and engineers try to capture in mainly syntactic terms how these relations should be described. Especially, ambiguity in dependency analysis of subordinate clauses has been one of the major causes of the failure of long sentence analyses.","As an information-theoretic and constraint-based framework, Head-driven Phrase Structure Grammar (Pollard and Sag, 1994) is well-suited for a formal treatment of HCF that simultaneously captures generalization in syntax and semantics as well as interactions between them. Building on the work by Gunji (1994) and Ohtani et al. (2000), we propose a head-driven account of HCF, which introduces non-trivial extensions to HPSG and makes it possible to construct a practical parser.","The organization of this paper is as follows: Sec. 2 explains our extension of HPSG. Sec. 3 concerns adjacency of predicates referring to causatives. Sec. 4 treats the adjunction of subordinate clauses and proposes a formalization of HCF in HPSG framework. Sec. 5 states concluding remarks. 305 synsem_struc syn SYN h- ead CASE\\tcase HEAD ARG-ST list(synsem_struc) MOD\\tlist(synsem_struc) VAL Lai","DJCNTASUBCAT list(synsem_struc) list(synsem_struc) sem INDEX index SEM RESTR list( pred PROCESS TENSE proc EVENT event ASPECT list(aspect)_ list(tense) Figure 1: Feature Structure in NAIST JPSG"]},{"title":"2 Preliminaries","paragraphs":["This section provides an overview of some of the major concepts underlying NAIST JPSG, based on HPSG (Pollard and Sag, 1994; Sag and Wasow, 1999) and some recent studies. We will use HPSG as a tool for the formal representation of our analysis. Besides introducing a detailed background to feature structures of JPSG, we provide principles, schemata, and notational conventions of the framework for linguistic knowledge representation adopted throughout the rest of the paper.","Our formalization is an extension to HPSG in the following two directions:","• Introducing a new feature, adjacent, and adopting some schemata and principles related to the feature. (see (Ohtani et al., 2000) for detail)","• (Partially) designing the contents of semantic feature including propositional contents, tense, and aspect. 2.1 The Feature Structure JPSG is an integrated theory of Japanese language syntax and semantics. In this framework, linguistic object is referred to as a sign, which is formally modeled as attribute value matrices. Sign includes sentence, clause, phrase and lexical item and most of them can be composed in an unified manner called unification within HPSG. Attribute names appear in capitals, and the type of an object appears in italics. See the example in Fig. 1.","list(a) represents the list type whose elements are of type a. The synsem_struc type has attributes or features labeled SYN(TAX) and SEM(ANTICS). SYN(TAX) and SEM(ANTICS) serve to represent syntactic and semantic properties of a word or phrase. A type assigned to the node also determines what attribute labels can appear in its feature structure. Thus a feature structure of type syn can have the attribute labels HEAD and VAL(ENCE). A feature structure of type head has subtypes depending on its part of speech, such as verb, noun and p(ar)t(i)cl(e), each of which may have some of the head feature, such as CASE for noun, ARG(UMENT)-ST(RUCTURE) for verb, and MOD(IFIER) for verb and ptcl. Some features, such as ARG-ST, have values, which are list of objects represented as list(synsem_struc) here. In figures in the 306"]},{"title":"a.","paragraphs":["HEAD SEM [ ptcl CASE gai INDEX RESTR name-rel NAME Naomi NAMED 0 B El b. HEAD [verb VFORM past ARG-ST (11 PP[ga]) INDEX","([sing-rel RESTR\\tSIT SINGER El SEM Figure 2: Phrasal Signs for (a) Naomi-ga and (b) utatta a. complement-head schema:\\t[phrase]\\tC[phrase] H b. adjunct-head schema:\\t[phrase]\\tA[phrase] H[phrase] c. 0-complement-head schema: [phrase]\\tH[word] d. pseudo-lexical-rule schema: [word]\\tX [word]\\tH [word] Figure 3: Schemata in NAIST JPSG later sections, the elements of such lists are enclosed in angle brackets where the elements are listed from the left. In the class of ARG-ST, MOD, SUBCAT(EGORIZATION), and ADJ(A)C(E)NT lists, the elements are synsem_struc object and the elements in RESTR(ICTION) list are predicate) object.","We will describe classes of linguistic objects using feature structures in which many of the features appropriate only for a subset of that class will be omitted, and the sorts of some value may not be maximally specific. 2.2 Principles and Schemata Let us look at features of some of lexical signs (e.g., words) that will also be referred to in the later discussion for phrasal signs.","A few more remarks on features are necessary for Fig. 2. From Fig. 2b, we see that the SEM of utatta (sang) is a semantic relation, sing-rel, which will also be the SEM of entire sentence headed by utatta. However, the SEM in Fig. 2b is (necessary) incomplete, lacking specifications of the participants in the singing event. This information is, of course supplied by the argument of utatta by unification.","The SEM of noun (particle phrase in precise), Naomi-ga in Fig. 2a contains the two attributes INDEX and RESTR(ICTION). The INDEX (a), for instance, provides a way to connect the use of the word Naomi-ga to the person called Naomi that the speaker is referring to.","So far we have seen the feature structure of (phrasal) signs. We are ready to move on to the composition of them. JPSG is a constraint-based theory of Japanese grammatical competence. All of its lexical entries, phrasal representations, rule and even universal principles assumed in HPSG are partial constraints on constructs used to model types of linguistic object.","Let us now turn to some universal principles of HPSG, and see how they interact with the set of schemata of JPSG shown in Fig. 3 where C, A, and H mean complement, adjunct, and head, respectively. X means any constituent. In Fig. 3, we describe another set of schemata though HPSG (Pollard and Sag, 1987; Pollard and Sag, 1994) has assumed seven ones. Complement-head schema (a) includes Head-Subject, Head-Complement, and Head-Subject-Complement in HPSG. Adjunct-head schema (b) corresponds to Head-Adjunct. 0-complement schema (c) and pseudo-lexical-rule schema (d) are newly introduced ones, which are necessary for explaining HCF. Head-Filler in HPSG is not included yet since we have not decided the treatment of gaps in Japanese. Head-Marker is abandoned since we treat both particles and complementizers as lexical heads. 307 Naomi-ga","S [SUBCAT\\tI \\t complement-head PP \\t","[SUBCAT\\t El )] 0-complement-head \\t V [ARG-ST\\t( XP[ga] )] utatta Figure 4: Parse Tree for (1) SUBCAT ADJCNT [ADJNT 11[SUBCAT ( )"]},{"title":"e","paragraphs":["ADJCNT ( ) Figure 5: Subcategorization Feature Principle2 We take a simple example to see how a sentence (1) is actually analyzed under JPSG framework.","(1) Naomi-ga\\tuta-tta. Naomi-NOM sing-PAST Ǹaomi sang a song' (1) has a structure conventionally represented in a tree diagram as in Fig. 4.","In Fig. 4, the SUBCAT list of the head utatta contains one element, which is to match the synsem_struc value of Naomi-ga. The Subcategorization Feature Principle in Fig. 5 tells us that this list must consist of the SUBCAT list of the whole phrase (and the list of synsem.struc values of the COMP-DTRS list).'","This section sketched the basic mechanisms for formalizing linguistic information within the framework of NAIST JPSG. We have not completely reviewed the essentials of the theory, nor have we discussed the JPSG treatment of HCF. In the following sections, we would like to use JPSG to demonstrate that HCF in Japanese can be treated in the formal framework."]},{"title":"3 Adjacency of Predicates 3.1 Complex Predicate: Causative","paragraphs":["The study of causative such as (2), along with other complex predicates, has always revolved around the issue regarding the syntactic constituency of complex predicates.","(2) Ken-ga Mai-o\\tutaw-ase-ta. Ken-NOM Mai-ACC sing-CAUS -PAST K̀en made Mai sing a song.' Since the complex predicate is made up of more than one predicative element, it linguistically has been of great concern whether each of such elements independently functions as a predicate heading a clause in syntax or they collectively function as one predicate. 'This means that the COMP-DTRS list of utatta may have exactly one element. This element is the sign for Naomi-ga and","its synsemstruc value is therefore the same synsemstruc object that appears on the SUBCAT list of utatta. 2ED means concatenation of the two lists that does not preserve the order of each element. El"]},{"title":"308 a.\\t","paragraphs":["S\\tb.\\tS NP\\tVP2\\tNP\\tVP","I","Ken-ga VPi\\tV\\tKen-ga NP\\tV Mai-o utaw ase-ta\\tMai-o V\\tV utaw ase-ta Figure 6: (a) Syntactic Analysis and (b) Lexical Analysis S\\t S NP\\tVP2\\tNP\\tVP2 I I\\t----------","Ken-ga VP i\\tV\\tKen-ga ADV\\tVP2","..-------------\\t1\\ti\\t,.....„----- ADV\\tVPi ase-ta\\tnando-mo VPi\\tV nando-mo Mai-o utaw\\tMai-o utaw ase-ta Figure 7: Structural Ambiguities Caused by Adverb Nando-mo 'Repeatedly'","The syntactic analysis as shown in Fig. 6a assumes that the complex predicate is indeed constructed by HCF where each predicate heads its own clause. The predicate does not form a syntactic constituent and they are hierarchically organized. The lexical analysis as shown in Fig. 6b, on the other hand, claims that the complex predicate is formed in the lexicon. So it is mapped onto syntax as one predicate. The internal complexity of the complex predicate is not accessible in syntax. The complex predicate as a whole heads one clause.","However, this picture is too simplified. The recent development in the theory of syntax no longer supports such a clear dichotomy (Manning et al., 1999; Gunji, 1999). It has been known that a single complex predicate construction often shows the properties typical of monoclausal structure and those of biclausal structure at the same time. From the theoretical viewpoint, both analyses have the same explanatory power since they can construct the same argument and semantic structures. So from the implementation viewpoint more 'efficient' analysis should be adopted.","Fig. 6a causes structural ambiguities and 'inefficient' for parsing if there is an adverb between two NPs. For example, if there is an adverb nando-mo 'repeatedly' between Ken-ga and Mai-o, the adverb could modify VP 1 and VP2 even though these ambiguities have almost the same semantics (Fig. 7). In most cases, whether these ambiguities should be distinguished depends on the semantics of each predicate and pragmatic context. To differentiate structurally between the two cases results in increasing the total cost of parsing. The analysis shown in Fig. 6b, on the other hand, can delay such disambiguation until s̀emantic' or 'pragmatic' analyzing phase, though it requires some lexical rules that construct complex predicate. 3.2 Adjacent Feature and Pseudo-Lexical-Rule Schema Pseudo-lexical-rule schema in Fig. 3d is introduced to reduce structural ambiguities when an auxiliary verb specifies the left adjacent sister as word. ADJCNT feature adopted in ICOT JPSG (Gunji, 1987; Tsuda et al., 1989) concerns the specification. Fig. 8 shows Adjacent Feature Principle. Note that SUBCAT feature is inherited from the head daughter to the mother in Adjacent Feature Principle while 309 [ga]l HEAD\\t[wo]] PP ADJCNT ( \\t Complement-Head phrase","V/ HEAD A SUBCAT 0-Complement-Head XP[ga], YP[ni]","\\t ZP[wo] El word HEAD ADJCNT ARG-ST Mai-o V","PP HEAD ADJCNT Ken-ga Ei E1 A ( / HEAD V SUBCAT El El word","V ADJCNT ARG-ST (UP[ga] , WP[wo] word HEAD ADJCNT ARG-ST A verb ( El V[word]) CI V E3 SUBCAT El ADJCNT IEI","[ADJCNT )]\\t[SUBCAT ADJCNT Figure 8: Adjacent Feature Principle ADJCNT feature is required to be empty in the Subcategorization Feature Principle in Fig. 5. Note also that both principles require the ADJCNT feature of the complement daughter to be empty.","Fig. 9 shows how pseudo-lexical-rule schema and ADJCNT feature (principle) work in the analysis described in Fig. 6b. Note that the ADJCNT feature of (s)ase-ta 'caused' is not empty while the ADJCNT [ HEAD SUBCAT ( O) \\tComplement-Head ) E13, El Pseudo-Lexical-Rule utaw ase-ta Figure 9: Parse Tree of 'Ken-ga Mai-o utaw ase-ta' (Ken made Mai sing) feature of the mother is empty. Adjacent Feature Principle ensures the VP containing more than two auxiliary verbs form a left-branching parse tree, the principle requires the complement daughter to have empty ADJCNT feature.","Pseudo-lexical rule schema allows the higher constituent of the complex predicate to inherit the argument structure of the lower predicate, and as a result, the schema makes the two predicates form a constituent in syntax. In Fig. 9, matrix verb utaw 'sing' and causative verb (s)ase appear adjacent to each other when they are linearized on the surface. This surface formation makes a parser work more 310","Table 1: Minami's Four Levels with Constituents","A Subordinate clauses lead by conjunctives nagara, tutu, mama, tameni, . . . + a manner adverb a phonologically null nominative NP -I- a complement + a predicate","B Subordinate clauses lead by conjunctives node, tameni, reba, . . . + a restrictive modifier + nominative NP whose role is actor + an instance of level A + (negation) + tense","C Subordinate clauses lead by conjunctives kara, nara, te, . . . + a nonrestrictive modifier + an instance of level B + a modal element","D Subordinate clauses lead by conjunctive to + a vocative + an instance of level C sentence-final particle(s) efficient, since the structural ambiguities explained in above are avoided. In other words, syntactic analysis and lexical analysis have assimilated to a large extent, and they are no longer contrastive under our framework. 4 Adjunction of Predicative Constituents 4.1 Minami's Four-Levels Hierarchical Structure Minami (1974) draws four levels A, B, C, and D within Japanese clause structure from co-occurrence observed between various constituents. Table 1 summarizes characteristics of those levels. These levels form hierarchical ordering where level A is the lowest and level D is the highest. The level of the (subordinate) clause is defined by the head of the clause, that is, conjunctive. Roughly speaking, clause a can be embedded as a subordinate clause into a matrix clause 13, if and only if a is a member of the same or lower level than the one 3 belongs to. This condition disambiguates (3a) and (3b):","(3) a. [ Mai-ga\\tutaw-to ]B [gita-o\\thiki-nagara\\t.. . Mai-NOM sing-then\\tguitar-ACC play-while (̀Lit.) When Mai sings, while someone playing the guitar, ... '","b.*[ [ Mai-ga\\tutaw-to I B gita-o\\thiki-nagara 1,4 .. . Mai-NOM sing-then guitar-ACC play-while Conjunctive to 'then' leads to a subordinate clause in level B while conjunctive nagara 'while' leads to a subordinate clause in level A. Level A is the innermost layer of the sentential hierarchy and it cannot contain a level B subordinate clause. Thus, Minami's description gives a rough sketch of conditions of combinatorial nature of clause level.","Yoshimoto et al. (2000) proposed a formal treatment of Minami's hierarchy under the framework of HPSG and Discourse Representation Theory. However, their analysis focused only on the interpretation of temporal relation between the events described in subordinate and matrix clauses, and it simply reformulates Minami's hierarchy as 'hierarchy feature' which can take value A, B, C, and D.","Minami's (and Yoshimoto's) work seems to capture a surface ranking for such combination with using somewhat tentative levels, and there is no answer to the question: Which linguistic information is the origin of HCF (and his level of hierarchy)?","There is also strong needs for such conditions or heuristics that restrict the inclusion among these sorts of clauses when a system parses long and complex sentences. In order to refine the conditions or heuristics into more well-grounded rules, linguistic explanation is required that reveals the mechanism behind the hierarchy among these levels. 4.2 Modifier Feature and Adjunct-Head Schema Adjunct-head schema in Fig. 3b handles modification or adjunction between two elements, such as adverb and verb, and adjective and noun. This schema involves Modifier Feature Principle illustrated in 311 ] Complement-Head or RESTR El 0 INDEX Pseudo-Lexical-Rule INDEX RESTR","\\t 0 Modifier-Head SUBCAT O ADJCNT ( [ SUBCAT ADJCNT Figure 10: Modifier Feature Principle [MOD O","[RESTR INDEX RESTR A INDEX\\t[RESTR El RESTR Figure 11: Semantic Feature Principle Fig. 10. As is required by Subcategorization Feature Principle in Fig. 5, the ADJCNT feature of the head daughter must be empty in this principle. This constraint avoids structural ambiguities which would be caused by an adverb intervening between Mai-o and utaw in Fig. 6b. The SUBCAT feature of the head daughter is inherited to the mother. This allows arguments and modifiers to be scrambled one another.","We also introduce Semantic Feature Principle in Fig. 11, which consists of two cases as in standard HPSG, where operator G is an ordinary list concatenation. When the headed structure is complement-head structure or pseudo-lexical-rule structure, the semantic head is identical to the syntactic one. On the other hand, the semantic head is the modifier when the headed structure is modifier-head structure.","We analyze subordinate clause as modifier to the matrix clause. Fig. 12 illustrates analysis of (4), where adjunct-head schema in Fig. 3b and Modifier Feature Principle play a crucial role.","(4) Ken-ga\\tosokunat-ta node isogi\\tnagara sitakusi-ta. Ken-NOM be-late-PAST because be-hurried while prepare-PAST K̀en prepared as being hurry since he was late for something.' In Fig. 12, each subordinate clause is analyzed as an adverbial phrase (ADVP). Their MOD features specify their sisters as VPs. On the other hand, the SUBCAT feature of the lowest VP, sitakusi-ta, is propagated up to the mothers and is canceled by the higher PP.","As mentioned in Sec. 4.1, HCF in Japanese has the following characteristics:","1. Co-occurrence between subordinate and matrix clauses concerns the conjunctives, which are their lexical heads. 2. Each conjunctive constrains existence of tense and aspect in their complement verb phrase.3 Minami treated these two characteristics as a single hierarchy, whose levels are distinguished by labels A, B, C, and D. A close observation, however, indicates that they concern different structures: modification and adjacency which is a special case of complementation. Moreover, these two characteristics entail the","3We do not commit ourselves whether -ru and -ta convey tense information or not. Although we place them within tense feature for the simplicity, the following discussion depends only on the existence of -ta and distinction between -ru and -ta. For the same reason, we neither commit ourselves whether -(te)i and non -(te)i form of verb convey aspect information or not though they are described in aspect feature. 312 osokunat-ta node [ SUBCAT ADJCNT Complement-Head PP VP SUBCAT [ADJCNT Ken-ga\\t\\t Adjunct-Head ADVP [MOD( El ] ij","[ADJCNTADJCNT \\t Adjunct-Head ADVP [MOD ( ) VP [SUBCAT El ADJCNT sitakusi-ta Figure 12: Adjunct-Head Structures with Subordinate Clauses","Table 2: Minami's Embeddedness and Phrase Structure Minami's Embeddedness Phrase Structure VPi -conj i is embedded within VP2 -conj 2 (((VP1-conj1 VP2) conj 2) VP) VP1 -conj 1 is not embedded within VP2 -conj 2 (VPi --conji (VP2-coni2 VP)) hypothesis that co-occurrence of the clauses should have (indirect) relation with existence of tense and aspect within themselves.","To formalize HCF, we must also reformulate èmbeddedness' in Minami's notion into phrase structure. Suppose that a given sentence has two subordinate clauses VP 1 -conj 1 and VP2 -conj2 and also has matrix clause VP. We then assume the correspondence between Minami's embeddedness and phrase structure as shown in Table 2. Regarding conj 2 , the difference between embeddedness is reflected by modification of VP2 with/without VP]. -conji -","These considerations lead us to introduce the lexical entries of conjunctives in Fig. 13 and 14, which have ADJCNT and MOD features to state the above characteristics. means some kind of 'composition' that merges the aspects/tenses of subordinate and matrix clauses. Since the detail of the operation does not concern the following discussion, we only assume that the result of the operation be a list. As Minami pointed, level A clauses cannot contain tense markers (joc113 si). ADJCNT feature in nagara specifies that the adjacent VP does not have tense. On the other hand, level B clauses must contain tense markers, so the ADJCNT feature in node is specified as such. Note that this specification does not exclude non-ta-form of the VP adjacent to node since we define it as underspecification of tense.","Although we simply describe the semantics of subordinate clause headed by nagara or node as aspects in the matrix clause, we do not commit ourselves to this description. The following discussion does not rely on how the semantics of subordinate clauses is represented within the semantics of the matrix clause. 4.3 Modifier Feature and Subordinate Clauses Fig. 15 illustrates the interaction among various schemata and principles. In contrast to ADJCNT feature, MOD feature specifies the property of the phrase to be modified. The first element of the MOD feature of the subordinate clause should be unified with the phrasal sign of matrix clause due to Modifier Feature Principle. Constraints on ADJCNT and MOD features eliminate improper parses (5b) and (5c). El El >1 isogi nagara 313 [\\tp( EVENT [ACTOR RI TENSE ( ) Knagaraa sp El El EVENT ASPECT _TENSE [ACTOR 4 ADJCNT SUBCAT MOD SEM","HEAD adv HEAD\\tverb SEM","\\t RESTR SUBCAT (XP[ga]","HEAD verb INDEX SEM RESTR INDEX 13 EVENT (RESTR\\tASPECT TENSE Figure 13: Lexical Entry for Nagara (5) a. [ Ken-ga\\t[ [ osokunat-ta node\\t[ [ isogi\\tnagara sitakusi-ta\\t] 1. \\t Ken-NOM\\tbe-late-PAST because\\tbe-hurried while prepare-PAST","b. * [ [ [ Ken-ga\\tosokunat-ta\\tnode ] isogi\\tnagara Ken-NOM be-late-PAST because be-hurried while c. * [ Ken-ga\\t[ [ osokunat-ta node\\t] [ isogi\\tnagara\\t• • \\t Ken-Nom\\tbe-late-PAST because be-hurried while As is mentioned in Minami (1974), subordinate clause followed by nagara cannot contain a nominative NP. This property is captured by ADJCNT feature of nagara, whose first element is unified with phrasal sign immediately preceding nagara. The element specifies SUBCAT feature as the list whose first element is a phrase marked by nominal (particle) ga. This means that a nominative NP is not saturated in the subordinate clause followed by nagara.","The ADJCNT feature of nagara also accounts for another property. The subordinate clause followed by nagara cannot have tense which is represented by ru and ta. The empty list of the TENSE feature in the ADJCNT feature reflects this property. (5b) violates these two constraints on the feature of nagara. (5c) violates the constraint that the HEAD feature in MOD feature be of type verb.","In contrast to ADJCNT feature, MOD feature specifies the property of the phrase to be modified. The first element of the MOD feature of nagara should be unified with the phrasal sign of matrix clause due to Modifier Feature Principle. This unification ensures that the missing subject of the subordinate clause be identical to the subject of the matrix clause, since the semantic contents of the missing subject (represented as variable gi in Fig. 13) is shared with ACTOR features (1) in the first element of ADJCNT feature and (2) in the first element of MOD feature. Fig. 15 illustrates this situation where the SEM feature of the argument in subordinate clause isogi 'be-hurried' and ACTOR feature in the matrix clause sitakusita 'prepared' share their contents.","As illustrated in Fig. 14, the subordinate clause followed by node can contain a nominative NP and it must exhibit tense. They are represented by the lack of constraints on SUBCAT feature and the non-empty value of TENSE feature in ADJCNT feature, respectively. 314","adv HEAD verb [SEM\\tRESTR ASPECT TENSE ( tense )}"]},{"title":"11)","paragraphs":["gi"]},{"title":"1 -) a a","paragraphs":["ADVP [MOD ( [TENSE ri])] TENSE O ADV[ADJCNT","\\t )1","osokunat-ta\\t node [SUBCAT (","VP ACTOR TENSE ACTOR TENSE El E3 [ SUBCAT","VP ACTOR TENSE MOD ADVP ACTOR TENSE PI 0","El VP [TENSE Oa)]","HEAD verb INDEX 6 SEM RESTR\\tASPECT(EVENT TENSE INDEX HEAD ADJCNT SUBCAT MOD SEM ( [EVENT ASPECT TENSE 10 I","Knodeasp I RESTR Figure 14: Lexical Entry for Node SUBCAT TENSE","\\t El El PP\\t SUBCAT","VP ACTOR TENSE S A 0"]},{"title":"1","paragraphs":["Ken-ga sitakusita VP [SUBCAT (xP[gc]ig)] Apv [ACTORADJCNTTENSE ( isogi nagara Figure 15: Detailed Parse Tree for Fig. 12 315","Note that the properties of nagara: (i) absence of nominative and tense of the subordinate clause, (ii) co-indexing between nominative of the subordinate clause and subject of matrix clause and the properties of node: (i) arbitrary presence of nominative and (ii) obligatory presence tense for subordinate clause are described as lexical information in local manner. These constraints form interaction among constraints expressed in the lexical entries. Thus there is no need for assuming tentative labels A, B, C, and D of subordinate clauses."]},{"title":"5 Concluding Remarks","paragraphs":["Earlier works capture constraints on the HCF as syntactic ones and the notion on adjacency and modify is not necessarily stressed. We have tried to specify them from semantic embedding for feature structure described in the lexicon.","A parser based on a declarative grammar that deals with various aspects of language is indispensable for natural language processing. For constructing a practical parser, we develop a unification-based grammar. The principles, schemata and features are designed through considering various aspects of Japanese and describing regularities among them as a set of local constraints. There still remain many problems, since complicated interactions occur in clause structure in Japanese. In this paper we gave a more fine-grained explanation for the constraints in HCF than one proposed by Minami, and our explanation is based only on the information in lexical entries and would be applicable to other conjunctives."]},{"title":"References","paragraphs":["Gunji, Takao. 1987. Japanese Phrase Structure Grammar. Reidel, Dordrecht.","Gunji, Takao. 1994. Nihongo kukOzO-bunpO ni motozuku kOritsutekina kObunkaiseki no kenkyil (studies on efficient parsing based on Japanese phrase structure grammar). Grant-in-aid for scientific research by ministry of education, science and culture, Japan, Osaka University. In English and Japanese.","Gunji, Takao. 1999. On lexicalist treatments of Japanese causatives. In Levine and Green (Levine and Green, 1999), chapter 3, pages 119-160.","Levine, R. D. and G. M. Green, editors. 1999. Studies in Contemporary Phrase Structure Grammar. Cambridge University Press, Dordrecht.","Manning, Christopher D., Ivan A. Sag, and Masayo Lida. 1999. The lexical integrity of Japanese causatives. In Levine and Green (Levine and Green, 1999), pages 39-79.","Minami, Fujio. 1974. Gendai Nihongo no laze) (Structure of Contemporary Japanese). Taishukan, Tokyo. In Japanese.","Ohtani, Akira, Takashi Miyata, and Yuji Matsumoto. 2000. On HPSG-based Japanese grammar — refinement and extension for implementation —. Journal of Natural Language Processing, 7(5):19-49. In Japanese. Pollard, Carl and Ivan A. Sag. 1987. Information-Based Syntax and Semantics. CSLI. Pollard, Carl and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. The University of Chicago Press.","Sag, Ivan A. and Thomas Wasow. 1999. Syntactic Theory: A Formal Introduction. The Center for the Study of Language and Information (CSLI), Stanford University.","Tsuda, Hiroshi, KOiti Hasida, and Hidetosi Sirai. 1989. cu-Prolog and its application to a JPSG parser. In Koichi Furukawa, Hozumi Tanaka, and Tatsunosuke Fujisaki, editors, Logic Programming '89, volume 485 of Lecture Notes in Artificial Intelligence. Springer-Verlag, pages 134-143.","Yoshimoto, Kei, Chidori Nakamura, and Yoshiki Mori. 2000. A unified approach to tense in Japanese. In Proceedings of the 14th Pacific Asia Conference on Language, Information, and Computation (PACLIC14), pages 389-400, Japan, February. 316"]}]}