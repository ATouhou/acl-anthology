{"sections":[{"title":"Mining the Relation between Sentiment Expression and Target Using Dependency of Words ","paragraphs":["Zhongchao Fei, Xuanjing Huang, and Lide Wu Department of Computer Science and Technology, Fudan University, Shanghai, 200433, China {zcfei, xjhuang, ldwu}@fudan.edu.cn Abstract. In some applications of opinion mining in text, it is important to distinguish what an author is talking about from the subjective stance towards the topic. Therefore, it needs to find the relation between sentiment expression and target. This paper proposes a novel method based on dependency grammars to mine the relation. In this method, the process of mining the relations is turned into a procedure of searching in the dependency tree of a sentence. The result of our experiments shows that word dependency relation based methods is more flexible and effective than some previous surface patterns based methods. Keywords: Opinion Mining, Dependency Grammars, Sentiment Analysis, Dependency of Words."]},{"title":"1 Introduction","paragraphs":["Opinion mining is also called sentiment analysis. It is to analyze whether an author expresses a favorable or unfavorable sentiment for a specific target. Now, it has been extensively used in text filtering, public opinion tracking, customer relation management, etc. [8],[9],[12],[19]. For example, during mining the opinion about a product of customers, we need to find what the customers remark on. It means we should not only extract the sentiment expressions, but also find the targets. Therefore, it needs to mine the relation between sentiment expression and target [9]. This paper will focus on it. The rest of the paper is arranged as following. Section 2 introduces some previous work. Section 3 provides how to gain subjective words. Section 4 introduces the dependency relation between words. Section 5 and section 6 put forward our method on mining the relation. Experiment and result are discussed in the last section."]},{"title":"2 Previous Work","paragraphs":["There is some previous work about opinion mining. Some previous work usually depend on the position between words [8],[9],[12],[17]. In some of the publications, n-gram was used [1],[15]. Turney (2002) utilized some phrase patterns such as RB/RBR/RBS+JJ+NN/NNS; JJ+NN/NNS+ Anything; RB+VB+ Anything. These patterns are composed of subjective adjectives, nouns, adverbs, etc. Nasukawa (2003) uses some patterns as","V+Obj: admire somebody,","JJ+Obj: crude oil. 257 V is the subjective verbs, JJ represents subjective adjectives. Obj represents the target. Nasukawa further defined some transfer verbs in the patterns, such as get, feel, etc, which may help to expression sentiment. Yi et al. (2003) utilized some patterns based on BNP. Popescu and Etzioni (2005) defined 10 kinds of rules to extract opinion patterns. For example,","If ∃ (M, NP = f) po = M : (expensive) scanner,","If ∃ (S = f, P, O) po = O : lamp has (problems), po=potential opinion, M=modifier, NP=noun phrase, S=subject, P=predicate, O=object. These rules point out which component of the patterns is the feature (target) and which is the subjective word. They also mentioned that these patterns are based on some dependency relations, but they did not depict them in detail. As we can see, the above methods acquire relations based on fixed position of words. Some important relations may be missed. For example, (1) The characters and acting is nothing spectacular. (2) The story is needlessly and pointlessly concluded with a violent sequence. (3) This plot thread predictably leads to violence. In these samples, the words in bold are targets and subjective words. It is difficult to contain such instances using the patterns above."]},{"title":"3 Collecting Subjective Words","paragraphs":["In most of the previous work, sentiment expressions mainly depend on some words, which can express subjective sentiment orientation. For example, good often expresses positive sentiment orientation, bad often expresses negative sentiment orientation. Such subjective words will also be used in our method. One of the subjective words set we used is from General Inquirer terms. In it, some words have the attribute of sentiment orientation as positive or negative.1","We will use nouns, adjectives, adverbs, and verbs that have such attribute. Considering the subjective words may be domain-restricted, we also gain another two subjective words set using bootstrapping method based on WorldNet [2],[14]. Seeds are collected manually from the corpus we used. Then we extend these seeds by their synonyms through WordNet2.1. We extend the seeds of their first sense to get the word set WE1st, and extend the seeds of all their senses to get word set WEAll. The results are shown in Table 2."]},{"title":"4 Dependency of Words","paragraphs":["The dependency relation of words is based on dependency grammars [7], [19]. It refers to the binary relation between two words. Each relation has a word as parent (or head). The other is the child (or modifier). A word has one parent at most. Nevertheless, a word may have several children. The relations of a sentence will form a dependency tree. Parts of the relations are showed in Table 1.  1 http://www.wjh.havard.edu/~inquirer/spreadsheet_ guide.htm 258 Table 1. Some dependency relations between words","Relation type Description Samples Parent Son subj subject He will go go He obj object tell him tell him","a good book book good mod modifier (adj , adv , ...) go there go there comp complement in the room in room Dependency relations defined by dependency grammars are useful to do sentiment analysis. They will help to find the relations between sentiment expression and target. Based on the transitivity of relations, different words in a sentence may be related. For example, (4) This film is genuinely funny. The dependency relations of this sentence are as Figure 1.   Fig. 1. Dependency relations of example (4). In Figure 1, the head of an arrow direct to the child. The tail comes from the parent. The tag in an arrow is the type of the relation. We can see that the subjective word funny and the target film is the child of is. The word genuinely modifies funny directly. Then, based on the transitivity of the relations, we can find genuinely is related to the word film indirectly. The sentiment expression and the target pair {film, genuinely funny} can be extracted by our method at last. "]},{"title":"5. Three Instances of Dependency Relations for Opinion Mining","paragraphs":["With these relations defined by the dependency grammars, we find there are three instances about the relation for opinion mining as Figure 2. target S- words same ancestor S- words target target S- words A B C  Fig. 2. Three instances of dependency sub-trees for opinion mining S-words = subjective words. The dashed means the nodes may not be related directly. i ) The subjective words are in the children of target as A in Figure 2. In such instance, the sentiment expressions are in the modifiers of targets, which include adjective, noun, participle phrase, and attributive clause, etc. For example, (5) There's a great movie! the genuinelyisfilm funnyspec subj mod comp 259 Dependency relations: {(there, 's), ('s ,null), (a, movie), (great,movie), (movie,'s)}. (6) Lumumba is a story that deserves to be told. Dependency relations: {(Lumumba,is), (is, null), (a, story), (story, is), (that, story), (deserves, that), (to ,deserves), (be, to), (told, be)}. In the brackets, the second words are the parents. null means the word in the bracket is the root of the dependency tree. In (5), movie is the target and great is the modifier. In (6), story is the target and deserves is the related subjective word. ii ) The target and the subjective words are in the different children of the same ancestor as B in Figure 2. We will deal with the instance that the same ancestor is a verb. For example, (7) The movie is just plain lazy! Dependency relations: {(the, movie), (movie, is), (is, null), (just, is), (plain, lazy), (lazy, is)}. In (7), the target is movie and the subjective word is lazy. Their have the same ancestor is. In (3), the target is plot thread and the subjective word is violence, leads is their common ancestor. In such instance, subjective words may also be in an adverbial modifier, a predicative, or a complement of the verb. iii ) The subjective words are in ancestors of the target as C in Figure 2. We will deal with the instance that the subjective word is a verb, and the target is in the subject or object of the verbs. For example, (8) Avoid this film at all costs. (9) For folks like myself who love the first movie and enjoy the games. In (8), avoid is the subjective word and film is the target. In (9), love and enjoy are both subjective words. movie and game are the targets. Besides the relations between subject word and target, there are also dependency relations between subjective words and their modifiers. For example, (10) There are a number of completely meaningless story sidetracks. In (10), completely modifies meaningless. In (7), plain modifies lazy. These words enhance the strength of the sentiment. Such kinds of modifiers are in the children of the subjective word. They will affect the strength or orientation of the sentiment. We call them S-word in the following sections. Some of the words in General Inquirer terms, which are with the attribute of “Negate” or “Strong” and without the attribute of “Positiv” or “Negativ”, such as not, rarely, never, etc. are used as S-word in our method."]},{"title":"6 Mining Dependency Relations","paragraphs":["When mining the relations, we first search for which sentences may express subjective opinion. It is to find whether it contains any subjective words. If a subjective word appears, we will search for the related targets and S-words. It is a procedure of searching in a multi-way tree."]},{"title":"6.1 Mining Steps","paragraphs":["According to the analysis of section 5, we design the mining steps as following. Step 1: If a subjective adverb is found, go to the next step. If a subjective adjective or noun is found, go 260 to step 3. If a subjective verb appears, go to step 4. Step 2: Search in the ancestors of the adverb. If a subjective adjective is met, go to the next step. If a verb is met, go to step 4. Else, go to step 8. Step 3: Search in the ancestors of the subjective adjective or subjective noun. If a verb is met, go to the next step. If a target is met, go to step 6. Else, go to step 8. Step 4: Search in the children of the verb. If a target appears, go to next step, else go to step 8. Step 5: Search in the children of the verb and extract the S-words. Step 6: If subjective adjectives appear, search for the S-words in their children. Step 7: Search in the remainder of the sentence until it is finished. Step 8: Output the extracted targets, subjective words, and S-words. For example, in (2), the dependency of words is {(The, story), (story, is), (is, null), (needlessly, is), (and, is), (pointlessly, concluded), (concluded, is), (with, concluded), (a, sequence), (violent, sequence), (sequence, with)}. First, we find the subjective word needlessly, and then find its parent is. It is a verb. Next, the target story is found in the children of is. With the same way, we can find the subjective word pointlessly, violent and their target story. The dependency relation pair as {story, needlessly pointlessly violent} was extracted finally. It expresses the same sentiment orientation to the target as the sentence try to do. Table 2. Statistics of Subjective words Words Set adjective adverb noun verb total Seeds 173 44 42 24 283 WE1st 414 94 170 27 705 WEAll 696 110 360 73 1239 GI-Terms 1571 70 1441 1108 4190 Table 3. Statistics of Sentences SjWords FTerms Both Total GI-Terms 50519 24841 WE1st 33342 17656 WEAll 41245 29298 21106 64720 GI-Terms = General Inquirer terms SjWords = the number of sentences that contain subjective words. FTerms = number of sentences that contains the film terms. Both = the number of sentences that contain both the subjective words and the film terms. Total (table 3) = total number of sentences of the corpus."]},{"title":"7 Experiment and Analysis 7.1 Experiment","paragraphs":["We use the polarity dataset 2.0 in our experiment2",". It includes 1000 positive and 1000 negative reviews on films. In our experiment, classification of the sentiment orientation will not be done. We will test the recall and the precision of the extracted pairs. Some of the English parsers, such as Stanford Parser and MiniPAR achieve a high precision to extract word dependency relations [7], [13]. We use the Stanford parser (Version of 2005.7) in our experiment.  2 http://www.cs.cornell.edu/people/pabo/movie-review-data 261 As all the characters in the corpus are in lowercase, which increases difficulty to do name entity extraction. Therefore, the proper nouns, such as titles of films are not included in the targets. Only some popular film terms, such as story, dialogue, plot, script, etc. are included. We totally collect 86 popular film terms from the corpus and online film glossary3",". Table 3 shows the statistics of the sentences that contains subjective words and film terms4","of the corpus. Several patterns used by Nasukawa (2003), Yi et al. (2003), Popesecu et al. (2005), Liu et al. (2005) are adopted to compare with our method. These patterns are","(RB)+JJ+(NN)+Target; ((RB)+JJ)+NN+ Target;","Target+ VB+(RB)+JJ/NN; Target+(RB)+V; (RB)+V+Target. JJ, NN, RB, and V are all limited to subjective words. The bracket means the component in it is optional. The patterns used by Turney (2002) are not included in the baseline, as some of his patterns do not contain targets. Table 4 shows the number of sentences that the pairs of target and sentiment expression are extracted using different method from the corpus with GI-Terms. DR represents our dependency relation based method. The search depth of DR-4 is limited to 4 when search for the children or the ancestors. The search depth of DR-All is not limited. Table 5 shows some of the extracted pairs. To evaluate the method in detail, we randomly annotated 400 sentences that contain both subjective words of GI-terms and the film terms to analysis5",". In our evaluation, if the subjective stance of the extracted sentiment expressions is the same as the subjective stance of the sentence to the same target, we say the sentiment expression and the target are coherent and the sentence is mined correctly. Therefore, the definitions of precision and recall are as following. A= number of sentences that mined correctly; B= number of sentences which sentiment expression and target pairs were extracted from; C= the number of sentences that contain coherent sentiment expression and target pairs. A Precision= B A Recall=","C In these 400 sentences, C is 262. The results are in Table 6."]},{"title":"7.2 Analysis","paragraphs":["From Table 6, the F-value of dependency-based method is higher than the baselines. It shows that our method is superior to some patterns based method. Through the analysis, we find some reasons that affect the precision and recall. First, the precision is lower when testing with GI-terms. It is because many words without obvious sentiment orientation in film reviews, such as basic, mend, create, etc. are considered as the subjective  3 http://www.filmsite.org/filmterms.html 4 The POS-tagger we used is Stanford Log-linear Model Tagger v1.0. 5 http://www.cs.fudan.edu.cn/mcwil/~zcfei/sent/sent.htm 262 words in General Inquirer terms. There is also another main reason that affects the precision. It is due to some redundancy relations are extracted by our method. For example, (14) A movie for the teen generation that touches on a very cool idea, but presents it in a very bad package. (15) What adds depth to the story is a subplot in which the principal of Danny's school becomes obsessed with purging the hatred from Danny. In example (14), {movie, very cool bad} is extracted. In example (15), {story, hatred} is extracted. Their sentiments orientations are not the same as the sentences try to express. From Table 6, we can see that the precision is higher when the depth of search is limited to 4 than not limited. It is because redundant relations are reduced when the search depth is limited. In our experiment, the F-value is highest when the depth is limited to 4. Table 4. Statistics of extracted sentiment expression pairs(GI-Terms) Method Count Baseline1 6701 Baseline2 12545 DR-4 19556 DR-All 21257 Table 5. Samples of extracted pairs Target Sentiment Expression music cool movie no originality film avoid dialogue, editing shoddy Basline1: (RB)+JJ+(NN)+Target,((RB)+JJ)+NN+ Target. Basline2: baseline; Target+ VB+(RB)+JJ/NN; Target+(RB)+V; (RB)+V+Target. Table 6. Evaluation on 400 sSentences Method Baseline1 Baseline2 DR-4 DR-All DR-4 DR-All DR-4 DR-All Word Set GI-Terms GI-Terms GI-Terms GI-Terms WE1st WE1st WEAll WEAll Precision 69.6% 68.2% 67.3% 63.4% 77.2% 74.5% 74.9% 70.8% Recall 20.9% 44.3% 76.3% 79.4% 60.6% 62.2% 65.6% 68.3% F(ß=1) 32.1% 53.7% 71.5% 70.5% 67.9% 67.7% 69.9% 69.5%"]},{"title":"8. Conclusion and Future Work","paragraphs":["We present a dependency grammars based method to extract sentiment expression and target pairs in opinion mining. It shows advantage over the patterns-based method. By evaluation on a subset of the test corpus, we get promising result. However, in the dependency-based method, we find it difficult to avoid extracting redundancy relations. We find it a little arbitrary to limit the search depth. In the future, we would like to find more effective ways to reduce redundancy relations. In addition, the dependency relation instances in section 5.2 at present are not elaborate enough. We will also try to refine them. 263"]},{"title":"References","paragraphs":["1. Dave, Kushal, Steve Lawrence, David M. Pennock. Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews. WWW2003, May 20-24, 2003, Budapest, Hungary. 2. Esuli, Andrea, Fabrizio Sebastiani. Determining the Semantic Orientation of Terms through Gloss Classification. Submitted to CIKM’05, Oct.31, 2005, Bremen, DE. 3. Fraser, Norman M. Parsing and dependency grammar. UCL working papers in Linguistics. 1:296-338. 1989. 4. Hu, Minqing, Bing Liu. Mining and Summarizing Customer Reviews. Proceeding in KDD’04, August 22-25, 2004, Seattle, Washington, USA. 5. Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan, Thumbs up? Sentiment Classification using Machine Learning Techniques, Proceedings of EMNLP 2002. 6. Zhu, Yanlan , Jin Min, Ya-qian Zhou, Xuanjing Huang, Lide Wu. Semantic Orientation Computing Based on HowNet. Journal of Chinese Information Processing. Vol1, No.20, Jan. 2006. 7. Lin, Dekang, Dependency–based Evaluation of MiniPAR. In Proceedings of the Workshop on the Evaluation of Parsing Systems. May, 1998. 8. Liu, Bing, Minqing Hu, Junsheng Cheng. Opinion Observer: Analyzing and Comparing Opinions on the Web. WWW 2005, May 10-14, 2005, Chiba, Japan. 9. Nasukawa, Tetsuya, Jeonghee Yi. Sentiment Analysis: Capturing Favorability Using Natural Language Processing. K-CAP’03, October 23-25, 2003, Sanibel Island, Florida, USA. 10. Turney, Peter, Measuring Praise and Criticism: Inference of Semantic Orientation from Association. ACM Transactions on Information Systems, Vol. 21, No. 4, October 2003, Pages 315-346. 11. Pang, Bo, Lillian Lee. Seeing stars: Exploiting class relations for sentiment categorization with respect to rating scales. Proceedings of the ACL 2005. 12. Popescu, Ana-Maria, Oren Etzioni. Extracting Product Features and Opinions from Reviews. Proceedings of HLT-EMNLP, 2005. 13. Swanson, Reid and Andrew S. Gordon. A Comparison of Alternative Parse Tree Paths for Labeling Semantic Roles. Accepted Posters , COLING•ACL. 2006. 14. Takamura, Hiroya, Takashi Inui, and Manabu Okumura. Extracting Emotional Polarity of Words using Spin Model. In Proceedings of the Joint Workshop of Vietnamese Society of AI, SIGKBS-JSAI, ICS-IPSJ and IEICE-SIGAI on Active Mining, 2004. 15. Yu, Hong, Vasileios Hatzivassiloglou. Towards Answering Opinion Questions: Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences. In Proceedings of EMNLP 2003. 16. P. D. Turney and M. L. Littman. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems, 21(4):315–346, 2003. 17. Turney, Peter. Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. Proceedings of the ACL 2002, July. pp. 417-424. 18. Yi, Jeonghee, Tetsuya Nasukawa, Razvan Bunescu, Wayne Niblack. Sentiment Analyzer: Extracting Sentiments about a Given Topic using Natural Language Processing Techniques. Proceedings of ICDM, pp.427-434, 2003 19. Yli-Jyrä, Anssi, Multiplanarity – a Model for Dependency Structures in Treebanks. In: Second Workshop on Treebanks and Linguistic Theories, Sweden. 2003. 189–200. 264"]}]}