{"sections":[{"title":"The stock index forecast based on dynamic recurrent neural network trained with GA","paragraphs":["Fang Yixian1,∗","Wang Baowen2","Wang Yongmao1","1 Science of college,Yanshan University, Qinhuangdao Hebei Province, China,066004","2 Information of college, Yanshan University,Qinhuangdao Hebei Province, China,066004","Abstract:In order to forecast the stock market more accurately, according to the dynamic property for the stock market, propose the real time modeling forecast via dynamic recurrent neural network and use GA to study online, then it improves the network performance and better describes the dynamic characteristic of stock market. By forecasting Shanghai negotiable securities index, it shows better validity.","Keyword: Dynamic property Neural network Stock index Genetic algorithm"]},{"title":"1 Introduction","paragraphs":["The stock market is a very complicated nonlinear dynamic system, it has both the high income and high risk properties. So the forecast of stock market trend has been always paid attention to by stockholders and invest organization. However, because of the high nonlinearity of the stock market, it is difficult to reveal the inside law by the traditional forecast methods, so we are not satisfied with many of the applied effect for forecast analysis method [1]",".","In recent years, the rapid development of computer and artificial intelligence technology provide many new technology methods for the modeling and forecast of the stock market [1]",". The neural network gains wide application in the aspect of nonlinear forecast due to its broad adaptive and learning ability. There is many neural networks applied in forecasting stock price, at present, the most widely used neural network is BP NN, but BPNN has many shortcomings such as the slow learning rate, large calculate amount, easy to get into local minimum and bigger randomicity and so on. This affects the predicted results of the stock price. RBF neural networks is also a very popular method to predict stock market, this network has better calculational and spreading abilities, it also has stronger nonlinear mapped ability[2]",". But the stock market is not only with nonlinearity but also chaos, and it is a dynamic system related to time (time is a independent variable). Therefore the network for predicting itself is a dynamic system, it requires us to introduce short-time memory function in network. According to short-time the dynamic neural network can be divided into time delay NN and local or whole feedback NN. This paper uses an improved Elman dynamic recurrent neural network model[3-4]","to carry modeling forecast for stock index, this neural network has better effect in dealing with time varying information aspect, the results show that using it to predict time varying stock index will have satisfactory effect."]},{"title":"2 Neural network predict approach for stock price ","paragraphs":["∗ E-mail: jiahao218@126.com, Tel: 0335-8515601 319 Let"]},{"title":"{ }(1, 2,","paragraphs":["t"]},{"title":"Xt N= L )","paragraphs":["be the data series of time-varying volatility for stock price, the stock predict is to set up a model"]},{"title":"G","paragraphs":[", and describe the relation between j"]},{"title":"X","paragraphs":["and prevenient price"]},{"title":"()","paragraphs":["12"]},{"title":",,,","paragraphs":["j jjk"]},{"title":"XX X","paragraphs":["−− −"]},{"title":"L ()","paragraphs":["12"]},{"title":",,,","paragraphs":[". j jj jk"]},{"title":"XGXX X","paragraphs":["−− −"]},{"title":"= L","paragraphs":[","]},{"title":"( )1, 2,jk k=+ +L","paragraphs":["This paper use dynamic recurrent neural network to describe mathematics model, compared to feedforward neural network, it conquers the defect of feedforward neural network without dynamic property. It can make the trained network possess nonlinear mapped and dynamic characteristics. We introduces genetic algorithm to adjust model constantly during learning process, it makes the network model more intelligent[5]","."]},{"title":"2.1 Network Structure","paragraphs":["This paper uses an improved Elman dynamic recurrent neural network model. Its structure is the following Fig.1.  Fig.1 The structure of dynamic recurrent neural network where"]},{"title":"()x t","paragraphs":["is the input of NN at time ,"]},{"title":"t ( )yt","paragraphs":["is the output of NN at time . Compared to feedforward neural network, it is introduced the associated nodes besides the input nodes, the hidden nodes and the output nodes. The associated nodes can be used to store the activity of hidden nodes at the preceding time, and it is exported to the hidden nodes at the next time. That makes recurrent NN have dynamic memory ability. Feedback plus is"]},{"title":"t α","paragraphs":[". We can regard the associated","nodes as input nodes, only its input is the output of the hidden nodes at the former time. The dynamic equation of NN are as follows,"]},{"title":"() ( ) () () () () ()() ()() (","paragraphs":["1 1"]},{"title":"1 111","paragraphs":["h ii i ii h","ii ij j i j"]},{"title":"yt W t H t Ht fht ht wt xt t H t tαν θ","paragraphs":["= ="]},{"title":"⎧ =−⎪ ⎪ ⎪ = ⎡⎤⎨ ⎣⎦ ⎪ ⎪ =− + − −+ ⎪⎩ ∑ ∑ ) ","paragraphs":["320 where is the weight between input layer neuron and hidden layer neuron , is the weight between hidden layer neuron"]},{"title":"i","paragraphs":["and output neuron ,"]},{"title":"()","paragraphs":["i"]},{"title":"wt i ()","paragraphs":["i"]},{"title":"Wt ( )","paragraphs":["ij"]},{"title":"tν","paragraphs":["is the feedback weight between hidden neuron and associated nodes,"]},{"title":"i ( )","paragraphs":["i"]},{"title":"Ht","paragraphs":["is the output of hidden nodes ,"]},{"title":"h","paragraphs":["is the number of the hidden nodes."]},{"title":"i ( )","paragraphs":["i"]},{"title":"tθ","paragraphs":["is the bias value of hidden layer node ."]},{"title":"i ()f •","paragraphs":["is the Sigmoid transfer function. Let"]},{"title":"( )yt","paragraphs":["be the expected output, then we have"]},{"title":"( ) ( ) ( )et yt yt=−","paragraphs":[". Let"]},{"title":"() () ()(","paragraphs":["2"]},{"title":"1 2 )E tytyt=−","paragraphs":["be the performance index."]},{"title":"2.2 NN learning algorithm","paragraphs":["Because grads descend algorithm exists faults that the learning results depend excessively on the initial weight vector and that it is easy to get into local minimum, we adjust network weight with GA. GA is a searching algorithm based on natural selection and natural gene, usually it is composed of four basic operations: encoding, crossover, mutation, selection. At present most of the GA is applied in feedforward NN, we apply GA to training the weight of the dynamic recurrent network..","Firstly, we should do some preparative work for GA: confirm the coding form of chromosome(this paper adopts binary system coding), the number of chromosome"]},{"title":"μ","paragraphs":["and the length of chromosome L. Let the length of each weight be , the NN structure be 1-M-N-1, the crossover probability is , the mutation probability is , the allowed maximum error square sum is"]},{"title":"l Pc Pm ε","paragraphs":[". The error square sum is"]},{"title":"() ()","paragraphs":["2 ikk"]},{"title":"Eytyt=−⎡ ⎤⎣ ⎦∑","paragraphs":[". Genetic evolution process of network weight is as follows: (1) Set the above given parameters. (2) Produce an initial colony with"]},{"title":"μ","paragraphs":["individuals. (3) Calculate the fitness of every unit,"]},{"title":"()","paragraphs":["1"]},{"title":"exp min","paragraphs":["ii"]},{"title":"fEE","paragraphs":["i−"]},{"title":"=−⎡ ⎤⎣ ⎦","paragraphs":[","]},{"title":"1, ,i μ= L","paragraphs":["If there is a fitness of an individual that satisfies"]},{"title":"min","paragraphs":["i"]},{"title":"E ε<","paragraphs":[", then stop, otherwise","perform step(4). (4) According to fitness, choose"]},{"title":"μ","paragraphs":["individuals to construct father colony.","(5) According to crossover probability , mutation probability , take crossover and mutation operation for father colony , then we will get a new colony. Then come back to step(3)."]},{"title":"Pc Pm 3 The modeling simulation of Shanghai negotiable securities index","paragraphs":["321","Here we choose the stock price of Shentiandi on 2006.5.16 as samples. Choose the sample data from 09:30 am to 15:00 pm as the training samples of dynamic recurrent neural network. We choose one data every minute from opening quotation to closing quotation, there are 330 data samples. After data processing we choose odd 280 data as samples, the preceding 220 data is input samples, we choose 60 data before closing quotation as test samples.","After theory analysis and experimentation for stock price that we have choose we think the structure of dynamic recurrent neural network should be 1-3-3-1 (input node, associated node, hidden node and output node are 1, 3, 3, 1, respectively). Feedback coefficient of the associated node"]},{"title":"0.65α =","paragraphs":[","]},{"title":"( ) 0.5","paragraphs":["i"]},{"title":"tθ =","paragraphs":[", the bound of network weight , and are"]},{"title":"[1","paragraphs":[", and"]},{"title":"[3","paragraphs":["respectively. Test sample i"]},{"title":"W","paragraphs":["i"]},{"title":"w","paragraphs":["ij"]},{"title":"v ,1]− [0, 3] ,3]− ( ) ( )1x kyk−⎡ ⎤⎣ ⎦","paragraphs":["is single input and single output mode. Training network is mostly modifying the weight of network, make the network have dynamic characteristic. The overall steps"]},{"title":"500N =","paragraphs":[", we show every value of the vectors with binary system encoding string which length is 10 . the number of samples"]},{"title":",,Wwv μ","paragraphs":["=30, crossover probability , mutation probability is adaptive ( the smaller fitness is, the larger mutation probability is ). The mutation probability"]},{"title":"0.60Pc = 0.001 [1:1: ] 0.001/Pm μ μ= −×","paragraphs":[","]},{"title":"0.001ε =","paragraphs":[". After 150 times genetic evolution, the optimized results are"]},{"title":"[ ]0.4089, 0.8778, 0.3354","paragraphs":["T"]},{"title":"W =− −","paragraphs":[","]},{"title":"[ ]2.7632, 2.6463, 2.2665","paragraphs":["T"]},{"title":"w = 1.8860 2.2696 1.4047 0.0616 0.7728 1.5647 2.3546 2.8652 0.3217","paragraphs":["T"]},{"title":"v −⎡⎤ ⎢⎥=− −⎢⎥ ⎢⎥−⎣⎦ ","paragraphs":["The curve of target function optimization is as follows: ","Fig.2 Optimization Process of Target Function We choose the optimized NN weight as initial value of weight for dynamic NN, then train and","simulate the trend of the stock index, the forecasting result of simulation is follow as Fig.3. From 322 simulation chart we can know that the predicted result is closer to the true value at the former half hour, however, the approaching error is a little big latter. Therefore we can know that the closer the time of predicted stock index to time of the chosen sample value the better the predicted result is.  Fig.3 Predicted Simulation Figure"]},{"title":"4 Conclusion ","paragraphs":["The stock market in our country is far from effective market and the information of the market can not entirely reflected the stock price on time. So there is some error on price predicted, but in a short time the stock price can be predicted, and this model is comparatively exact in the aspect of predicting the trend of stock price. For spacious stockholders, the most important thing is not the stock price but the trend of the stock market, therefore the model of dynamic neural network is feasible."]},{"title":"Reference [1]","paragraphs":["Wang Shangfei, Zhou Peiling, Wu Gengfeng. The application of RBF in the predict of stock market[J]. Prediction,1998,(6):44-46.","[2] Zhou Guangxu, RBF.based time-series forecasting[J].computer applications,2005(9): 2179-2183.","[3] Elman J L. Finding structure in time. Cognitive Science, 1990, 14: 179-211.","[4] Lee, R.S.T. An intelligent based stock prediction system using hybrid RBF recurrent network.. systems, man and cybernetics. Part A, IEEE Transaction on volume 34, Issue 3, May 2004, Pages: 421-428.","[5] Ni Lifeng. Fast tracking band-pass filter [J]. Journal of vibration, measurement & Diagnosis 2002,{3)218-221.  323"]}]}