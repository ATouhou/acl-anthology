{"sections":[{"title":"ExploringExploringExploringExploring EmotionalEmotionalEmotionalEmotional WordsWordsWordsWords forforforfor ChineseChineseChineseChinese DocumentDocumentDocumentDocument ChiefChiefChiefChief EmotionEmotionEmotionEmotion AnalysisAnalysisAnalysisAnalysis","paragraphs":["∗∗∗∗"]},{"title":"Yunong Wu, Kenji Kita, Fuji Ren, Kazuyuki Matsumoto and Xin Kang Faculty of Engineering,","paragraphs":["University of Tokushima, Minami-josanjima, Tokushima, 771-0206, Japan","wuyunong@iss.tokushima-u.ac.jp {kita, ren, matumoto, kangxin}@is.tokushima-u.ac.jp Abstract.Abstract.Abstract.Abstract. In this study, we develop a document emotion analysis model by making use of the function of emotional words annotation. Eight basic emotion categories have been selected, including Expect, Joy, Love, Surprise, Anxiety, Sorrow, Anger and Hate, for both the word and the document level emotion analysis. We introduce two parameters, term relevance and term frequency, to evaluate the relations between the word emotions and the document emotions. Promising experimental results reveal the effectiveness of our document emotion analysis model under different emotion situations. Keywords:Keywords:Keywords:Keywords: emotional words annotation, document emotion analysis, term relevance, term frequency.","∗ This work was supported in part by a grant from the Grant-in-Aid for Scientific Research (B) numbered 21300036 and Young Scientists (B) numbered 23700252 from the Japan Society for the Promotion of Science, and Grant-in-Aid for Challenging Exploratory Research numbered 21650030 from the Ministry of Education, Science, Sports and Culture. Copyright 2011 by Yunong Wu, Kenji Kita, Fuji Ren, Kazuyuki Matsumoto and Xin Kang 25th Pacific Asia Conference on Language, Information and Computation, pages 597–606 597"]},{"title":"1111 IntroductionIntroductionIntroductionIntroduction","paragraphs":["Document emotion analysis has become a popular subject in natural language processing studies, which however has been reported to be a challenging problem since people's inner emotions are not easy to be represented exactly only through semantic labels given by machines.","Generally speaking, emotion analysis can be divided into two quite different levels: the coarse emotion analysis and the fine-grained emotion analysis. For the former study, researchers have conducted much work on dividing the documents into three classes according to their polarities: the positive documents, the negative documents, and the neutral documents. While for the latter study, researchers often concentrate on extracting some significant types of emotions, such as Expect, Joy, Love, Surprise, Anxiety, Sorrow, Anger and Hate. And this extracting process covers different textual levels, including words, sentences, paragraphs as well as documents.","In this paper we are focusing on two important parts of the fine-grained emotion analysis: emotional words annotation and document emotion analysis. Totally eight emotion categories are selected, namely, Expect, Joy, Love, Surprise, Anxiety, Sorrow, Anger and Hate.","Under the subject of emotional words annotation, most studies are concentrating on exploring a variety of emotion lexicons. Such studies include (Hu and Liu, 2004; Tokuhisa et al., 2008), in which machine learning techniques are also utilized. However, at most of the time, using emotion lexicons could not be a good idea for analyzing the emotions in the real-world texts, since the emotion lexicons are static while in the real-world the word emotions could always change in different contexts. When a certain number of the matched words are found with different emotion tags according to the emotion lexicon, this method often fails. As reported in (Fragopanagos and Taylor, 2005), emotion analysis could suffer from insufficient or misleading emotion features if context is not taken into account.","Therefore, we explore an automatic document emotion analysis model, which takes the dynamically annotated emotional words as features and explores the statistic parameters extracted from the Ren-CECps1","(Quan and Ren, 2010) to help correctly predict the document emotions from previously generated word emotions.","We regard Conditional Random Fields (CRFs) (Lafferty et al., 2001) as the appropriate algorithm for capturing the contextual information in a sentence. For the document emotion analysis, we use the function of emotional words annotation and extract the term relevance parameter and the term frequency parameter which help to correctly accumulate the document emotions from the word emotions within this document.","Experimental result reveals that the term relevance parameter makes contribution to the document emotion, and demonstrates the effectiveness of our document emotion analysis model, which can deal with the document under different emotion situations.","The rest of this paper is organized as follows: Section 2 describes the related work. Section 3 demonstrates the emotional words annotation. Section 4 illustrates document emotion analysis. Finally Section 5 concludes this paper."]},{"title":"2222 RelatedRelatedRelatedRelated WorkWorkWorkWork","paragraphs":["Affective information processing is quite a challenging problem for artificial intelligence (Ren, 2009). Especially lots of researches have been focusing on emotion analysis on emotion polarities classification or some specific fine-grained emotions from reviews (Pang et al., 2002; Turney, 2002), feedbacks (Gamon, 2004) and blogs (Yang et al., 2007).","Most emotion classification experiments were carried out by exploring machine learning 1","Ren-CECps is a Chinese emotion corpus which can be found at http://a1-www.is.tokushimau.ac.jp/member/ren/Ren-CECps1.0/DocumentforRen-CECps1.0.html 598 methods such as Support Vector Machine (SVM) (Matsumoto et al., 2005; Chesley et al., 2006) or Conditional Random Fields (CRFs) (Zhao et al., 2008). The emotion classification experiment implemented by (Chen et al., 2007) compared the two methods and proved that the CRFs classifiers performs better.","To tag emotions from words to sentences, (Das and Bandyopadhyay, 2009) made an experiment, by using CRFs on the Bengali corpus. In his study, emotion tags are pre-assigned based on a Bengali SentiWordNet which is translated from English SentiWordNet. However, since the tagging procedure was based on an immovable word list without considering the contextual information, their result is bound to suffer from the curse of emotion lexicon with either high coverage/low precision or low coverage/high precision (Ng et al., 2006).","Recent research on document emotion analysis includes (Pang and Lee, 2002), which proposed a textual categorization based approach to recognize the positive and negative polarities of documents. Also, (Yang et al., 2007) tried to match the word emotions to the document emotions. (Alm et al., 2005) conducted a text based emotion predication experiment by employing machine learning method. These methods are either semi-automatic or automatic but depending on inflexible emotion lexicons.","In this paper, we build an automatic document emotion analysis model, with dynamically extracted emotional keywords as features to predict the document emotions. We use Ren-CECps as our data set, which is a well developed Chinese emotion corpus with emotional words as well as modification components manually tagged out considering the context."]},{"title":"3333 EmotionalEmotionalEmotionalEmotional WordsWordsWordsWords AnnotationAnnotationAnnotationAnnotation","paragraphs":["Emotional words are the keywords that express emotions and affect the emotions of sentences and documents. Research conducted by (Kang et al., 2010) has proved that annotating emotions of words with high precision helps emotion analysis of sentences and documents.","In general, part-of-speeches are considered as the emotional component which can supply additional information. Therefore, POS could be a favorable feature for emotional words annotation. On the other hand, since the word emotions are expressed not only by the word itself but also through the context in a sentence, we also consider three types of modification relationships in the sentence for emotional words annotation.","Our study on emotional words annotation is based on the Ren-CECps, which is a Chinese emotional corpus consisting of 1,487 Chinese blog documents with totally 35,096 sentences. Not only the large text segment such as documents, paragraphs and sentences, but also the most basic lingual units such as the words and phrases are annotated with eight basic emotion tags: Expect, Joy, Love, Surprise, Anxiety, Sorrow, Anger and Hate. Although most emotional words in Ren-CECps are tagged with more than one emotions, we regard the emotions with the highest emotion intensities2","as the chief emotions, and will assign each emotional word a chief emotion tag."]},{"title":"3.13.13.13.1 FFFFeatureeatureeatureeature SSSSeeeelllleeeectionctionctionction WordsWordsWordsWords","paragraphs":["We employ the words string as the feature, since the identities of words themselves are important emotion carriers, which are regarded as the basic element in emotion analysis generally. POSPOSPOSPOS (part-of-speech)(part-of-speech)(part-of-speech)(part-of-speech) TagsTagsTagsTags It has been observed that the POS tag can convey additional information for emotion analysis. (Chesley et al., 2006) has proved the importance of verbs and adjectives through the experiment on polarity determination. In this study, we adopt all the POS tags as features for emotional words annotation. 2 Emotional intensities (from 0.1 to 1.0) of each emotional words are given in Ren-CECps. 599 DegreeDegreeDegreeDegree WordsWordsWordsWords Word emotion could be influenced by the existence of degree word. For example: \"这个问题很幼稚。(This is a very naive question.)\" In the example above, with the emotional word \"幼稚(naive)\" modified by the degree word \"很(very)\" in the sentence, the intensity of sentence emotion has been increased apparently. We check each word whether it is modified by the degree word or not, and use these degree modifications as a feature. NegativeNegativeNegativeNegative WordsWordsWordsWords With very high frequency, negative words such as \"不(no)\", \"不会(cannot)\", are made use of reversing the word meaning and shifting emotion type in the Chinese document. In the following sentence, \" 我不善长写诗赋词。(I am not good at writing the poems.)\". As the emotional word \" 善长(good at)\" is modified by the negative word \" 不(not)\", the sentence emotion express a opposite emotion to the word emotion. Therefore, the appearance of the negative modifications would be considered as a feature. ConjunctionsConjunctionsConjunctionsConjunctions Simple sub-sentences can be assembled into a complex sentence with the conjunction. The occurrences of conjunctions are often accompanied with apparent emotion variations in the sentence. For example, \"虽然有些累,但我会坚持下去。(Although I felt a little tired, I will keep it up.)\" The conjunction \" 虽然... 但(although)\" is employed in the sentence, so the sentence can express much stronger emotion. As a consequence, we judge whether each word is under a conjunction modification or not, and employ this conjunction modification as a feature."]},{"title":"3.23.23.23.2 CRFCRFCRFCRF BasedBasedBasedBased EmotionalEmotionalEmotionalEmotional WordsWordsWordsWords AnnotationAnnotationAnnotationAnnotation","paragraphs":["Conditional Random Fields (CRF) has been employed for recognizing the emotional words and their emotion categories. To better understand the function of the context information in emotional words annotation, we experiment on three levels of language modes: 1-gram, 2-gram and 3-gram. As depicted through expression 3.1 to expression 3.5, these N-gram models are built on each emotion features described previously to represent the context of emotional words. Fw = {1-gram(Word)} ∪{2-gram(Word)} ∪{3-gram (Word)} (3.1) Fpos = {1-gram(POS)} ∪{2-gram(POS)}∪{3-gram (POS)} (3.2) Fdm = {1-gram(D-mod)} ∪{2-gram(D-mod)} ∪{3-gram (D-mod)} (3.3) Fnm = {1-gram(N-mod)} ∪{2-gram(N-mod)} ∪{3-gram (N-mod)} (3.4) Fcm = {1-gram(C-mod)} ∪{2-gram(C-mod)}∪{3-gram (C-mod)} (3.5) where \"D-mod\", \"N-mod\", \"C-mod\" represent the modification relations between words and degree words, negative words, conjunctions respectively, while Fw, Fpos, Fdm, Fnm and Fcm correspond to the word string features, the POS features, the degree words modification features, the negative words modification features and conjunctions modification features separately. After we filtered out some extremely short sentences, and sentences which only contain punctuations, there are 31,070 sentences left for the emotional words annotation experiments. 24,856 sentences are randomly selected for training, and the rest 6,214 sentences for testing."]},{"title":"3.33.33.33.3 ResultResultResultResult andandandand DiscussionDiscussionDiscussionDiscussion","paragraphs":["Table 3.1 gives the precision, recall and F-score of emotional words annotation. We can find that the three emotions Love, Sorrow and Anxiety, get the best F-scores 60.77%, 44.13%, 44.10%, while Surprise, Hate and Anger emotions get the worst three F-scores 26.11%, 33.02%, 26.01%. For one reason, when a person is in the passive state, he may express multiple negative 600 emotions at the same time, such as Anger and Hate, which makes it difficult even for human to annotate. For the emotion of Surprise, we think that the lack of training data directly lead to the such low recall, since the number of words conveyed Surprise is only 1.96% of whole emotional words. TableTableTableTable 3.3.3.3.1111:::: Precision, recall and F-score of emotional words annotation Emotion Precision Recall F-score No_emo 0.941841 0.987083 0.963931 Joy 0.610493 0.330892 0.429170 Hate 0.553704 0.235248 0.330204 Love 0.673164 0.553813 0.607684 Sorrow 0.586558 0.353374 0.441261 Anxiety 0.531632 0.376790 0.441014 Surprise 0.543210 0.171875 0.261128 Anger 0.551724 0.170213 0.260163 Expect 0.631902 0.314504 0.419980 Av. 0.624914 0.388199 0.461615"]},{"title":"4444 DocumentDocumentDocumentDocument EmotionEmotionEmotionEmotion AnalysisAnalysisAnalysisAnalysis","paragraphs":["We propose a new method for document emotion analysis by employing the function of automatic emotional words annotation, which has been introduced in Section 3. Two parameters, term relevance tr and term frequency tf, are constructed for evaluating the relation between the word emotion (which is automatically extracted from the document) and the document emotion. Normalization is conducted so that the emotion values could be comparable among documents of different lengths.","We use 211 blog documents collected from the Internet for document emotion analysis. All these articles belong to four blog users in different emotional situations. Each document is previously segmented into words and phrases. Human experts annotated each document with at least one emotion tag from the emotion tag list (Expect, Joy, Love, Surprise, Anxiety, Sorrow, Anger and Hate), while the word emotions are not annotated."]},{"title":"4.14.14.14.1 DocumentDocumentDocumentDocument EmotionEmotionEmotionEmotion AssumptionAssumptionAssumptionAssumption","paragraphs":["Just as the documents are composed of the words, intuitively, we assume that the document emotions are determined by the word emotions contained in the documents.","There are some reasons for this assumption: First, the document are more likely to convey the same emotion as the emotion of words. Second, although there exists some words that contain different emotions from the overall emotions of the corresponding documents, we find that the most appearance of such words follows some statistical rules. Third, the document emotions constructed by the simple accumulation of word emotions are not exact enough, since the accumulation would cause some difficulties in comparing the emotion values of documents of different lengths, while fortunately the term frequency (TF), which is a widely used parameter for document analysis, could help to normalize our document emotion values."]},{"title":"4.24.24.24.2 DocumentDocumentDocumentDocument EmotionEmotionEmotionEmotion AnalysisAnalysisAnalysisAnalysis (DEA)(DEA)(DEA)(DEA) ModelModelModelModel","paragraphs":["The document emotion is constructed from word emotions with two weight parameters. Our DEA model predicts the emotion of a document as an eight dimensional vector, with each element represents the possible value of corresponding emotion. Each part of the calculation processing is illustrated in detail as follows: 1)1)1)1) EmotionEmotionEmotionEmotion VectorVectorVectorVector ofofofof WordsWordsWordsWords 601 we extract an emotion vector for each word in document , which is a binary-valued eight-dimensional vector with each element"]},{"title":"e","paragraphs":["k1 ("]},{"title":"8,2,1 ...=k","paragraphs":[") representing that the th"]},{"title":"k","paragraphs":["emotion (such as Love, Hate, Sorrow, ...) is reflected from the word i"]},{"title":"w","paragraphs":["while"]},{"title":"e","paragraphs":["k0 represents that the th"]},{"title":"k","paragraphs":["emotion is not reflected.","We exploit the function of emotional words annotation to recognize the emotional words in the blog documents collected from the Internet. As the documents in the test corpus are just given emotion tags in document level, we have to extract the three modification features for each sentence of test corpus before Emotional words Annotation. Our solution here is that we build three word lists by extracting degree words, negative words and conjunctions respectively from Ren-CECps. The modification words are available by means of word matching in test corpus with the three word lists.","The table 4.1 shows the portion of the eight-dimensional emotional vector of emotional words in the first document in the test corpus. TableTableTableTable 4.1:4.1:4.1:4.1: Emotion word and emotion type Emotion Words Emotion Types e1 e2 e3 e4 e5 e6 e7 e8 活力(vitality)"]},{"title":"( )","paragraphs":["1we 0 0 1 0 0 0 0 0 幸福(happiness)"]},{"title":"( )","paragraphs":["2we 1 0 0 0 0 0 0 0 埋葬(bury)"]},{"title":"( )","paragraphs":["3we 0 0 0 1 0 0 0 0 宝贝(baby)"]},{"title":"( )","paragraphs":["4we 0 0 1 0 0 0 0 0 幸运(luck)"]},{"title":"( )","paragraphs":["5we 1 0 0 0 0 0 0 0 享受(enjoy)"]},{"title":"( )","paragraphs":["6we 1 0 0 0 0 0 0 0 2)2)2)2) TermTermTermTerm RelevanceRelevanceRelevanceRelevance we construct a term relevance parameter i"]},{"title":"tr","paragraphs":[", which reveals the relevance between the word emotion and the corresponding document emotion, for each word i"]},{"title":"w","paragraphs":[". This is conducted by thoroughly analyzing the emotional words from the Ren-CECps emotion corpus depicted in"]},{"title":"( ) ( ){ } ∑","paragraphs":["=","=∧∈ = M j ji jijii i n MjDeweDww tr 1 , ,,1,~| ...(4.1) The numerator part of equation (4.1) counts the appearance of word i"]},{"title":"w","paragraphs":["in each document j"]},{"title":"D","paragraphs":["with"]},{"title":"Mj ...,2,1=","paragraphs":["(Ren-CECps), where"]},{"title":"( ) ( )","paragraphs":["ji"]},{"title":"Dewe ~","paragraphs":["signifies the compatibility between the word emotions and the document emotions, say, there is at least one common emotion element shared by the word emotion vector"]},{"title":"( )","paragraphs":["i"]},{"title":"we","paragraphs":["and the document emotion vector"]},{"title":"( )","paragraphs":["j"]},{"title":"De","paragraphs":[". Under this condition, we can use a binary variable to represent this relationship:"]},{"title":"( ) ( ) ( ) ( ){ }","paragraphs":["0,1~ >= jiji DeweDewe (4.2) in which"]},{"title":"( ) ( )","paragraphs":["ji"]},{"title":"Dewe ~","paragraphs":["takes the value of 1 if condition=true, while the value of 0 if condition=false."]},{"title":"ba,","paragraphs":["represents the inner product between two vectors"]},{"title":"a","paragraphs":["and"]},{"title":"b","paragraphs":[". 602 The denominator part of equation (4.1) counts the appearance of words , which is represented by ji"]},{"title":"n","paragraphs":[", , from each document j"]},{"title":"D","paragraphs":[". Therefore, equation (4.1) gives us an evaluation of the confidence, which we call the term relevance"]},{"title":"tr","paragraphs":[", that the emotion of word i"]},{"title":"w","paragraphs":["is compatible with the emotion of the document which it belongs to. The term relevance values as well as compatibility counts and appearance counts of some words in the first document in the test corpus are listed in table 4.2. TableTableTableTable 4.2:4.2:4.2:4.2: Term relevance of emotional word Emotional Word i"]},{"title":"w","paragraphs":["Compatibility i"]},{"title":"comp","paragraphs":["Appearance Count i"]},{"title":"count","paragraphs":["Term relevance i"]},{"title":"tr","paragraphs":["有害(harmful) 5 5 1.000000 宝贝(baby) 47 52 0.903846 活力(vitality) 15 19 0.789474 埋葬(bury) 10 13 0.769231 幸运(luck) 27 41 0.658537 享受(enjoy) 143 235 0.608511 幸福(happiness) 323 670 0.482090 模范(model) 0 6 0.000000 3)3)3)3) TermTermTermTerm FrequencyFrequencyFrequencyFrequency we construct a term frequency parameter ji"]},{"title":"tf","paragraphs":[", for a word i"]},{"title":"w","paragraphs":["from the document j"]},{"title":"D","paragraphs":["as"]},{"title":"⎪ ⎩ ⎪ ⎨ ⎧ ∉ ∈ = ∑","paragraphs":["∈ Ei Ei Ww jk ji ji"]},{"title":"Wwif Wwif n n tf","paragraphs":["Ek"]},{"title":"0","paragraphs":[", , , (4.3) with"]},{"title":"Ni ,,2,1 ...=","paragraphs":["and"]},{"title":"Mj ,,2,1 ...=","paragraphs":["(Testing). Again, ji"]},{"title":"n","paragraphs":[", counts the appearance of word in document j"]},{"title":"D","paragraphs":[". The term frequency here represents the proportion of the emotion values of word i"]},{"title":"w","paragraphs":["in the emotion values of j"]},{"title":"D","paragraphs":[". Because the document emotion is composed of the word emotions, and the number of emotional words in each document often varies, we need this term frequency to normalize the accumulation effect. Therefore, for each emotional word Ei"]},{"title":"Ww ∈","paragraphs":[", we compute its frequencies among all the emotional words in the document j"]},{"title":"D","paragraphs":[", and for the unemotional words Ei"]},{"title":"Ww ∉","paragraphs":[", we just ignore their contribution to the document emotion and assign the value of 0. In this study, term frequency is a significant weighted parameter which measures the importance of a word in our test corpus. For some words in the first document in the test corpus, the term frequency values as well as appearance counts and total emotional word counts are listed in table 4.3. TableTableTableTable 4.3:4.3:4.3:4.3: Term frequency of emotional word 603 Emotional Word i"]},{"title":"w","paragraphs":["Appearance Count i"]},{"title":"count","paragraphs":["Total Emotional Word Count j"]},{"title":"total","paragraphs":["Term Frequency ji"]},{"title":"tf","paragraphs":[", 活力(vitality) 1 185 0.005405 幸福(happiness) 1 185 0.005405 埋葬(bury) 2 185 0.010811 宝贝(baby) 1 185 0.005405 幸运(luck) 1 185 0.005405 享受(enjoy) 1 185 0.005405 4)4)4)4) DocumentDocumentDocumentDocument EmotionEmotionEmotionEmotion CalculationCalculationCalculationCalculation Finally, document emotion"]},{"title":"( )","paragraphs":["j"]},{"title":"De","paragraphs":["is accumulated by word emotion"]},{"title":"( )","paragraphs":["i"]},{"title":"we","paragraphs":["within it, weighted by term relevances i"]},{"title":"tr","paragraphs":["and term frequencies ji"]},{"title":"tf","paragraphs":[", as equation (4.4) shown below:"]},{"title":"( ) ( )∑","paragraphs":["∈"]},{"title":"⋅⋅=","paragraphs":["ji Dw iijij"]},{"title":"trtfweDe","paragraphs":["(4.4)"]},{"title":"( ) ( )∑","paragraphs":["∈"]},{"title":"⋅=","paragraphs":["ji Dw ijij"]},{"title":"tfweDe","paragraphs":["(4.5)"]},{"title":"4.34.34.34.3 EvaluationEvaluationEvaluationEvaluation MethodsMethodsMethodsMethods","paragraphs":["we are considering three levels of precisions for evaluating the model performance, which are depicted in equations 4.6, in which i can take the values of {1, 2, 3}."]},{"title":"( )","paragraphs":["( ) DocumentsAll DocumentMatched iprecision i =_ (4.6)","In the first level of evaluation, we choose the emotion with the highest emotion value from the predicted emotion vector as the predicted document emotion. By comparing this emotion with emotions annotated by human experts, we conclude the predicted emotion is correct, if predicted emotion matches annotated emotion of the corresponding document in test corpus. We count the number of the matched documents, which i takes the value of 1, in the numerator part of equation (4.6), and count the number of documents in test corpus as All Documents in the denominator part.","In the second level, we refer to two emotion types with the highest values in the emotion vector as the predicted document emotion. We treat them as a correct matching if there is at least one of the two emotion types could match the annotated emotions of the corresponding document in the test corpus.","In the third level, three emotion types are under consideration as the second level."]},{"title":"4.44.44.44.4 eResultseResultseResultseResults andandandand DiscussionDiscussionDiscussionDiscussion","paragraphs":["We use 211 documents from four blogs to test the performance of our DEA model. In order to examine the effectiveness of term relevance , we plan to carry out a comparative experiment using equation (4.5), in which term relevance is not employed. We list the three levels of precisions for the documents of each blog, and also counts the precisions of the documents from all the blogs as a whole. The detailed results are shown in the Table 4.4 and Table 4.5. 604 TableTableTableTable 4.4:4.4:4.4:4.4: Results of comparative experiment in three levels of evaluation methods Blog ID Num.Of Documents Precision_1 Precision_2 Precision_3 ID1 37 0.189189 0.729730 0.837838 ID2 18 0.222222 0.777778 0.888889 ID3 73 0.068493 0.369863 0.616438 ID4 83 0.168675 0.445783 0.662651 Overall 211 0.142180 0.497630 0.696682","Compared with the three precisions of comparative experiment, experiment which utilizes term relevance gets the better performance. Therefore, we believe that term relevance makes a contribution to the document emotion analysis. Nevertheless, the value of precision_2 and precision_3 of ID 1 and ID2 for both experiments are the same, we find that they have the same number of correct predicted document emotions but not the same identities of documents. TableTableTableTable 4.5:4.5:4.5:4.5: Results of adopted experiment in three evaluation methods Blog ID Num.Of Documents Precision_1 Precision_2 Precision_3 ID1 37 0.270270 0.729730 0.837838 ID2 18 0.277778 0.777778 0.888889 ID3 73 0.082192 0.438356 0.657534 ID4 83 0.192771 0.46988 0.686747 Overall 211 0.175355 0.530806 0.720379","As shown in Table 4.5, the DEA model gets relatively lower precisions in the first level of evaluation for different blog documents, but achieves much better results in the second and the third level. Because most documents are conveying multiple emotions at the same time, the latter two level of precisions also confirm the promising result of our model.","The source of this test corpus also provides some insight into document emotion analysis. The blog documents used for document emotion analysis are collected from four different blog users under different emotional situations: The ID1 blog user lost his son in the earthquake and missed his child in blogs; the ID2 blog user suffered from a serious disease and wrote blogs for encouraging herself; the ID3 blog user lost her boyfriend in an accident, and wrote her beautiful memories in blogs; the ID4 blog user had been betrayed by her husband, so complained in blogs.","These documents from different emotion situations are used to test the robustness of our DEA model: Firstly, the experiment in Table 4.5 shows similar results , which proves that our DEA model can deal with different kinds of emotional situations. Secondly, through a thorough examination, we also find that the documents of the ID3 blog user get the lower emotion precision than the other blog documents. This happens when the blog user uses the positive emotional words to express negative emotions (e.g. the pleased memory of life conveyed the sadness of the current emotion). This turns to be one of the most difficult situations in our document emotion analysis: although the annotators could precisely tag the document with negative emotions, such as sorrow, it is still not easy for machines to judge the real emotions through the large amount of positive emotional words."]},{"title":"5555 ConclusionsConclusionsConclusionsConclusions","paragraphs":["In this paper, we develop a document emotion analysis model by making use of the function of emotional words annotation. Two parameters, term relevance and term frequency, are introduced to evaluate the relations between the word emotions and the document emotions.","By utilizing the modification relationship in the context, we build an automatic Emotional 605 Words Annotation system, which could get word emotions with higher context sensitivity compared to traditional emotion lexicons.","We perform document emotion analysis by using the result of our Emotional Words Annotation. Under the relation assumption between document emotions and word emotions, we introduce term relevance and term frequency in the process. Experimental results reveal that our DEA model achieves promising performance under different emotion situations.","We notice that the incorrectly tagged word emotions through Emotional Word Annotation could influence the accuracy of document emotion analysis. One of the most important affects comes from the three word lists from which we extract the modification features for emotional word annotation, as we have mentioned in section 4.2. These word lists are totally empirical, and contain large amount of inaccuracy. The inaccurate modifications employed as the features in CRF model would finally cause the inaccurate annotated emotional words, and indirectly affect the performance of document emotion analysis.","We also find document emotion analysis become more difficult when large amount of positive emotional words are used in a blog document to express negative emotions. Although the annotators could precisely comprehend the negative emotions in the blog documents, which is still not an easy task for machines to judge such real emotions."]},{"title":"ReferencesReferencesReferencesReferences","paragraphs":["Chesley, P., B. Vincent, L. Xu, and R. Srihari. 2006. Using verbs and adjectives to automatically classify blog sentiment. AAAI Symposium on Computational Approaches to Analysing Weblogs (AAAI-CAAW), pp. 27–29.","Clore, G.L., A. Ortony and M. A. Foss. 1987. The psychological foundations of the affective lexicon. Journal of Personality and Social Psychology, 53:751–766.","Das, D. and S. Bandyopadhyay. 2009. Word to Sentence Level Emotion Tagging for Bengali Blogs. Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 149–152, Suntec, Singapore.","Fragopanagos, N. and J.G. Taylor. 2005. Emotion Recognition in Human-Computer Interaction. Neural Networks, vol. 18, pp. 389-405.","Gamon, M. 2004. Sentiment classification on customer feedback data: noisy data, large feature vectors, and the role of linguistic analysis. Proceedings the 20th International Conference on Computational Linguistics.","Hu, M. and B. Liu. 2004. Mining and summarizing customer reviews. Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 168–177.","Kang, X., F. Ren and Y. Wu. 2010. Bottom Up: Exploring Word Emotions for Chinese Sentence Chief Sentiment Classification. Proceedings of 6th International Conference on Natural Language Processing and Knowledge Engineering.","Lafferty, J., A. McCallum and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. Proceedings of International Conference on Machine Learning-01.","Matsumoto, S., H. Takamura and M. Okumura. 2005. Sentiment Classification Using Word Sub-sequences and Dependency Sub-trees. Proceedings of the 9th Pacific-Asia Conference on Knowledge Discovery and Data Mining.","NG, V., S. Dasgupta and S. M. Niaz Arifin. 2006. Examining the role of linguistic knowledge sources in the automatic identification and classification of reviews. Proceedings of the COLING/ACL 2006.","Pang, B., L. Lee and S. Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning. Proceedings of the Conference on Conference on Empirical Methods in Natural Language Processing.","Quan, C. and F. Ren. 2010. A blog emotion corpus for emotional expression analysis in Chinese. Computer Speech and Language, Vol.24, No.1, pp.726-749","Ren, F., 2009, Affective Information Processing and Recognizing Human Emotion. Electronic Notes in Theoretical Computer Science, Vol.225, No.2009, pp.39-50.","Turney, P.D. 2002. Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia.","Tokuhisa, R., K. Inui, and Y. Matsumoto. 2008. Emotion Classification Using Massive Examples Extracted from the Web. Proceedings of COLING 2008, pp. 881-888.","Yang, C., K.H-Y. Lin and H-H. Chen. 2007. Building Emotion Lexicon from Weblog Corpora. Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics.","Yang, C., K.H.-Y. Lin and H.-H. Chen. 2007. Emotion Classification from Web Blog Corpora. IEEE/WIC/ACM.","Zhao, J., K. Liu and G. Wang. 2008. Adding Redundant Features for CRFs-based Sentence Sentiment Classification. Proceedings of Empirical Methods in Natural Language Processing. 606"]}]}