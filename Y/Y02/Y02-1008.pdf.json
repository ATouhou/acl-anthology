{"sections":[{"title":"A Deterministic Method for Structural Analysis of Compound Words in Japanese","paragraphs":["Dongli Han, Takeshi Ito and Teiji Furugori","Department of Computer Science, The University of Electro-Communications","1-5-1 Chofugaoka, Chofu-shi, Tokyo 182-8585, Japan","{han, ito, furugori@phaeton.cs.uec.ac.jp} Abstract Structural analysis of compound words is necessary and an important process in natural language processing. Proposed here is a corpus- and statistics- based method for the structural analysis of compound words in Japanese. We determine the structure of a compound word by using Internet corpus and calculating the strength of word association among its constituent words. Experiments with 5, 6, 7, and 8 kanji compound words show that our method works well and its performance is better than those of other comparable studies. 1\\tIntroduction A sequence of words may assume a single syntactic function in English and the same is true in Japanese. Machine translation system, for instance, consists of three words machine, translation and system. Its equivalent in Japanese, MA FIR 3 5-1A, is a compound word with three constituent words, OW (machine), (translation), and (system). It is a single concept and functions as a noun.","Both English and Japanese face problems in processing such a sequence of words. A problem involved in English is in identifying the sequence of words as a syntactic as well as semantic unit. It is easy to find a compound word in Japanese but we have difficulties in segmenting it into constituent words as well as determining its syntactic or semantic structure among the constituents.","Finding its constituents and determining the structure of a compound word is an important process in constructing practical natural language systems for machine translation, information retrieval, text summarization, etc. For the compound word fc H g"]},{"title":"ait","paragraphs":["(the former president of Bank of Japan), for instance, there are six lexically possible segmentations: 7-E/ H I iei g , 7GI 19 /, /en,","H /*tit&\\tH /WA, 7G H /e/It and 5---C H / ;F /glia, the correct segmentation here being 7c(former)/ H (Bank of Japan)/a ot (president).","Standing alone, the word segmentation is useful in many areas of natural language processing. However, we should know how the constituents in a compound word are combined to make the meaning, say, for its translation into foreign languages. 7G/19 \"d /km has two probable dependency structures: (CAM H )(a4 ))) and (((A)( H ))(M)). The former leads to the meaning of the former president of Bank of Japan and the latter the president of former Bank of Japan. The problem is how can we arrive at the structure, ((i-E)(( H 1A1F)(atit))).","In this paper we offer a method for analyzing the structure of compound words in Japanese. In Section 2 describes some previous work done for a compound word on the identification of constituents and determination of its structure. We propose a method and subsequently an algorithm in 79 Section 3 for analyzing the structure of compound words using the strength of association measures among the constituent words. In Section 4 conducts experiments for our method and others, and compares the results. Finally, we conclude the paper with some remarks in Section 5. 2 Some Work on the Analysis of Compound Words We have two tasks in the analysis of a compound word: identification of its constituents and then the determination of its structure. Our present interest lies in the latter task.","There are numerous studies on the identification for the constituents of a compound word. To mention a few, Miyazaki et al. (1984) used a handcrafted, rule-based method and a technique of ambiguity resolution for segmenting a compound word. Takeda and Fujisaki (1987) segmented kanji compound words using Markov Model. Utiyama and Itahashi (1992) divided a compound noun expressed in hiragana characters into component nouns based on word co-occurrence relation. In recent ones, Shimohata et al. (1997) and Fujii et al. (1999) segmented a compound word into its constituents employing simple heuristics based mainly on the features of Japanese character types. Han et al. (2001a) devised a segmentation strategy using contextual information from a corpus.","Relatively few studies are available on the determination of dependency structure of a compound word. Nishino and Fujisaki (1988) attempted to analyze the structure of a kanji compound word using a probabilistic CFG. Miyazaki et al. (1993) used a large amount of handcrafted rules and resolved the ambiguities on semantic structure in compound words.","These studies are all rule-based and have obvious deficiencies. \\tObtaining rules is time-consuming process to begin with. Then rules are limited, fixed and not easily extendable.","Recently the researchers have turned to corpus and statistical means to analyzing the structure of compound words. Along this line, Kobayasi et al. (1994) built dependency trees for a compound word, calculated the likelihood of each tree structure using collocational information on its constituents extracted from a corpus, and selected the one with the highest likelihood value as the correct structure of the compound word. In this process, they used a thesaurus and got the collocational data through its classes to which each constituent of a compound word belongs.","Using a similar method, Hisamitsu and Nitta (1996), in an analysis of compound words extracted from news articles,, tried to overcome a deficiency in the study of Kobayasi et al. that it could not deal with abbreviated words or, for that matter, unknown words in the corpus used. However, the method he adapted seems restricted only to the analysis of newspaper articles.","Our method of analyzing the structure of a compound word is corpus- and statistics- based, too. But it is different from others in a few points. Methodologically, it uses a deterministic process. Computationally, we calculate the strength of association, for the constituent words in a compound word using mutual information-like measures and determine its correct structure by discarding less probable ones along the way. Data-wise, we use the Internet corpus to coping with data sparseness problem and getting reliable statistical information. 3 A Structural Analysis of Compound Word Our idea for analyzing the structure of compound words is similar to those used in various disambiguation tasks (e.g., Alves, 1996; Wu & Furugori, 1996; Karov et al., 1998). We all use a kind of"]},{"title":"80","paragraphs":["corpora and statistical means and then eliminate the more unlikely and select the more likely to get the desired result. However, the difference is that we use a deterministic process and keep discarding less likely candidates along the way we go, rather than collecting all the candidates first and then selecting the most probable one from them. 3.1 Analytical Processes • A compound word consists of a sequence of words. Each word in the compound word, except the rightmost one or headword, relates to, or depends semantically on, one of other words in its right more strongly than to any other words. For example,"]},{"title":"RN","paragraphs":["(Kansai) relates more strongly to (airport) than to INIA(international) in l"]},{"title":"N/111\\t","paragraphs":["(Kansai International Airport).","We know for a Japanese compound word that the semantic dependency relations among its con-","stituents has the following characteristics: • The dependency relation that holds between two constituents is unique, i.e., no constituent","relates to more than one constituent. • An element, except the headword, depends always on a constituent to its right. • No dependency relations cross each other.","The last characteristic is to mean that we never have dependency relations something like: A B We may be able to find the structure of a compound word with its constituents, w i w2 \\twi \\twn using the dependency relations among its constituent words. An algorithm for this is:","Stepl : For any word wi ( 1 i 5. n –1) in the constituent sequence, S of n words, w1w2 \\twn , find the word wi to which wi has the dependency relation wi–* wi (i < f ). Call the set of relations the rules, R.","Step2: Repeat the following","2.1 Find the handle, h, or the leftmost dependency relation in S with the","minimum inter-constituent distance ( =1); Remove the handle from R.","2.2 If h takes a form of\\tamalgamate wi and wi in S with"]},{"title":"Co","paragraphs":["where C is an amalgamated constituent.","2.3 If h takes a form of wi --> Ci±ti or Cij_1","-p w, , amalgamate wi","and Ci+1j or Ci,j_1 and\\tin S with"]},{"title":"Co .","paragraphs":["2.4 If h takes a form of Ci,i+x Ci+x+1,j ( x >0), amalgamate Ci,i+x and","Ci+x+1,j in S with Co 2.5 Replace the expression in R that is the same as the right side of ex-","pression in h with ci,1.","until no amalgamation becomes possible. Let us see how the algorithm works. Suppose the compound word to be analyzed has five con-","stituents, w1 w2 w3 w4 w5 . Suppose also that we have found the following rules in Stepl.","Wl --> W3 ,","W2 ---> W 3 3 9"]},{"title":"81","paragraphs":["W3 -4 W5 ,","W4 --> W5","We then find h to be w2 w3 in Step 2.1. So, we amalgamate w2 and w3 with C23 in","Step 2.2 and get new S of w1 C23 w4 w5 . In Step 2.5, R is changed to:","W C23 , 51","C2,3\\tW5,","W4 -÷ W5","With the new S and R , we go back to Step 2.1 and repeat the processes in Step 2. This time,","we find h to be w1 -- C23 in Step 2.1, amalgamate w1 and C23 with C13 in Step 2.3 and get","C13 w4 W5 , and change R in Step 2.5 to: C1,3 -÷ W5 , W4","–*","In the next time around, h is W4 W5 and applying the Steps 2.2 and 2.5, we get new S and R of C1,3 C4,5 and C13 -> C4,5 . Repeating Step 2 again, we get h of C1,3 C4,5 , amalgamate C13 and C45 with C15 in Step 2.4, and finally stop processing as no further amalgamation becomes possible.","Table 1 shows the above processes step by step and Figure 1 the structure of the compound word analyzed.","Table 1: Processes of Structural Analysis Steps\\tConstituents 2.1, 2.2\\tw1 C2,3 W4 w5 2.5 Rules w C2,31 C2,3 w5 W4 W5 Handle and Amalgamation W2 -9 W3\\tC2,3 2.1, 2.3 2.5 2.1, 2.2 2.5 2.1, 2.4 2.5 C1,3 W4 W5 C1,3\\tW5, W4 -+ Wi 2,3\\tC1 , 3 C1,3 C4,5 C1,5 C1,3\\tC4,5 W4 -9 W5 C45 C1,3 ---> C4,5\\tC1,5 (no rules left)","We left Step 1 unexplained, but this is the most crucial step in the algorithm. We base our analysis in this paper on a search in which we try to find each relation of x ----> y in a compound word always in relation to the rightmost constituent or the headword. We describe this process in detail in the next sub-section. C1,5 C23 Wl \\tW2\\tw4 \\tW5 Figure 1: Structure of Compound Word Analyzed"]},{"title":"82","paragraphs":["3.2 Measurement of the strength of association We try to determine the dependency relation, x ---> y , using some mutual information-like metrics. As is well-known, mutual information (M/ ) is a standard way of estimating the strength of lexical association between any two words (Church, 1990). It is defined as:"]},{"title":"I","paragraphs":["N x f(w,,w2))"]},{"title":"f (","paragraphs":["w"]},{"title":"i)","paragraphs":["x"]},{"title":"f(w2)","paragraphs":["where N is the size of the corpus used in the estimation, f(w„w2 ) is the frequency of co-occurrences of wi and w2 , and f(wi ) and f(w2 ) is the frequency of each word.","Naturally the reliability of MI depends greatly on the statistical data obtained from the corpus to be used. This leads us for our analysis to use Internet corpus rather than other corpora widely available.","Owing to its largeness in size, the Internet corpus is expected to make the data sparseness problem less problematic than that in the use of other corpora.' In fact, it seems that we are able to access at least 42 million pages of Japanese texts using Goo2 , a well-known Internet search engine that is said to be the biggest in Japan.","We modify formula (1) and define two types of Internet-based Mutual Information (IMI) as in formulas (2) and (3) and then use them to measure the strength of association between two words w1 and w2. IMII (wi , w2) = log"]},{"title":"r","paragraphs":["X hit(wl AND w2)) hit(wl)xhit(w2)  log( N xhit(w,w2) hit(wl)xhit(w2)","In the formulas, N denotes the total number of the Japanese URLs registered in a search engine. It is 42 million in our case. hit(x) is the hit number we get when searching the word x in a search engine; < w, AND w2 > is a query formula gotten by applying the logical operator AND to w1 and w2 ; hit(w,w2 ) is the hit number when searching a compound word of the two constituent words wi and w2 .","• In our algorithm to finding x ----> y in a compound word, we first find the most unacceptable constituent pair (,Wmua,Wn) that has the weakest strength of association in all pairs of ( wi , wn),3 where 1 i n – 2.4 We then take wmua as the starting point, find wmac for which winua has the highest strength of association in the sequence of W mua+1 • • • W n_i , compare ( W mua , W mac ) with ( Wmua",",Wn)9 let mac = n if ( Wmua , n ) is more acceptable, and choose the pair with bigger associa-1 Bergh et al. (1998) estimates that the Internet material published in English and accessed through the AltaVista search engine is about 25 times bigger than that in the Bank of English (320 million words), 80 times bigger than that in the BNC (100 million words), 160 times bigger than that in the CobuildDirect corpus (in its 50-million-word version), and 8000 times bigger than that in Brown and LOB corpora (one million words each). The usefulness of the Internet corpus has been proven in various linguistic applications (e.g., Mihalcea and Moldovan, 1999; Miyahira et al., 2000; Han et al., 2001b). 2 http://goo.ne.jp 3 We try to find inner relations first by doing this. Although intuitive, we believe this is a better way of finding the structure of a compound word. 4","We do not take wn_i into account as it is obvious that we have wn_i ---> wn . 1(wi,w2)= log (1) IMl (2) (3)"]},{"title":"83","paragraphs":["tion value as a dependency relation in the compound word. After this, we divide the sequence wl...wm„„...wm,,,...wn into twoparts W1...minn,,,w,„„,...wn and wm„„±1...wmac, and for each one apply the above process recursively. Below is an algorithm to do the task. Main {","For each wi in wi w2 \\twi \\t34) n-2 { set mark[wi ]= 0 } call R _ search ( w1 w2","Sub R _search( w1 w2 \\t \\t ) {","if (exist -wi l{mark[wi ] = 0, i E (1...n — 2)} ) { compute and find the smallest IMI(wi , 14in )1 finark[wi ]= 0 A i E (1...n — 2)}","and let it be Bff(w„,„a , compute and find the largest IMI(wmuii ,w j )I{j E (mua +1...n — 1)}","and let it be Bff(w mua , wmac if all(wnia ,wmac ) < IMI(w,nua,wn)","set mac=n acquire a dependency relation w, nua\\twmac set mark[wn ,a ]= 1 call R _ search ( Wmua+1 \\tWmac) call R _search(w1 \\tw wmac \\twn)","Here, mark is an array storing 2-value flags for wi (i =1...n— 2 ). When the dependency relation for w1 has been found, we let mark[w, ] be 1, otherwise 0; Wmua indicates the word for which the strength of association ( wmua ,wn ) is weaker than between any other constituent word and wn . Similarly, Wmac is the word for which (wnwa , wmac ) takes the strongest association; R _search is a subprogram that is recursively invoked for seeking dependency relations among the constituent words in the compound word to be analyzed.","In our algorithm, we always take wmua as the starting point to find its most acceptable companion. This is meaningful. Among all the dependency relations, the ones related to the headword are more significant for determining the structure. The analysis would become futile when a wrong dependency relation in which the headword takes part is obtained. We are to avoid such a disaster by putting our hand on wmua that always has the weakest relation with the headword. 4 Experiments and Results We examine how effective our method is by conducting some experiments for our method. We first describe the nature of test data and then show the experimental results. 4.1 Test Data We use Mainichi News' 1994, an annual volume of a newspaper in Japanese, as the source for the test data. We select from it the top 100 most frequently utilized compound words for the lengths of 4, 5, 6, 7, and 8 and segment them into their constituent words using the system Han et al. have built (2001a). But we use the four sets of 100 compound words for the length of 5 to 8 in the test, since we found that many of 4 kanji-character words are divided into two constituent words and it therefore makes the structural analysis meaningless. 4.2 Preliminary Experiments Table 2 contains the experimental results with baseline methods and ours. The result in (a) is obtained from a baseline method called leftmost derivation (Lauer, 1995) in which a word is always attached to its predecessor in a phrase. The result in (b) shows the performance of another baseline method opposite to the first one, i.e., rightmost derivation that seems to be effective in analyzing the structure of a certain type of Japanese noun phrases (Furugori & Alves, 1999).","Table 2: Experimental Results 1 (% correct) Length","Method (a) (b) (c) (d) (e) five\\tsix\\tseven\\teight 79\\t53\\t43\\t36 82\\t56\\t43\\t20 83\\t65\\t37\\t25 86\\t67\\t56\\t49 83\\t71\\t57\\t55","The results in (c), (d) and (e) show the performances from our methods with the use of formulas (1), (2), and (3), respectively. Here, we used the EDR Japanese Corpus 5 in the calculation of MI in (c).","The success rate in any method decreases as the length of kanji character sequence increases. This is natural as the candidate structures in a compound word increase with the length. In fact, 5 kanji-character sequences in our test data have 2.4 constituents on average and so for each of them, we would have 1 or 2 possible structures. The average number of constituents for 8 kanji-character sequences is about 4 with the maximum possible structures of 5.","The results in (c), (d) and (e) are better than those of baseline methods. The difference in performance becomes greater as the character length becomes bigger, except in the case of (c).","We contend that the result in (c) is something to do with the data sparseness problem that comes from the use of a conventional corpus. For this, we have found that the numbers of constituent words that do not occur or co-occur are 2, 4, 16, and 19 in the EDR corpus, respectively, for the compound words of the length 5, 6, 7, and 8.","Between the results of (d) and (e), we see the latter is better than the former, except in the case of character length being 5. This is expected. In formulas (2) and (3) used for (d) and (e), w1 and w2 are constituent words of a compound word, and hit(w1 AND w2 ) in (2) searches web pages where w1 and w2 co-occur in a document, while hit(w04,2 ) in (3) searches the pages where w1 and w2 appear in succession of w1 w2 . In other words, hit(w1 AND w2 ) makes the search operation less focused or less contextually bound but produces matches more in volume, while hit(wl w2 ) makes the search operation more focused or more contextually bound but produces 5 The EDR Japanese Corpus is provided by the Japanese Electronic Dictionary Research Institute. It contains 210,000 sentences with all the words segmented. 85"]},{"title":"Iimi,","paragraphs":["(w ,, w2) = IMI2(wi,w2) if wini E TLO otherwise IM11(w,,w2) (4) Table 3: Experimental Results 2 (% correct)","Length","Method Hybrid D-tree(1) D-tree(2) five\\tsix\\tseven\\teight 88\\t74\\t66\\t64 86\\t68\\t56\\t48 83\\t71\\t57\\t55 matches less in volume. So, when we have no data sparseness problem with the corpus we use, it is better to use hit(wi w2 ), rather than hit(w, AND w2 ) , to analyze the structure of a compound word whose constituents are assumed to have a tendency to appear closely with each other."]},{"title":"4.3 Refined Experiment","paragraphs":["A close examination reveals that over half of the analytical errors in (e) are correctly analyzed using the formula (2) for (d). For instance, for the compound word, H\\tA'(Wrestling Society of Japan) (Q\\t: Japan iq\\t: wrestling SA- : society) we get a wrong result (((Q *)(4:0))(A-)) in (e): we hardly find a compound word H AK/IAA- on the Internet. But the correct structure of ((1] 2K)A11)(11M-))) is obtainable in (d) as H * and","co-occur with some distance in documents on the Internet.","We also find that most of the wrongly analyzed compound words in (e) begin with a constituent word, called the lead word or wiead here, that represents one of the following three concepts, called TLO here: (1) Time\\te.g., Ali H (the day before), *1 T (postwar) (2) Location e.g., H *(Japan), \\tiT(Pacific Ocean), *A(Tokyo), Wg(Kansai) (3) Organization e.g., D g(United Nations), n k (Liberal Democratic Party),","H g (Nissan), VK(Upper House) The lead word in general relates most strongly to the headword in a compound word. For instance, *A is a lead word in ViA(Tokyo)/Ma(foreign)/A#(exchange)/*(market) meaning foreign exchange market in Tokyo and then we know that we have,r","these facts in mind, we try to refine our method, devise a hybrid method combining the strengths in (d) and (e), and test it in experiment. The formula for the hybrid method is: The initial constituent word in a compound word denoted as w ini in (4) is determined whether to be a W lead using the dictionary Matsumoto et al. (2001) use for ChaSen, a morphological analyzer.","Table 3 shows the experimental results with the use of (4). Included here for the sake of comparison are the two results from dependency tree method, D-tree(1) and D-tree(2), used in Kobayasi et al. (1994) and Hisamitsu et al. (1996): D-tree(1) estimated the strength of association between words using the formula (2) and D-tree(2) the formula (3)."]},{"title":"86","paragraphs":["Figure 2 exemplifies the results from the baseline method (a), D-tree(1) method, and hybrid method in graph. From these, we know that our hybrid method works well. Its performance as we can see is better than those of any other comparable methods in analyzing the structure of compound words. 100 90 80 70","• 60","• 50","co","• 40","• 30 20 10 0 —4-- Method (a)","D–tree(1) Method —à— Hybrid Method 6","\\t 7","\\t 8 length of kanji characters Figure 2: Performances in Various Methods 4.4 An Illustrative Example Let us take an example to see how the analysis is done by the hybrid method. Consider this compound word: \\t ift/ at *MI"]},{"title":"a im\\t","paragraphs":["(bills on political reform) \\t"]},{"title":"(","paragraphs":["g"]},{"title":"ab :","paragraphs":["politics OA\\t: reform 1341\\t: relation a* : bill) We do not find a lead word here. So, we use formula (3) to calculate the strength of association between the headword and other constituent words as is in the top of Figure 3.","-2.178 0.514 I 0 . 1 0 5 1 1 *IN\\t4t\\tiA* .110"]},{"title":"mrg-m*","paragraphs":["starting point :","-2.178","-L635","0.006","1\\tI"]},{"title":"Naft","paragraphs":["04eV starting point :"]},{"title":"ll","paragraphs":["0.514 -0.951","But at* --•M* ill IA\\t • Figure 3: Processes of Finding Dependency Relations 87 Now we locate the starting point of the analysis at p ia', and get the first dependency relation"]},{"title":"--","paragraphs":["q"]},{"title":"lv","paragraphs":["as iA* is the only word following"]},{"title":"ma.","paragraphs":["Then we get h1// (eaft,2A*) as the strongest one among IMI (XVIE1,2A*), MR . ( gal±titi g ) and IMI (Rift,i1V): we acquire the dependency relation kit6--qA* as is in the middle of Figure 3. Finally, by comparing IMI ("]},{"title":"dt*,r","paragraphs":["g"]},{"title":"r","paragraphs":["g ) and 1-M/ (eA*,i13g ), we obtain the dependency relation for 2A*, the last constituent word:"]},{"title":"2A*---qA","paragraphs":["as is in the bottom of Figure 3. The dependency relations for all the constituent words are: (13064 --> 2AV 2AX -->\\\\t"]},{"title":"I","paragraphs":["The analytical processes, after getting the dependency relations, are already explained in Section 3.1. 00ixf\\tat*\\t1414 Figure 4: Resulting Structure Figure 4 shows the resulting structure,"]},{"title":"(00,-/Exi)(2A*))((mg)(m*))),","paragraphs":["and Table 4 contains some more exemplary results from the hybrid method. Table 4: Exemplary Results6 Length of Compound Segmentation Structure","5\\tN/411/R (cabinet / vice / secretary) R/*/A111(Upper House / plenary / session) 113 /111*IK/01(medium / constituency / system) FJ/ \\tg(domestic I gross / product) NA/Cdfitg/A(home and abroad I price I gaps)","6\\t114 P§/1111gli/i(Kansai / international / airport) MOI/ffi/RT-05(experiment / use / atomic reactor) H */5M/4E(Japan I baseball / association) *2M\\ P6/101( desired / retail / price)","/ trade / representative / section)","7\\tRitt/i0/AtiT/it(politics / funds / regulation I act) ft/fR/01/Kglik(Liberal Democratic Party / former / vice / president) */g nittan/$11 (usA / federation / preparation / system) kfM/ftX/I31/91(proportion / representative / parallel / system) 1114/41:1414/W(United Nations I peace / keep / force)","8\\t1 ift/W4/1114/M*(politics / reform / relation / bill) tg f=1\"/$1-/OCX/RA(general / diplomacy I policy / bureau chief)","Ill/NA/St(North America I free I trade / agreement) /1N/S*IK/1:L1J/ftX(small / constituency / proportion / representative) '11 dVik.1/ 4̂/ik/i;*(small and medium / enterprise / finance / corporation) «vg-a)«fflo(Rv)» «oR)«*)(A-ra)» (wiixia*K))(00) *\\tP400)(tg)) * (qP4M-)(04))(A)) ((RINX(1111gii)(4))) (((P)(fii))(g-T-V\")) (( El *)((ff)(g')̀)) *(0A-2)(4\\))004,4»"]},{"title":"* cale)(Ax)xoxxx») caottom»((m)(it)))","paragraphs":["mt)((4)00(gga)))) a(*)(gAlmtfin)(9im))) *\\toixot"]},{"title":"AxIA»)($10) * (wm4)(*fil))((#14)(V)))","paragraphs":["(«Rift)(alc*))((44)(i-Alk)))"]},{"title":"wafr)((","paragraphs":["3Z)(gCM)))(M ((1I *)(((n F13 )( A))( t))) * MON)(N*IK))(1tM))(ftX)) * ((((41 iiN)(11k-1))(4kE))W-4)) Note: * indicates a failure, i.e., wrong structure. 6","A compound word consists of nouns alone or noun(s) and affix(es) attached to them. In this table and other places, we tried to use English nouns when transcribing its constituents. For instance, e(M at* (political reform) consists of two nouns and thus we give the transcription:"]},{"title":"Rel/dt*(politics","paragraphs":["/ reform). 88"]},{"title":"4.5 Evaluation","paragraphs":["The results we got are better than those of others, though a direct comparison with other studies is impossible for various reasons. In reference, Kobayasi et al. (1994) reported their results on 5 and 6 kanji compound words with the success rate of 79% and 70%. Hisamitsu and Nitta (1996) got the rates of 89% and 70% for 5 and 6, 58% and 58% for 7 and 8 kanji compound words.","A problem we encounter is the compound word whose constituents consist of the words something like:"]},{"title":"IR/hcf*/frI/51/---?::","paragraphs":["(the forth criminal investigation section of Osaka Police Department)","(iC 1 : Osaka VW : Police Department E: criminal investigation : four •Ir",":","section)","We get (((()CPK)(RqW))(4 ))((n)(?\" ))) in our method, but the correct one should be(((iC 1R)(Vi))(( I)((ig1)(?\" )))). This error comes from the improper segmentation of the compound word. If we get DP as a word, in stead of FY?' , then our method works perfectly.","An expression relating to some kinds of numbers like in this example is troublesome. The same is true for a prefix or a suffix that appears in a compound word. We see about 30% of the errors in our experiment are of this nature. Some post-segmentation strategies on numerical expressions, prefixes and suffixes may be necessary to improve the performance.","Another problem is seen in a compound word like:"]},{"title":"H *cafti/f","paragraphs":["g"]},{"title":"4","paragraphs":["(Japanese record holder) H : Japan"]},{"title":"EU :","paragraphs":["record if-V4A. : holder","This is a case where the refinement gets against us. When we are to apply (e) to this, we get the right answer as ((("]},{"title":"*)(pE0))(1-504-g)),","paragraphs":["but in the hybrid method El * is a lead word and we get the wrong answer, (("]},{"title":"*)((p2O)(igtM)).","paragraphs":["This type of errors counts about 20% in all the errors. The rest of the errors come from various reasons. Let us see a typical example."]},{"title":"N","paragraphs":["1"]},{"title":"1","paragraphs":["1"]},{"title":"/in * $1.1","paragraphs":["(current medium constituency system) ("]},{"title":"Nn- :","paragraphs":["current\\t: medium"]},{"title":"in * :","paragraphs":["constituency"]},{"title":"$11 :","paragraphs":["system) We get the result from our method of"]},{"title":"(((4V-i)((41)(3n*K)))(91)).","paragraphs":["Here,"]},{"title":"Nfi","paragraphs":["is estimated to depend semantically on 3N*K, while the correct relation should be"]},{"title":"C-7-1--41̂.","paragraphs":["The reason for the failure is that we have few co-occurrence of"]},{"title":"Fr","paragraphs":["and $1,i on the Internet. When we change"]},{"title":"91","paragraphs":["to MI, a word having the same meaning with"]},{"title":"91,","paragraphs":["we get the correct result of"]},{"title":"((NE-)(W11)(3N* K))(91P1))). 5","paragraphs":["Conclusion We have presented a method of analyzing the structure of compound words in Japanese using the strengths of word association among the constituent words. The experimental result that followed indicates that our method sounds better both in the computation time and accuracy. 89","However, we may have ways to get better results. Since the analysis depends partly on the result of word segmentation, we should refine the segmentation system so that it gives us better and suitable results fit for our analysis. It may be desirable in the structural analysis to incorporate a distance measure that is proven effective in analyzing semantic structure of compound words (Kobayasi et al., 1994) and dependency relations among the phrases in Japanese sentences (Zhang & Ozeki, 1997).","References","Alves, E. (1996). \"The selection of the most probable dependency structure in japanese using mutual in-","formation\". In Proceedings of the 34th Annual Meeting of the Association for Computational Linguis-","tics, pp. 372-374.","Bergh, G., Seppdnen A., & Trotta, J. (1998). \"Language corpora and the internet: a joint linguistic re-","source\". In Renouf, A. (Ed.): Explorations in Corpus Linguistics, Rodopi B.V., Amsterdan, pp.","41-54.","Church, K., & Hanks, P. (1990). \"Word association norms, mutual informaion and lexicography\". Computational Linguistics, 16, 22-29.","Fujii, A., & Ishikawa, T. (1999). \"Cross-language information retrieval using compound word translation\". In Proceedings of the 18th International Conference on Computer Processing of Oriental Languages (ICCPOL'99), pp. 105-110.","Furugori, T., & Alves, E. (1999). \"Disambiguation of syntactic structures using the strength of association in three word dependency relations\". Journal of Quantitative Linguistics, 6(2), 101-107.","Han, D., Kato, K., & Furugori, T. (2001a). \"Automatic segmentation of compound word in Japanese using contextual information\". Technical Report of IEICE. NLC 2001-05, 29-34. (in Japanese).","Han, D., Wu, H., & Furugori, T. (2001b). \"Resolving overlapping ambiguities and selecting correct word sequence in chinese using Internet corpus\". Journal of Natural Language Processing, 8(3), 107-121.","Hisamitsu, T., & Nitta, Y. (1996). \"Analysis of Japanese compound nouns by direct text scanning\". In Proceedings of the 16th International Conference on Computational Linguistics (COLING '96), pp. 550-555.","Karov, Y., & Edelman, S. (1998). \"Similarity-based word sense disambiguation\". Computational Linguistics, 24, 41-59.","Kobayasi, Y., Tokunaga, T., & Tanaka H. (1994). \"Analysis of Japanese compound nouns using collocational information\". In Proceedings of the 15 th International Conference on Computational Linguistics (COLING'94), pp. 865-869.","Lauer, M. (1995). \"Corpus statistics meet the noun compound: some empirical results\". In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pp. 47-54.","Matsumoto, Y et al. (2001). Morphological analysis system ChaSen version 2.2.8 manual. http://chasen.aist-nara.ac.jp/chasen/doc/chasen-2.2.8.pdf.","Mihalcea, R., & Moldovan, D. I. (1999). \"A method for word sense disambiguation of unrestricted text\". In Proceedings of 37th Annual Meeting of the Association for Computational Linguistics, pp. 152-158.","Miyahira, T., Watanabe, H.., Tazoe, E., Kamiyama, Y., & Takeda, K. (2000). Internet kikaihonyaku no sekai. Mainichi Communications, Inc. (in Japanese).","Miyazaki, M. (1984). \"Automatic segmentation method for compound words using semantic dependent relationships between words\". Transactions of Information Processing Society of Japan, 25, 970-979. 90 (in Japanese).","Miyazaki, M., Ikehara, S., & Yokoo, A. (1993). \"Combined word retrieval for bilingual dictionary based on the analysis of compound words\". Transactions of Information Processing Society of Japan, 34, 743-753. (in Japanese).","Nishino, T., & Fujisaki, T. (1988). \"A stochastic parsing of kanji compound words\". Transactions of Information Processing Society of Japan, 29, 1034-1042. (in Japanese).","Shimohata, S., & Sugio, T. (1997). \"Keyword extraction using character type and decomposition of compound word\". Technical Report of lEICE. NLC1997-07 , 13-18. in Japanese).","Takeda, K., & Fujisaki, T. (1987). \"Automatic decomposition of kanji compound words using stochastic estimation\". Transactions of Information Processing Society of Japan, 28, 952-961. (in Japanese).","Utiyama, M., & Itahashi, S. (1992). \"Division of Japanese compound nouns using co-occurrence relation\". SIG notes, NL-91, Information Processing Society of Japan, 47-54. (in Japanese)","Wu, H., & Furugori, T. (1996). \"A hybrid disambiguation model for prepositional phrase attachment\". Literary and Linguistic Computing, 11, 187-192.","Zhang, Y., & Ozeki, K. (1997). \"Dependency analysis of Japanese sentences using the statistical property of dependency distance between phrases\". Journal of Natural Language Processing. 4(2), 3-19. (in Japanese)."]},{"title":"91","paragraphs":[]}]}