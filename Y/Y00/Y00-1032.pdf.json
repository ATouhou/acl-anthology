{"sections":[{"title":"Domain Unconstrained Language Understanding Based on How-net *4.","paragraphs":["Jhing-Fa Wang, * Hsien-Chang Wang and * Chin-Nan Lee","Department of Computer Science and Information Engineering","+ Department of Electrical Engineering","National Cheng-Kung University, Taiwan, R.O.C."]},{"title":"Abstract","paragraphs":["In this paper, we propose a method for domain unconstrained language understanding based on the How-net knowledge base. The goal is to construct a system that reads in an article and answers some related questions. For each sentence in the article, word segmentation is first applied. Then, the major components such as agent, theme, event, time, and place are extracted to construct a semantic-slot table and a semantic network. Answers of the questions are derived using two approaches, which are based on the relational and hierarchical relation among the major components. Our method is applied to the understanding of the primary-school textbook, and it is able to answer questions in the exercise of the textbook."]},{"title":"1. Introduction","paragraphs":["Currently, most available applications of natural language processing (NLP) are domain specific. In this paper, we propose a method for domain unconstrained language understanding. The knowledge base we used is the How-net knowledge base, which is constructed by researchers in Beijing. The description and content of How-net can be found in the following URL, http://www.how-net.com. How-net describes the relationship of objects using both concepts and attributes. Based on How-net knowledge base, we have some methods to analyze the sentences of an article. First, word segmentation is performed to find the corresponding word sequence. Then, major components (agent, event, time, place, and theme) conveyed in the sentence are extracted. Finally, the semantic table and semantic network are constructed for the understanding of the article. For the experiment, we try to answer the questions in the exercises of the primary-school textbook. Article of each lesson is used to construct the corresponding semantic table and semantic network. Answers of the questions are derived by measuring the likelihood of the major components. This paper is organized as follows. In Section 2, we introduce basic concept of the How-net knowledge base. In Section 3, the method to analyze sentences is described. In Section 4, we show how to answer the questions of the primary-school textbook. The conclusion is given in the final Section."]},{"title":"2. The Structure of How-net","paragraphs":["How-net is a Chinese knowledge base which describes the objects using concepts and attributes. The basic units in the How-net are physical and spiritual objects such as components, attributes, time, space, events, attribute values, and so on. Common and individual characteristics of concepts are both recorded in How-net. Consider the words \"g-(doctor)\" and \"2ff(patient)\" as example, the common characteristic of them is \"people\". This common characteristic is recorded in the How-net. On the other hand, \"doctor\" has the individual characteristic being the agent of \"cure\"; and \"patient\" has the individual characteristic being the experiencer of \"suffer\". The relations among different concepts and attributes are also described by How-net. The relations are shown below: (1) Upper-Down relation.\\tEx. Father-Son, Father-Daughter, .. (2) Synonymous relation.\\tEx. Good-Well, Big-Large, ... (3) Antonymous relation.\\tEx. Good-Bad, Large-Small, ... (4) Attribute-Host relation.\\tEx. Age-Person, Color-Flower, .. (5) Component-Entire relation.\\tEx. Leg-Body, Door-House, .. (6) Material-Product relation.\\tEx. Rice-Wine, Sand-Glass, ... (7) Event-Agent relation.\\tEx. Cure-Doctor, Build-Worker, .. Figure 1 is an example showing relations among some objects (in rectangle shape) and actions (in round-rectangle shape). Figure 1. Example of relations among objects. 3. Analysis of the Sentences 3.1 Word Segmentation Unlike western language such as English, Chinese sentence is composed by characters. Since How-net is a word-based knowledge base, each sentence has to be segmented into word-sequence for further processing. Word segmentation can be done by several approaches. The simplest one is to use the greedy algorithm. This algorithm treats the input sentence as a large string, and then shrinks the string gradually to check whether the shrunk substring is a lexical term. The segmentation results may be different if the shrinking directions are different. For example, the sentence \"7t_gp.A-istRibt,t4 (The life in college is very cheerful)\" may be segmented into \" 7t-A-(college student) ?S(live) avery) ilk,(cheerful)\" if the string is shrunk from right to left. However, it may also be segmented into \" A•(college) \\t (life) j,R(very) 'W(cheerful)\", which is the correct segmentation, if shrunk from left to right. In this paper, we employ the greedy algorithm for both shrinking directions. If the segmentation results are the same for both directions, then we are done. If not, the bigram scores of both word-sequences are calculated to determine the correct segmentation. This bigram information is trained using a large amount of news corpus. Since the bigram score calculation can be found in many lectures, it is abbreviated here. Note that if the segmentation result contains dangling single-characters, these single-characters may be further combined with other words/characters to form a compound word using word-formation rules. For example, one of the rules is to deal with the Chinese naming principle. We try to combine the characters sequence \" \\t \\t Rt into one word \" (Lee Kin-Nan)\" since \" \\t (Lee)\" is a Chinese surname. Another example is that the word sequence 11 •0-2- (thy)\\tM(neat)\" is combined into the compound word iP?P (clean)\" since it satisfy the adjective formation rule. 3.2 Extracting Major Components of the Sentence Based on our previous study [2], we think that to understand a sentence is to know the answers of SW, i.e., who, what, when, where, and which. In this paper, we define these answers as the major components of sentence. The major components represent the agent, theme, time, place, and event conveyed in the sentence and they contain essential information to understand the sentence. For example, to analyze the sentence"]},{"title":"\"..","paragraphs":["71"]},{"title":"1p-","paragraphs":["f"]},{"title":"e","paragraphs":["tti"]},{"title":"iajp","paragraphs":["(Lee Kin-Nan broke the window of the classroom)\", the sentence is first segmented into the word sequence: \" \\t\\t (Lee Kin-Nan) P(broke) ttV(classroom) 0(De) j (window)\". Then, the major components are determined by the part-of-speech tags found in How-net. In this example, we have the words: Lee Kin-Nan (agent: n. name of people); break (event: v. break); classroom (place: n. place to conduct a lesson); window (theme: n. the hole in the wall to illuminate the house). The major components in such a simple sentence can be easily determined. However, for some complex sentences, we may need extra information to properly catch the meaning of the sentences. So, the attributes of each component are attached to carry more information. Each component may have none or more than one attribute. The attribute of agent, for example, can be the height, weight, age, color, and so on. After extracting the major components of each sentence, the semantic table that consists of the major components and their attributes can be constructed sentence by sentence. Figure 2 shows an example text chosen from the primary-school textbook. The corresponding semantic table is shown in Table 1. Note that the attribute of an event can be another event or sentence."]},{"title":"MMV-_LT7\\t° RifriMT*T- ,\\t° KM_EziAllqq7A °\\ttzfrP_NA ° T*W A\\tMVRA'-'1'n - W-,\",-;11MWTR r TVAin fiTZ afirki gla ' 4, 2a: ° '4 14MAT fEfiUM ° MM,FiR r 4 R--VE/1.1.","paragraphs":["(S i ) My brother is going to school, (5 2) He is very happy. (S3) He is in the first grade, (5 4) I am in the second grade. (S 5) Mother says to me, (S 6) \"today is the first day for your brother going to school, (5 7) you","should take him to school carefully. (S8)I go to school with my brother hand in hand. (S9)There are many cars in the road: (S i o) big cars and small cars. (S 11 ) The cars run far and near, (5 12) my brother is afraid of the running cars. (S 13) I told my brother, (5 14) \"Don't be afraid. (S 15) Look, the red light is on, (S 16) don't go.","(5 17) Wait until the green light is on, (S 18) then cross the road.\" (5 19) My brother says, (5 20) \"OK, I will remember that.\"","Figure 2. The article chosen from the first grade textbook. 3.3 Constructing the Semantic Network In addition to the semantic table, semantic network [3,4] also records the relationship of each sentence. The nodes of the semantic network are the major components and their attributes of the sentences. The edges are the relations of major components and attributes. The semantic network is constructed gradually while reading each sentence of the text. When the major components and attributes are extracted, if the component already exists in the semantic network, the attributes and relations are updated using current ones. Otherwise, new nodes and edges are added into the semantic network. Figure 3 – Figure 6 illustrate the construction of semantic network when input the sentences Sl–S4 in Figure 2. Note that new nodes and edges of the semantic network are painted in white color. H4 MI time","N( feature"]},{"title":"C","paragraphs":["_EW schoolgo to younger brother","Figure 3. Semantic network construction, step 1: Input the sentence \"firZ1-:4.7̀*(My brother is going to school)\" Figure 4. Semantic network construction, step 2: Input the sentence \"faaiff./(He is very happy)\"","Figure 5. Semantic network construction, step 3: Input the sentence \" (My brother is a new student in first grade)","Figure 6. Semantic network construction, step 4: Input the sentence"]},{"title":"\"R_E_-:_g-r","paragraphs":["(I am in second grade)\""]},{"title":"4. Answering the questions","paragraphs":["The questions we deal with are those in the exercises of primary-school textbook. Each question in the exercise provides several candidate answers for the reader to choose the right one. Some examples of the questions are shown below. \\t Ql : It4.11_3- CUT /"]},{"title":"\\t\\t","paragraphs":["The classroom is the place to (study / ride)."]},{"title":"Q2: (","paragraphs":["g"]},{"title":"M. / Ma)\\t","paragraphs":["° If the (red / green) light is on, you can cross the road."]},{"title":"Q3: AWIAT:","paragraphs":["iwin Tivn). Brave is to be (afraid / not afraid).","Q4: mm.2:—vAni,i\\t/ My brother is a new (student / classroom) in the first grade. Q5: There are many (students / cars) in the school. I am in the (first / second) grade. To answer the questions, we have developed two methods. The first one tries to find answer directly from the input text. The other one calculates the relation score among major components extracted from the questions and the article to find the proper answer. 4.1 Answering the Question Directly from the Text Some questions of the primary-school textbook are easy to answer. The answer can be found by scanning the article to match the sentence that has the same components in question. For example, Q6 is a question of this kind. To answer question Q6, we first extract the components of the question, i.e., \"R(I)\". This component is used to active the corresponding subgraph in the semantic network. Then, the answers \"—g(first grade), iiiiR(second grade)\" are determined by choosing the one which matches the components best. In this case, the answer will be \"ii it(second grade)\". 4.2 Answering the Question According to the Similarity Measure If the method described in Section 4.1 does not work, we use another approach to find the right answer. This approach checks the similarities of the major components in the question. The similarities are measured by the relation derived from the How-net. Two kinds of similarities, i.e., relational and hierarchical similarity, are used to calculate the overall similarity measure."]},{"title":"4.2.1\\tMeasuring Relational Similarity","paragraphs":["In the How-net knowledge base, each word has its corresponding definition(s). These definitions are recorded in How-net as the field \"DEF\". For example, the words \"fflt-\"̂ (school)\", \"(student))\", and \" nrnicar) have the DEFs as shown below. Note that a word may have several meanings, thus it has many DEFs. W_C[49479]=VSZ II word index G_C = N //part of speech tag DEF[0]=InstitutePlaceligffi // definition of the word's concept","Feature of noun: *engagelft#affairsl.A","Feature of verb: engagelfX${agent,content} DEF[1]=©teachig","Feature of verb: teachig{agent,content,target}/{agent,patient,ResultEvent} DEF[2]=@studyl,","Feature of verb: studyiNagent,content,source} DEF[3]=educationigW","Feature of noun : educationlgt W_C[49451]=T G C = N DEF[0]=humanIA","Feature of noun: N.1.1.1.1.1.1!namelt!wisdomitig!abilitylgjj!occupationl","ffafractiffM DEF[1]=*studff","Feature of verb : studyffiagent,content,source} DEF[2]=educationigft","Feature of noun :education \\t W_C[34290]=A G_C = N DEF[0]=LandVehiclel","Feature of noun: N.1.1.1.2.2.7.3.1#1andil*WeVehicleGoIR","Feature of verb: VehicleGoll.{agent,direction,Locationlni,LocationFin} The similarity of different words is measured by comparing their DEFs. Words with similar DEFs will result in higher similarity measure. For example, the relational similarity of the words \" ffltk(school)\" , \" _W_(student))\" , and \" n(car)\" are calculated as: N .1 .1 .2 mental 3k N.1 .1 .3 event 4r -ft-N.1 entity -or int","N.2 attribute N.3","quantity Att_lk","N.1.1.1.1 animate\\tethi N.1.1.1.1.1 AnimalHuman *Ji","4hJ N.1.1.1.1.2 plant tk 4-b7 N.1.1.1.1.3 bacterial\\t4-h3 N.1.1.1.2.1 nature jc 5 4bJ N.1.1.1.2.2 artifact .1.. s._ 4b, N.1.1.1.1.1.1 human ,nC_ N.1.1.1.1.1.2 animal lifk","N.1.1.1","phsical fi 'W N.1.1.1.2","inanimate -\"-±_ 01-N.1.1.1.3 shape N.1.1.2.1 emotion '1*,.6. N.1.1.2.2 expr ience N.1.1.2.3 aspiration ;tbitik N.1.1.2.4 thinking N.1.1.2.5 information N.1.1.2.6 regulation #4?-4E. N.1 .1 .2.7 right 441 +.1 N.1.1.2.8 duty N.1.1.3.1 fact ir 4*- N.1.1.3.2 phenomena\\tSt.","N.1.1.2.4.1 though","N.1.1.2.4.2 method 97-51 \\t N.1.1.2.4.3 purpose ill 6,3 N.1.1.2.4.4 reason 1.1_ - N.1.1.2.4.5 standpoint - N.1.1.2.4.6 knowledge\\t,=7Siliz N.1.1.3.2.1 disease 4X• N.1.1","- thing","4b1 N.1.2\\t N.1.1.4.1 institution 44,k44* time .4- FA","\\tN.1.1.4\\tN.1.1.4.2 army \\t","-component -","N.1.1.4.3 InstitutePlace **/.1- -4rs","N.1.1.4.4 community Mil ft N.1.3\\tN.1.3.1 direction 75-- f7 space - N.1.3.2 location 4L 1 N.1.4\\t","N.1.4.1 part is ft-","component","N_1.4.2 fitting me. ft-Relational Similarity (No.49479\\t& No.49451 Vt') =12 Relational Similarity (No.49479 \\t\\t& No.34290\\t= 2 Relational Similarity (No.49451 ''fit' & No.34290\\t= 3 From above result, we can conclude that the word \"VOschool)\" is more similar to (student)\" than \"I-1, ift(car)\"."]},{"title":"4.2.2\\tMeasuring Hierarchical Similarity","paragraphs":["How-net also specifies the hierarchical relation of entities like a tree structure as shown in Figure 7. In this paper, the hierarchical similarity of two objects is defined as the shortest-path distance between these objects. For example, the similarity measure of \"human\" and \"animal\" is two, as shown is the upper-right part of Figure 7. Figure 7. The hierarchical relation of objects. —334-- 4.2.3\\tAnswering the Question According to the Similarity Measure With the similarity measures obtained by the above methods (relational and hierarchical), we are able to answer questions that can not be answered using the method in Section 4. For example, the similarity measure of major components in Q4 and Q5 can be calculated as below. Q4: '/I_'---1T-VAFYJ\\t/\\t°","My brother is a (new student / classroom) in the first grade. Major components: \"(brother)\", 111(new student)\", \"(classroom)\" Similarity measure (No.10017'W & No.48295W 1) = 10 Similarity measure (No.100171"]},{"title":"MW","paragraphs":["& No.221917A1 = 0 The answer is : \"Vit(new student)\""]},{"title":"Q5: Tf3Z1I-4M-in\\t/\\t°","paragraphs":["There are many (students / cars) in the school. Major components: \"PM(school)\",\"3t.(student)\",\",*(car)\" Relational Similarity (No.49479 \\t\\t& No.49451\\t= 12 Relational Similarity (No.49479"]},{"title":"'VSz'","paragraphs":["& No.34290\\t= 2 The answer is : \"04.44.(student)\""]},{"title":"5. Discussion and Conclusion","paragraphs":["As the technique of speech processing improved, the success of speech applications, such as human-machine interactive system and spoken dialogue system, now depends on the success of natural language processing. Currently, few significant results are presented for Chinese NLP due to the lack of good knowledge base. In this paper, we employ the How-net to be our knowledge base for the domain unconstrained language understanding. Methods to answer the questions of the input article are proposed. Word segmentation, major component extracting, and semantic network construction of the input article enable us to derive the answer of the questions in the primary-school textbook. Although the How-net plays an important role in our system, we find that some adaptations should be made to achieve better performance for the Chinese language understanding in Taiwan. The major shortcoming is that How-net is built in the Mainland China, thus some wording habits are different from that in Taiwan. For instance, the word \"software\" means"]},{"title":"\"Vx \"","paragraphs":["in Taiwan, however, it is written as \"","\\t \" in Mainland China. This kind of word-disagreement should be solved before the How-net can be applied deeply in the natural language processing of Chinese in Taiwan. We are currently enhancing the How-net by using the word dictionary built by the Academic Sinica of Taiwan [5]. Our future research is to apply the techniques described in this paper to the task of web understanding."]},{"title":"6. References","paragraphs":["[1] Zhen-Dong Dong, The How-net web site, http://www.how-net.com/ [2] Thing-Fa Wang, Hsien-Chang Wang, Chin-Nan Lee and Mao-Sheng Hung, \"On the Construction of the Knowledge Base for the Domain Unconstrained Spoken Dialogue System\", Oriental COCOSDA 1999, pp.133-136. [3] J. Allen, Natural Language Understanding, Second Edition, The Benjamin/Cummings Publishing Company, Inc. 1995. [4] J. Rumbaugh, et. al. Object-Oriented Modeling and Design, Prentice Hall, 1991."]},{"title":"[5] FrI Z-Mignii\\M\" 141 3ZMW}C (EN)\", 41 fiic-fARME1Af454=F3,","paragraphs":["1993. o to chool"]},{"title":"MEM","paragraphs":["any ig and small"]},{"title":"It","paragraphs":["d, on reen, 0 R Sentence classification Declarative Declarative Declarative","periodTime point attrib. attrib. S1 52 S3 S4\\tDeclarative S5\\tSubordination S6 \\tDeclarative Sll \\tDeclarative S12","\\t Declarative S14\\tImperative S15\\tDeclarative S16\\tImperative 517\\tImperative S18\\tAdverbial clause S19\\tDeclarative S20\\tAffirmative","Agent\\tattribute Event Trans. Intrans. attribute Theme attribute Place to from S7","\\t Imperative 58 \\tDeclarative S9","\\t Declarative S10 \\tDeclarative S13 \\tSubordination (period)Today. (at) School (at) Road Road Table 1. The semantic-slot table for the text in Figure 2 -338-"]}]}