{"sections":[{"title":"Ambiguity Resolution in Chinese Word Segmentation*","paragraphs":["Sun Maosong Tsinghua University and City University of Hong Kong E-mail: dcsjpf@tsinghua.edu.cn, ctmssun@cityu.edu.hk","Benjamin K T'sou City University of Hong Kong","E-mail: rlbtsou@cpccux0. cityu. edu. hk ABSTRACT A new method for Chinese word segmentation named Conditional F&BMM (Forward and Backward Maximal Matching) which incorporates both bigram statistics (i.e., mutual information and difference of t-test between Chinese characters) and linguistic rules for ambiguity resolution is proposed in this paper. The key characteristics of this model are the use of: (i) statistics which can be automatically derived from any raw corpus, (ii) a rule base for disambiguation with consistency and controlled size to be built up in a systematic way. 1. Ambiguities in Chinese Word Segmentation","In Chinese, there are no delimiters, such as spacing in English, to explicitly indicate","boundaries between words. Chinese word segmentation, viewed as the first step in any Chinese","information processing system, has been intensively studied by the Chinese language computing","community in the last decade. Unfortunately, a satisfactory segmentation procedure remains elusive.","Ambiguity is one of two main obstacles to progress in Chinese word segmentation research","(another is Unknown Word) [I]. We have to face two kinds of fundamental ambiguities:","• Type I — Overlapping Ambiguity (OA)","( 1 )\\tQ;.. \\̂-1.F. ffi"]},{"title":"flf.91±.","paragraphs":["At least two possible segmentations which overlap in position exist for the sequence \"IP,"]},{"title":"\\n\"","paragraphs":["and \"*\\ ffi\\tif we simply match it with a Chinese dictionary. • Type II — Categorial Ambiguity (CA)","(2)a. VT\\tEljf kittf4 b. - -\\t"]},{"title":"±.","paragraphs":["Note the sequence \"--T-1\" \" in (2): the constituents should be combined as a single word in (a), but they should be separated in (b) because of the productivity of expressions such as 1j/17,","Basic methods for dealing with segmentation ambiguities so far can be either rule-based [2,3] or statistics-based [4,5]. The former employs the conventional maximal matching strategy, either forward or backward (referred here as RIM and BMM respectively), or both , as a detector of ambiguities, and applies relevant rules from the rule base to solve them. The problems in this approach are (i) the constructions of 0As in texts to be processed are nearly unpredictable, resulting in unwieldy complexity in rule base establislunent and maintenance, and (ii) it always fails in finding CAs. The latter gives segmentation possibilities exhaustively by dictionary lookup as a * This research is supported in part by the Youth Science Foundation of Tsinghua University, Beijing, and by the Language Information Sciences Research Centre, City University of Hong Kong 121 candidate space to the input sentence first, then makes use of statistics (typically word frequencies) to prune the candidates for the solution. But what is confusing in this approach is the acquisition of statistical data. It can be estimated that to obtain more reliable word frequencies, a pre-segmented corpus with at least 20M words is needed because there exist about 50,000 words in a medium sized Chinese dictionary. This is as yet an impractical mammoth task.","Focusing on the problems identified above, a new method named Conditional F&BMIL1 which incorporates both statistics and rules into ambiguity resolution is proposed in this paper. The task of F&BMM is to find OAs whereas an additional \"Conditional\" mechanism is responsible for finding CAs. A Chinese character bigram model, having been trained automatically from a very large corpus, is utilized as the means to disambiguate ()As. The disambiguation of CAs, however, will be carried out by some general rules invoked by internal constructions of CA s accordingly. 2. Ambiguity Detection & Resolution 2.1. Why F&BMM Can Work?","The idea of segmenting Chinese sentences with F&BMA4 simultaneously is not something new.","But till now no quantitative analysis appears available in the literature to validate the feasibility of","this strategy. We test this by applying F&BMM to a set of randomly selected Chinese texts with","55230 characters, or 3680 sentences. The following is observed from the result:","case I.: The output of FMA1 and BMA/fare different, but both are incorrect","(3) 441V.Virit±A,A.ftY1---A-:- Fmm: 44\\1:),\\VIWg VkZ: \\±3)1N\\rt-Vi-05'\\tincorrect BMM: lq-\\1)).\\-Vi\\n\\l_kZ\\L-EUX;(±1trr\\*-1-Y\\t==> incorrect","Total in number: 2 sentences (0.054%) case 2: The output of FMA4 and BMM are different, but only one is correct (4) i--1-1514JIMZ.--->5fM5(1,41 FMM:\\t GV \\t==> incorrect BMM: \\t \\t ==> correct Total in number: 340 sentences (9.24%)","case 3: The output of FMA4 and BMM are identical but incorrect"]},{"title":"(5) 5.13,AT-IMM61413R152","paragraphs":["EMM&BMA4."]},{"title":"aw-r\\---\\A\\n\\g*\\","paragraphs":["m\\t==> incorrect Total in number: 15 sentences (0.41%)","case 4: The output of FMM and BMM are identical and correct (6) *ElbnifrricSiligf44-4-4ZAJI BIllif&BA1114:1:1\\pri)ii\\t*:\\ritvf:1-4.4 rc\\Avli\\t==> correct","Total in number: 3323 sentences (90.30%)","Case 2 and case 3 are examples of OAs and CAs respectively. Such ambiguities can be successfully captured by F&BMM ( the Conditional mechanism needs to be elaborated for case 3, see section 2.3) . Case I, on the other hand, is really a \"blind area\" for F&BMA/1, but as can be seen, it only accounts for a very small part of the whole texts (0.054%), and may be omitted in practical considerations. This suggests that F&BMM is quite appropriate for the purpose of Chinese word segmentation. 122 2.2. Resolving Ambiguities of Type I","Mutual information and t-test, two important concepts in information theory and statistics, have been exploited to measure the degree of association between two words in an English corpus[6]. We adopt these measures almost completely here, with one major modification: the variables in two relevant formulae are no longer words but Chinese characters. Definition 1 Given a Chinese character string ixyl , the mutual information between characters x and y is defined as: var(p(*)) + var(p(ylx)) where p(y1x) is the conditional probability of y given x, and p(zfy), of z given y, and var(p(y1x)), var(p(zly)) are variances of p(y(x) and of p(zly) respectively.","Note that tx.,(y) is attached to a character y, whereas I (x: y) is attached to the location between two adjacent characters x and y. This inconsistency may cause some inconvenience if we try to incorporate both. We initially introduce a new measure instead: Definition 3 Given a Chinese character string 'vxyw', the difference oft-test between characters x and y is defined as:","At (x: y) tv.y (x) - t .,,.(y)","Like I (x: y) now, At (x: y) is also allocated to the location between characters x and y. Furthermore, the domain that At (x: y) covers is 4 characters, larger than that of t, (y) (3 characters). These two features make At (x: y) more suitable for our needs.","Both ./(x:y) and At (x: y) serve as estimates to measure the combinatorial propensity between characters x and y: the higher the value, the stronger the combinatorial propensity. For example, in the following sentence: (7) I (x: y)\\t6.2\\t5.2\\t2.6\\t4.4\\t0.0\\t2.2\\t1.6 At (x: y)\\t25.5\\t2.8\\t-86.7\\t164.2\\t-106.6\\t36.8\\t-52.2 I (x: y)\\t7.3\\t1.3\\t7.2\\t0.2\\t-0.3\\t5.2 At (x: y)\\t73.4\\t-55.7\\t20.8\\t8.2\\t-39.5\\t60.1 1(&:*) is very high (7.3), so \"'VS\" should be absolutely combined; 1(n:Y1, 1 ) is very low (- 0.3),thus \"regt\" should be separated. Similarly, \"ft should be combined but \"El iz.\" separated, because of their respective At values: At (ft: El) = 164.2, At (D:)/_) = -106.6.","In some complicated cases however, I (x: y) and Al(x:y) should be both used judiciously and jointly, allowing them to complement each other. Sorting character pairs collected in (7) according to I (x: y) in descendent order, we get: &,1* giR Ot: *CI 4.-T*, AM tfk\\t-133.in\\tnire, 7.3 7.2\\t6.2 5.2\\t5.2 4.4\\t2.6 2.2\\t1.6\\t1.3\\t0.2 0.1)\\t-0.3 A \\t B\\tC","P(x)P(Y) where p(x,y) is the co-occurence probability of x and y, and p(x), p(y) are the independent probabilities of x and y respectively. Definition 2 Given a Chinese character string 'xyz', the t-test of the character y relevant to characters x and z is defined as: P(z 1.0 P(Ylx) tx.: (Y) 1 (x: y) = loge\\txP( 123 For character pairs in area A or area C,"]},{"title":"I (x: y)","paragraphs":["allows judgment to be properly made by itself. But for those in area B, it seems not so clear: 1(t:t)(5.2) is equivalent to At :31)(5.2), and further, Aft:E)(4.4) is lower than 1(:1) , 1( 1L;:f0(2.2) is also lower than 1(;:*), even lower than 1(*:ft)(2.6), why should \"t l\", \"ft \" 11..R\" be grouped together while \"g;, \"*It\" must be separated? There will be no explanation based solely on"]},{"title":"(x: y) .","paragraphs":["We sort character pairs by their dt(x:"]},{"title":"y)","paragraphs":["this time: RE]"]},{"title":"1m\\tgig im\\tof","paragraphs":["R& Mt *ft M/4: \\t","164.2 73.4 60.1\\t36.8 25.5\\t20.8 8.2\\t2.8\\t-39.5 -52.2 -55.7 -86.7 -106.6","A\\tB\\t C","Consider the above character pairs again. The distinction between At (t it:31)(60.1) and At (t.:*)(2.8) is quite significant given At :) equals .1(;t: V), indicating that \"t1 31\" should be combined and \",t*\" separated. The situation becomes even more apparent if \"ft0\" and \"Vt\" are included: \"RD\" goes forward to the head of the queue from area B to area A ( At (ft:0) = 164.2), and \"Vt\" moves almost to the tail from area B to area C (At (V :ft) = -86.7) . That is","really what we are expecting! The algorithm integrating these two kinds of statistics for OA resolution is sketched below:","step 1. for an input sentence S, segment it with FMM and Blt/L14 respectively, deriving two candidate segmentations SEG] and SEG2.","step 2. if SEG I and ̂EG2 are identical, then output it as the result; otherwise","step 3. if number of words in SEG1 and SEG2 are different, then output one which will result in less words ; otherwise","step 4. for any two successive words FRAG1 in ,SEG I and their counterparts FRAG2 in ̂EG2 composed of also two words, if the location between two words in FRAG1 denoted as ptl is different from that in FRAG2 denoted as p12, then","step 4.1. if I(pt2) - 1(pt1) > a then output FRAG1 for the corresponding part of S;","if /(/)/1) - 1(pt2) > a then output FRAG2 for the corresponding part of S;","step 4.2. if [1(pt 1) - 1(pt2)1 < a then","if At (pt2) - At (ptl)\\t(3 then output FRAG1 for the corresponding part of S;","if At (ptl) At (pt2)\\t13","then output FRAG2 for the corresponding part of S;","step 4.3. if Apt 1) - 1(pt2)1 < a and I At (ptl) - At (pt2)I < 13 then","if 1(pt2) - 1(ptl) ) 0 then output FRAG1 for the corresponding part of S.","otherwise output FRAG2 for the corresponding part of S.","1* The constants a ,13 are to be determined by experimentation. *I","Applied to 340 OAs found by FW&BMA/1 mentioned in section 2.1, 292 (i.e., 85.9%) are correctly segmented. There is a 35.9% improvement over the average accuracy of 50.0% when FMM and BMA4 are applied separately.","Some of the experimental results are listed below to illustrate the performance of this algorithm: (4) frnIttitt---\"IF.:fitR1,&-T. FMM:\\t(Vatt\\III--%;\\tfil\\PM-V"]},{"title":"I (x: y)\\t","paragraphs":["8.8"]},{"title":"At (x: y)\\t","paragraphs":["51.6","BMM:\\t\\\\t(\\t—\\tfiZ1xA)\\t==> output (x: y)\\t4.6 At(x:y) -29.0 124 This situation can be processed by the algorithm easily (step 4.1). (8) ft-1̂ LT01,3"]},{"title":"*VitiK","paragraphs":["Fmm:"]},{"title":"(ft","paragraphs":["."]},{"title":"14-","paragraphs":["•"]},{"title":"\\fik.-T_. \\-4","paragraphs":["33"]},{"title":"u\\","paragraphs":["11',"]},{"title":"n)","paragraphs":["\\t"]},{"title":"2xjj \\","paragraphs":["I (x: y)\\t 5.5 At (x: y)\\t 4.9 BMM:\\t 42 \\\\t==> output I(x:y)\\t 5.7 At (x: y)\\t-81.7","In this case, the difference between /03:11-0 and 1(*:TJJ) is not large enough, so the difference of At (Vj:FK) and & (4:1-J)) must be taken into account. OA in (8) can be successfully solved now (step4.2). It is obvious that if a decision is made by comparing the values of I(Ij:rtk) and of I(4z:lij) only, the results will be misleading."]},{"title":"(9) its\\tT Vt311in","paragraphs":["Fmm:"]},{"title":"wreg\\--2:-,1","paragraphs":[","]},{"title":"\\oz\\Tvt\\t-1\\)\\t\\","paragraphs":["I (x: y)\\t 5.3 At (x: y)\\t 13.5 BA1114: ortviig\\v,t-A-t\\ht\\--ntrf* iv\\t\\ i\\t==> output I (x: y)\\t 4.3 At (x: y)\\t 15.0 Neither the difference between /(iii:2) and ./(r-rt:J:it) nor that between At (tit: E) and At","it-) would be significant this time. We shall have to return to the starting point, that is, making use","of mutual information solely (step4.3). A key characteristic of this algorithm is that the relevant statistics (Chinese character bigram) can be trained automatically from any raw corpus of unlimited size without any requirement of human monitoring. In our experience of training such statistics with a news corpus of 20M Chinese characters, we have found it very easy and fast to adapt parameters of the model to any new application domain of word segmenter under the condition that the electronic corpus is available accordingly. 2.3. Resolving Ambiguities of Type","Definition 4 A word w is said to have feature 'ck' if w can be further split into n words ,\\t-wi ,\\t(n\\t2), and there exists at least one Chinese sentence involving w in which -14, 1 ,...,-w; ,\\tw n can be syntactically and semantically justified if w is simply viewed as a character string.","By definition, words with 'ck' feature can be pre-defined and enumerated in the dictionary . In our dictionary for word segmentation, 4171 out of 61039 entries are marked with 'ck'. \"—f-f\" and \"t-A\" , as illustrated in (2) and (5), are typical examples.","In section 1 of this paper, we regard our approach as Conditional F&BAIM. Conditional means that if a word with 'ck' is encountered in the process of segmentation, F&BMA/1 will no longer be an absolute ruler; the possibility of splitting them into words with smaller units needs to be","reserved for further accounting. In our experience, words of this sort can be divided into some single groups according to their shared parts of speech and a sequence of smaller words with different parts of speech. For instance, words like\\tugv,\\t',Ertl.. IlEtft11 , „Egg„ ,\\t911.1 „ ,\\t„ \"\\t\" can be regarded as a single group, because they are both 'noun' and 'numeral +","classifier' construction. Then, a generalization rule for dealing with this CA group can be set up: #RULE [w I POS: NOUN, WC: NUMERAL+CL4 ^̂ IFIER] if w can take the position of 'numeral + classifier' in the sentence to be segmented then segment it into two words as 'numeral' and 'classifier'; otherwise output w as a 'noun' One point deserving attention is that the construction of CA s can be predicted in general as","contrasted with the unpredictability of OAs. In other words, a rule base for the disambiguation of","CAs with consistency and controlled size can be conducted in a more systematic way. 3. Conclusion","The design principle for the presented model should benefit some practical applications of word segmentation in, for example, post-processing of OCR, speech recognition and synthesis systems, in which a trade off among accuracy, cost and speed must be made. The limitation of the model is mainly caused by the fact that the character bigram only approximates the unigram model of word in nature. In addition, ambiguities associated with unknown words are not taken into account at all. Improvement on these will be our future work. Reference","[1] M.S. Sun and B.K. T'sou, \"Theoretical Aspects of Chinese Word Segmentation\", Applied Linguistics (Beijing), No.4, 1995","[2] T.S. Yao, G.P. Zhang and Y.M. Wu, \"A Rule-based Chinese Word Segmentation System\", Journal of Chinese Information Processing, Vol.4, No.1, 1990","[3] K.K. He and H. Xu, \"Design Principles of an Expert System for Automatic Word Segmentation of Written Chinese Texts\", Journal of Chinese Infbrmation Processing, Vol.5, No.2,199I","[4] C.K. Fan and W.H. Tsai, -Automatic Word Identification in Chinese Sentences by the Relaxation Technique\", Computer Processing of Chinese & Oriental Languages, Vol.4, No.1, 1988","[5] J.S. Zhang, Z.D. Chen and S.D. Chen, \"A Method of Word Identification for Chinese by Constraint Satisfaction and Statistical Optimization Techniques\", Proc. of ROCLING-IV, Kenting, Taiwan, 1991","[6] K.W. Church, P. Hanks and D. Hindle, \"Using Statistics in Lexical Analysis\", in Lexical Acquisition: Exploiting On-line Resources to Build a Lexicon, edited by U. Zernik, Hillsdale, N.J.:Erlbaum, 1991 126"]}]}