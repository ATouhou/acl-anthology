{"sections":[{"title":"Book Reviews Cognitive Science: An Introduction","paragraphs":["For instance, for a direct causal relationship, once the simple sentences that express the ACT and RESULT have been chosen, the choice of syntactic structure, the ordering of information, and the number of sentences still remain. Moreover, not all combinations of these choices yield acceptable texts. The discourse grammar encodes the acceptable choice combinations for the semantic relationship.","Thus, in order to build a generation system which is able to handle some particular semantic relation, one must first do a detailed linguistic analysis to find the simple sentences that could be used to convey the information (and encode this in the lexicon grammar), and next do another linguistic analysis to see how these simple sentences can be combined, ordered, and syntactically presented so as to convey the semantic relationship (and encode this in the discourse grammar). Once the analysis has been done, the generation system can use these two grammars to do generation. It is the case, however, that the two grammars encode choices that are mutually dependent. Thus a choice in one will limit the available choices in the other. The priority of these decisions can only be determined within a particular domain. In applying this generation model to several domains, Danlos is extremely thorough and insightful.","While one would hope that the domain dependence that Danlos advocates is not necessary, her analysis is quite convincing. Throughout the book she points out areas where \"general principles\" used by others must actually be operationalized in a very domain-dependent fashion. Thus the usefulness of such principles is called into question.","In all I found the book to be most interesting. As a computer scientist I found the book's linguistic analysis very helpful. It forced me to look at generation fi'om a new point of view. I would expect that linguists will have a similar reaction because of the book's strong commitment to processing. I believe that Danlos has been able to successfully straddle the fence that lies between these two fields. In doing so, she has made a real contribution to both. Kathleen McCoy is an assistant professor at the University of Delaware working in the areas of natural language generation, discourse, and correcting misconceptions. McCoy's address is: Department of Computer and Information Sciences, University of Delaware, Newark, DE 19716. E-mail: mccoy@udel.edu COGNITIVE SCIENCE: AN INTRODUCTION Neil A. Stiilings; Mark H. Feinstein; Jay L. Garfield; Edwina L. Rissland; David A. Rosenbaum; Steven E. Weisler:; and Lynne Baker-Ward (Hampshire College and University of Massachusetts,","Amherst, MA) The MIT Press/Bradford Books, Cambridge, MA","1987, xvii+533 pp. ISBN 0-262-19257-8, $25.00 (hb) Reviewed by Helen M. Gigley National Science Foundation The study of cognitive science in modern terms is an emerging field and the term itself evokes many discussions regarding its nature. For instance, what are critical aspects of its study, and to what degree can certain traditional disciplines contribute? Given these facts, this book makes a significant contribution to providing a basic overview of current cognitive science. But I am not reviewing it strictly for its contribution to the study of cognitive science. Instead, I am reviewing it here as it might be used for an introduction to natural language processing (NLP) or to issues which are relevant to computational linguistics. The attempt will be to focus only on issues that are related to language and its processing. However, since there are areas where the separation of language and cognition in general are impossible, there will be some related description of the cognitive discussions.","The overall presentation of the material is at a level that is easily accessible to students unfamiliar with the problems raised. Specifically, for persons beginning the study of language as a part of cognition, including its acquisition, its processing, and aspects of its knowledge base, I find the discussions very adequate in most respects. Because the chapters are individually authored, there is some disparity in style and type of information contained, but for most chapters this can be overtooked.","First, I will raise some problems that I found with the text that might influence its selection. Of critical import to a book such as this is a chapter that attempts to integrate what has been presented separately. This is lacking here and I feel is a serious omission. Having one final chapter that pulls together the threads of commonality that have been described throughout is very important for new students in a field. Even having suitable pointers between chapters as cross-reference to where another viewpoint of the same problem is presented would be helpful. This also is not done; the reader is left to infer such relationships. Without significant guidance from someone who is knowledgeable across several of the disciplines, seeing the parallel and interrelated research efforts is not a trivial task, but is necessary to fully grasp the problems faced in cognitive science 116 Computational Linguistics, Volume 14, Number 3, September 1988 Book Reviews Cognitive Science: An Introduction study. This overall integration is also directly relevant to the study of language and, I feel, computational linguistics in particular.","Now with regard to some pickier points, let me illustrate where more cross-talk among the authors may have helped. It appears that the authors of \"Architecture of the Mind\" (Chapter 2) and the AI chapters (Chapters 4 and 5) did not comment or read each other's contributions. In Chapter 2 the following statement appears without any further expansion:","Anderson (1983) proposes a representation for procedural","knowledge called a production system and provides a","much more detailed theory of how goal-directed behavior","can be maintained than we have been able to provide","here. (p. 60) There is no reference to the development of a production system theory by Newell and Simon (1972) among others (cf. Chapter 1 of Anderson (1983)). The work of Newell and Simon is raised in the context of their general problem-solving approach (GPS) in Chapter 4, but there is no mention there of the fact that they also defined a production system control theory as one way of effectively computing solutions to their problem-solving strategy. Furthermore, examples and full discussion of a production system control are presented in Chapter 4 without any reference to either of these works. Given the chronology of the original production system work, this cross-reference omission, as clearly shown by the Anderson text, demonstrates where cross-chapter talk would have benefitted this volume.","Another instance where a similar situation arises is in dealing with the spreading activation paradigm, which was first defined as a memory access and representation device by an AI researcher, Quillian (1968). This paradigm is described as being developed by Collins and Loftus (1975) and others (Chapter 3) and yet their work references Quillian's throughout. There is only one brief statement in the AI chapter that mentions Quillian's significant contribution.","This lack of cross-chapter integration, which I feel to be especially relevant for new students of language processing--computationally or otherwise, as well as for cognitive scientists--requires having a suitable source of outside information. Again I will state that it could have been handled either by inclusion of pointers to related work or a concluding overview chapter.","Now, specifically to the issue of the possible use of this text as an introduction to NLP or to computational linguistics, I feel that the book is an excellent beginning in spite of the issues just discussed. It covers many basic issues of language from viewpoints emphasizing linguistic theory through those dealing with performance. It defines many basic concepts necessary to define language processes and provides adequate examples and discussion of them.","The chapters on AI are extremely well written and concise. They give a clear introduction to problems within AI independently of the problems being tackled. For students lacking exposure to computational issues, they provide an extremely good basic introduction to the problems involved in developing a computational counterpart to any theory. The introductory remarks relating AI to the other fields of cognitive science more than adequately cover the issues.","In contrast, the chapter on philosophy (Chapter 8) I find to be of little relevance to natural language issues as they might be integrated within either an NLP course or one on computational linguistics. This is due to the style of the chapter as well as the fact that many philosophical issues that are more directly related to natural language (i.e., truth conditions, possible world semantics, predicate logic, and so on) are described in an excellent presentation in the chapter on semantics (Chapter 10). Perhaps this is another instance where the presentations would have been enhanced by cross-talk. I believe that philosophical issues of language are a very critical part of any understanding of natural language processing as well as computational linguistics in general, but find the particular presentation here lacking in developing a suitable relationship to either. In using this book as a text, I would probably skip this chapter.","The chapter on neuroscience (Chapter 7), which many might consider tangential to NLP, however, is very well done. It is clearly presented and provides quite a comprehensive overview of neurofunctioning. There are many examples and the discussions are intuitive and clearly depict some critical issues that are important in an introductory text. There seems to be a minor problem in the discussion of aphasia, though, and that is the definition of conduction aphasia where comprehension is noted as being impaired (p. 294), whereas several noteworthy references in the study of aphasia characterize it as good to excellent (cf. Goodglass and Kaplan 1983, 1972, Kertesz 1979). Perhaps this is just an error in proofreading.","The breadth of exposure to language issues and related study that is contained in this text is excellent for the most part, but the one chapter (Chapter 11) specific to natural language processing is the weakest. When reading the title of the chapter, \"Natural Lan-guage Processing\", I immediately thought of computational approaches to NLP (my bias); but they are given little emphasis. Within the computational approaches included, there seems to be an inordinate amount of credit given to computational approaches using scripts or frames to the exclusion of other significant approaches to NLP.","The NLP chapter does mention Winograd's SHRDLU model (1972) and briefly describes what is achieved. However, the import of its development in the historical perspective of when it was done is lost. After finishing this chapter, it seems that the only relevant computational work in NLP was done by the group working under Schank or within the scripts and frames approaches. While these have had an impact on some approaches to NLP, I do not think they should be Computational Linguistics, Volume 14, Number 3, September 1988 117 Book Reviews Machine Translation: Past, Present, Future presented as the only significant computational contributions. There is no discussion of processing as it is defined computationally. There is no mention of processing concerns that require integration of some of the issues raised in other chapters (Chapters 2, 4, and 5), such as the knowledge base necessary for natural language processing and the fact that one must consider what control structures or procedures must be in place to process language. These issues are never related to language as a process.","The emphasis is on more psycholinguistically motivated approaches and perhaps that is why the computational aspects included are biased to only include those which emphasize meaning representations as scripts and schemas while ignoring all other computational approaches. Computational language processing approaches that are omitted range from the ATN work of Woods (1970) to the ARPA projects of the mid-'70s (HWlM, Woods et al. 1976, HEARSAY-II, Erman et al. 1980). These are the biggest omissions and limit the use of this text to introduce natural language processing or to form a basis for a computational linguistics course. However, one can supplement this by using the discussion of language processing in a suitable introductory AI text such as Barr and Feigenbaum (1981).","In conclusion, this book is an excellent attempt to present aspects of cognitive science from within disciplines that are each approaching its study. For introductory NLP or computational linguistic study, I would use this at least as a supplementary text. I know of no other equally broad and comprehensive source of material that is relevant to language study from so many perspectives. Given the above-stated problems, I would also be prepared to supplement the book in ways previously discussed. This is especially critical to the issues of natural language processing and to integrating viewpoints of the same problem across the discussion. REFERENCES","Anderson, J.R. 1983 The Architecture of Cognition, Harvard University Press, Cambridge, MA.","Barr, A. and Feigenbaum, E.A. 1981 The Handbook of Artificial Intelligence 1, William Kaufmann, Inc.","Collins, A.M. and Loftus, E.F. 1975 A Spreading Activation Theory of Semantic Processing. Psychological Review 82(6): 4(17--428.","Erman, L.D., Hayes-Roth, F., Lesser, V.R., and Reddy, D.R. 1980 The HEARSAY-II speech-understanding system: Integrating knowledge to resolve uncertainty. Computing Surveys 12: 213-253.","Goodglass, H. and Kaplan, E. 1983 The Assessment of Aphasia and Related Disorders (2nd ed.). Lea and Febiger.","Kertesz, A. 1979 Aphasia and Associated Disorders: Taxonomy, Localization, and Recovery. Grune and Stratton.","Newell, A. and Simon, H.A. 1972 Human problem solving. Prentice-Hail, Englewood Cliffs, NJ.","Quillian, M.R. 1968 Semantic Memory. In M. Minsky (ed.), Semantic Information Processing. MIT Press, Cambridge, MA.","Winograd, T. 1972 Understanding Natural Language. Academic Press, New York, NY.","Woods, W.i~. 1970 Transition Network Grammars for Natural Lan-guage Arlalysis. Communications of the ACM 13(10): 591-606.","Woods, W. A.; Bates, M.; Brown, G.; Bruce, B.; Cook, C.; Klovstad, J.; Mal@oul, J.; Nash-Webber, B.; Schwartz, R.; Wolf, J.; and Zue, V. 1976 Speech Understanding Systems--Final Report. Technic~'.l Report 3438, Volume 4, Bolt Beranek and Newman, Inc. Helen Gigley's areas of interest include computational linguistics and neurolinguistics, artificial intelligence and neurophysiology, and neural-based cognitive modeling. She received a Ph.D. in computer science in 1982 from the University of Massachusetts, Amherst. Gigley's address is National Science Foundation, 1800 G St., NW, Rm. 304, Washington, DC 20550. E-mail: hgigley@note.nsf.gov MACHINE TRANSLATION: PAST, PRESENT, FUTURE. William John Hutchins University of East Anglia) (Ellis Horwood Series in Computers and their","Applications) Ellis Horwood: Chichester, 1986, 382 pp. ISBN 0-85312-788-3, $49.95 (hb) Reviewed by Richard Kittredge Universit( de Montreal and Odyssey Research Associates Most computational linguists are probably aware that machine translation (MT) has provided the impetus for a number of important advances in linguistics and computing over the past 40 years. But even those who have worked on MT could not have fully appreciated the breadth, depth and impact of MT activity around the globe before reading Hutchins's book Machine Translation: Past, Present, Future. For most of us, I think, its publication has come as a very pleasant and welcome surprise for a number of reasons. First, the recent reawakening of interest in MT worldwide calls for a balanced historical overview of the approaches used and the experience gained to date. Hutchins's volume helps satisfy this need for a critical collective consciousness, and sets a high standard for future works of this nature.","Second, Hutchins's thorough treatment of the history of MT is interspersed with short summaries of the technical problems and approaches in linguistic analysis and natural language processing as they have related to MT. The result is a very readable and even entertaining book, which can serve as an introduction to the field for a wide audience including not only translators, linguists, and computer scientists, but also the general (technically literate) public. The students in my graduate MT seminar, for example, have found it the most useful single book on the subject.","Third, it satisfies the long-standing need for a good single-volume reference on MT. Its detailed and crossreferenced description of virtually all known MT 118 Computational Linguistics, Volume 14, Number 3, September 1988"]}]}