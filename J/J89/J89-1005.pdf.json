{"sections":[{"title":"BOOK REVIEWS","paragraphs":["AN ARTIFICIAL INTELLIGENCE APPROACH TO LEGAL REASONING Anne von der Lieth Gardner Cambridge, MA: MIT Press, 1987, xiii + 225 pp.","ISBN 0-262-07104-5; $22.50 (hb) Reviewed by Martha Evens Illinois Institute of Technology This book provides an extremely well-written introduction to legal artificial intelligence combined with a highly original approach to problems of legal reasoning. Although this book is a revised version of her Ph.D. thesis, Gardner's ideas are mature and the exposition is designed to make both legal and computational problems clear to the general reader. These ideas are embodied in an automated system for solving offer and acceptance problems in contract law.","Chapter 1 provides an introduction to the problems of modeling legal reasoning. One major complication is the open texture or incomplete definition of many legal predicates. Another is that the program must be able to distinguish between problems it can handle and those that may well cause experts to disagree. The choice of offer and acceptance problems in contract law as a problem domain has the advantage that this area does not require a great deal of legal background. Also these problems make more use of case law than of statutes; thus they are rule-guided but not rule-governed.","Chapter 2 goes more deeply into the place of rules in legal reasoning. From the point of view of the expert system designer, the law has certain advantages. Lawyers have been known to write down explicit, if non-computational, rules for legal reasoning, although much of this work is controversial. Chapter 3 goes on to discuss the problem of applying rules to the stated facts of the case. Rules of commonsense knowledge are necessary here as well as heuristics for understanding cases and recognizing examples of patterns. Chapter 4 relates this research to other work in legal artificial intelligence.","Chapter 5 attacks problems of the representation of natural language text. The facts of a problem are translated into a set of logical formulas in the predicate-calculus syntax of Genesereth's MRS. The representation methodology pays particular attention to reported speech, an important feature of contract cases. Analysis of the predicate-calculus representation determines Computational Linguistics, Volume 15, Number 1, March 1989 whether any given speech act has the effective force of a declaration. Then declarations are further analyzed to see whether they are indeed legal acts.","Chapter 6 focuses on a different kind of representation problem, the problem of representing legal knowledge. Knowledge of the basic legal categories and the way elements of those categories may be ordered is represented in an augmented transition network with arcs labeled \"offer\", \"acceptance\", etc. Knowledge of the definitions of the major categories is expressed in \"if... then\" rules. Knowledge about undefined predicates is expressed in the representation system already developed for representing text in the previous chapter. Finally, Chapter 7 traces the operations of Dr Gardner's system on a number of illuminating example problems, annotated with insightful comments. Her program is written in a combination of MRS and MacLisp and runs on a DecSystem-20 at Stanford.","In summary, this book provides a fascinating computational framework for modeling legal reasoning, combining automated reasoning, concepts from legal theory, and techniques for representing legal knowledge and natural language text. For the computational linguist the most interesting sections are the discussion of speech acts and the methodology for representing reported speech in Chapter 5. Martha Evens is a past president of the ACL. She and James Sprowl developed the legal document generation system ABF. Her present research concerns computational uses of on-line dictionaries, especially for text generation. Evens's address is: Department of Computer Science, Illinois Institute of Technology, 10 West 31st Street, Chicago, IL 60616. E-mail: csevens@iitvax.bitnet MATHEMATICS OF LANGUAGE Alexis Manaster-Ramer (ed.) (Wayne State University) Amsterdam: John Benjamins, 1987, x + 401 pp. ISBN 1-55619-032-8 and 90-272-2049-2, Dfl 125.-,","$50.00 (hb) Reviewed by Barron Brainerd University of Toronto The editor takes the mathematics of language to mean \"the mathematical properties that may--under certain assumptions about modeling--be attributed to human language and related symbolic systems, as well as the increasingly active and autonomous scholarly discipline 53 Book Reviews Mathematics of Language that studies such things.\" This is an umbrella under which almost all of us can shelter. Indeed, the book contains, according to the editor, \"applications of the several fields of the theory of computation (formal languages, automata, complexity), formal logic, topology, set theory, graph theory, and statistics.\" This sort of hyperbole seems to be almost essential to the genre. Take graph theory as an example: there are lots of graphs in the book but little of the theory of same comes into play within the discussions.","The book is not well edited: there are references to texts not in bibliographies (p. 4), typos (e.g., pp. 3,181, 258, 260, 281), missing edges on graphs (p. 194), page permutations (p. 273 should follow 271 directly) to mention only the tip of the iceberg.","The informal style is sometimes too much so: Kuroda (A \"topological approach to structural equivalence of formal languages\"), for example, defines a partial sentence as a subtree of the tree corresponding to a sentence of a grammar G with at least one terminal attached and then says, a little later, that the sentences of a regular language are the only partial sentences ! In general, the exposition is too casual to the extent that it is not clear what the space being topologized is--the trees in K or the subtrees in K. Finally, he makes statements asserting the existence of homeomorphisms without specifying the mappings---cf, particularly pp. 184 and 185. The paper finally founders in vagueness at the end.","The papers are uneven in length, quality, and degree of specificity--some being lists of theorems, in some cases not proved even elsewhere (Kac and Kuroda). The longest paper (56 pages), Roach's \"Formal properties of head grammars\", though potentially very interesting, is marred by expositional infelicities such as a lack of examples to support the definitions, multiple reference (N can be either the natural numbers or a set of nonterminal symbols), the introduction of unspecified symbols (u, g, v, w, h, and x in Definition 9), and a general peppering of typos. It takes a more devoted reader than this one to bother sorting it all out.","The shortest paper (12 pages), Walter J. Savitch's \"Theories of language learnability\", is at the other end of the spectrum. It investigates definitions of formal learnability and shows that they tend either to accept all recursively enumerable languages as learnable or only finite languages as learnable. And then he suggests, \"Why not finite languages?\" These would be too large for the learner to learn the language as a list, but s/he might achieve economy of description \"in going from finite to context-free descriptions\" (p. 370). There's a lot to be said for the notion that present-day English is \"essentially\" finite, and in order to be \"learnable\", its structure must be organized in some way. The learning process is then the internalization of the organization in some form. Computational Linguistics, Volume 15, Number 1, March 1989","\"Finding natural languages a home in formal language theory\", by Rounds, Manaster-Ramer, and Friedman, suggests, \"instead of regarding a language as a monolithic infinite collection of strings, we consider it a sequence of finite languages, each of which is an approxi~mation to the ideal infinite language\" (p. 354). Their concern is then with economy of description of these approximating languages. A CFG is profligate if it has more nonterminal than terminal symbols. They then show that no nonprofligate CFG exists for a language with mirror images as a productive grammatical device. Since we would like grammars to be non-profligate and natural languages don't support productive mirror images, there seems to be no problem here, but the authors show an analogous result for finitely productive reduplication. Since natural languages do reduplicate, in order to achieve economy of description we must go beyond CFGs to generate natural languages.","The second-longest paper, \"On the design of finite transducers for parsing phrase-structure languages\" by Langendoen and Langsam, defines a finite transducer that recognizes a context-free fragment of English that contains left and right embedding and finite central embedding. They argue that \"the theory of finite transducers . . . is appropriate as a theory of a person's knowledge of a natural language, but that a more powerful theory is needed as a theory of natural language itself\" (p. 234).","The papers of Berwick and Ristad are concerned with inadequacies of various models popular among present-day linguists. Berwick (\"Computational complexity, mathematical linguistics, and linguistic theory\") makes the point that we \"should not be looking for some familiar natural mathematical class of objects as coextensive with the natural languages; rather we should first try to determine what the properties of natural languages are, and then fix their mathematical properties\" (p. 2). He proceeds to outline some of the shortcomings of GPSG, GB, and LFG theories in terms of complexity theory.","Ristad (\"Sources of intractability in GPSG theory\") gives a clear exposition of the notion NP-hard and proves that GPSG-recognition is NP-hard and hence GPSGs as they stand are not parsable in polynomial time.","Marsh (\"Graphs and grammars\") deals with classes of grammars (extensions of CFGs), the structure of whose outputs is depicted using directed acyclic graphs that are not trees--in particular Pereira's extraposition grammars, phrase-linking grammars of Peters and Ritchie, and his mother-and-daughter grammars. He investigates their generating power and closure properties. Proofs included!","Ojeda (\"Discontinuity and phrase structure grammar\") extends the GPSG model beyond trees in an attempt to handle discontinuous constituents in Spanish 54 Book Reviews and English. His extension is to my mind ad hoc and although it works for his examples, might not adapt itself to more complex problems like negation in French.","Karen Jensen (\"Binary rules and nonbinary trees: Breaking down the concept of phrase structure\") is concerned with the passage from binary rules (and trees) that capture significant generalizations about natural languages to list structures that are more satisfactory for further processing. Her solution can handle discontinuous constituents and is suitable for treating languages with free word order.","In \"The notion of 'rule of grammar' reconsidered\" Michael Kac defends the notion that \"grammatical analysis requires that we have a way of formally representing the variety of distinct etiological properties that can be manifested by ungrammatical strings, this diversity corresponding to the variety of distinct rules of grammar\" (p. 137). He argues that getting the standard linguistic theories (various versions of TG, GPSG, etc.) to serve the purpose of etiological analysis is \"problem-atical\". His \"fundamental principles\" (pp. 120, 122) appear to require that a grammar supply a structure not only for elements of the language L that it generates but also for the elements in the complement of L. In his formal development, however, he defines an object (Definition 9) in terms of itself and this circularity would appear to render the result ill-defined. Since his main argument depends on this definition, I stopped reading. It is a good practice to buttress complicated definitions with examples both for the good of the writer as well as that of the reader.","There are three papers on tree-adjoining grammars: an introduction by Joshi, \"Unbounded dependencies and subjacency in a tree adjoining grammar\" by A.S. Kroch, and \"On the progression from context-free to tree adjoining languages\" by Joshi et al. This presents an easy access to a useful collection of results concerning a rather pregnant linguistic model.","Finally, three of the papers are concerned with semantics proper. G.N. Carlson's \"Exceptions to generic generalizations\" deals with the construction of a formal semantics using a sort of default mechanism in order to interpret statements like \"Dogs bark\" when clearly barkless dogs exist. Davis and Papcun in \"The structure underlying a semantic domain\" provide a rather metaphorical model vr (volumetric representation) \"to formalize lexical knowledge in a practical way\". They investigate various models--semantic networks, multi-dimensional scaling, and clustering--be-fore settling on their own spatial (and somewhat intensional) model of a semantic domain. The third paper, R.H. Thomason's \"Remarks on linguistic semantics\", is an expository article concerned with the interface between linguistics and philosophy, dealing with the literature of such topics as tense and aspect, propositional attitudes, and vagueness. Computational Linguistics, Volume 15, Number 1, March 1989 The Vastness of Natural Languages Barron Brainerd is Professor of Mathematics and Linguistics at the University of Toronto. He is the author of Weighing Evidence in Language and Literature: A Statistical Approach and Introduction to the Mathematics of Language Study. Brainerd's address is: Department of Mathematics, University of Toronto, Toronto, Ontario, Canada M5S IA1. THE VASTNESS OF NATURAL LANGUAGES D. Terence Langendoen and Paul M. Postal (Graduate Center, City University of New York and IBM Thomas J. Watson Research Center, Yorktown Heights, NY) Oxford, England; Basil Blackwell, 1984, ix + 189 pp. ISBN 0-631-13461-1 (hb); ISBN 0-631-14756-X, £8.95 (sb) Reviewed by James V. Rauff Millikin University This book is an extended argument in support of the theses that natural languages are transfinitely unbounded collections, that sentences are not limited in length (number of words) by any cardinal number, finite or transfinite, and that no constructive grammar can be an adequate grammar for any natural language.","Chapter 1 is an introduction to those aspects of set theory needed to develop the main points of the book. Specifically, the notion of a class arising from Cantor's and Russell's paradoxes and the Cantor power set are introduced.","Chapter 2 sets forth what the authors call the \"received position about natural languages\" (hereafter NLs). The received position is that NL sentences are finite in length. Length is defined in terms of number of words, although the authors argue later that we could just as well count phonemes as words without seriously affecting their arguments. NLs as collections of finite-length sentences are therefore countably infinite (or denumerable). Finally, related to the finiteness of sentences is the \"received position\" that grammars for NLs are constructive.","Chapter 3 argues that there is \"no motivation for imposing size laws on NL sentences\" (p. 44). Invoking Occam's Razor, the authors claim that size laws are extra-linguistic restrictions not needed for grammatical description and therefore unjustified.","Chapter 4 presents the main theoretical points of the book. Taking as axiomatic for NLs a property of coordination that allows for unrestricted coordinate compounding of sentences, the authors present the NL Vastness Theorem, which asserts that NLs are not sets, but rather classes with no fixed cardinality. The argument can be illustrated with their example (pp. 55-57):","1. Let L be the NL English.","2. The set S o is contained in L, where","S O = {Babar is happy; I know that Babar is happy;","I know that I know that Babar is happy; . . .} 55"]}]}