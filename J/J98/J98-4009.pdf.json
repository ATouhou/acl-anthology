{"sections":[{"title":"","paragraphs":["Computational Linguistics Volume 24, Number 4"]},{"title":"The Architecture of the Language Faculty Ray Jackendoff","paragraphs":["(Brandeis University) Cambridge, MA: The MIT Press (Linguistic Inquiry monographs, edited by Samuel Jay Keyser, volume 28), 1997, xvi+262 pp; paperbound, ISBN 0-262-60025-0, $20.00"]},{"title":"Reviewed by Suzanne Stevenson Rutgers University","paragraphs":["Much current research on natural language emphasizes the critical contribution of lexical information to the definition and computation of linguistic structures. Motivations for the focus on the lexicon cross the fields of theoretical linguistics, computational linguistics, and psycholinguistics--for example, to explain the interaction of broad syntactic principles with individual lexical information (e.g., Grimshaw 1990), to capture the syntactic and statistical relationships among words (e.g., Srinivas 1997), and to relate lexical and syntactic processing within a cognitive theory of language (e.g., MacDonald, Pearlmutter, and Seidenberg 1994).","The convergence of this focus on the lexicon across diverse fields of linguistic study has led to a tremendous potential for cross-disciplinary fertilization, to which Jackendoff is no stranger. Many computational linguists will be familiar with his past work on lexical-conceptual structure (e.g., Jackendoff 1983), which has been influential in computational lexical semantics and machine translation (e.g., Dorr 1993). Within this context, Jackendoff's new book,"]},{"title":"The Architecture of the Language Faculty,","paragraphs":["offers a new path to the conclusion of the centrality of the lexicon within a broad theory of human language, in which his notion of lexical structure is extended both in scope and power. While focusing on arguments from theoretical linguistics to support his views, Jackendoff explores the psycholinguistic and computational implications for many of his conclusions. The book addresses issues ranging from expletive infixation to the nature of consciousness, but here I'll focus on the lexical aspects of the proposal.","Working from fundamental assumptions about the modularity of cognitive subsystems, Jackendoff explores the ensuing constraints on the basic architecture of linguistic theory, and consequences for the nature of the lexicon. The proposal hinges on a concept that he terms here Representational Modularity--the idea that the mind is divided into modules on the basis of the representational format that a cognitive system uses. 1 For example, phonology, syntax, and semantics will comprise three separate representational modules, because the structures they manipulate require different formal primitives and combinatorial principles. Because representational modules cannot communicate directly with each other (since, by definition, they don't understand each other's \"language\"), Jackendoff further proposes the existence of"]},{"title":"interface modules-- specialized","paragraphs":["components of the mind that translate between relevant aspects of two 1 The book thus relates to another thread of computational linguistic research that of modularity in Government-Binding parsing (e.g., Crocker [1992], Merlo [1996], among many others). Jackendoff's sense of modularity differs in that it applies across linguistic subsystems, and across cognitive subsystems more generally, rather than"]},{"title":"within","paragraphs":["the syntactic component of grammar. 652 Book Reviews or more cognitive subsystems. Only the outputs of the representational modules are accessible to the interface module that translates between them. The characterization of the interface module within the linguistic faculty, rather than the representational modules themselves, is the focus of Jackendoff's present study.","As a starting point, Jackendoff assumes that an interface module consists of a set of correspondence rules between representational formats, which may be specified as obligatory, optional or default. The book presents and reviews a number of linguistic phenomena and analyses to explore the relationship between the representational modules of grammar (phonology / syntax / semantics), thereby determining the necessary properties of the correspondence rules that relate them. Jackendoff shows that the correspondences mediated by the interface module are complex, partial and nonderivational. He further concludes that the lexicon, rather than occurring as a separate representational module, is an important component of this interface, playing a crucial role in linking together and licensing structures across the submodules of the linguistic system.","Jackendoff's general argument about the nature and role of the lexicon can be briefly summarized as follows. Representational Modularity demands that the language faculty must be split into three modules--phonolog~ syntax, and semantics-- each of which manipulates structures that are stated in its own representational format. Lexical items, which include phonological, syntactic, and semantic content, cannot be inserted as a whole into a structure in any one of these modules, since doing so would violate Representational Modularity. Instead, a lexical item is a set of three structures (phonological syntactic, and semantic) that are linked by correspondence rules. Each component of the lexical item is unified with the output structure of the appropriate representational module, and the correspondence rules ensure that the correct linkages between the pieces of a lexical item are enforced. The lexical items thus are crucial both in licensing and linking the outputs of the individual representational modules. Since each lexical item makes reference to phonological syntactic, and semantic structures, the lexicon must be conceived of as a part of the linguistic interface module, rather than as a representational module itself.","Simply put, the claim is that what we call the lexicon is not a distinct entity but rather a subset of the interface relations between the three grammatical subsystems. This formulation leads to some advantages for how we factor information among the components of grammar. For example, note that in addition to word-level linkages, the interface module must also include correspondence rules that relate higher-level phrase structures, as well as lower-level (intraword) morphological structures. Since lexical items are part of this general interface, there is then no need to restrict them to word-sized elements--they can be affixes, single words, compound words, or even whole constructions. Jackendoff's proposal thus has the potential to provide a uniform characterization of morphological, lexical, and phrase-level knowledge and processes, within a highly lexicalized framework.","To see whether this potential is realizable, some important aspects of the approach must be fleshed out. One consequence of Jackendoff's proposal is that much of the work of linguistic theory is accomplished by the correspondence rules that relate the various levels of representation. Thus, the interface module that encapsulates these rules is a source of tremendous formal power--at least in addition to, if not instead of, the representational modules encoding the traditional components of grammar. Yet, while representational modules are explicitly constrained (to manipulate only a single representational format), the formal restrictions on interface modules are not made precise in the book. For example, Jackendoff asserts that some aspects of the output structures of the representational modules are \"visible\" to the interface and some are 653 Computational Linguistics Volume 24, Number 4 not, and furthermore that some aspects must be visible to a subset of the rules and not to others--in neither case providing a formal characterization of how this distinction is made. The lack of restrictions on the linguistic interface module---the content of which is mediated only by what Jackendoff calls a balancing of power among relevant modules--means that it isn't clear what couldn't go into the interface. If there are no restrictions on the correspondence rules in terms of what informatiqn--and sets of information across modules they have access to, then there's no modularity left at all the interface module is completely \"interactive.\" Given that so much grammatical knowledge is being pushed into the interface module, this kind of issue will be crucial to a final evaluation of Jackendoff's proposal.","For the most part, the book is extremely well-written, and full of fascinating examples and analyses of phenomena crossing the boundaries of phonology, syntax, and semantics. Its breadth of scope means that the technical details of specific examples might not have the depth or sophistication that would satisfy an expert in that area, but the intent to examine the boundaries--both between subcomponents within the language faculty, as well as between the language faculty and other cognitive systems--qeads to interesting insights and proposals on topics that are often neglected in more-narrowly focused research. For example, although highly speculative, the epilogue on the implications of Representational Modularity for the relations between language and thought, and between attention and consciousness, is highly thought-provoking. I found the book enjoyable and engaging, and believe that it will appeal to computational linguists with an interest in linguistic theory and cognitive science, and especially the relation between the two.","One aspect of the book that I think may detract from the enjoyment of some readers is the (in my view, unwarranted) focus on comparisons to assumptions and proposals of Chomsky. While this perspective may make sense for an audience of theoretical syntacticians in the Chomskyan tradition, the intent of the book to situate linguistics within the broader cognitive sciences makes this emphasis a bit baffling. By contrast, more discussion could have been devoted to exploring in detail the relation to more similar frameworks (such as HPSG, LFG, and Optimality Theory), in which the assumption of multiple levels of representations and (nonderivational) correspondences between them is not new. I suspect that computational linguists will find much to admire in Jackendoff's proposed widening of the perspective within theoretical linguistics, and in his concern with psychological and computational issues, but will be puzzled by the perceived need for detailed arguments against such Chomskyan assumptions as syntactocentrism and the emphasis on derivational relations.","References","Crocker, Matthew W. 1992. A Logical Model of Competence and Performance in the Human Sentence Processor. Doctoral dissertation, University of Edinburgh.","Dorr, Bonnie. 1993. Machine Translation: A View from the Lexicon. The MIT Press, Cambridge, MA.","Grimshaw, Jane. 1990. Argument Structure. The MIT Press, Cambridge, MA.","Jackendoff, Ray. 1983. Semantics and Cognition. The MIT Press, Cambridge, MA.","MacDonald, Maryellen, Neal Pearlmutter, and Mark Seidenberg. 1994. The lexical nature of syntactic ambiguity resolution. Psychological Review, 101(4):676-703.","Merlo, Paola. 1996. Parsing with Principles and Classes off Information. Kluwer Academic Publishers, Dordrecht.","Srinivas, Bangalore. 1997. Complexity of Lexical Descriptions and its Relevance to Parsing. Doctoral dissertation, Department of Computer and Information Science, University of Pennsylvania. (Available as technical report 97-10, Institute for Research in Cognitive Science, University of Pennsylvania.) 654 Book Reviews Suzanne Stevenson is an assistant professor in the Department of Computer Science, and in the Center for Cognitive Science (RuCCS), at Rutgers University. Her research is in the area of computational models of human syntactic processing, focusing on the relation of lexical and syntactic theories to cognitively motivated parsing mechanisms. Stevenson's address is Department of Computer Science, Rutgers University, CoRE Building, Busch Campus, New Brunswick, NJ 08903; e-mail: suzanne@cs.rutgers.edu 655"]}]}