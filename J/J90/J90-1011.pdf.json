{"sections":[{"title":"Book Reviews Computational Linguistics: An Introduction","paragraphs":["G6ran Maimgren describes regularities in polysemy: types of metaphoric transfer of meaning in nouns, regular extensions in verb meanings, and changes in adjective meanings as the argument changes. While these papers are written about Swedish, they make one itch to try out these ideas on an English corpus. Martha Evens is a professor of Computer Science at Illinois Institute of Technology. She is a co-author of one book on lexical-semantic relations and the editor of another. In 1984 she was president of the Association for Computational Linguistics. Evens's address is: Department of Computer Science, Illinois Institute of Technology, 10 West 31 st Street, Chicago, IL 60616. E-mail: csevens@iitvax.bitnet COMPUTATIONAL LINGUISTICS: AN INTRODUCTION Ralph Grishman (New York University) Cambridge, U.K.: Cambridge University Press, 1987, viii + 193 pp. (Studies in Natural Language Processing) Hardbound, ISBN 0-521-32501-1, $39.50; Softbound, ISBN 0-521-31038-5, $14.95 (20% discount to ACL members) Reviewed by John Roach Virginia Polytechnic Institute and State University Grishman's book provides an introductory overview of the computational linguistics field. Instructors looking for a good introductory text to use in a course devoted to computational linguistics should consider this book as a strong candidate if they wish to emphasize a linguistics approach. The book consists of five sections: introduction (5%), syntax analysis (45%), semantic analysis (29%), discourse analysis and information structuring (11%), and language generation (7%), as well as a short section of 34 exercises covering all chapters of the book. The book's emphasis reflects the predominant trends in the field. Grishman avoids extreme positions and gives a remarkably neutral account. By the same token, however, students will hardly know anything of the controversies that have shaken the field.","Many different approaches could be taken when attempt-ing a broad survey of computational linguistics. Artificial intelligence could be emphasized (including accounts of past programs), a cognitive science approach might be attempted, or a linguistic orientation might be the main emphasis. Grishman elects the linguistic approach, although some artificial intelligence programs are discussed. The book Natural Language Processing by Harry Tennant (1981), which covers many AI programs, is referenced (together with Winograd's Language as a Cognitive Process [1983]) as a supplement in the introductory chapter. Using both of these books together could make for a very good course: Grishman's book provides a strong linguistic orientation, and Tennant's book presents practice and applications. The main difficulty with using both texts together would be the need to integrate the disparate approaches. By taking a linguistic viewpoint, Grishman's text fails fully to cover many different computational approaches to language. For use in a class, the book must be supplemented.","As an example of topics not (sufficiently) covered, consider case frame analysis. The text barely mentions case frames, and the only analysis of canonical verbs with agents, instruments, affected entity, etc., occurs in a brief discussion of Schank's conceptual dependency theory. Any instructor wishing to cover the large amount of computational linguistics research in this area will have to draw more material from elsewhere.","Grishman does concentrate on the central themes of linguistics: transformational grammar, translating surface forms into semantic meaning structures (first-order logic statements in this case) and, to a lesser extent, discourse analysis.","In the syntax chapter, Grishman first asks whether syntactic analysis is really necessary, since some researchers today question the need. He observes that syntactic analysis is the norm and highly useful. He also briefly addresses the difficulty of parsing non-well-formed inputs. He then presents the Chomsky hierarchy of grammars, regular, context-free, and context-sensitive, followed by a rather nice example of a context-free grammar and a parser for it. Sections on transformational grammar and an associated parser are covered in thorough detail. Augmented phrasestructure grammars (including NYU's Linguistic String Project and ATNs) are also covered. The syntax chapter concludes with brief discussions of some specific problems: ambiguities in attaching prepositional phrases to what they should modify and analyzing coordinate conjunctions. The latest advances in syntactic theory (government-binding, X-bar syntax, etc.) have not been included. Nevertheless, this is a very full chapter that provides quite good coverage of syntactic parsing techniques. The semantic analysis chapter introduces predicate logic as the formal language into which surface forms can be translated. Grishman also discusses shortcomings of predicate logic as a representation language, after which he mentions Montague semantics but provides no treatment.","Semantic constraints, semantic grammars, and sublanguages are explained briefly but well. Grishman then discusses some classic semantic problems, including anaphora and reference (a very nice treatment), discourse entities, and noun phrases. The chapter concludes with an interesting discussion of uses of logic as a representation language, including deducing consequences from sentences using the-orem provers. As with the syntax chapter, the latest hot buttons in semantics are not treated (situation semantics, for example, is not mentioned anywhere) but the coverage of topics presented contains insightful discussions.","Examples are well chosen and informative. Occasionally, the reader might wish for more extensive examples.","The syntax and semantics chapters occupy much of the book. The chapter on discourse and structured representations is therefore rather short. Grishman reviews what we Computational Linguistics Volume 16, Number 1, March 1990 51 Book Reviews Speaking: From Intention to Articulation might call the \"world knowledge/deep reasoning\" school of thought, which is the current paradigm in AI, engendered by Charniak's dissertation. He introduces frames, scripts and plans, MOPS, and information formats (from the Linguistic String Project, NYU). The chapter concludes with a discussion of handling dialogue. Although there is a good discussion of some points, this chapter is somewhat disappointing because many areas of research are left out or no examples are given: classic pragmatics is not discussed at all, story and text grammars are only mentioned, MOPs are only mentioned, and no mention is made of rhetorical structure theory. Perhaps the author felt that this area was not very well settled and therefore should not be treated extensively. Graduate students, however, should be treated to open problems as well as to (purported) solutions.","The language generation chapter is quite brief and treats sentence generation from a syntactic point of view. A short discussion on text generation completes the chapter. Clearly, more could be done with generation even if it is \"the poor cousin\" of automated language research.","Grishman spends little time trying to fill in the technical linguistic background of the reader. There are short introductions to the Chomsky hierarchy of grammars and predicate logic, but the reader is mostly presumed to be conversant with linguistic theory. The book is, after all, about computational linguistics. The amount of introductory material seems reasonable relative to the expository material. For computer science graduate students, however, this account would have to be supplemented with more introductory linguistics material. The book also contains little philosophical discussion. The author does not attempt to address the problem of defining meaning, let alone the role of meaning and language for the concept of mind (a hot topic for some cognitive psychologists and philosophers). Admittedly, such discussions can become abstruse and perhaps not very useful, and Grishman typically avoids such topics.","The author frequently writes short evaluations of previous efforts in an attempt to weigh the contribution of the work. The evaluations seem very fair; Grishman does not take doctrinaire stances toward different approaches to natural language, an excellent way to write an introductory text. One nice touch of the book is the pursuit of topics through several different chapters. For example, the problem of quantifier ordering is discussed both in the semantics chapter as a representation problem and in the language generation chapter. Various such themes are pursued throughout the book.","In summary, this introductory text takes a stand, a point of view, toward the computational linguistics field. It can be used most profitably in classes with students who already have some linguistics background. If supplemented with additional material, it could also be used for courses populated by computer science students. The book is interestingly written with many insightful discussions, and it is the only (introductory) computational linguistics textbook that looks at the field from a linguist's point of view. REFERENCES Tenna:at, H. 1981 Natural Language Processing. Petrocelli Books, New York. Winograd, T. 1983 Language as a Cognitive Process: Volume I: Syntax. Addison-Wesley, Reading, MA. John Roach is an associate professor of computer science at Virginia Tech. He works on the influence of social factors on understanding in dialogue and text and with extensions of semantic grammars. Roach's address is: Department of Computer Science, Virginia Tech, Blacksburg, VA 24061. E-mail: roach@vtopus.cs.vt.edu SPEAKING: FROM INTENTION TO ARTICULATION Willem J. M. Levelt (Max-Planck-Institut fiir Psycholinguistik) Cambridge, MA: MIT Press, 1989, xvii + 566 pp. (ACL-MIT Press Series in Natural- Language","Processing) Hardbound, ISBN 0-262-12137-9, $39.95 (20% discount","to ACL members) Reviewed by M. Martin Taylor and lnsup Taylor Defence and Civil Institute of Environmental Medicine and University of Toronto OVERVIEW In Speaking, Pim Levelt has written a majestic book. It is majestic in its scope, in the power and elegance of its writing, and in the regal authority with which it describes cognitive structures and processes that are almost inaccessible to experimental study. It discusses in 12 chapters how a speaker produces fluent speech, from concept and intention to articulation. It is hard to believe that one person could attempt such a task, let alone that he could complete it so well. The book is intended primarily for advanced students in psyeholinguistics, but we find it to be better suited to students of computational linguistics, since we think Levelt has described how speaking could be done, but not necessarily how it is done by humans.","The book contains many technical terms and concepts, clearly introduced and used, and avoids statistics and computer jargon. Very occasionally, traces of Dutch creep in, though not obtrusively. Blackboardchalk, passingnote, and swimmingwater are given as examples of English compound words; bank is said to have as its two meanings \"financial institution\" and \"furniture\". Despite these small lapses, Levelt's knowledge about English (as well as his ability to use it) far surpasses that of most English speakers untrained in linguistics.","The book is well designed and carefully proofread. There is a good index, and more than 600 references. We found only three misprints in 500 pages of text, as well as one \"cognitive misprint\" that is amusing because it occurs in a discussion of similar phenomena in speech (the commen-52 Computational Linguistics Volume 16, Number 1, March 1990"]}]}