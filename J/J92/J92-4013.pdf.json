{"sections":[{"title":"Briefly Noted Computers and Musical Style David Cope","paragraphs":["(University of California, Santa Cruz) Madison, Wisconsin: A-R Editions Inc (The Computer Music and Digital Audio Series, edited by John Strawn, Volume 6), 1991, xvii"]},{"title":"+ 246","paragraphs":["pp. Hardbound, ISBN 0-89579-256-7, $45.95 Music, it has often been suggested, is a form of language. If this is true, perhaps some of the techniques of computational linguistics might be profitably applied to musical issues. In"]},{"title":"Computers and Musical Style,","paragraphs":["composer David Cope describes a new way of an-alyzing musical style, by using computer pattern matching to identify characteristic motives, or short sequences of musical intervals. Cope has developed an automatic composer, using an ATN music grammar to recombine these motives, producing convinc-ing music in the style of composers ranging from Mozart to Gershwin.","Cope's primary motivation in this work was a practical one: suffering from \"composer's block,\" he felt the need for a \"composer's partner.\" To that end, Cope has developed a series of computer programs capable of composing music in the style of a particular composer. Drawing on the frequently observed parallel between linguistic phrase structure rules and the structure underlying musical phrases, Cope defines an ATN grammar as the basis of his automatic composer. Using work by music the-orists such as Schenker, Cope defines five musical categories: statement, preparation, extension, antecedent, and consequent. The grammar governs the ways in which these five basic categories can be combined to form phrases. Cope creates a lexicon by extracting characteristic patterns from exist-ing works of a given composer, and cataloging these patterns as to category. With a composer-specific lexicon and ATN grammar, the program is capable of randomly producing new works in the style of that composer. The program has produced works in the styles of composers such as Bach, Mozart, Brahms, Chopin, and Scott Joplin. Although none of these compositions could be mistaken for genuine works of the composers they are meant to emulate, the resemblance is at times quite striking. In particular, I found the works in the style of Brahms and Chopin surprisingly evocative.","However, it is far from clear how the program produced these compositions. Composer Cope is clearly a convert to the joys of Lisp hacking, and he presents a simple version of his program virtually line by line, including many program traces. The more elaborate version of the program, which actually produced all the musical examples, is too large for such treatment. Instead, Cope contents himself with a vague, partial descrip-tion of the program, leaving it quite unclear how the program actually produced all these interesting compositions.","The most innovative aspect of this work is the notion that signatures, or common patterns, can be automatically extracted from a body of work. In the current implementation, the patterns are found by comparing simple sequences of intervals of a fixed length. Even with such simple comparisons, some strik-ing regularities emerge, suggesting that this is a promising approach to the definition and analysis of musical"]},{"title":"style.--Daniel Hardt, University of Pennsylvania Daniel Hardt","paragraphs":["is a Ph.D. candidate in Computational Linguistics at the University of Pennsylvania. He has a Bachelor of Music in Violin Performance from the Curtis Institute of Music."]},{"title":"Logic and Information Keith Devlin","paragraphs":["(Colby College, Maine) Cambridge, England: Cambridge University Press, 1991, xii + 308 pp. Hardbound, ISBN 0-521-41031-4, $34.50 In"]},{"title":"Logic and Information,","paragraphs":["Keith Devlin attempts to develop a theory of information suitable for the study of cognition. It is in-tended that the theory be amenable to all varieties of information flow, though natural language semantics is given special consideration.","Apart from the introductory and conclud-ing chapters, the book divides into two parts. Chapters 2 through 5 spell out Devlin's theory of information, a version of Situation Theory. Chapters 6 through 9 then explore the application of this theory to two areas: mental states, perception, and action, and natural language semantics. Devlin explicitly 566 Briefly Noted argues\" that an account of the former is required by any adequate theory of the latter, and such concerns are evident in his semantic treatment of natural language.","The version of Situation Theory presented is the most complete and accessible published since Barwise and Perry's original work, including many of the advances that have been made in recent years. As Devlin is quick to acknowledge, however, it is not a definitive statement of Situation Theory per se, which continues to evolve. Unfortunately, Devlin does not highlight areas of Situation Theory where opinions differ, and it is difficult to distinguish what is the received view from Devlin's own persuasions. Furthermore, while Devlin does attempt to motivate all aspects of his theory, the motivation is not always convincing.","With regard to natural language semantics, Devlin considers the meanings of both individual words and sentences, as well as the impact of various classes of utterance. Further application of the theory is given via the specific consideration of quantification, negation, conditionals, speaker's intentions, and paradox and ambiguity. Devlin projects"]},{"title":"his","paragraphs":["attempts at these areas as first approximations. Nevertheless his accounts do show promise and, I think, merit more discussion than is given.--Richard Cooper, University College London"]},{"title":"Structures for Semantics Fred Landman","paragraphs":["(Cornell University) Dordrecht: Kluwer Academic Publishers (Studies in Linguistics and Philosophy 45, edited by Gennaro Chierchia, Pauline Jacobson, and Francis J. Pelletier), 1991, x + 366 pp. Hardbound, ISBN 0-7923-1239-2, $110.00, £67.00, Dfl 200.00 \"Structures for Semantics offers an advanced course in logical and mathematical techniques and structures that are used in semantics, in relation to their semantic applications. The book helps students with a background in semantics to develop their skills of formalization and it makes research in semantics accessible. Workers in other disciplines will use it to discover more about the role of formal modelling in current semantic research, and about semantics itself.'--From the publisher's announcement"]},{"title":"Partitioned Representations: A Study in Mental Representation, Language Understanding and Linguistic Structure John Dinsmore","paragraphs":["(Southern Illinois University at Carbondale) Dordrecht: Kluwer Academic Publishers (Studies in Cognitive Systems, edited by James H. Fetzer, Volume 8), 1991, xvii + 331 pp. Hardbound, ISBN 0-7923-1348-8, $59.50, £42.00, Dfl 125.00 Dinsmore proposes a formalism for mental representations divided into locally consistent domains called spaces. The theory does not specify the representation within the spaces; Dinsmore relies primarily on first-order logic, but also employs a semantic network. The primary application area is language and in this respect the work can be regarded as a formalization of Fauconnier's (1985) mental spaces, sharing a concern with presupposition, counterfactuals, and aspect. Correspondences to natural deduction, Kamp's (1981) discourse representation theory, frames, belief spaces, contextlayered databases, and mental models are also outlined.","The approach views language comprehension as the firing of a series of production rules that project an utterance through various intermediate representations or projections. Intermediate projections are mixtures of semantic structures and as-yetunprocessed surface fragments. This simplification allows Dinsmore to focus on the construction and maintenance of spaces as a sentence is processed. Rules perform three classes of operations: Contextualization makes decisions about the global placement of in-put forms on the basis of the pragmatic setting. Distribution allocates structures already in one space to other spaces, relying more heavily on surface cues. Parochial processing includes more familiar interpretation processes such as definite reference determina-tion, lexical and structural disambiguation, and metonymy and metaphor interpretation. The power of the theory, however, derives • largely from the restriction that these processes are confined to operation solely within single spaces.","The book can be seen as making two primary contributions. First, it synthesizes loose ideas that have been floating around in AI 567 Computational Linguistics Volume 18, Number 4 and cognitive science for some time, and which many theories and systems have already incorporated in specialized form. On the whole Dinsmore does a good job of sketching the relationships to other frame-works. Second,"]},{"title":"it","paragraphs":["proposes a specific architecture and set of production rules for processing a variety of language constructs. Since the major part of the book is concerned with these language examples, it is some-what frustrating that correspondences, differences, and extensions to Fauconnier's theory are not specifically clarified. Interestingly, connections to the line of work on represent-ing existence by Meinong (1904/1960), Parsons (1980), Lambert (1983), Rapaport (1985), and Hirst (1989, 1991) are also missing, though overlapping concerns are addressed (we might profitably think of spaces as hold-ing cells for"]},{"title":"nuclear","paragraphs":["relations, with"]},{"title":"extranuclear","paragraphs":["relations being those that span spaces).","The book is well written and Dinsmore's style is generally easy to read. The rules and processes are illustrated through many examples. All the more technical and formal discussion is confined to the last three chapters, which form an appendix. This arrangement makes the book more difficult for the computer scientist, but probably improves its readability for"]},{"title":"linguists.--Dekai Wu, University of Toronto References","paragraphs":["Fauconnier, Gilles (1985)."]},{"title":"Mental Spaces.","paragraphs":["Cambridge, MA: The MIT Press.","Hirst, Graeme (1989). \"Ontological assumptions in knowledge representation.\" In"]},{"title":"Proceedings, 1st International Conference on Principles of Knowledge Representation and Reasoning.","paragraphs":["Toronto, May 1989. Morgan Kaufmann, 157-169.","Hirst, Graeme (1991). \"Existence assumptions in knowledge representation.\""]},{"title":"Artificial Intelligence,","paragraphs":["49, 199-242.","Kamp, Hans (1981). \"A theory of truth and semantic representation.\" In"]},{"title":"Truth, Interpretation, and Information (Selected Papers from the Third Amsterdam Symposium),","paragraphs":["(Groningen-Amsterdam Studies in Semantics), edited by Jeroen A. G. Groenendijk, Theo M. V. Janssen, and"]},{"title":"Martin B. J.","paragraphs":["Stokhof, 1-41. Foris. Lambert, Karel (1983)."]},{"title":"Meinong and the Principle of Independence.","paragraphs":["Cambridge University Press.","Meinong, Alexius (1904/1960). \"Ober Gegenstandstheorie'. In Alexius Meinong (ed.),"]},{"title":"Untersuchungen zur Gegenstandstheorie und Psychologie.","paragraphs":["Leipzig: Barth. (In English as \"The theory of objects\" (Isaac Levi, D. B. Terrell, and Roderick Milton Chisholm, trans.), in Roderick Milton Chisholm (ed.),"]},{"title":"Realism and the background of phenomenology.","paragraphs":["Glencoe, IL: Free Press, 1960, 76-117.)' Parsons, Terence (1980)."]},{"title":"Nonexistent Objects.","paragraphs":["Yale University Press.","Rapaport, William J. (1985). \"Meinongian semantics for propositional semantic networks.\" In"]},{"title":"Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics.","paragraphs":["Chicago, IL, 43--48."]},{"title":"Connectionist Natural Language Processing: Readings from Connection Science Noel Sharkey (editor)","paragraphs":["(University of Exeter) Dordrecht: Kluwer Academic Publishers, 1992, ix + 375 pp. Hardbound, ISBN 0-7923-1542-1, $88.50, £51.50, Dfl 150.00 Seventeen papers on connectionist natural language processing that were originally published in the journal"]},{"title":"Connection Science","paragraphs":["are reprinted in this volume:"]},{"title":"Catherine L. Harris","paragraphs":["\"Connectionism and cognitive linguistics\""]},{"title":"John Rager and George Berg","paragraphs":["\"A connectionist model of motion and government in Chomsky's government-binding theory\""]},{"title":"David J. Chalmers","paragraphs":["\"Syntactic transformations on distributed representations\""]},{"title":"S.M. Lucas and R.I. Damper","paragraphs":["\"Syntactic neural networks\""]},{"title":"Gerard Kempen and Theo Vosse","paragraphs":["\"Incremental syntactic tree formation in human sentence processing: A cognitive architecture based on activation decay and simulated annealing\""]},{"title":"Stefan Wermter and Wendy G. Lehnert","paragraphs":["\"A hybrid symbolic/connectionist model for noun phrase understanding\""]},{"title":"Stan C. Kwasny and Kanaan A. Faisal","paragraphs":["\"Connectionism and determinism in a syntactic parser\""]},{"title":"Peter J. Wyard and Charles Nightingale","paragraphs":["\"A 568 Briefly Noted single layer higher order neural net and its application to context free grammar recognition\"","Robert B. Allen \"Connectionist language users\"","Risto Miikkulainen \"Script recognition with hierarchical feature maps\"","Guenbee Lee, Margot Flowers, and Michael Dyer \"Learning distributed representations of conceptual knowledge and their application to script-based story processing\"","Suzanne M. Mannes and Stephanie M. Doane \"A hybrid model of script generation: Or getting the best from both worlds\"","Lorraine F.R. Karen \"Identification of topical entities in discourse: A connectionist approach to attentional mechanisms in language\"","Mary Hare \"The role of similarity in Hungarian vowel harmony: A connectionist account\"","Robert F. Port \"Representation and recognition of temporal patterns\"","Michael Gasser and Chan-~ Lee \"Networks that learn about phonological feature persistence\"","W.A. Ainsworth and N.P. Warren \"Pronuncia-tion of digit sequences in text-to-speech systems\" The Compact Disk Handbook (Second Edition) Ken C. Pohlmann (University of Miami) Madison, Wisconsin: A-R Editions Inc (The Computer Music and Digital Audio Series, edited by John Strawn, Volume 5) 1992, xv + 349 pp. Hardbound, ISBN 0-89579-301-6, $49.95; paperbound, ISBN 0-89579-300-8, $34.95 Now that you've got the first CD-ROM from the ACL Data Collection Initiative spinning happily in its drive and visions of user in-terfaces for CDs are dancing in your head, maybe it's time to open up the black box and learn a bit about how CDs actually work. While the emphasis, obviously, is on audio CDs, Pohlmann's comprehensive, up-to-the-minute handbook covers all aspects of all types of CDs, including data formats, encoding, error correction, disk manufacturing, and the architecture of drives and players.-- G.H. 569"]}]}