{"sections":[{"title":"","paragraphs":["Book Reviews"]},{"title":"Japanese Sentence Processing Reiko Mazuka and Noriko Nagai (editors)","paragraphs":["(Duke University) Hillsdale, NJ: Lawrence Erlbaum Associates, 1995, x+360 pp; hardbound, ISBN 0-8058-1125-7, $89.95"]},{"title":"Reviewed by Patrick Sturt University of Edinburgh 1. Overview Japanese Sentence Processing","paragraphs":["is a collection of fourteen papers that arose from \"The International Symposium on Japanese Sentence Processing\" held at Duke University in 1991. The approach of the book is deliberately interdisciplinary, aiming, in the words of the editors in their introductory chapter, \"to illuminate the mechanisms of Japanese sentence processing from the viewpoints of linguistics, psycholinguistics, and computer science\" (p. 1). It would be fair to say that, of the three disciplines, psycholinguistics emerges as the main beneficiary of the book; in particular, the chapters by Inoue and Fodor (\"Information paced parsing of Japanese,\" chapter 2), and Mazuka and Itoh (\"Can Japanese speakers be led down the garden path?,\" chapter 13), which give an overview of the particular problems of processing Japanese and their implications for existing processing models, have already contributed a great deal towards bringing a cross-linguistic perspective to psycholinguistic research. Despite this, the book does contain material that is interesting to computational linguists, though there are certain areas of computational linguistics that are not represented at all, one obvious example being corpus-based statistical NLP.","Three of the papers are directly relevant to computational linguistics in that they describe actual implementations--K6iti Hasida's \"A constraint-based view of language\" (chapter 6) describes a constraint-logic-programming system that uses numeric computation to allow for a graded notion of constraint violation. He gives two examples to show how the system can be used for abductive inference and disambiguation using discourse context. Megumi Kameyama's \"The Japanese language engine\" (chapter 7) describes the Japanese descendant of the Core Language Engine (Alshawi 1992). Like the CLE, Kameyama's JLE builds up logical forms via an underspecified representation called \"Quasi logical form\" (QLF) using a unification-based grammar. The paper contains an interesting discussion of how linguistic aspects of Japanese led to design features of the system that differ radically from the English CLE; an example is that in the JLE, relative clause dependencies are left underspecified at QLF, to be resolved, with the aid of discourse knowledge, in the mapping to logical form proper, while in the CLE, standard gap-threading techniques are used to build the dependencies during grammatical analysis. Robert Berwick and Sandiway Fong's \"Madama Butterfly redux\" (chapter 8) describes a principle-based parsing system that can be parameterized to handle Japanese or English input. One interesting aspect of the paper is the authors' discussion of how they tackle the serious problem of nondeterminism that is inherent in parsing directly with GB principles, while trying to remain as faithful as possible to the modular organization of the grammatical theory. 145 Computational Linguistics Volume 22, Number 1","The volume also contains an overview of Japanese Phrase Structure Grammar (JPSG) by Takao Gunji (chapter 5). JPSG is a declarative unification formalism similar to HPSG (Pollard and Sag 1994), but designed specifically for Japanese. The chapter introduces the main mechanisms of the theory, and shows how they can be applied to capture certain control and binding phenomena in Japanese.","The book also contains papers that describe models based on well-known computational formalisms, but which are stated at a theoretical level--Amy Weinberg's \"Licensing constraints and the theory of language processing\" (chapter 10) and Paul Gorrell's \"Japanese trees and the garden path\" (chapter 14) both discuss Japanese processing effects in the light of theoretical models based on Description Theory (Marcus, Hindle, and Fleck 1983).","Apart from the papers mentioned above, there are psycholinguistic papers reporting experimental results--Mineharu Nakayama's \"Scrambling and probe recognition\" (chapter 11) and Tsutomu Sakamoto's \"Transparency between parser and grammar\" (chapter 12). There are also papers that approach Japanese from the perspective of theoretical linguistics, but which make important use of processing and discourse Bradley Pritchett and John Whitman's \"Syntactic representation and interpretive preference\" (chapter 3), Noriko Nagai's \"Constraints on topics and their gaps\" (chapter 4), and Susumu Kuno's \"Null elements in parallel structures in Japanese\" (chapter 9). 2. Discussion The book certainly succeeds in its aim of presenting Japanese sentence processing in an interdisciplinary light, yet there are places where a fuller synthesis could have been achieved. In general, the book would have benefited if the editors had arranged for each chapter to be followed by a short commentary discussing the content of the chapter from the perspective of a different discipline. For example, Mazuka and Itoh (chapter 13, p. 313) outline a \"tentative attachment strategy,\" which involves a distinction between \"segmenting\" phrases and clauses (identifying the beginning and the end of each unit) and \"attaching\" them into the parse tree. As it stands, it is fairly difficult to gain a concrete grasp how this would work in an incremental parse. However, a commentary by a computational linguist could have outlined techniques to implement such a strategy (for example, various forms of underspecification, or chunking), and discussed the empirical consequences of adopting these. Equally, Hasida's paper (chapter 6), which argues for nonmodular information flow in a computational language processing system might have been followed by a commentary by a psycholinguist outlining the experimental evidence for and against modular information flow in human language processing, and comparing his model with other simultaneous constraint satisfaction models proposed within psycholinguistics (for example, that of MacDonald, Pearlmutter, and Seidenberg (1994)). Hasida's chapter would also have benefited from a discussion of the contributions that the proposed constraint-based system could make to the particular problems involved in processing Japanese; as it stands, the Japanese language does not even receive a mention, which, given the title of the book, is surprising to say the least.","The quality of editing is very high, and I have only found a small number of typos. Since none of them drastically affects the interpretation of the text, I will not list them here. 146 Book Reviews","References","Alshawi, Hiyan, ed. (1992). The Core Language Engine. Cambridge, MA: The MIT Press.","MacDonald, Maryellen C.; Pearlmutter, Neal J.; and Seidenberg, Mark S. (1994). \"Lexical Nature of Syntactic Ambiguity Resolution.\" Psychological Review, 101(4): 676-703.","Marcus, Mitchell C.; Hindle, Donald; and Fleck, Margaret. (1983). D-theory: Talking about Talking about Trees. Proceedings, 21st Annual Meeting of the Association for Computational Linguistics, 129-136.","Pollard, Carl and Sag, Ivan A. (1994). Head-driven Phrase Structure Grammar. Stanford, CA: Center for the Study of Language and Information and Chicago: The University of Chicago Press. Patrick Sturt is a Ph.D. student at the Centre for Cognitive Science, University of Edinburgh. His research interests include computational and experimental psycholinguistics, in particular, issues related to reanalysis and head-final processing. Sturt's address is: Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, UK; e-mail: sturt@cogsci.ed.ac.uk 147"]}]}