{"pubtype":"article","citekey":"TACL480","author":"Ryan Cotterell and Nanyun Peng and Jason Eisner","title":"Modeling Word Forms Using Latent Underlying Morphs and Phonology","journal":"Transactions of the Association for Computational Linguistics","volume":"3","year":"2015","keywords":"","abstract":"The observed pronunciations or spellings of words are often explained as arising from the ünderlying forms ̈of their morphemes. These forms are latent strings that linguists try to reconstruct by hand. We propose to reconstruct them automatically at scale, enabling generalization to new words. Given some surface word types of a concatenative language along with the abstract morpheme sequences that they express, we show how to recover consistent underlying forms for these morphemes, together with the (stochastic) phonology that maps each concatenation of underlying forms to a surface form. Our technique involves loopy belief propagation in a natural directed graphical model whose variables are unknown strings and whose conditional distributions are encoded as finite-state machines with trainable weights. We define training and evaluation paradigms for the task of surface word prediction, and report results on subsets of 7 languages.","issn":"2307-387X","url":"https://tacl2013.cs.columbia.edu/ojs/index.php/tacl/article/view/480","pages":"433--447"}
