{"sections":[{"title":"Projection-based Acquisition of a Temporal Labeller Kathrin Spreyer","paragraphs":["∗"]},{"title":"Department of Linguistics University of Potsdam Germany spreyer@uni-potsdam.de Anette Frank Dept. of Computational Linguistics University of Heidelberg Germany frank@cl.uni-heidelberg.de Abstract","paragraphs":["We present a cross-lingual projection framework for temporal annotations. Automatically obtained TimeML annotations in the English portion of a parallel corpus are transferred to the German translation along a word alignment. Direct projection augmented with shallow heuristic knowledge outperforms the uninformed baseline by 6.64% F1-measure for events, and by 17.93% for time expressions. Subsequent training of statistical classifiers on the (imperfect) projected annotations significantly boosts precision by up to 31% to 83.95% and 89.52%, respectively."]},{"title":"1 Introduction","paragraphs":["In recent years, supervised machine learning has be-come the standard approach to obtain robust and wide-coverage NLP tools. But manually annotated training data is a scarce and expensive resource. Annotation projection (Yarowsky and Ngai, 2001) aims at overcoming this resource bottleneck by scaling conceptually monolingual resources and tools to a multilingual level: annotations in existing monolingual corpora are transferred to a different language along the word alignment to a parallel corpus.","In this paper, we present a projection framework for temporal annotations. The TimeML specification language (Pustejovsky et al., 2003a) defines an annotation scheme for time expressions (timex for","∗","The first author was affiliated with Saarland University (Saarbrücken, Germany) at the time of writing. John [met]event Mary [last night]timex. John [traf]event Mary [gestern Abend]timex. Figure 1: Annotation projection. short) and events, and there are tools for the automatic TimeML annotation of English text (Verhagen et al., 2005). Similar rule-based systems exist for Spanish and Italian (Saquete et al., 2006). However, such resources are restricted to a handful of languages.","We employ the existing TimeML labellers to an-notate the English portion of a parallel corpus, and automatically project the annotations to the word-aligned German translation. Fig. 1 shows a simple example. The English sentence contains an event and a timex annotation. The event-denoting verb met is aligned with the German traf, hence the latter also receives the event tag. Likewise, the components of the multi-word timex last night align with German gestern and abend, respectively, and the timex tag is transferred to the expression gestern abend.","Projection-based approaches to multilingual annotation have proven adequate in various domains, including part-of-speech tagging (Yarowsky and Ngai, 2001), NP-bracketing (Yarowsky et al., 2001), dependency analysis (Hwa et al., 2005), and role semantic analysis (Padó and Lapata, 2006). To our knowledge, the present proposal is the first to apply projection algorithms to temporal annotations."]},{"title":"489","paragraphs":["Cross-lingually projected information is typically noisy, due to errors in the source annotations as well as in the word alignment. Moreover, successful projection relies on the direct correspondence assumption (DCA, Hwa et al. (2002)) which demands that the annotations in the source text be homomorphous with those in its (literal) translation. The DCA has been found to hold, to a substantial degree, for the above mentioned domains. The results we report here show that it can also be confirmed for temporal annotations in English and German. Yet, we cannot preclude divergence from translational correspondence; on the contrary, it occurs routinely and to a certain extent systematically (Dorr, 1994). We employ two different techniques to filter noise. Firstly, the projection process is equipped with (partly language-specific) knowledge for a principled account of typical alignment errors and cross-language discrepancies in the realisation of events and timexes (section 3.2). Secondly, we apply aggressive data engineering techniques to the noisy projections and use them to train statistical classifiers which generalise beyond the noise (section 5).","The paper is structured as follows. Section 2 gives an overview of the TimeML specification language and compatible annotation tools. Section 3 presents our projection models for temporal annotations, which are evaluated in section 4. Section 5 describes how we induce temporal labellers for German from the projected annotations; section 6 concludes."]},{"title":"2 Temporal Annotation 2.1 The TimeML Specification Language","paragraphs":["The TimeML specification language (Pustejovsky et al., 2003a)1","and annotation framework emerged from the TERQAS workshop2","in the context of the ARDA AQUAINT programme. The goal of the programme is the development of question answering (QA) systems which index content rather than plain keywords. Semantic indexing based on the identification of named entities in free text is an established","1","A standardised version ISO-TimeML is in preparation, cf. Schiffrin and Bunt (2006).","2","See http://www.timeml.org/site/terqas/in dex.html method in QA and related applications. Recent years have also seen advances in relation extraction, a variant of event identification, albeit restricted in terms of coverage: the majority of systems addressing the task use a pre-defined set of—typically domainspecific—templates. In contrast, TimeML models events in a domain-independent manner and provides principled definitions for various event classes. Besides the identification of events, it addresses their relative ordering and anchoring in time by integrat-ing timexes in the annotation. The major contribution of TimeML is the explicit representation of dependencies (so-called links) between timexes and events.","Unlike traditional accounts of events (e.g., Vendler (1967)), TimeML adopts a very broad notion of eventualities as “situations that happen or occur” and “states or circumstances in which something obtains or holds true” (Pustejovsky et al., 2003a); besides verbs, this definition includes event nominals such as accident, and stative modifiers (prepared, on board). Events are annotated with EVENT tags. TimeML postulates seven event classes: REPORTING, PERCEPTION, ASPECTUAL, I-ACTION, I-STATE, STATE, and OCCURRENCE. For definitions of the individual classes, the reader is referred to Saurı́ et al. (2005b).","Explicit timexes are marked by the TIMEX3 tag. It is modelled on the basis of Setzer’s (2001) TIMEX tag and the TIDES TIMEX2 annotation (Ferro et al., 2005). Timexes are classified into four types: dates, times, durations, and sets.","Events and timexes are interrelated by three kinds of links: temporal, aspectual, and subordinating. Here, we consider only subordinating links (slinks). Slinks explicate event modalities, which are of crucial importance when reasoning about the certainty and factuality of propositions conveyed by event-denoting expressions; they are thus directly relevant to QA and information extraction applications. Slinks relate events in modal, factive, counterfactive, evidential, negative evidential, or conditional relationships, and can be triggered by lexical or structural cues. 2.2 Automatic Labellers for English The basis of any projection architecture are high-quality annotations of the source (English) portion"]},{"title":"490","paragraphs":["e ∈ E temporal entity l ∈ E × E (subordination) link ws ∈ Ws, wt ∈ Wt source/target words al ∈ Al : Ws × Wt word alignment As ∋ as : E → 2Ws","source annotation At ∋ at : projected target (E × As × Al) → 2Wt","annotation Table 1: Notational conventions. of the parallel corpus. However, given that the projected annotations are to provide enough data for training a target language labeller (section 5), manual annotation is not an option. Instead, we use the TARSQI tools for automatic TimeML annotation of English text (Verhagen et al., 2005). They have been modelled and evaluated on the basis of the TimeBank (Pustejovsky et al., 2003b), yet for the most part rely on hand-crafted rules. To obtain a full temporal annotation, the modules are combined in a cascade. We are using the components for timex recognition and normalisation (Mani and Wilson, 2000), event extraction (Saurı́ et al., 2005a), and identification of modal contexts (Saurı́ et al., 2006).3"]},{"title":"3 Informed Projection 3.1 The Core Algorithm","paragraphs":["Recall that TimeML represents temporal entities with EVENT and TIMEX3 tags which are anchored to words in the text. Slinks, on the other hand, are not anchored in the text directly, but rather relate temporal entities. The projection of links is therefore entirely determined by the projection of the entities they are defined on (see Table 1 for the notation used throughout this paper): a link l = (e, e′",") in the source annotation as projects to the target annotation at iff both e and e′","project to non-empty sequences of words. The projection of the entities e, e′","themselves, however, is a non-trivial task.","3","TARSQI also comprises a component that introduces temporal links (Mani et al., 2003); we are not using it here because the output includes the entire tlink closure. Although Mani et al. (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations. a.. . . [ ws ]e . . . b. . . . [ ws ]e . . . . . . [ wt ]e . . . . . . [ wtj wtj+1 ]e . . . c. . . . [ wsi wsi+1 ]e . . . . . . [ wtj wtj+1 wtj+2 ]e . . . Figure 2: Projection scenarios: (a) single-word 1-to-1, (b) single-word 1-to-many, (c) multi-word. a. [ . . . ]e b. [ . . . ]e . . .[ . . . ]e′ wtj−2 wtj−1 wtj wtj+1 wt Figure 3: Problematic projection scenarios: (a) non-contiguous aligned span, (b) rivalling tags. Given a temporal entity e covering a sequence as(e) of tokens in the source annotation, the projection model needs to determine the extent at(e, as, al ) of e in the target annotation, based on the word alignment al . Possible projection scenarios are depicted in Fig. 2. In the simplest case (Fig. 2a), e spans a single word ws which aligns with exactly one word wt in the target sentence. In this case, the model predicts e to project to wt. A single tagged word with 1-to-many alignments (as in Fig. 2b) requires a more thorough inspection of the aligned words. If they form a contiguous sequence, e can be projected onto the entire sequence as a multi-word unit. This is problematic in a scenario such as the one shown in Fig. 3a, where the aligned words do not form a contiguous sequence. There are various strategies, described in section 3.2, to deal with non-contiguous cases. For the moment, we can adopt a conservative approach which categorically blocks discontinuous projections. Finally, Fig. 2c illustrates the projection of an entity spanning multiple words. Here, the model composes the projection span of e from the alignment contribution of each individual word ws covered by e. Again, the final extent of the projected entity is required to be contiguous.","With any of these scenarios, a problem arises when two distinct entities e and e′","in the source an-"]},{"title":"491","paragraphs":["1. project(as, al ): 2. at,C = ∅ 3. for each entity e defined by as: 4. at,C(e, as, al ) =","SC","ws∈as(e) proj(ws, e, as, al )","5. for each link l = (e, e′",") defined over as:","6. if at,C(e, as, al ) ̸= ∅ and at,C(e′",", as, al) ̸= ∅","7. then define l to hold for at,C","8. return at,C where","proj(ws, e, as, al ) = {wt ∈ Wt | (ws, wt) ∈ al ∧","∀e′ ∈ as. e′","̸= e ⇒ wt ̸∈ at,C(e′",", as, al)} and [C S =  S S : S","S is convex ∅ : otherwise Figure 4: The projection algorithm. notation have conflicting projection extents, that is, when at(e, as, al ) ∩ at(e′",", as, al ) ̸= ∅. This is illustrated in Fig. 3b. The easiest strategy to resolve conflicts like these is to pick an arbitrary entity and privilege it for projection to the target word(s) wt in question. All other rivalling entities e′","project onto their remaining target words at(e′",", as, al ) \\ {wt}.","Pseudocode for this word-based projection of temporal annotations is provided in Fig. 4. 3.2 Incorporating Additional Knowledge The projection model described so far is extremely susceptible to errors in the word alignment. Related efforts (Hwa et al., 2005; Padó and Lapata, 2006) have already suggested that additional linguistic information can have considerable impact on the quality of the projected annotations. We therefore augment the baseline model with several shallow heuristics encoding linguistic or else topological constraints for the choice of words to project to. Linguistically motivated filters refer to the part-of-speech (POS) tags of words in the target language sentence, whereas topological criteria investigate the alignment topology. Linguistic constraints. Following Padó and Lapata (2006), we implement a filter which discards alignments to non-content words, for two reasons: (i) alignment algorithms are known to perform poorly on non-content words, and (ii) events as well as timexes are necessarily content-bearing and hence unlikely to be realised by non-content words. This non-content (NC) filter is defined in terms of POS tags and affects conjunctions, prepositions and punctuation. In the context of temporal annotations, we extend the scope of the filter such that it effectively applies to all word classes that we deem unlikely to occur as part of a temporal entity. There-fore, the NC filter is actually defined stronger for events than for timexes, in that it further blocks projection of events to pronouns, whereas pronouns may be part of a timex such as jeden Freitag ‘every Friday’. Moreover, events prohibit the projection to adverbs; this restriction is motivated by the fact that events in English are frequently translated in German as adverbials which lack an event read-ing (cf. head switching translations like prefer to X vs. German lieber X ‘rather X’). We also devise an unknown word filter: it applies to words for which no lemma could be identified in the preprocessing stage. Projection to unknown words is prohibited unless the alignment is supported bidirectionally. The strictness concerning unknown words is due to the empirical observation that alignments which in-volve such words are frequently incorrect.","In order to adhere to the TimeML specification, a simple transformation ensures that articles and contracted prepositions such as am ‘on the’ are included in the extent of timexes. Another heuristics is designed to remedy alignment errors involving auxiliary and modal verbs, which are not to be annotated as events. If an event aligns to more than one word, then this filter singles out the main verb or noun and discards auxiliaries. Topological constraints. In section 3.1, we described a conservative projection principle which rejects the transfer of annotations to non-contiguous sequences. That model sets an unnecessarily modest upper bound on recall; but giving up the contiguity requirement entirely is not sensible either, since it is indeed highly unlikely for temporal entities to be realised discontinuously in either source or target language (noun phrase cohesion, Yarowsky and Ngai (2001)). Based on these observations, we propose two refined models which manipulate the projected annotation span so as to ensure contiguity. One"]},{"title":"492","paragraphs":["model identifies and discards outlier alignments, which actively violate contiguity; the other one adds missing alignments, which form gaps. Technically, both models establish convexity in non-convex sets. Hence, we first have to come up with a backbone model which is less restrictive than the baseline, so that the convexation models will have a basis to operate on. A possible backbone model at,0 is provided in (1). (1) at,0(e, as, al ) = ⋃ ws∈as(e)proj(ws, e, as, al ) This model simply gathers all words aligned with any word covered by e in the source annotation, irrespective of contiguity in the resulting sequence of words. Discarding outlier alignments is then for-malised as a reduction of at,0’s output to (one of) its greatest convex subset(s) (GCS). Let us call this model at,GCS. In terms of a linear sequence of words, at,GCS chooses the longest contiguous sub-sequence. The GCS-model thus serves a filtering purpose similar to the NC filter. However, whereas the latter discards single alignment links on linguistic grounds, the former is motivated by topological properties of the alignment as a whole.","The second model, which fills gaps in the word alignment, constructs the convex hull of at,0 (cf. Padó and Lapata (2005)). We will refer to this model as at,CH. The example in (2) illustrates both models. (2) [ . . . ]e ⋃C",": ∅ GCS : {1, 2}","1 2 3 4 5 CH : {1, 2, 3, 4, 5} Here, entity e aligns to the non-contiguous token sequence [1, 2, 5], or equivalently, the non-convex set {1, 2, 5}(= at,0(e)). The conservative baseline at,C rejects the projection altogether, whereas at,GCS projects to the tokens 1 and 2. The additional padding introduced by the convex hull (at,CH) further extends the projected extent to {1, 2, 3, 4, 5}. Alignment selection. Although bi-alignments are known to exhibit high precision (Koehn et al., 2003), in the face of sparse annotations we use unidirectional alignments as a fallback, as has been proposed in the context of phrase-based machine translation (Koehn et al., 2003; Tillmann, 2003). Furthermore, we follow Hwa et al. (2005) in imposing a limit on the maximum number of words that a single word may align to."]},{"title":"4 Experiments","paragraphs":["Our evaluation setup consists of experiments conducted on the English-German portion of the Europarl corpus (Koehn, 2005); specifically, we work with the preprocessed and word-aligned version used in Padó and Lapata (2006): the source-target and target-source word alignments were automatically established by GIZA++ (Och and Ney, 2003), and their intersection achieves a precision of 98.6% and a recall of 52.9% (Padó, 2007). The preprocessing consisted of automatic POS tagging and lemmatisation.","To assess the quality of the TimeML projections, we put aside and manually annotated a development set of 101 and a test set of 236 bisentences.4","All remaining data (approx. 960K bisentences) was used for training (section 5). We report the weighted macro average over all possible subclasses of timexes/events, and consider only exact matches. The TARSQI annotations exhibit an F1-measure of 80.56% (timex), 84.64% (events), and 43.32% (slinks) when evaluated against the English gold standard.","In order to assess the usefulness of the linguistic and topological parameters presented in section 3.2, we determined the best performing combination of parameters on the development set. Not surprisingly, event and timex models benefit from the various heuristics to different degrees. While the projection of events can benefit from the NC filter, the projection of timexes is rather hampered by it. In-stead, it exploits the flexibility of the GCS convexation model together with a conservative limit of 2 on per-word alignments. In the underlying data sample of 101 sentences, the English-to-German alignment direction appears to be most accurate for timexes. Table 2 shows the results of evaluating the optimised models on the test set, along with the baseline from section 3.1 and a “full” model which activates all","4","The unconventional balance of test and development data is due to the fact that a large portion of the annotated data became available only after the parameter estimation phase."]},{"title":"493","paragraphs":["events slinks time expressions model prec recall F prec recall F prec recall F timex-optimised 48.53 33.73 39.80 30.09 10.71 15.80 71.01 52.76 60.54 event-optimised 50.94 44.23 47.34 30.96 14.29 19.55 56.55 42.52 48.54 combined 50.98 44.36 47.44 30.96 14.29 19.55 71.75 52.76 60.80 baseline 52.26 33.46 40.80 26.98 10.71 15.34 49.53 37.80 42.87 full 51.10 40.42 45.14 29.95 13.57 18.68 73.74 54.33 62.56 Table 2: Performance of projection models over test data. [. . .] must today decide [. . .]: [. . .] (108723)","[. . .] hat heute über1 [. . .] zu entscheiden, nämlich über2 [. . .] APPR VVINF APPR Figure 5: Amending alignment errors. heuristics. The results confirm our initial assumption that linguistic and topological knowledge does indeed improve the quality of the projected annotations. The model which combines the optimal set-tings for timexes and events outperforms the uninformed baseline by 17.93% (timexes) and 6.64% (events) F1-measure. However, exploration of the model space on the basis of the (larger and thus presumably more representative) test set shows that the optimised models do not generalise well. The test set-optimised model activates all linguistic heuristics, and employs at,CH convexation. For events, projection considers bi-alignments with a fallback to unidirectional alignments, preferably from English to German; timex projection considers all alignment links. This test set-optimised model, which we will use to project the training instances for the maximum entropy classifier, achieves an F1-measure of 48.82% (53.15% precision) for events and 62.04% (73.74% precision) for timexes.5","With these settings, our projection model is capable of repairing alignment errors, as shown in Fig. 5, where the automatic word alignments are represented as arrows. The conservative baseline considering only bidirectional alignments discards all","5","The model actually includes an additional strategy to adjust event and timex class labels on the basis of designated FrameNet frames; the reader is referred to Spreyer (2007), ch. 4.5 for details.","event timex data prec recall prec recall all 53.15 45.14 73.74 53.54 best 75% 54.81 47.06 74.61 62.82 Table 3: Correlation between alignment probability and projection quality. alignments but the (incorrect) one to über1. The optimised model, on the other hand, does not exclude any alignments in the first place; the faulty alignments to über1 and über2 are discarded on linguistic grounds by the NC filter, and only the correct alignment to entscheiden remains for projection."]},{"title":"5 Robust Induction","paragraphs":["The projected annotations, although noisy, can be exploited to train a temporal labeller for German. As Yarowsky and Ngai (2001) demonstrate for POS tagging, aggressive filtering techniques applied to vast amounts of (potentially noisy) training data are capable of distilling relatively high-quality data sets, which may then serve as input to machine learning algorithms. Yarowsky and Ngai (2001) use the Model-3 alignment score as an indicator for the quality of (i) the alignment, and therefore (ii) the projection. In the present study, discarding 25% of the sentences based on this criterion leads to gains in both recall and precision (Table 3). In accordance with the TimeML definition, we further restrict training instances on the basis of POS tags by basically re-applying the NC filter (section 3.2). But even so, the proportion of positive and negative instances remains heavily skewed—an issue which we will address below by formulating a 2-phase classi-"]},{"title":"494","paragraphs":["prec recall F F model event slink 1-step 83.48 32.58 46.87 17.01 1-step unk 83.88 32.19 46.53 16.87 2-step 83.95 34.44 48.84 19.06 2-step unk 84.21 34.30 48.75 19.06","timex 1-step 87.77 49.11 62.98 1-step unk 87.22 49.55 63.20 2-step 89.52 51.79 65.62 2-step unk 88.68 50.89 64.67 Table 4: Classifier performance over test data. fication task.","The remaining instances6","are converted to feature vectors encoding standard lexical and grammatical features such as (lower case) lemma, POS, govern-ing prepositions, verbal dependents, etc.7","For slink instances, we further encode the syntactic subordination path (if any) between the two events.","We trained 4 classifiers,8","with and without smoothing with artificial unknowns (Collins, 2003), and as a 1-step versus a 2-step decision in which instances are first discriminated by a binary classifier, so that only positive instances are passed on to be classified for a subclass. The performance of the various classifiers is given in Table 4. Although the overall F1-measure does not notably differ from that achieved by direct projection, we observe a drastic gain in precision, albeit at the cost of recall. With almost 84% and 90% precision, this is an ideal start-ing point for a bootstrapping procedure."]},{"title":"6 Discussion and Future Work","paragraphs":["Clearly, the—essentially unsupervised—projection framework presented here does not produce state-of-the-art annotations. But it does provide an inex-","6","Note that slink instances are constructed for event pairs, as opposed to event and timex instances, which are constructed for individual words.","7","The grammatical features have been extracted from analyses of the German ParGram LFG grammar (Rohrer and Forst, 2006).","8","We used the opennlp.maxent package, http://maxent.sourceforge.net/. pensive and largely language-independent basis (a) for manual correction, and (b) for bootstrapping algorithms. In the future, we will investigate how weakly supervised machine learning techniques like co-training (Blum and Mitchell, 1998) could further enhance projection, e.g. taking into account a third language in a triangulation setting (Kay, 1997)."]},{"title":"Acknowledgements","paragraphs":["We would like to thank Sebastian Padó for provid-ing us with the aligned Europarl data, Inderjeet Mani and Marc Verhagen for access to the TARSQI tools, and James Pustejovsky for clarification of TimeML issues. We would also like to thank the three anonymous reviewers for helpful comments."]},{"title":"References","paragraphs":["Avrim Blum and Tom Mitchell. 1998. Combining Labeled and Unlabeled Data with Co-Training. In Proceedings of the 1998 Conference on Computational Learning Theory, pages 92–100, July.","Michael Collins. 2003. Head-Driven Statistical Models for Natural Language Parsing. Computational Linguistics, 29(4):589–637, December.","Bonnie J. Dorr. 1994. Machine Translation Divergences: A Formal Description and Proposed Solution. Computational Linguistics, 20(4):597–635.","Lisa Ferro, Laurie Gerber, Inderjeet Mani, Beth Sundheim, and George Wilson, 2005. TIDES 2005 Standard for the Annotation of Temporal Expressions, September.","Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan Kolak. 2002. Evaluating Translational Correspondence using Annotation Projection. In Proceedings of ACL-2002, Philadelphia, PA.","R. Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping Parsers via Syntactic Projection across Parallel Texts. Natural Language Engineering, 11(3):311–325.","Martin Kay. 1997. The Proper Place of Men and Machines in Language Translation. Machine Translation, 12(1-2):3–23.","Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of HLT/NAACL 2003, pages 127–133.","Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proceedings of the MT Summit 2005."]},{"title":"495","paragraphs":["Inderjeet Mani and George Wilson. 2000. Robust Temporal Processing of News. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL-2000), pages 69–76, Hong Kong.","Inderjeet Mani, Barry Schiffman, and Jianping Zhang. 2003. Inferring Temporal Ordering of Events in News. In Proceedings of the Human Language Technology Conference (HLT-NAACL-2003). Short paper.","Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee, and James Pustejovsky. 2006. Machine Learning of Temporal Relations. In Proceedings of ACL/COLING 2006, pages 753–760, Sydney, Australia.","Franz J. Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51.","Sebastian Padó and Mirella Lapata. 2005. Cross-lingual projection of role-semantic information. In Proceedings of HLT/EMNLP 2005, Vancouver, BC.","Sebastian Padó and Mirella. Lapata. 2006. Optimal constituent alignment with edge covers for semantic projection. In Proceedings of ACL-COLING 2006, Sydney, Australia.","Sebastian Padó. 2007. Cross-Lingual Annotation Projection Models for Role-Semantic Information. Ph.D. thesis, Saarland University, Saarbrücken, Germany.","James Pustejovsky, José Castaño, Robert Ingria, Roser Saurı́, Robert Gaizauskas, Andrea Setzer, and Graham Katz. 2003a. TimeML: Robust Specification of Event and Temporal Expressions in Text. In Proceedings of the Fifth International Workshop on Computational Semantics.","James Pustejovsky, Patrick Hanks, Roser Saurı́, Andrew See, Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim, David Day, Lisa Ferro, and Marcia Lazo. 2003b. The TimeBank Corpus. In Proceedings of Corpus Linguistics, pages 647–656.","Christian Rohrer and Martin Forst. 2006. Improving coverage and parsing quality of a large-scale LFG for German. In Proceedings of LREC 2006, pages 2206– 2211, Genoa, Italy, May.","Estela Saquete, Patricio Martı́nez-Barco, Rafael Muñoz, Matteo Negri, Manuela Speranza, and Rachele Sprugnoli. 2006. Multilingual Extension of a Temporal Expression Normalizer using Annotated Corpora. In Proceedings of the EACL 2006 Workshop on Cross-Language Knowledge Induction, Trento, Italy, April.","Roser Saurı́, Robert Knippen, Marc Verhagen, and James Pustejovsky. 2005a. Evita: A Robust Event Recognizer For QA Systems. In Proceedings of HLT/EMNLP 2005, pages 700–707.","Roser Saurı́, Jessica Littman, Bob Knippen, Robert Gaizauskas, Andrea Setzer, and James Pustejovsky, 2005b. TimeML Annotation Guidelines Version 1.2.1, October.","Roser Saurı́, Marc Verhagen, and James Pustejovsky. 2006. SlinkET: A Partial Modal Parser for Events. In Proceedings of LREC-2006, Genova, Italy, May. To appear.","Amanda Schiffrin and Harry Bunt. 2006. Defining a preliminary set of interoperable semantic descriptors. Technical Report D4.2, INRIA-Loria, Nancy, France, August.","Andrea Setzer. 2001. Temporal Information in Newswire Articles: an Annotation Scheme and Corpus Study. Ph.D. thesis, University of Sheffield, Sheffield, UK.","Kathrin Spreyer. 2007. Projecting Temporal Annotations Across Languages. Diploma thesis, Saarland University, Saarbrücken, Germany.","Christoph Tillmann. 2003. A Projection Extension Algorithm for Statistical Machine Translation. In Michael Collins and Mark Steedman, editors, Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP-2003), pages 1–8.","Zeno Vendler, 1967. Linguistics in Philosophy, chapter Verbs and Times, pages 97–121. Cornell University Press, Ithaca, NY.","Marc Verhagen, Inderjeet Mani, Roser Sauri, Robert Knippen, Jessica Littman, and James Pustejovsky. 2005. Automating Temporal Annotation with TARSQI. In Proceedings of the ACL-2005.","David Yarowsky and Grace Ngai. 2001. Inducing Multilingual POS Taggers and NP Bracketers via Robust Projection across Aligned Corpora. In Proceedings of NAACL-2001, pages 200–207.","David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing Multilingual Text Analysis Tools via Robust Projection across Aligned Corpora. In Proceedings of HLT 2001, First International Conference on Human Language Technology Research."]},{"title":"496","paragraphs":[]}]}