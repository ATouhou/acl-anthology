{"sections":[{"title":"HMMandCRFBasedHybridModelforChineseLexicalAnalysis    huangdg@dlut.edu.cn,suntian@gmail.com,jiaoshidou@gmail.com, computer@dlut.edu.cn,dingzhuoye@sina.com,wanrulove@sina.com   Abstract","paragraphs":["This paper presents the Chinese lexical analysis systems developed by Natural Language Processing Laboratory at Dalian University of Technology, which were evaluated in the 4th International Chinese Language Processing Bakeoff. The HMM and CRF hybrid model, which combines character-based model with word-based model in a directed graph, is adopted in system developing. Both the closed and open tracks regarding to Chinese word segmentation, POS tagging and Chinese Named Entity Recognition are involved in our systems’ evaluation, and good performance are achieved. Especially, in the open track of Chinese word segmentation onSXU,oursystemranks1st."]},{"title":"1 Introduction","paragraphs":["Chinesepresentsasignificantchallengesinceitis typically written without separations between words.Word segmentation hasthus long beenthe focusofsignificantresearchbecauseofitsroleasa necessarypre-processingphaseforthetasksabove. Meanwhile, the POS tagging and Chinese Named EntityRecognitionarealsothebasicstepsinChinese lexical analysis. Several promising methods areproposed by previousresearchers. In tradition, the Chinese word segmentation technologies can be categorized into three types, rule-based, machine learning, and hybrid. Among them, the machine learning-based techniques showed excellent performanceinmanyresearchstudies(Pengetal., 2004; Zhou et al., 2005; Gao et al., 2004). This methodtreatsthewordsegmentationproblemasa sequence of word classification. The classifier online assigns either “boundary” or “nonboundary”labeltoeachwordbylearningfromthe large annotated corpora. Machine learning-based wordsegmentationmethodisadoptedintheword sequence inference techniques, such as part-of-speech(POS)tagging,phraseschunking(Wuetal., 2006a) and named entity recognition (Wu et al., 2006b). But there are some cost problems in such machinelearningproblems,andsometimeschoose between word-based and character based is also a dilemma.","In our system, we present a hybrid model for Chinese word segmentation, POS tagging and namedentityrecognitionbasedonHMMandCRF model.Thecoreofthemodelisadirectedsegmentationgraphbasedonthemaximum matchingand second-maximum matching model. Inthedirected graph, the HMM modeland CRF model arecombined, the HMM model is used to process the known words (words in system dictionary); CRF modelisadoptedtoprocesstheunknownword,the cost problem can be solved. Meanwhile, for the CRF model, the character-based CRF model and word-based model areintegrated under theframework of the directed segmentation graph, so the integrativeCRFmodelcanbemoreflexibletorecognize both the simple and complex Chinese Named Entity with high precision. With the directedsegmentationgraph,Chinesewordsegmentation, POS tagging and Chinese Named Entity recognitioncanbeaccomplishedsimultaneously. 133 Sixth SIGHAN Workshop on Chinese Language Processing"]},{"title":"2 SystemDescription","paragraphs":["With the maximum matching and secondmaximummatching(MMSM)model,CRFmodel, andseveralpostprocessingstrategies,oursystems areestablished.FirsttheMMSMmodelisapplied, based on the system dictionary the original directedsegmentationgraphissetup.Thedirected graph is composed by the known words from the system dictionary, which are regarded as the candidate word of the segmentation result. Then some candidate Chinese Named Entity Recognition automata search the directed graph, andfindoutthecandidateChineseNamedEntities into the directed graph based on some generation rules. Then the CRF is applied to the candidate Chinese Named Entities to determine if they are real Chinese Named Entities that should be added intothedirectedgraph.Duringthisprocedure,the character-based CRF and word-based CRF are respectively applied to the simple and complex ChineseNamedEntitiesrecognition.","Inthefollowingsection,theChinesewordsegmentation,POStaggingandChinesenamedentity recognitioninopentrackwillbemainlydiscussed.","2.1 The maximum matching and secondmaximummatchingmodel The maximum matching and second-maximum matching(MMSM)model,whichisasegmentation method that keeps the maximum and secondmaximumsegmentationresultfromacertainposi- tioninasentence,andstorethecandidatesegmentationresultsinadirectedgraph,thensomedecodingalgorithmisadoptedtofindthebestpathinthe directedgraph.WiththeMMSMmodel,almostall the possible segmentation paths and most lexical information can be reserved for further use; little space cost is guaranteed by using the directed graph to store the segmentation paths; the context spaces are extended from single-dimension to multi-dimension. 2.2 ConditionalRandomFields Conditional random field (CRF) was an extension of both Maximum Entropy Model (MEMs) and Hidden Markov Models (HMMs) that was firstly introducedby(Lafferty etal.,2001).CRFdefined conditionalprobabilitydistribution P(Y|X)ofgiven sequence given input sentence where Y is the “class label” sequence and X denotes as the observationwordsequence. ACRFon (X,Y)isspecifiedbyafeaturevector F of local context and the corresponding feature weight λ.The Fcanbetreatedasthecombination of state transition and observation value in conventional HMM. To determine the optimal label sequence, the CRF uses the following equationtoestimatethemostprobability. Conditional random fields (CRFs) are undirected graphicalmodelstrainedtomaximizeaconditional probability (Lafferty et al., 2001). A linear-chain CRF with parameters"]},{"title":"},,{","paragraphs":["21"]},{"title":"Lλλ=Λ","paragraphs":["defines a","conditional probability for a state sequence T"]},{"title":"yyy K","paragraphs":["1"]},{"title":"=","paragraphs":[", given that and input sequence T"]},{"title":"xxx K","paragraphs":["1"]},{"title":"=","paragraphs":["is"]},{"title":"      = ∑ ∑","paragraphs":["= −Λ T t k ttkk x"]},{"title":"txyyf Z xyP","paragraphs":["1 1"]},{"title":"),,,(exp 1 )|( λ","paragraphs":["Where x"]},{"title":"Z","paragraphs":["is the normalization factor that makes the probability of all state sequences sum to one;"]},{"title":"),,,(","paragraphs":["1"]},{"title":"txyyf","paragraphs":["ttk − is ofen a binary-valued feature function and k"]},{"title":"λ","paragraphs":["is its weight. The feature functions can measure any aspect of a state transition, tt"]},{"title":"yy →","paragraphs":["−1 , and the entire observation sequence, x, centered at the current time step, t. For example, one feature function might have the value1when yt-1isthestate B, ytisthestate I,and xtissomeChinesecharacter. 2.3 ChineseNamedEntityRecognition First,wewillintroduceourChineseNamedEntity RecognitionpartfortheOpentrack.SeveralNER automata are adopted to find out all the candidate NEs in the directed graph, thenthe CRF model is applied to filter the candidate NEs to check if the specified NE should be added into the graph. To usetheCRF,first,wegeneratesomelistsfromthe trainingcorpus.","PSur:thesurnameofPersonName.","PC: the frequency information ofa characterin PersonName","PPre:theprefixofPersonName","PSuf:thesuffixofPersonName","LF: the frequency information of a character in LocalName","LC:thecentrecharacterofLocalName","LPre:theprefixofLocalName 134 Sixth SIGHAN Workshop on Chinese Language Processing","LSuf:thesuffixofLocalName","OF:thefrequencyinformationofacharacterin ORGName","OC:thecentrecharacterofORGName","OPre:theprefixofORGName","OSuf:thesuffixofORGName","Wedefinethetemplateasfollows:","PER:PSur(n)PC(n)PPre(n)PSuf(n),(n=-2,-1, 0,+1,+2)","LOC:LF(n)LC(n)LPre(n)LSuf(n),(n=-2,-1,0, +1,+2)","ORG: OF(n)OC(n)OPre(n)OSuf(n), (n = -2, -1, 0,+1,+2)","With the CRF we filter the candidate NEs.The candidate NEs are filtered and added into the directedsegmentationgraphasnewnodeswithnew edges.The NEsincludes personal name(PRE),locationname(LOC)andorganizationname(ORG).","The“PER”,”LOC”inopentrackisthesameas in the close track except some external resources. The external resources include external lexicon, name list for word segmentation, and generating thefeatures.","In the “ORG” part, a different method is proposed.Weadoptanautomaticrecognitionmethod of Chinese organization name with the combinationofSVMandMaximumEntropy.SVMmodel isusedtodecidethelatterboundaryofaorganization name, and then Maximum Entropy is used to confirmtheformerboundary.","First, a characteristic dictionary is collected from the training corpus. As for the words appearedinthecharacteristicdictionary,whetheritis the characteristic word of an organization name shouldbedecided.Asaproblemoftwovaluecategorization,SVMisappliedtocompletethistask.If itisconsideredtobeacharacteristicword,thenthe former boundary of an organization name is detected. Maximum Entropy can combine different kindsoftextinformation,andsolvetheproblemof therecognitionofthemorecomplexformerwords of the Chinese organization name, so the Maximum Entropy is adopted to confirm the former boundaryofORG.DuringtheNEsrecognitionand filtering the word and POS tag as main features andadoptacontextwindowoffivewords.","BecauseofthecomplexconstructionoftheChineseNamedEntity,onesinglestatisticalmodelcan notsolvesimpleandcomplexNERsimultaneously, such as the character-based CRF model makes lower recognition accuracy for complex NERs, meanwhile, the word-based CRF model will lose many useful features in processing simple NERs. Integrating the character-based and word-based CRFmodelintooneframeworkisthekeytosolve alltheNERssimultaneously.","In this paper, an integrative model based on CRF is proposed. With the preliminary results of the segmentation and POS tagging, at the bottom of the system, character-based CRF is applied to recognized simple PERs, LOCs, and ORGs; The recognitionresultwillbetransformedtothetopof the system together with the segmentation and POS tagging result. At the top of system, word-based CRF is used to recognize the nested LOCs and ORGs. The character-based model and word based model are integrated into one framework to recognition the NEs with different complexions simultaneously. The identification results of the bottom-levelprovidedecisionsupportforthehighlevel, the limitations of the separated character-based model and word-based model are avoided, andimprovesrecognitionaccuracyofthesystem. 2.4 Resultfromthedirectedgraph After the recognition and filtering of the Chinese Named Entity, the original segmentation directed graph is now with the candidate Chinese Named Entity nodes. Some decoding algorithm is needed tofindfinalpathfromthedirectedgraph.Here,we revised the Dijkstra minimum cost path algorithm to find out the minimum cost path from the directed graph. The calculation of the cost of the nodesandedgesinthedirectedgraphcanbefound in our related work(Degen Huang and Xiao Sun, 2007).Thefinalpathfromthedirectedgraphisthe result for the Chinese word segmentation, POS taggingandChineseNamedEntityrecognition."]},{"title":"3 EvaluationsandExperimentalResults 3.1 ResultofChinesewordsegmentation","paragraphs":["We evaluated our Chinese word segmentation modelintheopentrackonallthesimpleChinese corpus, such as University of Colorado, United States (CTB, 642246 tokens), State Language Commission of P.R.C.,Beijing(NCC, 917255 to-kens) and Shanxi University, Taiyuan (SXU 528238 tokens). The OOV-rate is 0.0555, 0.0474 and0.0512. 135 Sixth SIGHAN Workshop on Chinese Language Processing The CTB open track is shown in the following table1.WegetthethirdpositionintheCTBtrack bytheFresult. ","Table1.CTBopentrackresult CTB R P F Base 0.8864 0.8427 0.8640 Top 0.9710 0.9825 0.9767 Our 0.9766 0.9721 0.9743","IV-R IV-P IV-F Base 0.9369 0.8579 0.8956 Top 0.9698 0.9832 0.9764 Our 0.9805 0.9794 0.9800","OOV-R OOV-P OOV-F Base 0.9920 0.9707 0.9812 Top 0.0273 0.1858 0.0476 Our 0.9089 0.8553 0.8813  The NCC open track is shown in the following","table 2. In the NCC open track, we get the third","positiontrackbytheFresult. ","Table2.NCCopentrackresult NCC R P F Base 0.9200 0.8716 0.8951 Top 0.9735 0.9817 0.9776 Our 0.9620 0.9496 0.9557","IV-R IV-P IV-F Base 0.9644 0.8761 0.9181 Top 0.9725 0.9850 0.9787 Our 0.9783 0.9569 0.9675","OOV-R OOV-P OOV-F Base 0.0273 0.1858 0.0476 Top 0.9933 0.9203 0.9554 Our 0.7109 0.7619 0.7355  The SXU open track is shown in the following","table3.IntheSXUopentrack,wegetthefirsttwo","positionsbytheFresult. ","Table3.NCCopentrackresult NCC R P F Base 0.9238 0.8679 0.8949 Top 0.9820 0.9867 0.9844 Our 0.9768 0.9703 0.9735","IV-R IV-P IV-F Base 0.9723 0.8789 0.9232 Top 0.9813 0.9890 0.9851","Our 0.9872 0.9767 0.9820","OOV-R OOV-P OOV-F","Base 0.0251 0.0867 0.0389","Top 0.9942 0.9480 0.9705","Our 0.7825 0.8415 0.8109","","We also participate in the close track in CTB,","NCC and SXU corpus.The result isshown in the","followingtable4.","","Table4.SegmentationResultinclosetrack","R P F Foov Fiv CTB 0.9505 0.9528 0.9517 0.7216 0.9659 NCC 0.9387 0.9301 0.9344 0.5643 0.9524 SXU 0.9594 0.9493 0.9543 0.6676 0.9697  3.2 ResultofChineseNER We evaluated our named entity recognizer on the SIGHAN Microsoft Research Asia(MSRA) corpusinbothclosedandopentrack.  Table5.NERinMSRAclosedtrack: Close R P F PER 90.29% 95.19% 92.68% LOC 81.85% 92.78% 86.97% ORG 70.16% 84.05% 76.48% Overall 80.58% 91.07% 85.5%  Table6.NERinMSRAopentrack: Open R P F PER 92.06% 95.17% 93.59% LOC 83.62% 94.24% 88.62% ORG 74.04% 79.66% 75.65% Overall 82.38% 90.38% 86.19%  3.3 ResultofPOStagging ThePOStaggingresultofoursystemisshownin thefollowingtable7. ","Table7.POStagginginclosetrack Close Total-A IV-R OOV-R MT-R CTB 0.9088 0.9374 0.4866 0.8805 NCC 0.9313 0.9604 0.4080 0.8809 PKU 0.9053 0.9451 0.2751 0.8758  136 Sixth SIGHAN Workshop on Chinese Language Processing","Table8.POStagginginopentrack Open Total-A IV-R OOV-R MT-R CTB 91.2% 93.74% 53.61% 88.05% NCC 93.26% 96.04% 43.36% 88.09% PKU 93.29% 95.18% 63.32% 89.72%"]},{"title":"4 ConclusionsandFutureWork","paragraphs":["Inthispaper,thehybridmodelinoursystemis described,Anintegrativelexicalanalysissystemis implemented,whichcompletesallthestepsofthe lexical analysis synchronously, by integrating the segmentation,ambiguousresolution,POStagging, unknown words recognition into one theory framework.Theintegrativemechanismreducesthe conflicts betweenthesteps ofthelexical analysis. The experimental results demonstrate that, the in-tegrativemodelanditsalgorithmiseffective.The system used the automata recognition and CRF-basedhybridmodeltoprocesstheChineseNamed Entity. The Chinese word segmentation, POS tagging and Chinese Named Entity recognition are integrated; the character-based CRF and word-based CRF are integrated, the HMM, CRF and otherstatisticmodelareintegratedunderthesame segmentationframework.Withthismodelweparticipated in the “The Fourth SIGHAN Bakeoff” andgotgoodperformance."]},{"title":"References","paragraphs":["Degen, Huang and Xiao An Integrative Approach to ChineseNamedEntityRecognition,InProceedingsof the 6th International Conference on Advanced LanguageProcessingandWebInformationTechnology.","Gao,J.,Wu,A.,Li,M.,Huang,C.N.,Li,H.,Xia, X., andQin,H.2004. AdaptiveChinesewordsegmentation.InProceedingsthe41st Annual Meetingofthe Association for Computational Linguistics, pp. 21-26.","Lafferty,J.,McCallum,A.,andPereira,F.2001. Conditional Random Field: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning.","LanceA.RamshawandMitchellP.Marcus.1995. Text chunking using transformation-based learning. In Proceedings of the 3rd Workshop on Very Large Corpora, pages 82-94. Nocedal, J., and Wright, S. 1999.Numericaloptimization.Springer.","Peng, F., Feng, F., and McCallum, A. 2004. Chinese segmentation and new word detection using conditionalrandomfields.InPorceedingsoftheComputationalLinguistics,pp.562-568.","Shi, W. 2005. Chinese Word Segmentation Based On Direct Maximum Entropy Model. In Proceedings of theFourthSIGHANWorkshoponChineseLanguage Processing.","Wu,Y.C.,Chang,C.H.andLee,Y.S.2006a. Ageneralandmulti-lingualphrasechunkingmodelbased onmaskingmethod.LectureNotesinComputerScience(LNCS):ComputationalLinguisticsandIntelligentTextProcessing,3878:144-155.","Wu,Y.C.,Fan,T.K.,LeeY.S.andYen,S.J.200 6b. Extracting named entities using support vector machines,\" Lecture Notes in Bioinformatics (LNBI): Knowledge Discovery in Life Science Literature, (3886):91-103.","Wu,Y.C.,Lee,Y.S.,andYang,J.C.2006c. TheExplorationof Deterministic and Efficient Dependency Parsing. In Proceedings of the 10th Conference on NaturalLanguageLearning(CoNLL). 137 Sixth SIGHAN Workshop on Chinese Language Processing"]}]}