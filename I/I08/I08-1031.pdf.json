{"sections":[{"title":"Hypothesis Selection in Machine Transliteration: A Web Mining Approach Jong-Hoon Oh and Hitoshi Isahara Computational Linguistics Group National Institute of Information and Communications Technology (NICT) 3-5 Hikaridai,Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan {rovellia,isahara}@nict.go.jp Abstract","paragraphs":["We propose a new method of selecting hypotheses for machine transliteration. We generate a set of Chinese, Japanese, and Korean transliteration hypotheses for a given English word. We then use the set of transliteration hypotheses as a guide to finding relevant Web pages and mining contextual information for the transliteration hypotheses from the Web page. Finally, we use the mined information for machine-learning algorithms including support vector machines and maximum entropy model designed to select the correct transliteration hypothesis. In our experiments, our proposed method based on Web mining consistently outperformed systems based on simple Web counts used in previous work, regardless of the language."]},{"title":"1 Introduction","paragraphs":["Machine transliteration has been a great challenge for cross-lingual information retrieval and machine translation systems. Many researchers have developed machine transliteration systems that accept a source language term as input and then output its transliteration in a target language (Al-Onaizan and Knight, 2002; Goto et al., 2003; Grefenstette et al., 2004; Kang and Kim, 2000; Li et al., 2004; Meng et al., 2001; Oh and Choi, 2002; Oh et al., 2006; Qu and Grefenstette, 2004). Some of these have used the Web to select machine-generated transliteration hypotheses and have obtained promising results (Al-Onaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006; Qu and Grefenstette, 2004). More precisely, they used simple Web counts, estimated as the number of hits (Web pages) retrieved by a Web search engine.","However, there are several limitations imposed on the ability of Web counts to select a correct transliteration hypothesis. First, the assumption that hit counts approximate the Web frequency of a given query usually introduces noise (Lapata and Keller, 2005). Moreover, some Web search engines disregard punctuation and capitalization when matching search terms (Lapata and Keller, 2005). This can cause errors if such Web counts are relied on to select transliteration hypotheses. Second, it is not easy to consider the contexts of transliteration hypotheses with Web counts because Web counts are estimated based on the number of retrieved Web pages. However, as our preliminary work showed (Oh et al., 2006), transliteration or translation pairs often appear as parenthetical expressions or tend to be in close proximity in texts; thus context can play an important role in selecting transliteration hypotheses. For example, there are several Chinese, Japanese, and Korean (CJK) transliterations and their counterparts in a parenthetical expression, as follows. 1) 12 (Adrienne1 Clarkson2) 2) –1–2 (glucose1 oxidase2) 3) 1 \\b\\t\\b 2 (diphenol1 oxidase2) Note that the subscripted numbers in all examples represent the correspondence between the English word and its CJK counterpart. These parenthetical expressions are very useful in selecting translit-"]},{"title":"233","paragraphs":["eration hypotheses because it is apparent that they are translation pairs or transliteration pairs. However, we cannot fully use such information with Web counts.","To address these problems, we propose a new method of selecting transliteration hypotheses. We were interested in how to mine information relevant to the selection of hypotheses and how to select correct transliteration hypotheses using the mined information. To do this, we generated a set of CJK transliteration hypotheses for a given English word. We then used the set of transliteration hypotheses as a guide to finding relevant Web page and mining contextual information for the transliteration hypotheses from the Web page. Finally, we used the mined information for machine-learning algorithms including support vector machines (SVMs) and maximum entropy model designed to select the correct transliteration hypothesis.","This paper is organized as follows. Section 2 describes previous work based on simple Web counts. Section 3 describes a way of generating transliteration hypotheses. Sections 4 and 5 introduce our methods of Web mining and selecting transliteration hypotheses. Sections 6 and 7 deal with our experiments and the discussion. Conclusions are drawn and future work is discussed in Section 8."]},{"title":"2 Related work","paragraphs":["Web counts have been used for selecting transliteration hypotheses in several previous work (Al-Onaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006; Qu and Grefenstette, 2004). Because the Web counts are estimated as the number of hits by a Web search engine, they greatly depend on queries sent to a search engine. Previous work has used three types of queries—monolingual queries (MQs) (Al-Onaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006), bilingual simple queries (BSQs) (Oh et al., 2006; Qu and Grefenstette, 2004), and bilingual bigram queries (BBQs) (Oh et al., 2006). If we let S be a source language term and H = {h1, ···,hr} be a set of machine-generated transliteration hypotheses of S, the three types of queries can be defined as MQ: hi (e.g., , כ, and\\b\\t).","BSQ: s and hi without quotations (e.g., Clinton , Clinton כ, andClinton \\b \\t).","BBQ: Quoted bigrams composed of S and hi (e.g., “Clinton ”, “Clinton כ”, and “Clinton \\b\\t”). MQ is not able to determine whether hi is a counterpart of S, but whether hi is a frequently used target term in target-language texts. BSQ retrieves Web pages if S and hi are present in the same document but it does not take the distance between S and hi into consideration. BBQ retrieves Web pages where “Shi”or“hi S” are present as a bigram. The relative order of Web counts over H makes it possible to select transliteration hypotheses in the previous work."]},{"title":"3 Generating Transliteration Hypotheses","paragraphs":["Let S be an English word, P be a pronunciation of S, and T be a target language transliteration corresponding to S. We implement English-to-CJK transliteration systems based on three different transliteration models — a grapheme-based model (S → T ), a phoneme-based model (S → P and P → T ), and a correspondence-based model (S → P and (S, P ) → T ) — as described in our preliminary work (Oh et al., 2006). P and T are segmented into a series of sub-strings, each of which corresponds to a source grapheme. We can thus write S = s1, ···,sn = sn","1 , P = p1, ···,pn = pn","1 , and T = t1, ···,tn = tn","1 , where si, pi, and ti represent the ith","English grapheme, English phonemes corresponding to si, and target language graphemes corresponding to si, respectively. Given S, our transliteration systems generate a sequence of ti corresponding to either si (in Eq. (1)) or pi (in Eq. (2)) or both of them (in Eq. (3)).","PrG(T |S)=Pr(tn 1 |sn","1 ) (1)","PrP (T |S)=Pr(pn","1 |sn 1 ) × Pr(tn","1 |pn","1 ) (2)","PrC (T |S)=Pr(pn","1 |sn","1 ) × Pr(tn","1 |sn","1 ,pn","1 ) (3) The maximum entropy model was used to estimate probabilities in Eqs. (1)–(3) (Oh et al., 2006). We produced the n-best transliteration hypotheses using a stack decoder (Schwartz and Chow, 1990). We"]},{"title":"234","paragraphs":["then created a set of transliteration hypotheses comprising the n-best transliteration hypotheses."]},{"title":"4 Web Mining","paragraphs":["Let S be an English word and H = {h1, ···,hr} be its machine-generated set of transliteration hypotheses. We use S and H to generate queries sent to a search engine1","to retrieve the top-100 snippets. A correct transliteration and its counterpart tend to be in close proximity on CJK Web pages. Our goal in Web mining was to find such Web pages and mine information that would help to select transliteration hypotheses from these pages.","To find these Web pages, we used three kinds of queries, Q1=(S and hi), Q2=S, and Q3=hi, where Q1 is the same as BSQ’s query and Q3 is the same as MQ’s. The three queries usually result in different sets of Web pages. We categorize the retrieved Web pages by Q1, Q2, and Q3 into W1, W2, and W3.We extract three kinds of features from Wl as follows, where l =1, 2, 3.","• Freq(hi,Wl): the number of occurrences of hi in Wl","• DF reqk(hi,Wl): Co-occurrence of S and hi with distance dk ∈ D in the same snippet of Wl.","• PFreqk(hi,Wl): Co-occurrence of S and hi as parenthetical expressions with distance dk ∈ D in the same snippet of Wl. Parenthetical expressions are detected when either S or hi is in parentheses. We define D = {d1,d2,d3} with three ranges of distances between S and hi, where d1(d<5), d2(5 ≤ d<10), and d3(10 ≤ d ≤ 15). We counted distance d with the total number of characters (or words)2","between S and hi. Here, we can take the contexts of transliteration hypotheses into account using DF req and PFreq; while Freq is counted regardless of the contexts of the transliteration hypotheses.","Figure 1 shows examples of how to calculate Freq, DF reqk, and PFreqk, where S = Clinton,","1","We used Google (http://www.google.com)","2","Depending on whether the languages had spacing units, words (for English and Korean) or characters (for Chinese and Japanese) were chosen to calculate d. 1     1     W1: Q1=(Clinton )           Snippet1 Snippet2 Figure 1: Web corpora collected by Clinton and  Snippet1 1 2 3 Clinton1 14168 Clinton2 72 29 2 Snippet2 4 5 6 Clinton3 03681 Clinton4 40 0 37 Clinton5 85 41 0 Snippet2 1 2 3 Clinton3 6985 Clinton4 32 29 42 Clinton5 77 74 1 Table 1: Distance between Clinton and Chinese transliteration hypotheses in Fig. 1 hi= in W1 collected by Q1=(Clinton ). The subscripted numbers of Clinton and were used to indicate how many times they occurred in W1. In Fig. 1, occurs six times thus Freq(hi,W1)=6. Table 1 lists the distance between Clinton and within each snippet of W1. We can obtain DF req1(hi,W1)= 5. PFreq1(hi,Wl) is calculated by detecting parenthetical expressions between S and hi when DF req1(hi,Wl) is counted. Because all S in W1 (Clinton1 to Clinton5) are in parentheses, PFreq1(hi,W1) is the same as DF req1(hi,W1).","We ignore Freq, DF reqk, and PFreqk when hi is a substring of other transliteration hypotheses because hi usually has a higher Freq, DF reqk, and PFreqk than hj if hi is a substring of hj. Let a"]},{"title":"235","paragraphs":["set of transliteration hypotheses for S = Clinton be H= {h1 = , h2 = }. Here, h2 is a substring of h1. In Fig. 1, h2 appears six times as a substring of h1 and three times independently in Snippet2. Moreover, independently used h2 (1, 2, and 3) and S (Clinton3 and Clinton5) are sufficiently close to count DF reqk and PFreqk. Therefore, the Freq, DF reqk, and PFreqk of h1 will be lower than those of h2 if we do not take the substring relation between h1 and h2 into account. Considering the substring relation, we obtain Freq(h2,W1)=3, DF req1(h2,W1)=1, DF req2(h2,W1)=2, PFreq1(h2,W1)=1, and PFreq2(h2,W1)=2."]},{"title":"5 Hypothesis Selection","paragraphs":["We select transliteration hypotheses by ranking them. A set of transliteration hypotheses, H = {h1,h2, ···,hr}, is ranked to enable a correct hypothesis to be identified. We devise a rank function, g(hi) in Eq. (4), that ranks a correct transliteration hypothesis higher and the others lower. g(hi):H→{R: R is ordering of hi ∈H} (4)","Let xi ∈Xbe a feature vector of hi ∈H, yi = {+1, −1} be the training label for xi, and TD = {td1 =<x1,y1 >, ···,tdz =<xz,yz >} be the training data for g(hi). We prepare the training data for g(hi) as follows.","1. Given each English word S in the training-set, generate transliteration hypotheses H.","2. Given hi ∈H, assign yi by looking for S and hi in the training-set — yi =+1if hi is a correct transliteration hypothesis corresponding to S, otherwise yi = −1.","3. For each pair (S, hi), generate its feature vector xi.","4. Construct a training data set, TD: •TD= TD+ ⋃ TD−","•TD+","∋ tdi where yi =+1","•TD−","∋ tdj where yj = −1","We used two machine-learning algorithms, support vector machines (SVMs)3","and maximum entropy model4","for our implementation of g(hi). The SVMs assign a value to each transliteration hypothesis (hi) using gSV M(hi)=w · xi + b (5) where w denotes a weight vector. Here, we use the predicted value of gSV M(hi) rather than the predicted class of hi given by SVMs because our ranking function, as represented by Eq. (4), determines the relative ordering between hi and hj in H.A ranking function based on the maximum entropy model assigns a probability to hi using gMEM(hi)=Pr(yi =+1|xi) (6) We can finally obtain a ranked list for the given H— the higher the g(hi) value, the better the hi. 5.1 Features We represent the feature vector, xi, with two types of features. The first is the confidence scores of hi given by Eqs. (1)–(3) and the second is Web-based features — Freq, DF reqk, and PFreqk. To normalize Freq, DF reqk, and PFreqk, we use their relative frequency over H as in Eqs. (7)–(9), where k =1, 2, 3 and l =1, 2, 3. RF (hi,Wl)= Freq(hi,Wl)","∑ h j∈H Freq(hj,Wl) (7) RDFk(hi,Wl)= DFreqk(hi,Wl)","∑ h j∈H DFreqk(hj,Wl) (8) RP Fk(hi,Wl)= PFreqk(hi,Wl)","∑ h j∈H PFreqk(hj,Wl) (9)","Figure 2 shows how to construct feature vector xi from a given English word, Rachel, and its Chinese hypotheses, H, generated from our transliteration systems. We can obtain r Chinese transliteration hypotheses and classify them into positive and negative samples according to yi. Note that yi =+1 if and only if hi is registered as a counterpart of S in the training data. The bottom of Fig. 2 shows our feature set representing xi. There are three confidence scores in P (hi|S) according to transliteration models and the three Web-based features Web(W1), Web(W2), and Web(W3).","3","SV Mlight","(Joachims, 2002)","4","“Maximum Entropy Modeling Toolkit” (Zhang, 2004)"]},{"title":"236 ","paragraphs":["h","r...h","5h 4h","3h","2h","1H","-1-1-1-1-1+1 y","r...y","5y 4y","3y","2y","1Y Rachel RF(hi,W1) RDF1(hi,W1) RDF2(hi,W1) RDF3(hi,W1) RPF1(hi,W1) RPF2(hi,W1) RPF3(hi,W1) Web (W1) RF(W3) RDF1(hi,W3) RDF2(hi,W3) RDF3(hi,W3) RPF1(hi,W3) RPF2(hi,W3) RPF3(hi,W3) RF(hi,W2) RDF1(hi,W2) RDF2(hi,W2) RDF3(hi,W2) RPF1(hi,W2) RPF2(hi,W2) RPF3(hi,W2) PrG(hi|S) PrP(hi|S) PrC(hi|S) Web (W3)Web (W2)Pr(hi|S)xi","td1 ∈ TD+ td2, td3, td4, td5,...,tdr ∈ TD-","x","r...x","5x 4x","3x","2x","1X Figure 2: Feature vectors"]},{"title":"6 Experiments","paragraphs":["We evaluated the effectiveness of our system in selecting CJK transliteration hypotheses. We used the same test set used in Li et al. (2004) (ECSet) for Chinese transliterations (Xinhua News Agency, 1992) and those used in Oh et al. (2006) for Japanese and Korean transliterations — EJSET and EK-SET (Breen, 2003; Nam, 1997). We divided the test","ECSet EJSet EKSet Training Set 31,299 8,335 5,124","Development Set 3,478 1,041 1,024 Blind Test Set 2,896 1,041 1,024","Total 37,694 10,417 7,172 Table 2: Test data sets data into training, development, and blind test sets as in Table 2. The training set was used to train our three transliteration models to generate the n-best transliteration hypotheses5",". The development set was used to train hypothesis selection based on support vector machines and maximum entropy model.","We used the blind test set for evaluation. The evaluation was done in terms of word accuracy (WA). WA is the proportion of correct transliterations in the best hypothesis by a system to correct transliterations in the blind test set. System ECSet EJSet EKSet","KANG00 N/A N/A 54.1","GOTO03 N/A 54.3 N/A LI04 70.1 N/A N/A GM 69.0 61.6 59.0 PM 56.6 54.4 56.7 CM 69.9 65.0 65.1 Table 3: WA of individual transliteration systems (%) 6.1 Results: Web counts vs. Web mining We compared our transliteration system with three previous ones, all of which were based on a grapheme-based model (Goto et al., 2003; Kang and Kim, 2000; Li et al., 2004). LI046","is an English-to-Chinese transliteration system, which simultaneously takes English and Chinese contexts into consideration (Li et al., 2004). KANG00 is an English-to-Korean transliteration system and GOTO03 is an English-to-Japanese one – they segment a chunk of English graphemes and identify the most relevant sequence of target graphemes corresponding to the chunk (Goto et al., 2003; Kang and Kim, 2000) 7",". GM, PM, and CM, which are respectively based on Eqs. (1)–(3), are the transliteration systems we used for generating transliteration hypotheses. Our transliteration systems showed comparable or better performance than the previous ones regardless of the language.","We compared simple Web counts with our Web mining for hypothesis selection. We used the same set of transliteration hypotheses H then compared their performance in hypothesis selection with two measures, relative frequency and g(hi). Tables 4 and 5 list the results. Here, “Upper bound” is a system that always selects the correct transliteration hypothesis if there is a correct one in H. “Upper bound” can","5","We set n =10for the n-best. Thus, n ≤ r ≤ 3 × n where H = {h1,h2, ···,hr}","6","The WA of LI04 was taken from the literature, where the training data were the same as the union of our training set and the development set while the test data were the same as in our test set. In other words, LI04 used more training data than ours did. With the same setting as LI04, our GM, PM, and CM produced respective WAs of 70.0, 57.7, and 71.7.","7","We implemented KANG00 (Kang and Kim, 2000) and GOTO03 (Goto et al., 2003), and tested them with the same data as ours."]},{"title":"237","paragraphs":["System ECSet EJSet EKSet WC MQ 16.1 40.4 34.7 BSQ 45.8 74.0 72.4 BBQ 34.9 78.1 79.3 WM RF (W1) 62.9 78.4 77.1 RDF (W1) 70.8 80.4 80.2 RP F (W1) 73.5 79.7 79.4 RF (W2) 63.5 76.2 74.8 RDF (W2) 67.1 79.2 78.9 RP F (W2) 69.6 79.1 78.4 RF (W3) 37.9 53.9 55.8 RDF (W3) 76.4 69.0 70.2 RP F (W3) 76.8 68.3 68.7","Upper bound 94.6 93.5 93.2 Table 4: Web counts (WC) vs. Web mining (WM): hypothesis selection by relative frequency (%) System ECSet EJSet EKSet WC MEMWC 74.7 86.1 85.6 SV MWC 74.8 86.9 86.5 WM MEMWM 82.0 88.2 85.8 SV MWM 83.9 88.5 86.7","Upper bound 94.6 93.5 93.2 Table 5: Web counts (WC) vs. Web mining (WM): hypothesis selection by g(hi) (%) also be regarded as the “Coverage” of H generated by our transliteration systems. MQ, BSQ, and BBQ in the upper section of Table 4, represent hypothesis selection systems based on the relative frequency of Web counts over H, the same measure used in Oh et al. (2006): W ebCountsx(hi) ∑ hj∈H W ebCountsx(hj) (10) where W ebCountsx(hi) is a function returning Web counts retrieved by x ∈{MQ,BSQ,BBQ} RF (Wl), RDF (Wl), and RP F (Wl) in Table 4 represent hypothesis selection systems with their relative frequency, where RDF (Wl) and RP F (Wl) use∑3","k=1 RDFk(hj,Wl) and","∑3","k=1 RP Fk(hj,Wl), respectively. The comparison in Table 4 shows which is best for selecting transliteration hypotheses when each relative frequency is used alone. Table 5 compares Web counts with features mined from the Web when they are used as features in g(hi) — {Pr(hi|S), Web(Wl)} in MEMWM and SV MWM (our proposed method), while {Pr(hi|S), W ebCountsx(hi)} in MEMWC and SV MWC. Here, Web(Wl) is a set of mined features from Wl as described in Fig .2.                     Snippet1 retrieved by BSQ: Aman “” Snippet2 retrieved by MQ: “” (meaning Agard) |Cliff De Young| | | | EO | The Secret Life of Zoey (TV) 2002 , , , , Avery Raskin. Larry Carter. 4.92... |Cliff De Young| | | | EO | The Secret Life of Zoey (TV) 2002 , , , , , Avery Raskin. Larry Carter. 4.92... UNESCO. General Conference; 32nd; Election of member ···. . 1987--1991. · ··. . (1976). 1987--1991. · ·. 2001--2005. . 1993--1997.... UNESCO. General Conference; 32nd; Election of member ····. . 1987--1991. · ··. . (1976). 1987--1991. · ·. 2001--2005. . 1993--1997.... Snippet3 retrieved by MQ: ““”” (meaning (meaning RawcliffeRawcliffe)) Snippet4 retrieved by MQ: ““”” (meaning (meaning AAlderseyldersey)) Figure 3: Snippets causing errors in Web counts","The results in the tables show that our systems consistently outperformed systems based on Web counts, especially for Chinese. This was due to the difference between languages. Japanese and Chinese do not use spaces between words. However, Japanese is written using three different alphabet systems, called Hiragana, Katakana, and Kanji, that assist word segmentation. Moreover, words written in Katakana are usually Japanese transliterations of foreign words. This makes it possible for a Web search engine to effectively retrieve Web pages containing given Japanese transliterations. Like English, Korean has spaces between words (or word phrases). As the spaces in the languages reduce ambiguity in segmenting words, a Web search engine can correctly identify Web pages containing given Korean transliterations. In contrast, there is a severe word-segmentation problem with Chinese that causes Chinese Web search engines to incorrectly retrieve Web pages, as shown in Fig. 3. For example, Snippet1 is not related to “Aman” but to “a man”."]},{"title":"238","paragraphs":["Snippet2 contains a super-string of a given Chinese query, which corresponds to “Academy” rather than to “Agard”, which is the English counterpart of the Chinese transliteration . Moreover, Web search engines ignore punctuation marks in Chinese. In Snippet3 and Snippet4, “,” and “” in the underlined terms are disregarded, so the Web counts based on such Web documents are noisy. Thus, noise in the Chinese Web counts causes systems based on Web counts to produce more errors than our systems do. Our proposed method can filter out such noise because our systems take punctuation marks and the contexts of transliterations in Web mining into consideration. Thus, our systems based on features mined from the Web were able to achieve the best performance. The results revealed that our systems based on the Web-mining technique can effectively be used to select transliteration hypotheses regardless of the language. 6.2 Contribution of Web corpora","ECSet EJSet EKSet SVM MEM SVM MEM SVM MEM Base 73.3 73.8 67.0 66.1 66.0 66.4 W1 81.7 79.7 87.6 87.3 86.1 85.1 W2 80.8 79.5 86.9 86.0 83.8 82.1 W3 77.2 76.7 83.0 82.8 79.8 77.3 W1+2 83.8 82.3 88.5 87.9 86.3 85.9 W1+3 81.9 80.1 87.6 87.8 86.1 84.7 W2+3 81.4 79.8 88.0 87.7 85.1 84.3 WAll 83.9 82.0 88.5 88.2 86.7 85.8 Table 6: Contribution of Web corpora","In Web mining, we used W1, W2, and W3, collected by respective queries Q1=(S and hi), Q2=S, and Q3=hi. To investigate their contribution, we tested our proposed method with different combinations of Web corpora. “Base” is a baseline system that only uses Pr(hi|S) as features but does not use features mined from the Web. We added features mined from different combinations of Web corpora to “Base” from W1 to WAll.","In Table 6, we can see that W1, a set of Web pages retrieved by Q1, tends to give more relevant information than W2 and W3, because Q1 can search more Web pages containing both S and hi in the top-100 snippets if S and hi are a correct transliteration pair. Therefore, its performance tends to be superior in Table 6 if W1 is used, especially for ECSet. However, as W1 occasionally retrieves few snippets, it is not able to provide sufficient information. Using W2 or W3, we can address the problem. Thus, combinations of W1 and others (W1+2, W1+3, WAll) provided better WA than W1."]},{"title":"7 Discussion","paragraphs":["Several Web mining techniques for transliteration lexicons have been developed in the last few years (Jiang et al., 2007; Oh and Isahara, 2006). The main difference between ours and those previous ones is in the way a set of transliteration hypotheses (or candidates) is created.","Jiang et al. (2007) generated Chinese transliterations for given English words and searched the Web using the transliterations. They generated only the best transliteration hypothesis and focused on Web mining to select transliteration lexicons rather than selecting transliteration hypotheses. The best transliteration hypothesis was used to guide Web searches. Then, transliteration candidates were mined from the retrieved Web pages. Therefore, their performance greatly depended on their ability to mine transliteration candidates from the Web. However, this system might create errors if it cannot find a correct transliteration candidate from the retrieved Web pages. Because of this, their system’s coverage and WA were relatively poor than ours 8",". However, our transliteration process was able to generate a set of transliteration hypotheses with excellent coverage and could thus achieve superior WA.","Oh and Isahara (2006) searched the Web using given source words and mined the retrieved Web pages to find target-language transliteration candidates. They extracted all possible sequences of target-language characters from the retrieved Web snippets as transliteration candidates for which the beginnings and endings of the given source word","8","Since both Jiang et al.’s (2007) and ours used Chinese transliterations of personal names as a test set, we can indirectly compare our coverage and WA with theirs (Jiang et al., 2007). Jiang et al. (2007) achieved a 74.5% coverage of transliteration candidates and 47.5% WA, while ours achieved a 94.6% coverage of transliteration hypotheses and 82.0–83.9% WA"]},{"title":"239","paragraphs":["and the extracted transliteration candidate were phonetically similar. However, while this can exponentially increase the number of transliteration candidates, ours used the n-best transliteration hypotheses but still achieved excellent coverage."]},{"title":"8 Conclusion","paragraphs":["We have described a novel approach to selecting transliteration hypotheses based on Web mining. We first generated CJK transliteration hypotheses for a given English word and retrieved Web pages using the transliteration hypotheses and the given English word as queries for a Web search engine. We then mined features from the retrieved Web pages and trained machine-learning algorithms using the mined features. Finally, we selected transliteration hypotheses by ranking them. Our experiments revealed that our proposed method worked well regardless of the language, while simple Web counts were not effective, especially for Chinese.","Because our method was very effective in selecting transliteration pairs, we expect that it will also be useful for selecting translation pairs. We plan to extend our method in future work to selecting translation pairs."]},{"title":"References","paragraphs":["Y. Al-Onaizan and Kevin Knight. 2002. Translating named entities using monolingual and bilingual resources. In Proc. of ACL ’02, pages 400–408.","J. Breen. 2003. EDICT Japanese/English dictionary .le. The Electronic Dictionary Research and Development Group, Monash University. http://www.csse. monash.edu.au/j̃wb/edict.html.","I. Goto, N. Kato, N. Uratani, and T. Ehara. 2003. Transliteration considering context information based on the maximum entropy method. In Proc. of MT-Summit IX, pages 125–132.","Gregory Grefenstette, Yan Qu, and David A. Evans. 2004. Mining the Web to create a language model for mapping between English names and phrases and Japanese. In Proc. of Web Intelligence, pages 110– 116.","Long Jiang, Ming Zhou, Lee-Feng Chien, and Cheng Niu. 2007. Named entity translation with Web mining and transliteration. In Proc. of IJCAI, pages 1629– 1634.","Thorsten Joachims. 2002. Learning to Classify Text Using Support Vector Machines: Methods, Theory and Algorithms. Kluwer Academic Publishers.","I. H. Kang and G. C. Kim. 2000. English-to-Korean transliteration using multiple unbounded overlapping phoneme chunks. In Proc. of COLING ’00, pages 418–424.","Mirella Lapata and Frank Keller. 2005. Web-based models for natural language processing. ACM Trans. Speech Lang. Process., 2(1):3.","H. Li, M. Zhang, and J. Su. 2004. A joint source-channel model for machine transliteration. In Proc. of ACL ’04, pages 160–167.","H.M. Meng, Wai-Kit Lo, Berlin Chen, and K. Tang. 2001. Generating phonetic cognates to handle named entities in English-Chinese cross-language spoken document retrieval. In Proc. of Automatic Speech Recognition and Understanding, 2001. ASRU ’01, pages 311–314. Y. S. Nam. 1997. Foreign dictionary. Sung An Dang.","Jong-Hoon Oh and Key-Sun Choi. 2002. An English-Korean transliteration model using pronunciation and contextual rules. In Proc. of COLING2002, pages 758–764.","Jong-Hoon Oh and Hitoshi Isahara. 2006. Mining the Web for transliteration lexicons: Joint-validation approach. In Web Intelligence, pages 254–261.","Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara. 2006. A comparison of different machine transliteration models. Journal of Artificial Intelligence Research (JAIR), 27:119–151.","Yan Qu and Gregory Grefenstette. 2004. Finding ideographic representations of Japanese names written in Latin script via language identification and corpus validation. In Proc. of ACL ’04, pages 183–190.","Richard Schwartz and Yen-Lu Chow. 1990. The N-best algorithm: An efficient and exact procedure for finding the N most likely sentence hypothesis. In Procs. of ICASSP ’90, pages 81–84.","Xinhua News Agency. 1992. Chinese transliteration of foreign personal names. The Commercial Press.","L. Zhang. 2004. Maximum entropy model-ing toolkit for python and C++. http: //homepages.inf.ed.ac.uk/s0450736/ software/maxent/manual.pdf."]},{"title":"240","paragraphs":[]}]}