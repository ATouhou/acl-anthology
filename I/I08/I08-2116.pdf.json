{"sections":[{"title":"Multi-label Text Categorization with Model Combination based on F","paragraphs":["1"]},{"title":"-score Maximization Akinori Fujino, Hideki Isozaki, and Jun Suzuki NTT Communication Science Laboratories NTT Corporation 2-4, Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0237 {a.fujino,isozaki,jun}@cslab.kecl.ntt.co.jp Abstract","paragraphs":["Text categorization is a fundamental task in natural language processing, and is generally defined as a multi-label categorization problem, where each text document is assigned to one or more categories. We focus on providing good statistical classifiers with a generalization ability for multi-label categorization and present a classifier design method based on model combination and F1-score maximization. In our formulation, we first design multiple models for binary classification per category. Then, we combine these models to maximize the F1-score of a training dataset. Our experimental results confirmed that our proposed method was useful especially for datasets where there were many combinations of category labels."]},{"title":"1 Introduction","paragraphs":["Text categorization is a fundamental task in such aspects of natural language processing as information retrieval, information extraction, and text min-ing. Since a text document often belongs to multiple categories in real tasks such as web pages and international patent categorization, text categorization is generally defined as assigning one or more pre-defined category labels to each data sample. There-fore, developing better classifiers with a generalization ability for such multi-label categorization tasks is an important issue in the field of machine learning.","A major and conventional machine learning approach to multi-label categorization is based on binary classification. With this approach, we assume the independence of categories and design a binary classifier for each category that determines whether or not to assign a category label to data samples. Statistical classifiers such as the logistic regression model (LRM), the support vector machine (SVM), and naive Bayes are employed as binary classifiers (Joachims, 1998).","In text categorization, the F1-score is often used to evaluate classifier performance. Recently, methods for training binary classifiers to maximize the F1-score have been proposed for SVM (Joachims, 2005) and LRM (Jansche, 2005). It was confirmed experimentally that these training methods were more effective for obtaining binary classifiers with better F1-score performance than the minimum error rate and maximum likelihood used for training conventional classifiers, especially when there was a large imbalance between positive and negative samples. In multi-label categorization, macro-and micro-averaged F1-scores are often used to evaluate classification performance. Therefore, we can expect to improve multi-label classification performance by using binary classifiers trained to maximize the F1-score.","On the other hand, classification frameworks based on classifier combination have also been studied in many previous works such as (Wolpert, 1992; Larkey and Croft, 1996; Ting and Witten, 1999; Ghahramani and Kim, 2003; Bell et al., 2005; Fumera and Roli, 2005), to provide better classifier systems. In the classifier combination research field, it is known that weighted linear combinations of multiple classifiers often provide better classification performance than individual classifiers."]},{"title":"823","paragraphs":["We present a classifier design method based on the combination of multiple binary classifiers to improve multi-label classification performance. In our framework, we first train multiple binary classifiers for each category. Then, we combine these binary classifiers with weights estimated to maximize micro- or macro-averaged F1-scores, which are often used for evaluating multi-label classifiers. To estimate combination weights, we extend the F1-score maximization training algorithm for LRM described in (Jansche, 2005). Using three real text datasets, we show experimentally that our classifier design method is more effective than the conventional binary classification approaches to multi-label categorization.","Our method is based on a binary classification approach. However, Kazawa et al. (2005) proposed a method for modeling a map directly from data samples to the combination of assigned category labels, and confirmed experimentally that the method outperformed conventional binary classification approaches. Therefore, we also compare our method with the direct mapping method experimentally."]},{"title":"2 F","paragraphs":["1"]},{"title":"-score Maximization Training of LRM","paragraphs":["We first review the F1-score maximization training method for linear models using a logistic function described in (Jansche, 2005). The method was proposed in binary classification settings, where classifiers determine a class label assignment y ∈{1, 0} for a data sample represented by a feature vector x. Here, y(n)","=1(=0)indicates that the class label is assigned (unassigned) to the nth feature vector x(n)",".","The discriminative function of a binary classifier based on a linear model is often defined as","f (x; θ)=θt 1x + θ0, (1)","where θ =(θ0, θt 1)t","is a model parameter vector, and θt","1x implies the inner product of θ1 and x.A binary classifier using f (x; θ) outputs a predicted class label assignment ŷ for x as ŷ(n)","=1(=0) when f (x(n)","; θ) ≥ 0(< 0).","An LRM is a binary classifier that uses the discriminative function f (x; θ). In this model, the class posterior probability distribution is defined by using a logistic function:","g(z)={1+exp(−z)}−1 . (2) That is, P (y =1|x; θ)=g(f (x; θ)) and P (y = 0|x; θ)=1− P (y =1|x; θ)=g(−f (x; θ)). The LRM determines that y(n)","=1(=0)when P (y =1|x(n)","; θ) ≥ 0.5(< 0.5), since g(0) = 0.5. The model parameter vector θ is usually estimated to maximize the likelihood of P (y|x; θ) for training dataset D = {x(m)",",y(m)","}M","m=1 and the prior probability density of θ: JR(θ)= M∑ m=1","log P (y(m) |x(m)","; θ)+logp(θ). (3) In this paper, the classifier design approach that employs this training method is called LRM-L.","By contrast, in the training method proposed by (Jansche, 2005), the discriminative function f (x; w) is estimated to maximize the F1-score of training dataset D. This training method employs an approximate form of the F1-score obtained by using a logistic function.","The F1-score is defined as F1 =2(1/P R + 1/RE)−1",", where PR and RE represent precision and recall defined as PR = C/A and RE = C/B, respectively. Here, C represents the number of data samples whose true and predicted class label assignments, y(n)","and ŷ(n)",", respectively, correspond to 1. A represents the number of data samples for which ŷ(n)","=1. B represents the number of data samples for which y(n)","=1. C, A, and B are computed for training dataset D as C =","∑M","m=1 y(m)","ŷ(m)",", A =","∑M m=1 ŷ(m)",", and B = ∑M","m=1 y(m)",".","In (Jansche, 2005), ŷ(m)","was approximated by us-","ing the discriminative and logistic functions shown","in Eqs. (1) and (2) as","ŷ(m) ≈ g(γf(x(m)","; θ)),γ>0, (4) because limγ→∞ g(γf(x(m)","; θ)) = ŷ(m)",". Then, an approximate distribution of the F1-score for training dataset D was provided as F̃1(θ)= 2","∑M m=1 g(γf(x; θ))y(m)","∑M","m=1 y(m)","+ ∑M","m=1 g(γf(x; θ)) . (5) The θ estimate for the discriminative function f (x; θ) can be computed to maximize JF (θ)= log F̃1(θ)+logp(θ) around the initial θ value by using a gradient method. In this paper, the classifier design approach that uses this training method is called LRM-F."]},{"title":"824 3 Proposed Method","paragraphs":["We propose a framework for designing a multi-label classifier based on the combination of multiple models. In our formulation, multiple models are combined with weights estimated to maximize the F1-scores of the training dataset. In this section, we show our formulation for model combination and training methods for combination weights.","3.1 Combination of Multiple Models for Multi-label Categorization Multi-label categorization is the task of selecting multiple category labels from K pre-defined category labels for each data sample. Multi-label classifiers provide a map from a feature vector x to a category label assignment vector y = (y1,...,yk,...,yK )t",", where y(n)","k =1(=0)indicates that the kth category label is assigned (unassigned) to x(n)",".","In our formulation, we first design multiple models for binary classification per category and obtain J × K discriminative functions, where J is the number of models. The discriminative function of the jth model for the kth category is denoted by fjk(x; θjk), where θjk represents the model parameter vector. Let Θ={θjk}j,k be a model parameter set. We train model parameter vectors individually with each model training algorithm and obtain the estimate Θ̂={θ̂jk}jk. Then, we define the discriminative function of our multi-label classifier by combining multiple models such as fk(x; Θ̂, w)= J∑ j=1 wj fjk(x; θ̂jk)+w0, ∀k, (6) where w =(w0,w1,...,wj ,...,wJ )t","is a weight parameter vector and is independent of k. wj provides the combination weight of the jth model, and w0 is the bias factor for adjusting the threshold of the category label assignment.","We estimate the w value to maximize the micro-averaged F1-score (Fμ), which is often used for evaluating multi-label categorization performance. The Fμ-score of training dataset D = {x(m)",", y(m)","}M","m=1 is calculated as Fμ = 2","∑M m=1","∑K k=1 y (m) k ŷ(m)","k","∑M m=1","∑K k=1 y (m) k +","∑M m=1","∑K k=1 ŷ(m)","k , (7) We provide an approximate form of the Fμ-score of the training dataset, F̃μ( Θ̂, w), by using the approximation: ŷ(m) k ≈ g(γfk(x(m)","; Θ̂, w)),γ>0, (8) as shown in Eq. (4). In our proposed method, w is estimated to maximize F̃μ( Θ̂, w).","However, training dataset D is also used to estimate Θ. Using the same training data samples for both Θ and w may lead to a bias estimation of w. Thus, we used an n-fold cross-validation of the training data samples to estimate w as in (Wolpert, 1992). Let Θ̂(−m)","be the model parameter set estimated by using n − 1 training data subsets not containing {x(m)",", y(m)","}. Then, using F̃μ = 2 ∑ m,k y (m) k g(γfk(x; Θ̂(−m)",", w)) ∑ m,k y (m) k +","∑ m,k g(γfk(x; Θ̂(−m)",", w)) , (9) we provide the objective function of w such that Jμ(w)=log F̃μ +logp(w), (10) where p(w) is a prior probability density of w. We use a Gaussian prior (Chen and Rosenfeld, 1999) with the form as p(w) ∝","∏J j=0 exp{−(wj − ρj )2","/2σ2","j }, where σj , and ρj are hyperparameters in the Gaussian prior. We compute an estimate of w to maximize Jμ(w) around the initial w value by using a quasi-Newton method. In this paper, this formulation is called model combination by micro-averaged F1-score maximization (MC-Fμ). 3.2 Other Training Methods In multi-label categorization problems, the macro-averaged F1-score (FM ) is also used to evaluate classifiers. Moreover, the average labeling F1-score (FL) has been used to evaluate the average labeling performance of classifiers for data samples (Kazawa et al., 2005). These F1-scores are computed for training dataset D as FM = 1 K K∑ k=1 2","∑M m=1 y (m) k ŷ(m)","k","∑M m=1 y (m) k +","∑M m=1 ŷ(m)","k , (11) FL = 1 M M∑ m=1 2","∑K k=1 y (m) k ŷ(m)","k","∑K k=1 y (m) k +","∑K k=1 ŷ(m)","k . (12)","Using Eq. (8), we can also obtain the approximate forms, F̃M ( Θ̂, w) and F̃L( Θ̂, w), of the FM -"]},{"title":"825","paragraphs":["and FL-scores, and then present similar objective functions to that for the Fμ-score. Therefore, in the next section, we examine experimentally the performance of classifiers obtained by estimating w to maximize F̃M ( Θ̂, w) and F̃L( Θ̂, w). In this paper, these model combination methods based on FM - and FL-scores are called MC-FM and MC-FL, respectively."]},{"title":"4 Experiments 4.1 Test Collections","paragraphs":["To evaluate our proposed method empirically, we used three test collections: Reuters-21578 (Reuters), WIPO-alpha (WIPO), and Japanese Patent (JPAT) datasets. Reuters and WIPO are English document datasets and have often been employed for benchmark tests of multi-label classifiers.","The Reuters dataset contains news articles from the Reuters newswire and consists of 135 topic categories. Following the setup in (Yang and Liu, 1999), we extracted 7770 and 3019 articles as training and test samples, respectively. A subset consisting of the training and test samples contained 90 topic categories. We removed vocabulary words included either in the stoplist or in only one article. There were 16365 vocabulary words in the dataset.","The WIPO dataset consists of patent documents categorized using the International Patent Classifica-tion (IPC) taxonomy (Fall et al., 2003). The IPC taxonomy has four hierarchical layers: Section, Class, Subclass, and Group. Using patent documents belonging to Section D (textiles; paper), we evaluated classifiers in a task that consisted of selecting assigned category labels from 160 groups for each patent document. Following the setting provided in the dataset, we extracted 1352 and 358 patent documents as training and test samples, respectively. We removed vocabulary words in the same way as for Reuters. There were 45895 vocabulary words in the dataset.","The JPAT dataset (Iwayama et al., 2007) consists of Japanese patent documents published between 1993 and 1999 by the Japanese Patent Office. These documents are categorized using a taxonomy consisting of Themes and F-terms. The themes are top-label categories, and the patent documents belonging to each theme are categorized by using F-","Reuters WIPO JPAT Nav 1.17 1.28 10.5 Nmax 15 6 40 K 90 160 268 Nds 10789 1710 2464 NLC 468 378 2430","Nds/NLC 23.1 4.52 1.01 Table 1: Statistical information of three datasets: Nav and Nmax are the average and maximum number of assigned category labels per data sample, respectively. K and Nds are the number of category labels and data samples, respectively. NLC is the number of category label combinations appearing in each dataset. terms. Using patent documents belonging to Theme 5J104, we evaluated classifiers in a task that consisted of selecting assigned category labels from 268 F-terms for each patent document. 1920 patent documents published between 1993 and 1997 were used as training samples, and 544 patent documents published between 1998 and 1999 were used test samples. We extracted Japanese nouns, verbs, and adjectives from patent documents by using a morphological analyzer named MeCab 1",", and removed vocabulary words included in only one patent document. There were 21135 vocabulary words in the dataset.","Table 1 shows statistical information about the category label assignment of the data samples for the three datasets. The average numbers of assigned category labels per data sample, Nav, for Reuters and WIPO were close to 1 and much smaller than that for JPAT. The number of category label combinations, NLC , included in JPAT was larger than those for Reuters and WIPO. These statistical information results show that JPAT is a more complex multi-label dataset than Reuters or WIPO. 4.2 Experimental Settings For text categorization tasks, we employed word-frequency vectors of documents as feature vectors input into classifiers, using the independent word-based representation, known as the Bag-of-Words (BOW) representation. We normalized the L1norms of the word-frequency vectors to 1, to mitigate the effect of vector size on computation. We did not employ any word weighting methods such as inverse document frequency (IDF).","1","http://mecab.sourceforge.net/"]},{"title":"826","paragraphs":["We constructed three multi-label text classifiers based on our proposed model combination methods, MC-Fμ, MC-FM , and MC-FL, where LRM and SVM (J =2) were employed as binary classification models combined with each method. We trained the LRM by using LRM-L described in Section 2, where a Gaussian prior was used as the prior probability density of the parameter vectors. We provided the SVM by using SVMlight 2","(SVM-L), where we employed a linear kernel function and tuned the C (penalty cost) parameter as a hyperparameter.","To evaluate our proposed method, we examined the micro- and macro-averaged, and average labeling F1-scores (Fμ, FM , and FL), of test samples obtained with the three classifiers based on MC-Fμ, MC-FM , and MC-FL. We compared the performance of the three classifiers with that of two binary classification approaches, where LRM-L or SVM-L was used for binary classification.","We also examined two binary classification approaches using LRM-F and SVM-F. For LRM-F, we used a Gaussian prior and provided the initial parameter vector with a parameter estimate obtained with LRM-L. SVM-F is a binary classifier design approach that employs SVMperf 3",". For SVM-F, we used a linear kernel function, set the L (loss parameter) parameter to maximize the F1-score, and tuned the C (penalty cost) parameter as a hyperparameter.","Moreover, we examined the performance of the Maximal Margin Labeling (MML) method (Kazawa et al., 2005), which models the map from feature vectors to category label assignment vectors, because it was reported that MML provides better performance than binary classification approaches.","We tuned the hyperparameter of SVM-F for JPAT to provide good performance for test samples, because the computational cost for training was high. We tuned the other hyperparameters by using a 10fold cross-validation of training samples. 4.3 Results and Discussion In Table 2, we show the classification performance obtained for three datasets with our proposed and other methods described in Section 4.2. We examined nine evaluation scores: the micro-averaged F1-score (Fμ), precision (Pμ), and recall (Rμ), the","2","http://svmlight.joachims.org/","3","http://svmlight.joachims.org/svm perf.html Method Fμ (Pμ/Rμ) FM (PM /RM ) FL (PL/RM ) MC-Fμ 87.0 (87.4/86.7) 51.3 (60.0/48.4) 90.0 (90.1/92.3) MC-FM 85.0 (80.8/89.5) 53.9 (54.9/58.4) 89.7 (88.5/94.1) MC-FL 86.3 (84.3/88.3) 53.4 (59.6/52.6) 90.0 (89.3/93.6) LRM-L 85.2 (87.3/83.2) 46.1 (55.0/43.1) 86.9 (87.6/88.6) LRM-F 85.2 (87.2/83.2) 47.4 (58.5/42.7) 87.0 (87.6/88.7) SVM-L 87.1 (92.9/82.0) 48.9 (58.9/45.8) 88.1 (89.3/88.8) SVM-F 82.4 (78.9/86.2) 51.4 (49.4/60.1) 87.4 (86.9/91.4) MML 87.8 (92.6/83.4) 59.3 (62.6/60.0) 91.2 (91.7/93.2) (a) Reuters Method Fμ (Pμ/Rμ) FM (PM /RM ) FL (PL/RM ) MC-Fμ 51.4 (57.3/46.6) 30.4 (35.8/30.3) 46.9 (48.3/51.5) MC-FM 48.1 (46.1/50.4) 32.2 (33.8/36.0) 46.8 (46.3/56.0) MC-FL 48.6 (45.8/51.9) 32.5 (33.4/36.5) 47.1 (46.4/56.8) LRM-L 40.5 (68.0/28.9) 22.1 (33.7/17.9) 32.7 (36.5/32.0) LRM-F 41.0 (68.6/29.2) 22.3 (34.0/18.1) 33.2 (37.0/32.4) SVM-L 41.8 (61.9/31.5) 24.4 (34.2/21.0) 35.1 (38.8/35.3) SVM-F 48.3 (53.8/43.8) 32.3 (37.4/31.8) 45.6 (47.9/49.6) MML 48.6 (54.9/43.6) 30.8 (36.5/29.7) 49.4 (56.2/48.4) (b) WIPO Method Fμ (Pμ/Rμ) FM (PM /RM ) FL (PL/RM ) MC-Fμ 41.8 (42.6/41.1) 17.5 (21.4/17.4) 40.2 (43.5/44.4) MC-FM 40.6 (35.8/46.7) 20.2 (20.4/23.1) 39.4 (37.7/50.6) MC-FL 42.1 (42.3/41.9) 17.6 (21.1/17.8) 40.5 (43.2/45.2) LRM-L 33.9 (44.4/27.4) 15.8 (20.9/14.0) 32.2 (46.5/29.9) LRM-F 36.9 (44.6/31.5) 16.9 (22.9/14.7) 35.1 (47.3/34.1) SVM-L 33.3 (39.6/28.7) 16.3 (20.9/14.6) 31.9 (42.4/31.6) SVM-F 32.2 (28.6/36.8) 19.7 (15.0/38.4) 31.0 (30.7/40.0) MML 32.7 (42.1/26.8) 14.7 (19.4/12.9) 32.2 (51.8/30.5) (c) JPAT Table 2: Micro- and macro-averaged, and average labeling F1-scores (%) with our proposed and conventional methods. macro-averaged F1-score (FM ), precision (PM ), and recall (RM ), and the average labeling F1-score (FL), precision (PL), and recall (RL) of the test samples. FM and PM were calculated by regarding both the F1-score and precision as zero for the categories where there were no data samples predicted as positive samples.","LRM-F and SVM-F outperformed LRM-L and SVM-L in terms of FM -score for the three datasets, respectively. The training methods of LRM-F and SVM-F were useful to improve the FM -scores of LRM and SVM, as reported in (Jansche, 2005; Joachims, 2005). The Fμ- and FL-scores of LRM-F were similar or better than those of LRM-L. LRM-F was effective in improving not only the FM -score but also the Fμ- and FL-scores obtained with LRM.","Let us evaluate our model combination methods."]},{"title":"827","paragraphs":["MC-Fμ provided better Fμ-scores than LRM-F and SVM-F. The FM -scores of MC-FM were similar or better than those of LRM-F and SVM-F. Moreover, MC-FL outperformed LRM-F and SVM-F in terms of FL-scores. The binary classifiers designed by using LRM-F and SVM-F were trained to maximize the F1-score for each category. On the other hand, MC-Fμ, MC-FM , and MC-FL classifiers were constructed by combining LRM and SVM with weights estimated to maximize the Fμ-, FM -, and FL-scores, respectively. The experimental results show that our training methods for combination weights were useful for obtaining better multi-label classifiers.","MC-Fμ, MC-FM , and MC-FL outperformed MML as regards the three F1-scores for JPAT. However, MML performed better for Reuters than MC-Fμ, MC-FM , and MC-FL, and provided a better FL-score for WIPO. As shown in Table 1, there were more category label combinations for JPAT than for Reuters or WIPO. As a result, there were fewer data samples for the same category label assignment for JPAT. Therefore, MML, which learns the map directly from the feature vectors to the category label assignment vectors, would have been overfitted to the training dataset for JPAT. By contrast, our model combination methods employ binary classifiers for each category, which mitigates such an overfitting problem. Our model combination methods will be useful for complex datasets where there are many category label combinations."]},{"title":"5 Conclusion","paragraphs":["We proposed a multi-label classifier design method based on model combination. The main idea be-hind our proposed method is to combine multiple models with weights estimated to maximize evaluation scores such as the micro- and macro-averaged, and average labeling F1-scores. Using three real text datasets, we confirmed experimentally that our proposed method provided similar or better performance than conventional binary classification approaches to multi-label categorization. We also confirmed that our proposed method was useful for datasets where there were many combinations of category labels. Future work will involve training our multi-label classifier by using labeled and unlabeled samples, which are data samples with and without category label assignment."]},{"title":"References","paragraphs":["David A. Bell, J. W. Guan, and Yaxin Bi. 2005. On combining classifier mass functions for text categorization. IEEE Transactions on Knowledge and Data Engineering, 17(10):1307–1319.","Stanley F. Chen and Ronald Rosenfeld. 1999. A Gaussian prior for smoothing maximum entropy models. Technical report, Carnegie Mellon University.","C. J. Fall, A. Törcsvári, K. Benzineb, and G. Karetka. 2003. Automated categorization in the international patent classification. ACM SIGIR Forum, 37(1):10–25.","Giorgio Fumera and Fabio Roli. 2005. A theoretical and experimental analysis of linear combiners for multiple classifier systems. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(6):942–956.","Zoubin Ghahramani and Hyun-Chul Kim. 2003. Bayesian classifier combination. Technical report, Gatsby Computational Neuroscience Unit, University College London.","Makoto Iwayama, Atsushi Fujii, and Noriko Kando. 2007. Overview of classification subtask at NTCIR-6 patent retrieval task. In Proceedings of the 6th NTCIR Workshop Meeting on Evaluation of Information Access Technologies (NTCIR-6), pages 366–372.","Martin Jansche. 2005. Maximum expected F-measure training of logistic regression models. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP2005), pages 692–699.","Thorsten Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of the 10th European Conference on Machine Learning (ECML ’98), pages 137–142.","Thorsten Joachims. 2005. A support vector method for multivariate performance measures. In Proceedings of the 22nd International Conference on Machine Learning (ICML’05), pages 377–384.","Hideto Kazawa, Tomonori Izumitani, Hirotoshi Taira, and Eisaku Maeda. 2005. Maximal margin labeling for multi-topic text categorization. In Advances in Neural Information Processing Systems 17, pages 649–656. MIT Press, Cambridge, MA.","Leah S. Larkey and W. Bruce Croft. 1996. Combining classifiers in text categorization. In Proceedings of the 19th ACM International Conference on Research and Development in Information Retrieval (SIGIR-96), pages 289–297.","Kai Ming Ting and Ian H. Witten. 1999. Issues in stacked generalization. Journal of Artificial Intelligence Research, 10:271–289.","David H. Wolpert. 1992. Stacked generalization. Newral Networks, 5(2):241–259.","Yiming Yang and Xin Liu. 1999. A re-examination of text categorization methods. In Proceedings of the 22nd ACM International Conference on Research and Development in Information Retrieval (SIGIR-99), pages 42–49."]},{"title":"828","paragraphs":[]}]}