{"sections":[{"title":"","paragraphs":["Proceedings of the IJCNLP 2011 System Demonstrations, pages 5–8, Chiang Mai, Thailand, November 9, 2011. c⃝2011 Asian Federation of Natural Language Proceesing"]},{"title":"Using Linguist’s Assistant for Language Description and Translation   Stephen Beale University of Maryland, Baltimore County Baltimore, MD sbeale@cs.umbc.edu     Abstract ","paragraphs":["The Linguist’s Assistant (LA) is a practical computational paradigm for describing languages. LA seeks to specify in semantic representations a large subset of possible written communication. These semantic representations then become the starting point and or-ganizing principle from which a linguist describes the linguistic surface forms of a language using LA's visual lexicon and grammatical rule development interface. The result-ing computational description can then be used in our document authoring and translation applications."]},{"title":"1 Introduction","paragraphs":["The Linguist’s Assistant (LA) is a practical computational paradigm for describing languages. LA approaches the complex task of language description from two directions. From one side, LA is built on a comprehensive semantic foundation. We combine a conceptual, ontological framework with detailed semantic features that cover (or is a beginning towards the goal of covering) the range of human communication. An elicitation procedure has been built up around this central, semantic core that systematically guides the linguist through the language description process, during which the linguist builds a grammar and lexicon that “describes” how to generate target language text from the semantic representations of the elicitation corpus. The result is a “how to” guide for the language: how does one encode a given semantic representation in the language? Coming at the problem from the other side, LA also allows the linguist to collect language data in a more conventional manner – from naturally occurring texts and linguistically motivated elicitations (for example, a linguist in Vanuatu might want to explore alienable vs. inalienable possession or serial verb constructions using naturally occurring texts). Such texts are semantically analyzed using a convenient semi-automatic document authoring interface (“authored” in our con-text means that a semantic representation has been prepared), in effect adding them to the standard elicitation corpus. Existing grammar rules and lexical information can then either be confirmed or adjusted, or new descriptive knowledge added that allows the built-in text generator to produce target text that is substantially equivalent to the elicited examples. The result is a “how did” guide for the language: how did a native speaker encode natural text or linguistically focused elicitations? We believe that the combination of semantically motivated and linguistically motivated elicitation and description provides an ideal balance. The semantic-based elicitation is general and uniform across languages. It provides an efficient and relatively comprehensive standard for describing the majority of the linguistic phenomena in a language. We have found it to be an in-valuable starting point in the description process. It is, however, impossible to produce a general semantic-based elicitation scheme that is not overly burdensome on the user. In addition, linguists typically know the “interesting,” atypical or difficult aspects of a language. This is where linguistically based elicitation is invaluable. A third approach to language description is encouraged in the LA framework: acquiring knowledge (lexicon and grammar) to cover pre-authored texts. The semantically and linguistically motivated elicitations from the first two approaches above provide a solid foundation for lexicon and grammar development, but we have found that adding to that the experience and discipline of acquiring the knowledge necessary to generate actual texts is invaluable. This is usually 5 the best opportunity for documenting phenomena that are more lexically dependent since the vocabulary in the semantic-based elicitation stage is quite limited. For this reason we include several pre-authored (i.e. semantically analyzed and ready for use in our translation module) community development texts with LA. Underlying all these approaches to knowledge acquisition in LA is a visual, semi-automatic interface for recording grammatical rules and lexical information. Figure 1 shows an example of one kind of visual interface used for “theta-grid adjustment rules.” The figure shows an English rule used to adjust the “theta grid” or “case frame” of an English verb. Grammatical rules typically describe how a given semantic structure is realized in the language. The whole gamut of linguistic phenomena is covered, from morphological alternations (Figure 2) to case frame specifications to phrase structure ordering (Figure 3) to lexical collocations – and many others. These grammatical rules interplay with a rich lexical description interface that allows for as-signment of word-level features and the descrip-","tion of lexical forms","associated with individual","roots (Figure 4). Currently,","the linguist is responsible for","the creation of rules, albeit","with a natural, visual","interface that often is able to","set up the requisite input","semantic structures","automatically. We continue","work on a module that will","allow the semi-automatic","generation of rules similar to","research in the BOAS (McShane, et al., 2002), LinGO (Bender, at al., 2010), PAWS (Black and Black, 2009) and Avenue (Probst, et al., 2003) projects. Such a module will, we believe, make LA accessible to a larger pool of linguists. We also provide a grow-ing list of rule templates that linguists can use to describe common linguistic phenomena. Integrated with these elicitation and description tools is a text generator that allows for immediate confirmation of the validity of grammatical rules and lexical information. We also provide an interface for tracking the scope and examples of grammatical rules. This minimizes the possibility of conflicting or duplicate rules while providing the linguist a convenient index into the work already accomplished. And finally, we provide a utility for producing a written description of the language - after all, a computational description of a language is of no practical use (outside of translation applications) unless it can be conveniently referenced. Refer to Beale (submitted) for a comprehensive description of Linguist’s Assistant. Figure 1. Visual Interface for grammatical rules Figure 2. Morphological alternation rule Figure 3. Phrase structure ordering rule 6  Figure 4. Lexical forms for Spanish  LA has been used to produce extensive grammars and lexicons for Jula (a Niger-Congo language), Kewa (Papua New Guinea), North Tanna (Vanuatu), Korean and English. Work continues in two languages of Vanuatu, with additional languages planned in the near future. The result-ing computational resources have been used in our separate document authoring and translation applications to produce a significant amount of high-quality translations in each of these languages. Figures 5 and 6 present translations of a section of a medical text on AIDS into English Korean. Please reference Beale et al. (2005) and Allman and Beale (2004; 2006) for more information on using LA in translation projects, and for documentation on the evaluations of the translations produced. Note: LA can be used as the language-description module within our larger applications called TA (The Translator's Assistant, for translating health and community development materials, as well as “authoring” new texts) or TBTA (The Bible Translator's Assistant, for those interested in Bible Translation). We argue that the high quality results achieved in translation projects demonstrate the quality and coverage of the underlying language description that LA produces.","","  Figure 5. English translation of a medical text  Figure 6. Korean translation of a medical text"]},{"title":"2 Content of the Demonstration","paragraphs":["A partial example of the content of the proposed","demonstration can be found at","http://ilit.umbc.edu/sbeale/LA/ under the “Demo","Videos” link. These demonstration videos are","part of an online journal article (Beale, submit-","ted) that describes LA in depth. A draft of this","journal article can be found at the same website","under the “Publications” link.","We will be prepared to demonstrate, as appro-","priate to the interests of a particular group of par-","ticipants, the following: • An overview of LA • The semantic representation system • The document authoring system that en-","ables the semi-automatic analysis of new","texts or elicitations • How to create lexicons that are appropri-","ate for different kinds of languages • How to use the visual rule creation inter-","face to create various kinds of grammati-","cal rules • Multilingual examples of lexicons • Multilingual examples of grammatical","rules • Multilingual examples of translation re-","sults"," We will also prepare 10 minute modules with “hands-on” examples for any interested participants who wish to take a bit more time investigating LA."]},{"title":"3 Previous Experience in Teaching LA","paragraphs":["LA is the basis of a semester-long Honor’s College class at the University of Maryland, Balti-more County. In that class we present an overview of different types of linguistic phenomena. We then use LA to encode descriptive knowledge of multi-lingual examples of each. The class size is 25 students. 7","We have also prepared tutorials and online demonstrations (http://ilit.umbc.edu/sbeale/LA/) and informally used LA with a number of field linguists."]},{"title":"4 Required Resources","paragraphs":["We require a single projector. Internet service is not necessary."]},{"title":"5 Acknowledgements","paragraphs":["The author gratefully acknowledges the partnership of Tod Allman from the University of Texas, Arlington. Dr. Allman is co-developer of LA. "]},{"title":"References","paragraphs":["Allman, Tod. 2010. The translator‘s assistant: a multi-lingual natural language generator based on linguistic universals, typologies, and primitives. Arlington, TX: University of Texas dissertation.","Tod Allman and Stephen Beale. 2006. “A natural language generator for minority languages,” in Proceedings of SALTMIL, Genoa, Italy.","Tod Allman and Stephen Beale. 2004. “An environment for quick ramp-up multi-lingual authoring,” International Journal of Translation 16(1).","Stephen Beale. Submitted. “Documenting endangered languages with linguist’s assistant.” Language Documentation and Conservation Journal. Draft available at: http://ilit.umbc.edu/sbeale/LA/papers/DEL-for-LDC-journal.pdf","Stephen Beale, S. Nirenburg, M. McShane, and Tod Allman. 2005. “Document authoring the Bible for minority language translation,” in Proceedings of MT-Summit, Phuket, Thailand.","Emily Bender, S. Drellishak, A. Fokkens, M. Goodman, D. Mills, L. Poulson, and S. Saleem. 2010. “Grammar prototyping and testing with the LinGO grammar matrix customization system,” in Proceedings of the ACL 2010 System Demonstrations.","Sheryl Black and Andrew Black. 2009. “PAWS: parser and writer for syntax: drafting syntactic grammars in the third wave,” http://www.sil.org/silepubs/PUBS/51432/SILForu m2009-002.pdf.","Marjorie McShane, Sergei Nirenburg, Jim Cowie, and Ron Zacharski. 2002. “Embedding knowledge elicitation and MT systems within a single architecture,” Machine Translation 17(4), pp.271-305.","Katharina Probst, Lori Levin, Erik Petersen, Alon Lavie and Jaime Carbonell. 2003. “MT for minority languages using elicitation-based learning of syntactic transfer rules,” Machine Translation 17(4), pp.245-270.                                               8"]}]}