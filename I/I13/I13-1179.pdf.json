{"sections":[{"title":"","paragraphs":["International Joint Conference on Natural Language Processing, pages 1257–1263, Nagoya, Japan, 14-18 October 2013."]},{"title":"Constituency and Dependency Relationship from a Tree Adjoining Grammar and Abstract Categorial Grammar Perspective Aleksandre Maskharashvili and Sylvain Pogodalla INRIA, 54600 Villers-lès-Nancy, France LORIA, UMR 7503, 54506 Vandœuvre-lès-Nancy, France Sylvain.Pogodalla@inria.fr Aleksandre.Mashkharashvili@inria.fr Abstract","paragraphs":["This paper gives an Abstract Categorial Grammar (ACG) account of (Kallmeyer and Kuhlmann, 2012)’s process of transformation of the derivation trees of Tree Adjoining Grammar (TAG) into dependency trees. We make explicit how the requirement of keeping a direct interpretation of dependency trees into strings results into lexical ambiguity. Since the ACG framework has already been used to provide a logical semantics from TAG derivation trees, we have a unified picture where derivation trees and dependency trees are related but independent equivalent ways to account for the same surface–meaning relation."]},{"title":"1 Introduction","paragraphs":["Tree Adjoining Grammars (TAG) (Joshi et al., 1975; Joshi and Schabes, 1997) is a tree grammar formalism relying on two operations between trees: substitution and adjunction. In addition to the tree generated by a sequence of such operations, there is a derivation tree which records this sequence. Derivation trees soon appeared as good candidates to encode semantic-like relations between the elementary trees they glue together. However, some mismatch between these trees and the relative scoping of logical connectives and relational symbols, or between these trees and the dependency relations, have been observed. Solv-ing these problems often leads to modifications of derivation tree structures (Schabes and Shieber, 1994; Kallmeyer, 2002; Joshi et al., 2003; Rambow et al., 2001; Chen-Main and Joshi, To appear).","While alternative proposals have succeeded in linking derivation trees to semantic representations using unification (Kallmeyer and Romero, 2004; Kallmeyer and Romero, 2007) or using an encoding (Pogodalla, 2004; Pogodalla, 2009) of TAG into the ACG framework (de Groote, 2001), only recently (Kallmeyer and Kuhlmann, 2012) has proposed a transformation from standard derivation trees to dependency trees.","This paper provides an ACG perspective on this transformation. The goal is twofold. First, it exhibits the underlying lexical blow up of the yield functions associated with the elementary trees in (Kallmeyer and Kuhlmann, 2012). Second, using the same framework as (Pogodalla, 2004; Pogodalla, 2009) allows us to have a shared perspective on a phrase-structure architecture and a dependency one and an equivalence on the surface-meaning relation they define."]},{"title":"2 Abstract Categorial Grammars","paragraphs":["ACGs provide a framework in which several grammatical formalisms may be encoded (de Groote and Pogodalla, 2004). They generate languages of linear λ-terms, which generalize both string and tree languages. A key feature is to provide the user direct control over the parse structures of the grammar, the abstract language, which allows several grammatical formalisms to be defined in terms of ACG, in particular TAG (de Groote, 2002). We refer the reader to (de Groote, 2001; Pogodalla, 2009) for the details and introduce here only few relevant definitions and notations.","Definition. A higher-order linear signature is de-","fined to be a triple Σ = ⟨A, C, τ ⟩, where: • A is a finite set of atomic types (also noted","AΣ), • C is a finite set of constants (also noted CΣ), • and τ is a mapping from C to TA the set of","types built on A: TA ::= A|TA ⊸ TA (also","noted TΣ).","A higher-order linear signature will also be called 1257 a vocabulary. Λ(Σ) is the set of λ-terms built on Σ, and for t ∈ Λ(Σ) and α ∈ TΣ such that t has type α, we note t :Σ α (the Σ subscript is omitted when it is obvious from the context).","Definition. An abstract categorial grammar is a","quadruple G = ⟨Σ, Ξ, L, s⟩ where:","1. Σ and Ξ are two higher-order linear signatures, which are called the abstract vocabulary and the object vocabulary, respectively;","2. L : Σ −→ Ξ is a lexicon from the abstract vocabulary to the object vocabulary. It is a homomorphism1","that maps types and terms built on Σ to types and terms built on Ξ. We note t:=G u if L(t) = u and omit the G subscript if obvious from the context.","3. s ∈ TΣ is a type of the abstract vocabulary, which is called the distinguished type of the grammar. Definition. The abstract language of an ACG G = ⟨Σ, Ξ, L, s⟩ is A(G ) = {t ∈ Λ(Σ) | t :Σ s}","The object language of the grammar O(G ) = {t ∈ Λ(Ξ) | ∃u ∈ A(G ). t = LG(u)}","Since there is no structural difference between the abstract and the object vocabulary as they both are higher-order signatures, ACGs can be combined in different ways. Either by having a same abstract vocabulary shared by several ACGs in order to make two object terms (for instance a string and a logical formula) share the same underlying structure as Gd-ed trees and GLog in Fig. 1. Or by mak-ing the abstract vocabulary of an ACG the object vocabulary of another ACG, allowing the latter to control the admissible structures of the former, as Gyield and Gd-ed trees in Fig. 1."]},{"title":"3 TAG as ACG","paragraphs":["As Fig. 1 shows, the encoding of TAG","into ACG uses two ACGs Gd-ed trees =","⟨Σderθ, Σtrees, Ld-ed trees, s⟩ and Gyield =","⟨Σtrees, Σstring, Lyield, τ ⟩. We exemplify the","encoding2","of a TAG analyzing (1)3 1 In addition to defining L on the atomic types and on the","constants of Σ, we have: • If α ⊸ β ∈ TΣ then L(α ⊸ β) = L(α) ⊸ L(β). • If x ∈ Λ(Σ) (resp. λx.t ∈ Λ(Σ) and t u ∈ Λ(Σ)) then","L(x) = x (resp. L(λx.t) = λx.L(t) and L(t u) =","L(t) L(u))","with the proviso that for any constant c :Σ α of Σ we have","L(c) :Ξ L(α). 2 We refer the reader to (Pogodalla, 2009) for the details. 3 The TAG literature typically uses this example,","and (Kallmeyer and Kuhlmann, 2012) as well, to show the","mismatch between the derivation trees and the expected se- Λ(Σderθ) Λ(Σtrees) Gd-ed trees Λ(Σstring) Gyield Λ(ΣLog) GLog Figure 1: ACG architecture for TAG (1) John Bill claims Mary seems to love","This sentence is usually analyzed in TAG with","a derivation tree where the to love component","scopes over all the other arguments, and where","claims and seems are unrelated, as Fig. 2(a) shows.","The three higher-order signatures are:","Σderθ: Its atomic types include s, vp, np, sA, vpA. . . where the X types stand for the categories X of the nodes where a substitution can occur while the XA types stand for the categories X of the nodes where an adjunction can occur. For each elementary tree γlex. entry it contains a constant Clex. entry whose type is based on the adjunction and substitution sites as Table 1 shows. It additionally contains constants IX : XA that are meant to provide a fake auxiliary tree on adjunction sites where no adjunction actually takes place in a TAG derivation.","Σtrees: Its unique atomic type is τ the type of trees. Then, for any X of arity n belong-ing to the ranked alphabet describing the elementary trees of the TAG, we have a constant Xn :","n times","{ }} {","τ ⊸ · · · ⊸ τ ⊸ τ","Σstring: Its unique atomic type is σ the type of strings. The constants are the terminal symbols of the TAG (with type σ), the concatena-tion + : σ ⊸ σ ⊸ σ and the empty string ε : σ.","Table 1 illustrates Ld-ed trees.4","L yield is defined as","follows: • Lyield(τ ) = σ; • for n > 0, Lyield(Xn) = λx1 · · · xn.x1 +","· · · + xn; • for n = 0, X0 : τ represents a terminal sym-","mantics and the relative scopes of the predicates. 4 With L","d-ed trees(XA) = τ ⊸ τ and for any other type X, Ld-ed trees(XA) = τ . 1258","bol and Lyield(X0) = X. Then, the derivation tree, the derived tree, and the yield of Fig. 2 are represented by: t0 = Cto love (Cclaims Is CBill ) (Cseems Ivp) CMary CJohn Ld-ed trees(t0) = s2 (np1 John) (s2 (np1 Bill) (vp2 claims (s2 (np1 Mary) (vp2 seems (vp1 to love))) Lyield(Ld-ed trees(t0)) = John + Bill + claims","+ Mary + seems + to love γto love γJohnγMaryγseemsγclaims γBill (a) Derivation tree claims seems to love JohnMary Bill (b) Dep. tree s s vp s vp vp to love seems np Mary claims np Bill np John (c) Derived tree Figure 2: John Bill claims Mary seems to love"]},{"title":"4 From Derivation Trees to Dependency Trees","paragraphs":["(Kallmeyer and Kuhlmann, 2012)’s process to translate derivation trees into dependency trees is a two-step process. The first one does the actual transformation, using macro-tree transduction, while the second one modifies the way to get the yield from the dependency trees rather than from the derivation ones. 4.1 From Derivation To Dependency Trees This transformation aims at modeling the differences in scope of the argument between the derivation tree for (1) shown in Fig. 2(a) and the corresponding dependency tree shown in Fig. 2(b). For instance, in the derivation trees, claims and seems are under the scope of to love while in the dependency tree this order is reversed. According to (Kallmeyer and Kuhlmann, 2012), such edge reversal is due to the fact that an edge between a complement taking adjunction (CTA) and an initial tree has to be reversed, while the other edges remain unchanged.","Moreover, in case an initial tree accepts several adjunction of CTAs, (Kallmeyer and Kuhlmann, 2012) hypothesizes that the farther from the head a CTA is, the higher it is in the dependency tree. In the case of to love, the s node is farther from the head than the vp node. Therefore any adjunction on the s node (e.g. claims) should be higher than the one on the vp node (e.g. seems) in the dependency tree. We represent the dependency tree for (1) as t′","0 = dclaims dBill (dseems(dto love dJohn dMary )).","In order to do such reversing operations, (Kallmeyer and Kuhlmann, 2012) uses Macro Tree Transducers (MTTs) (Engelfriet and Vogler, 1985). Note that the MTTs they use are linear, i.e. non-copying. It means that any node of an input tree cannot be translated more than once. (Yoshinaka, 2006) has shown how to encode such MTTs as the composition G ′","◦ G −1","of two ACGs, and we will use a very similar construct. 4.2 The Yield Functions (Kallmeyer and Kuhlmann, 2012) adds to the transformation from derivation trees to dependency trees the additional constraint that the string associated with a dependency structure is computed directly from the latter, without any refer-ence to the derivation tree. To achieve this, they use two distinct yield functions: yieldTAG from derivation trees to strings, and yielddep from dependency trees to strings.","Let us imagine an initial tree γi and an auxiliary tree γa with no substitution nodes. The yield of the derived tree resulting from the operations of the derivation tree γ of Fig. 3 defined in (Kallmeyer and Kuhlmann, 2012) is such that","yieldTAG(γ) = a1 + w1 + a2 + w2 + a3","= (yieldTAG(γi ))(yieldTAG(γa))","= (λ⟨x1, x2⟩.a1 + x1 + a2 + x2","+ a3)⟨w1, w2⟩ where ⟨x, y⟩ denotes a tuple of strings.","Because of the adjunction, the corresponding dependency structure has a reverse order (γ′","= γ′ a(γ′","i )), the requirement on yielddep imposes that","yielddep(γ′ ) = a","1 + w1 + a2 + w2 + a3","= (yielddep(γ′","a))(yielddep(γ′","i ))","= (λ⟨x1, x2, x3⟩.x1 + w1 + x2 + w2","+ x3)⟨a1, a2, a3⟩","In the interpretation of derivation trees as strings, initial trees (with no substitution nodes) 1259","Abstract constants of Σ","derθ Their images by Σ","derθ The corresponding TAG trees","C","John : np c John : τ","= np","1 John γ","John = np John","C","seems : vp","A ⊸ vp","A c seems : (τ ⊸ τ) ⊸ (τ ⊸ τ)","= λo","vx.v (vp","2 seems x) γ","seems = vp seems vp∗","C","to love : s A ⊸ vp","A ⊸ np ⊸ np ⊸ s c","to love",": (τ ⊸ τ) ⊸ (τ ⊸ τ) ⊸ τ ⊸ τ ⊸ τ","= λo avso.s","2 o (a (s","2 s (v (vp","1 to love)))) γ to love = s np s np vp to love","C","claims : s","A ⊸ vp","A","⊸ np ⊸ s","A c","claims : (τ ⊸ τ) ⊸ (τ ⊸ τ) ⊸ τ ⊸ τ ⊸ τ","= λo","avsc.a (s","2 s (a (vp","2 claims c))) γ","claims = s np vp claims s∗ I X : X","A λx.x : τ ⊸ τ Table 1: TAG as ACG: the Ld-ed trees lexicon are interpreted as functions from tuples of strings into strings, and auxiliary trees as tuples of strings. The interpretation of dependency trees as strings leads us to interpret initial trees as tuples of strings and auxiliary trees as function from tuples of strings to strings. γi = Y X a1 a3 a2 X γa = X","X∗ w1 w2","γ = γi γa Figure 3: Yield from derivation trees","Indeed, an initial tree can have several adjunction sites. In this case, to be ready for another adjunction after a first one, the first result itself should be a tuple of strings. So an initial tree (with no substitution nodes) with n adjunction sites is interpreted as a (2n + 1)-tuple of strings. Accordingly, depending on the location where it can adjoin, an auxiliary tree is interpreted as a function from (2k + 1)-tuple of strings to (2k − 1)-tuple of strings.","Taking into account that to model trees having the substitution nodes is then just a matter of adding k string parameters where k is the number of substitution nodes in a tree. Then using the interpretation: yielddep(dto love) = λx11 x21.⟨x11, x21, to love, ε, ε⟩ yielddep(dseems) = λ⟨x11, x12, x13, x14, x15⟩. ⟨x11, x12 + seems + x13x14, x15⟩ yielddep(dclaims) = λx21 ⟨x11, x13, x14⟩. ⟨x11 + x21 + claims + x14 + x13⟩","we can check that yielddep(dclaims dBill (dseems(dto love dMary dJohn))) = ⟨John + Bill + claims + Mary + seems + to love⟩ Remark. The given interpretation of dto love is only valid for structures reflecting adjunctions both on the s node and on the vp node of γto love. So actually, an initial tree such as γto love yields four interpretations: one with the two adjunctions (5-tuple), two with one adjunction either on the vp node or on the s node (3-tuple), and one with no adjunction (1-tuple). The two first cases correspond to the sentences (2a) and (2b).5","Accordingly, we need multiple interpretations for the auxiliary trees, for instance for the two occurrences of seems in (3) where the yield of the last one yielddep(dseems) maps a 5-tuple to a 3-tuple, and the yield of the first one maps a 3-tuple to a 3-tuple. And yielddep(dclaims) maps a 3-tuple to a 1-tuple of strings. We will mimic this behavior by introduc-ing as many different non-terminal symbols for the dependency structures in our ACG setting. (2) a. John Bill claims Mary seems to love","b. John Mary seems to love (3) John Bill seems to claim Mary seems to love Remark. Were we not interested in the yields but only in the dependency structures, we wouldn’t have to manage this ambiguity. This is true both for (Kallmeyer and Kuhlmann, 2012)’s approach and ours. But as we have here a unified framework for the two-step process they propose, this lexical blow up will result in a multiplicity of types as Section 5 shows.","5","As the two other ones are not correct English sentences, we can rule them out. However, from a general perspective, we should take such cases into account. 1260"]},{"title":"5 Disambiguated Derivation Trees","paragraphs":["In order to encode the MTT acting on derivation trees, we introduce a new abstract vocabulary Σ′","derθ for disambiguated derivation trees as in (Yoshinaka, 2006). Instead of having only one constant for each initial tree as in Σderθ, we have as many of them as adjunction combinations. For instance, γto love gives rise to the several constants in Σ′","derθ: C11","to love : s31","A ⊸ vp53","A ⊸ np ⊸ np ⊸ s C10 to love : s31","A ⊸ np ⊸ np ⊸ s C01 to love : vp31","A ⊸ np ⊸ np ⊸ s C00 to love : np ⊸ np ⊸ s","Here, C11","to love is used to model sentences where both","adjunctions are performed into γto love. C10","to love and C01 to love are used for sentences where only one adjunction at the s or at the vp node occurs respectively. C00","to love : np ⊸ np ⊸ s is used when no adjunction occurs.6","This really mimics (Yoshinaka, 2006)’s encoding of (Kallmeyer and Kuhlmann, 2012) MTT rules: ⟨q0, Cto love(x1, x2, x3, x4)⟩ →","⟨q2, x2⟩(⟨q4, x4⟩(dto love(⟨q1, x1⟩, ⟨q3, x3⟩))) ⟨q0, Cto love(x1, x2, x3)⟩ →","⟨q2, x2⟩(dto love(⟨q1, x1⟩, ⟨q3, x3⟩)) ⟨q0, Cto love(x1, x2, x3)⟩ →","⟨q4, x4⟩(dto love(⟨q1, x1⟩, ⟨q3, x3⟩)) ⟨q0, Cto love(x1, x2)⟩ →","dto love(⟨q1, x1⟩, ⟨q3, x3⟩) where the states q0, q1, q2, q3 and q4 are given the names s, np, s31","A , np, and vp53","A resp.","Moreover, s31","A , vp31","A , . . . , vp2(n+1)2(n−1)","A . . . are designed in order to indicate that a given adjunction has n adjunctions above it (i.e. which scope over it). The superscripts (2(n + 1))(2(n − 1)) express that an adjunction that has n adjunctions above it is translated as a function that takes a 2(n + 1)-tuple as argument and returns a 2(n − 1)- tuple.","To model auxiliary trees which are CTAs we need a different strategy. For each such adjunction tree T we have two sets in Σ′","derθ: S1","T the set of constants which can be adjoined into initial trees and S2","T the set of constants which can be adjoined into auxiliary trees.","For instance, γseems would generate S1","seems that","includes C11","seems31, C10 seems31, C01","seems31, C00","seems31,","C11","seems53 etc. C00","seems31 is of type vp31","A , which means","that it can be adjoined into initial trees which","contain vp31","A as its argument type (e.g. C01","to love). 6 See note 5. C11 seems31 is of type s3−3","A ⊸ vp3−3","A ⊸ vp31","A . It means it expects two adjunctions at its s and vp nodes respectively and returns back a term of type vp31 A (as in John claims to appear to seem to love Mary). Here, s3−3","A and vp3−3","A are types used for modeling adjunction on adjunctions. When an auxiliary tree is adjoined into another auxiliary tree as in (3), we do not allow the former to modify the tupleness of the latter. For instance γseems would generate S2","seems that in-","cludes C11","seems3−3, C10 seems3−3, C01","seems3−3, C00","seems3−3, C11 seems5−5 etc. C00","seems3−3 has a subscript (k−k) that correspond to adjunctions into adjunction trees. The type of C00","seems3−3 is vp3−3","A , meaning that it can directly adjoin into auxiliary trees which have arguments of type vp3−3","A . C01","seems3−3 is of type","vp3−3 A ⊸ vp3−3","A , which means that it itself ex-","pects an adjunction and the result can be adjoined","into another adjunction tree. Now it is easy to define Lder from Σ′","derθ to Σderθ.","It maps every type X ∈ Σ′ derθ to X ∈ Σderθ and ev-","ery XN A to XA; types without numbers are mapped","to themselves, i.e. s to s, np to np, etc. Moreover,","the different versions of some constant, that were","introduced in order to extract the yield, are trans-","lated using only one constant and fake adjunctions.","For instance: Lder(C11","to love) = Cto love Lder(C10","to love) = λxso.Cto love x Ivp s o Lder(C00","to love) = Cto love Is Ivp"]},{"title":"6 Encoding a Dependency Grammar","paragraphs":["The ACG of (Pogodalla, 2009) mapping TAG derivation trees to logical formulas already encoded some reversal of the predicate-argument structure. Here we map the disambiguated derivation trees to dependency structures. The vocabulary that define these dependency trees is Σdep. It is also designed to allow us to build two lexicons from it to Σstring (to provide a direct yield function) and to ΣLog (to provide a logical semantic representation).","In Σdep constants are typed as follows: d5","to love : τ 1 np ⊸ τ 1","np ⊸ τ 5",". Here, τ 1","np is the type into which the np type is translated from disambiguated derivation tree. The superscript 1 indicates that τ 1","np will be translated into 1-tuple into Σstring. Now, it is easy to see that in order to translate C10","to love : s31","a ⊸ np ⊸ np ⊸ s and C01 to love : vp31","a ⊸ np ⊸ np ⊸ s, we need to 1261","have constants like: d3","s","to love : τ 1","np ⊸ τ 1","np ⊸ τ 3","and","d3v","to love : τ 1","np ⊸ τ 1","np ⊸ τ 3",".","Moreover, we have constants for adjunction","trees, like d5","seems : τ 5","⊸ τ 3","that will be used in","the translation of C01","seems53, and d5−5","seems : τ 5","⊸ τ 5","for C00","seems5−5. Furthermore, additional constants","are needed to have things correctly typed. For this","reason, the constants d1","3, d3","5 etc. are introduced.","Each d2n−1","2n+1 has type τ 2n+1","⊸ τ 2n−1",".","Finally, non-CTAs like nA, nd","A, vpA and sA are","translated as τ 2","nA, τ 2","nd","A",", τ 2","vp, and τ 2","s respectively. A","superscript 2 indicates that they are modeled as 2-","tuples in Σstring. Now we can define Ldep, the lexicon from Σ′","derθ","to Σdep translating disambiguated derivation trees","into dependency trees: Ldep(s) = τ 1 Ldep(np) = τ 1","np Ldep(X (2n+1)(2n−1) A ) = τ 2n+1","⊸ τ 2n−1","Ldep(X","(2n+1)(2n+1)","A ) = τ 2n+1","⊸ τ 2n+1","for X ∈ s31","A , vp53","A . . .","Ldep(C11 to love) = λS V s o.S(V (d5","to love s o))","Ldep(C10 to love) = λS s o.S(d3","to love s o)","Ldep(C01 to love) = λS V s o.V (d3","to love s o)","Ldep(C00 seems53) = λx.d5","seemsx","Ldep(C01 seems53) = λV x.d53(V (d5","seems x))","Ldep(C11 seems53) = λS V x.d53(S(V (d5","seems x)))","Ldep(C01 seems5−5) = λV x.V (d5−5","seems x)","Ldep(C00 seems5−5) = λx.d5−5","seems x Furthermore, we describe ΣLog 7","and define two lexicons: Ldep. yield : Σdep −→ Σstring and Ldep. log : Σdep −→ ΣLog. Table 2 provides examples of these two translations. Ldep. yield: It translates any atomic type τ n","or τ n","X with X ∈ {nA, nd","A . . .} as a n-tuple of string (σ ⊸ σ · · · ⊸ σ) } {{ }","n+1-times ⊸ σ.8","ΣLog: Its atomic types are e and t and we have the constants: john, mary, bill of type e, the constant love of type e ⊸ e ⊸ t, the constant claim of type e ⊸ t ⊸ t and the constant seem of type t ⊸ t.","Ldep. log: Each τ 2(n+1)","is mapped to t, τ 1","np is mapped to (e ⊸ t) ⊸ t, τ 2","nAd is mapped to (e → t) ⊸ (e ⊸ t) ⊸ t. The types 7 We refer the reader to (Pogodalla, 2009) for the details. 8 We encode a n-tuple ⟨M1, . . . , Mn⟩ as","λf.f M1 M2 . . . Mn where each Mi has type σ.","of non-complement-taking verbal or senten-","tial adjunctions τ 2","vp and τ 2","s are translated as","t ⊸ t. Let us show for the sentence (1) how the ACGs","defined above work with the data provided in","Table 2. Its representation in Σ′","derθ is: T0 = C11 to love (Cclaims31 CBill ) Cseems53 CMary CJohn. Then","Lder(T0) = t0","and","Ldep(T0) = d1 claimsdBill (d53","seems(d5","to lovedMary dJohn)) = t′","0 and finally Ldep. yield(t′","0) = Lyield(Ld-ed trees(t0)) = λf.f (John + (Bill + (claims + ((Mary + ((seems + to love) + ε)) + ε)))) and Ldep. log(t′","0) = claim bill (seem (love john mary)"]},{"title":"7 Conclusion","paragraphs":["In this paper, we have given an ACG perspective on the transformation of the derivation trees of TAG to the dependency trees proposed in (Kallmeyer and Kuhlmann, 2012). Figure 4 illustrates the architecture we propose. This transformation is a two-step process using first a macro-tree transduction then an interpretation of dependency trees as (tuples of) strings. It was known from (Yoshinaka, 2006) how to encode a macro-tree transducer into a Gdep◦G −1","der ACG composition. Dealing with typed trees to represent derivation trees allows us to provide a meaningful (wrt. the TAG formalism) abstract vocabulary Σ′","derθ encoding this macro-tree transducer. The encoding of the second step then made explicit the lexical blow up for the interpretation of the functional symbols of the dependency trees in (Kallmeyer and Kuhlmann, 2012)’s construct. It also provides a push out (in the categorical sense) of the two morphisms from the disambiguated derivation trees to the derived trees and to the dependency trees. The diagram is completed with the yield function from the derived trees and from the dependency trees to the string vocabulary.","Finally, under the assumption of (Kallmeyer and Kuhlmann, 2012) of plausible dependency structures, we get two possible grammatical approaches to the surface-semantics relation that are related but independent: it can be equivalently modeled using either a phrase structure or a dependency model. 1262 Abstract constants of Their images by Ldep. yield Their images by Ldep. log Σdep dJohn : τ 1","np John λP.P john","d5","to love : τ 1 np ⊸ τ 1","np ⊸ τ 5","λS O.λf.f O S to love ε ε λO S.S(λx.O(λy.(love x y)))","d3s","to love : τ 1 np ⊸ τ 1","np ⊸ τ 3","λS O.λf.f O (S + to love) ε λO S.S(λx.O(λy.(love x y)))","d3v","to love : τ 1 np ⊸ τ 1","np ⊸ τ 3","λS O.λf.f (O + S) to love ε λO S.S(λx.O(λy.(love x y)))","d1","claims : τ 1 np ⊸ τ 1","np ⊸ τ 1","λS c.λf.c(λx1 x2 x3.f(x1 + S + claims + x2 + x3)) λS c.S(λx.claim x c)","d3","claims : τ 1 np ⊸ τ 1","np ⊸ τ 3","λS c.λf.c(λx1 x2 x3.f(x1 + S) (claims + x2 + x3)) λS c.S(λx.claim x c)","d5−5","seems : τ 5","⊸ τ 5","λc.λf.c(λx1 . . . x5.f x1 (x2 + seems + x3 + x4)x5) λc.seem c","d5","seems : τ 5","⊸ τ 3","λc.λf.c(λx1 . . . x5.f x1 x2 (seems + x3) x4 x5) λc.seem c","d2n−1","2n+1 : τ 2n+1","⊸ τ 2n−1","λgf.g(λx1 . . . xn.f x1 . . . (xn + xn+1 + xn+2) . . . x2n+1) λx.x : t ⊸ t Table 2: Lexicons for yield and semantics from the dependency vocabulary derivation trees Λ(Σderθ)","disambiguated derivation trees Λ(Σ′","derθ) Lder derived trees Λ(Σtrees) Ld-ed trees strings Λ(Σstring) Lyield dep. trees Λ(Σdep) Ldep Ldep. yield logical formulas Λ(ΣLog) Ldep. log Figure 4: General architecture"]},{"title":"References","paragraphs":["Joan Chen-Main and Aravind K. Joshi. To appear. A dependency perspective on the adequacy of tree local multi-component tree adjoining grammar. Journal of Logic and Computation.","Philippe de Groote and Sylvain Pogodalla. 2004. On the expressive power of Abstract Categorial Grammars: Representing context-free formalisms. Journal of Logic, Language and Information, 13(4):421– 438.","Philippe de Groote. 2001. Towards abstract categorial grammars. In Proceedints of ACL, pages 148–155.","Philippe de Groote. 2002. Tree-adjoining grammars as abstract categorial grammars. In Proceedings of TAG+6, pages 145–150. Università di Venezia.","Joost Engelfriet and Heiko Vogler. 1985. Macro tree transducers. J. Comput. Syst. Sci., 31(1):71–146.","Aravin K. Joshi and Yves Schabes. 1997. Tree-adjoining grammars. In G. Rozenberg and A. Salomaa, editors, Handbook of formal languages, volume 3, chapter 2. Springer.","Aravind K. Joshi, Leon S. Levy, and Masako Takahashi. 1975. Tree adjunct grammars. Journal of Computer and System Sciences, 10(1):136–163.","Aravind K. Joshi, Laura Kallmeyer, and Maribel Romero. 2003. Flexible composition in ltag: Quantifier scope and inverse linking. In Harry Bunt, Ielka van der Sluis, and Roser Morante, editors, Proceedings of IWCS-5.","Laura Kallmeyer and Marco Kuhlmann. 2012. A formal model for plausible dependencies in lexicalized tree adjoining grammar. In Proceedings of TAG+11, pages 108–116.","Laura Kallmeyer and Maribel Romero. 2004. Ltag semantics with semantic unification. In Proceedings of TAG+7, pages 155–162.","Laura Kallmeyer and Maribel Romero. 2007. Scope and situation binding for ltag. Research on Language and Computation, 6(1):3–52.","Laura Kallmeyer. 2002. Using an enriched tag derivation structure as basis for semantics. In Proceedings of TAG+6.","Sylvain Pogodalla. 2004. Computing Semantic Representation: Towards ACG Abstract Terms as Derivation Trees. In Proceedints of TAG+7, pages 64–71, Vancouver, BC, Canada. http://hal.inria. fr/inria-00107768.","Sylvain Pogodalla. 2009. Advances in Abstract Categorial Grammars: Language Theory and Linguistic Modeling. ESSLLI 2009 Lecture Notes, Part II. http://hal.inria.fr/hal-00749297.","Owen Rambow, K. Vijay-Shanker, and David Weir. 2001. D-Substitution Grammars. Computational Linguistics.","Yves Schabes and Stuart M. Shieber. 1994. An alternative conception of tree-adjoining derivation. Computational Linguistics, 20(1):91–124.","Ryo Yoshinaka. 2006. Extensions and Restrictions of Abstract Categorial Grammars. Phd, University of Tokyo. 1263"]}]}