{"sections":[{"title":"","paragraphs":["The Companion Volume of the Proceedings of IJCNLP 2013: System Demonstrations, pages 29–32, Nagoya, Japan, 14-18 October 2013."]},{"title":"NICT Disaster Information Analysis System Kiyonori Ohtake Jun Goto Stijn De Saeger","paragraphs":["∗"]},{"title":"Kentaro Torisawa Universal Communication Research Institute, NICT / Kyoto, Japan. {kiyonori.ohtake, goto-j, stijn, torisawa} (at) nict.go.jp Junta Mizuno Resilient ICT Research Center, NICT / Miyagi, Japan. junta-m (at) nict.go.jp Kentaro Inui Graduate School of Information Sciences, Tohoku University / Miyagi, Japan. inui (at) ecei.tohoku.ac.jp Abstract","paragraphs":["Immediately after the 2011 Great East Japan Earthquake, the Internet was flooded by a huge amount of information concerning the damage and problems caused by the earthquake, the tsunami, and the nuclear disaster. Many reports about aid efforts and advice to victims were also transmitted into cyberspace. However, since most people were overwhelmed by the massive amounts of information, they could not make proper decisions, and much confusion was caused. Furthermore, false rumors spread on the Internet and fanned such confusion. We demonstrate NICT’s prototype disaster information analysis system, which was designed to properly organize such a large amount of disaster-related information on social media during future large-scale disasters to help people understand the situation and make correct decisions. We are going to deploy it using a large-scale computer cluster in fiscal year 2014."]},{"title":"1 Introduction","paragraphs":["It is widely recognized that Twitter and other social media played a significant role during the aftermath of the 2011 Great East Japan Earthquake by providing a huge amount of information concerning damages, problems, and aid efforts. But since this information exploded without any system to organize and disseminate it, most of the posted information was not effectively utilized for helping people (Varga et al., 2013).","We demonstrate NICT’s prototype disaster information analysis system that organizes a large","*Current address: Nuance Communications, Inc., Germany. stijn.desaeger (at) nuance.com amount of disaster-related information and supports victims and rescue workers during future large-scale disasters. Its core is a question-answering (QA) system that lists answers to such disaster-related questions as “What is in short supply in Tokyo?” from the 50 million tweets transmitted within a month after the Great East Japan Earthquake. We designed our QA system to provide a wide range of answers including unpredictable ones, unlike the single answers given by IBM’s Watson (Ferrucci et al., 2010). With our system, we can actually find much unpredictable information that is useful in aid efforts, including such diverse topics as allergy friendly food for children, psychotropic medicine, dialyzers, and women’s underwear, all of which were scarce in the earthquake and tsunami areas. One lesson from the Great East Japan Earthquake was that a large-scale disaster can destroy a wide range of infrastructure in society, disrupt daily lives, and cause many unpredictable situations. We expect that QA systems, which can automatically process huge bodies of text to extract a wide range of answers to a wide range of questions, will be indispensable for dealing with such unpredictable situations.","Also, our system can map answers to Google Maps and help local governments and NPOs recognize the big picture of the damage caused by disasters as well as the gaps in aid efforts. An-other of its functionalities helps people recognize false rumors spread on social media like Twitter. One well-known false rumor just after the earthquake was that Povidone-iodine provides protec-tion from radioactivity. Using the methodologies of the STATEMENT MAP (Mizuno et al., 2012), our system would have identified that this rumor had been refuted by tweets just after it started to spread. If many people had found such tweets, the spread of such rumors might have been stopped or mitigated. 29","In this demonstration, we use as an information source the more than 50 million disaster-related tweets that were posted from March 9, 2011 to April 4, 2011. We show that our system provides valuable answers that are hard to predict and anticipate. We also demonstrate how its results support the decision-making processes of local governments or humanitarian organizations during large-scale disaster situations and how to deal with the credibility issues of tweets."]},{"title":"2 Overview of NICT’s disaster information analysis system","paragraphs":["Our system consists of the following components: a QA module, a web-based interface, a large-scale pattern entailment database1","obtained from the web, and an indexing module for Twitter data.","The QA module is an extension of a pattern-based relation extraction method (De Saeger et al., 2009). Basically, it converts such input questions as “What causes deflation?”, into lexico-syntactic pattern “X causes Y” and automatically computes its entailing patterns with the database, such as “X triggers Y” and “Y is a cause of X”. X and Y are variables that correspond to the topic and interrogative pronoun of the question. These patterns are then matched against the index constructed from Twitter data after one of the variables is filled with the corresponding noun in the original question (Y = “deflation” in the above example). The nouns matching the unfilled variable (X) are provided as answers. This is the basic algorithm, which was extended in several aspects to deal with a wide range of questions.","Figure 1 shows the system’s interface on web browsers that accept any simple natural language question. The system provides two modes for displaying the answers. One is the semantic map mode that categorizes the answers in semantic clusters with different colors to help users quickly survey all the answers for interesting and surpris-ing answers (Figure 2). The other is Google Maps mode, which locates answers on Google Maps (Figure 3).","The system, which we demonstrate at IJCNLP 2013, runs on a single server. We are now developing a system that can work on large-scale computer clusters that can work with on-line indexing in real-time and simultaneously respond in real-1 This database includes more than six billion pattern","pairs. Figure 1: System’s interface. time to many questions.","In our evaluation we obtained an average of 1,900 answers per question with 76% recall and 56% precision. We used 300 useful and important questions for disaster situations and 22,000 answers, which were manually collected using a full text search engine, and checked the top 1,000 results of each search.","Our system’s target domain is not limited to disasters. We can apply it general events. At IJCNLP 2013, NICT also demonstrates WISDOM2013 (Tanaka et al., 2013), which shares the same QA module and targets a very large-scale web archive without limitation of the target domain."]},{"title":"3 Outline of demonstration","paragraphs":["The following four steps outline our demonstration:","1. Our system accepts such questions as “What is in short supply in Tokyo?” We can choose a user interface for the system’s response when we input a question.","2. Our system returns in the selected interface the results that were discovered from the 50 million tweets.","3. Our system can show a pop-up window that indicates the original tweets if we want to see the original texts from which the answer was extracted.","4. We can use the STATEMENT MAP developed by Tohoku University to confirm the credibility of the original tweets.","Since our system uses Japanese tweets and its results are in Japanese, we provide English translations.","Below, we describe the details of our system’s results, and a method to check a given answer’s credibility to a user’s question. We also describe a smartphone version of the QA interface, which is also shown during our demonstration. 30 Figure 3: System’s result on Google Maps for the question:Where are the power outages in Miyage prefecture? 3.1 System results in selected interface After a question is input, the system returns answers in the selected interface mode. The results of question “What shortages are there in Miyagi prefecture?” in the semantic map mode are shown in Figure 2. Many unpredictable answers are given.","During a large-scale disaster, we must grasp the locations of events that answer such questions as “Where are the power outages in Tokyo?” To understand the geological relations of events, our system locates the results on Google Maps. An example of our system’s results in the Google Maps mode is shown in Figure 3. We didn’t employ geotags in the tweets, because less than 1%2","of them were geotagged. Instead, we prepared a huge location dictionary that contains location names and their addresses. The system uses this dictionary to detect location names and processes them for the Google Gecoding API3",". By locating the results on a map, we can easily create a bird’s-eye view for the focus area that enables us to send relief to heavily damaged areas.","We also integrated into our scheme an information extraction system that was designed to extract problem reports and aid messages related to a disaster from tweets (Varga et al., 2013). If a 2 http://semiocast.com/publications/","2010 03 31 only thirty percent of tweets","are from the us 3 https://developers.google.com/maps/","documentation/geocoding/ Figure 4: STATEMENT MAP results for statement: “Povidone-iodine protects us from radioactivity.” question like “What problems have been reported in Fukushima prefecture?” is given, the problem reports, aid messages, and tweet pairs, which are problem-aid tweet matches, are provided by the information extraction system. These answers consist of the reports of the problems related to disasters along with aid messages, i.e., tweets describing efforts to solve problems. Such information is particularly useful for grasping the big picture of the damage and corresponding rescue efforts. 3.2 Checking credibility issues Due to the unreliable nature of information obtained by social media, someone may want to verify an answer’s credibility. For example, the results for the question, “What is effective against radiation?” include such unreliable ones as gargling, soft seaweed, beer, and soybeans. Our system provides a support method that evaluates the credibility of information sources by presenting a comprehensive survey of opinions on a topic.","Figure 4 shows the results4","produced with a STATEMENT MAP of the query: “Povidone-iodine protects us from radioactivity.” Both opinions affirming and contradicting this statement are arranged to highlight their contrast. If a statement is a false rumor, many contradicting tweets will probably be presented. 3.3 Smartphone applications An application that provides almost all of the functions of our system is available for iPhones. Figure 5 shows some screenshots of the iPhone application. 4 The tweets are blacked out due to copyright issues. 31 Figure 2: Example of system’s answer in semantic map mode Figure 5: Screenshots of iPhone application"]},{"title":"4 Conclusion","paragraphs":["This paper briefly introduced NICT’s prototype disaster information analysis system, and our demonstration of it at IJCNLP 2013. We will make the system available to the public in fiscal year 2014. Future work will introduce such new functionalities as Why-Question Answering (Oh et al., 2013)."]},{"title":"References","paragraphs":["Stijn De Saeger, Kentaro Torisawa, Jun’ichi Kazama, Kow Kuroda, and Masaki Murata. 2009. Large scale relation acquisition using class dependent patterns. In Proceedings of the IEEE International Conference on Data Min-ing (ICDM’09), pages 764–769.","David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A. Kalyanpur, Adam Lally, J. William Murdock, Eric Nyberg, John Prager, Nico Schlaefer, and Chris Welty. 2010. Building Watson: An overview of the deepQA project. AI Magazine, 31(3):59– 79.","Junta Mizuno, Eric Nichols, Yotaro Watanabe, and Kentaro Inui. 2012. Organizing information on the web through agreement-conflict relation classification. In Proceedings of the 8th Asia Information Retrieval Societies Conference (AIRS2012), pages 126–137.","Jong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto, Motoki Sano, Stijn De Saeger, and Kiyonori Ohtake. 2013. Why-question answering using intra- and inter-sentential causal relations. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1733–1743.","Masahiro Tanaka, Stijn De Saeger, Kiyonori Ohtake, Chikara Hashimoto, Makoto Hijiya, Hideaki Fujii, and Kentaro Torisawa. 2013. WISDOM2013: A large-scale web information analysis system. In Proceedings of the IJCNLP 2013 System Demonstrations.","István Varga, Motoki Sano, Kentaro Torisawa, Chikara Hashimoto, Kiyonori Ohtake, Takao Kawai, Jong-Hoon Oh, and Stijn De Saeger. 2013. Aid is out there: Look-ing for help from tweets during a large scale disaster. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1619–1629. 32"]}]}