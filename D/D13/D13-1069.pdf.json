{"sections":[{"title":"","paragraphs":["Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 736–746, Seattle, Washington, USA, 18-21 October 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Automatically Determining a Proper Length for Multi-documentSummarization: A Bayesian Nonparametric ApproachTengfei Ma and Hiroshi NakagawaThe University of Tokyo7-3-1 Hongo, Bunkyo-ku, Tokyo{matf@r., nakagawa@}dl.itc.u-tokyo.ac.jpAbstract","paragraphs":["Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multi-document summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ”reconstruction” by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination."]},{"title":"1 Introduction","paragraphs":["Text summarization is the process of generating a short version of a given text to indicate its main topics. As the number of documents on the web exponentially increases, text summarization has attracted increasing attention, because it can help people get the most important information within a short time.","In most of the existing summarization systems, people need to first define a constant length to restrict all the output summaries. However, in many cases it is improper to require all summaries are of the same length. Take the multi-document summarization as an example, generating the summaries of the same length for a 5-document cluster and a 50-document cluster is intuitively improper. More specifically, consider two different clusters of documents: one cluster contains very similar articles which all focus on the same event at the same time; the other contains different steps of the event but each step has its own topics. The former cluster may need only one or two sentences to explain its information, while the latter needs to include more.","Research on summary length dates back in the late 90s. Goldstein et al. (1999) studied the characteristics of a good summary (single-document summarization for news) and showed an empirical distribution of summary length over document size. However, the length problem has been gradually ignored later, since researchers need to fix the length so as to estimate different summarization models conveniently. A typical instance is the Document Understanding Conferences (DUC)1",", which provide authoritative evaluation for summarization systems. The DUC conferences collect news aritcles as the input data and define various summarization tasks, such as generic multi-document summarization, query-focused summarization and update summarization. In all the DUC tasks, the output is restricted within a length. Then human-generated 1 After 2007, the DUC tasks are incorporated into the Text","Analysis Conference (TAC). 736 summaries are provided to evaluate the results of different summarization systems. Limiting the length of summaries contributed a lot to the development of summarization techniques, but as we discussed before, in many cases keeping the summaries of the same size is not a good choice.","Moreover, even in constant-length summarization, how to define a proper size of summaries for the summarization tasks is quite a problem. Why does DUC2007 main task require 250 words while Update task require 100 words? Is it reasonable? A short summary may sacrifice the coverage, while a long summary may cause redundance. Automatically determining the best size of summaries according to the input documents is valuable, and it may deepen our understanding of summarization.","In this work, we aim to find the proper length for document summarization automatically and generate varying-length summaries based on the document itself. The varying-length summarization is more robust for unbalanced clusters. It can also provide a recommended size as the predefined summary length for general constant-length summarization systems. We advance a Bayesian nonparametric model of extractive multi-document summarization to achieve this goal. As far as we are concerned, it is the first model that can learn appropriate lengths of summaries.","Bayesian nonparametric (BNP) methods are powerful tools to determine the size of latent variables (Gershman and Blei, 2011). They let the data ”speak for itself” and allow the dimension of latent variables to grow with the data. In order to integrate the BNP methods into document summarization, we follow the assumption that the original documents should be recovered from the reconstruction of summaries (Ma and Wan, 2010; He et al., 2012). We use the Beta process as a prior to generate binary vectors for selecting active sentences that reconstruct the original documents. Then we construct a Bayesian framework for summarization and use the variational approximation for inference. Experimental results on DUC2004 dataset demonstrate the effectiveness of our model. Besides, we reorganize the original documents to generate some new datasets, and examine how the summary length changes on the new data. The results prove that our summary length determination is rational and necessary on unbalanced data."]},{"title":"2 Related Work2.1 Research on Summary Length","paragraphs":["Summary length is an important aspect for generating and evaluating summaries. Early research on summary length (Goldstein et al., 1999) focused on discovering the properties of human-generated summaries and analyzing the effect of compression ratio. It demonstrated that an evaluation of summarization systems must take into account both the compression ratios and the characteristics of the documents. Radev and Fan (2000) compared the readability and speedup in reading time of 10% summaries and 20% summaries2","for topic sets with different number of documents. Sweeney et al. (2008) developed an in-cremental summary containing additional sentences that provide context. Kaisser et al. (2008) studied the impact of query types on summary length of search results. Other than the content of original documents, there are also some other factors affect-ing summary length especially in specific applications. For example, Sweeney and Crestani (2006) studied the relation between screen size and summary length on mobile platforms. The conclusion of their work is the optimal summary size always falls into the shorter one regardless of the screen size.","In sum, the previous works on summary length mostly put their attention on the empirical study of the phenomenon, factors and impacts of summary length. None of them automatically find the best length, which is our main task in this paper. Nevertheless, they demonstrated the importance of summary length in summarization and the reasonability of determining summary length based on content of news documents (Goldstein et al., 1999) or search results (Kaisser et al., 2008). As our model is mainly applied for generic summarization of news articles, we do not consider the factor of screen size in mobile applications. 2.2 BNP Methods in Document Summarization Bayesian nonparametric methods provide a Bayesian framework for model selection and adaptation using nonparametric models (Gershman 2 10% and 20% are the compression rates, and the documents","are from search results in information retrieval systems. 737 and Blei, 2011). A BNP model uses an infinite-dimensional parameter space, but invokes only a finite subset of the available parameters on any given finite data set. This subset generally grows with the data set. Thus BNP models address the problem of choosing the number of mixture components or latent factors. For example, the hierarchical Dirichlet process (HDP) can be used to infer the number of topics in topic models or the number of states in the infinite Hidden Markov model (Teh et al., 2006).","Recently, some BNP models are also involved in document summarization approaches (Celikyilmaz and Hakkani-Tür, 2010; Chang et al., 2011; Darling and Song, 2011). BNP priors such as the nested Chinese restaurant process (nCRP) are associated with topic analysis in these models. Then the topic distributions are used to get the sentence scores and rank sentences. BNP here only impacts the number and the structure of the latent topics, but the summarization framework is still constant-length. Our BNP summarization model differs from the previous models. Besides using the HDP for topic analysis, our approach further integrates the beta process into sentence selection. The BNP method in our model are directly used to determine the number of summary sentences but not latent topics."]},{"title":"3 BNP Summarization","paragraphs":["In this section, we first introduce the BNP priors which will be used in our model. Then we propose our model called BNP summarization. 3.1 The Beta Process and the Bernoulli process The beta process(BP) (Thibaux and Jordan, 2007; Paisley and Carin, 2009) and the related Indian buffet process(IBP) (Griffiths and Ghahramani, 2005) are widely applied to factor/feature analysis. By defining the infinite dimensional priors, these factor analysis models need not to specify the number of latent factors but automatically determine it.","Definition of BP (Paisley et al., 2010): Let B0 be a continuous measure on a space Θ and B0(Θ) = γ. If Bk is defined as follows, Bk = N ∑ k=1 πkδθk , πk","∼ Beta( αγ N ,α(1 − γ","N )) θk ∼ 1 γ B0 (1) (where δθk is the atom at the location θk; and α is a positive scalar), then as N →∞,Bk → B and B is a beta process: B ∼ BP(αB0).","Finite Approximation: The beta process is defined on an infinite parameter space, but sometimes we can also use its finite approximation by simply setting N to a large number (Paisley and Carin, 2009).","Bernoulli Process: The beta process is conjugate to a class of Bernoulli processes, denoted by X ∼ Bep(B). If B is discrete, of the form in (1), then X = ∑","k bkδθk where the bk are independent Bernoulli variables with the probability p(bk = 1) = πk. Due to the conjugation between the beta process priors and Bernoulli process, the posterior of B given M samples X1,X2, ...XM where Xi ∼ Bep(B)fori =1,,,M.is also a beta process which has updated parameters: B|X1,X2, ..., XM ∼ BP(α + M, α α+M B0 + 1 c+M ∑","i Xi) (2) Application of BP: Furthermore, marginalizing over the beta process measure B and taking α = 1, provides a predictive distribution on indicators known as the Indian buffet process (IBP) (Thibaux and Jordan, 2007). The beta process or the IBP is often used in a feature analysis model to generate infinite vectors of binary indicator variables(Paisley and Carin, 2009), which indicates whether a feature is used to represent a sample. In this paper, we use the beta process as the prior to select sentences. 3.2 Framework of BNP Summarization Most existing approaches for generic extractive summarization are based on sentence ranking. However, these methods suffer from a severe problem that they cannot make a good trade-off between the coverage and minimum redundancy (He et al., 738 2012). Some global optimization algorithms are developed, instead of greedy search, to select the best overall summaries (Nenkova and McKeown, 2012). One approach to global optimization of summarization is to regard the summarization as a reconstruction process (Ma and Wan, 2010; He et al., 2012) . Considering a good summary must catch most of the important information in original documents, the original documents are assumed able to be recovered from summaries with some information loss. Then the summarization problem is turned into finding the sentences that cause the least reconstruction error (or information loss). In this paper, we follow the assumption and formulate summarization as a Bayesian framework.","First we review the models of (Ma and Wan, 2010) and (He et al., 2012). Given a cluster of M documents x1,x2, ..., xM and the sentence set contained in the documents as S =[s1,s2, ..., sN ], we denote all corresponding summary sentences as V =[v1, ..., vn], where n is the number of summary sentences and N is the number of all sentences in the cluster. A document xi and a sentence vi or si here are all represented by weighted term frequency vectors in the space Rd",", where d is the number of total terms (words).","Following the reconstruction assumption, a can-didate sentence vi can be approximated by the linear combination of summary sentences: si ≃∑n","j=1 w′","jvj, where w′","j is the weight for summary sentence vj. Thus the document can also be approximately represented by a linear combination of summary sentences (because it is the sum of the sentences). xi ≃ n ∑ j=1 wjvj. (3) Then the work in (He et al., 2012) aims to find the summary sentence set that can minimize the reconstruction error ∑N","i=1 ||si − ∑n","j=1 w′","jvj||2","; while the work in (Ma and Wan, 2010) defines the problem as finding the sentences that minimize the distortion between documents and its reconstruction dis(xi, ∑n","j=1 wjvj) where this distortion function can also be a squared error function.","Now we consider the reconstruction for each document, if we see the document xi as the dependent variable, and the summary sentence set S as the independent variable, the problem to minimize the reconstruction error can be seen as a linear regression model. The model can be easily changed to a Bayesian regression model by adding a zero-mean Gaussian noise ε (Bishop, 2006), as follows. xi = n ∑ j=1 wjvj + εi (4) where the weights wj are also assigned a Gaussian prior.","The next step is sentence selection. As our system is an extractive summarization model, all the summary sentences are from the original document cluster. So we can use a binary vector zi =< zi1, ..., ziN >T","to choose the active sentences V (i.e. summary sentences) from the original sentence set S. The Equation (4) is turned into xi =∑N","j=1 φij ∗zijsj +εi. Using a beta process as a prior for the binary vector zi, we can automatically infer the number of active component associated with zi. As to the weights of the sentences, we use a random vector φi which has the multivariate normal distribution because of the conjugacy. φi ∈ RN","is an extension to the weights {w1, ...wn} in (4).","Integrating the linear reconstruction (4) and the beta process3","(1), we get the complete process of summary sentence selection as follows. xi = S(φi ◦ zi)+εi S =[s1,s2, ..., sN ] zij ∼ Bernoulli(πj) πj","∼ Beta( αγ N ,α(1 − γ","N )) φi","∼N(0,σ2 φI) εi","∼N(0,σ2 ε I) (5) where N is the number of sentences in the whole document cluster. The symbol ◦ represents the elementwise multiplication of two vectors.","One problem of the reconstruction model is that the word vector representation of the sentences are sparse, which dramatically increase the reconstruction error. So we bring in topic models to reduce the 3 We use the finite approximation because the number of sen-","tences is large but finite 739 dimension of the data. We use a HDP-LDA (Teh et al., 2006) to get topic distributions for each sentence, and we represent the sentences and documents as the topic weight vectors instead of word weight vectors. Finally xi is a K-dimensional vector and S is a K ∗ N matrix, where K is the number of topics in topic models."]},{"title":"4 Variational Inference","paragraphs":["In this section, we derive a variational Bayesian algorithm for fast inference of our sentence selection model. Variational inference (Bishop, 2006) is a framework for approximating the true posterior with the best from a set of distributions Q : q∗ = arg minq∈Q KL(q(Z)|p(Z|X)). Suppose q(Z) can be partitioned into disjoint groups denoted by Zj, and the q distribution factorizes with respect to these groups: q(Z)=∏M","j=1 q(Zj). We can obtain a general expression for the optimal solution q∗","j (Zj) given by","ln q∗ j (Zj)=Ei̸=j[ln p(X, Z)] + const. (6) where Ei̸=j[ln p(X, Z)] is the expectation of the logarithm of the joint probability of the data and latent variables, taken over all variables not in the parti-tion. We will therefore seek a consistent solution by first initializing all of the factors qj(Zj) appropriately and then cycling through the factors and replacing each in turn with a revised estimate given by (6) evaluated using the current estimates for all of the other factors.","Update for Z p(zij|πj,xi,S,φi) ∝ p(xi|zij,sj,φi)p(zij|πj) We use q(zij) to approximate the posterior: q(zij)","∝ exp{E[ln(p(xi|zij,z−j i ,S,φi)) + ln(p(zij|π))]} ∝ exp{E[ln(πj)]}∗","exp{E[− 1","2σ2","ε ( x−j i − sjzijφij)T (","x−j","i − sjzijφij)","]} ∝ exp{ln(πj)}∗ exp{−","(","φ2","ij ∗ z2 ij ∗ sT","j sj − 2φij ∗ zij ∗ sjT","∗ x−j","i )","2σ2 ε } (7)","where x−j","i = xi − S−j","(φ−j","i ◦ z−j","i ), and the symbol","̄indicates the expectation value. The φ2","ij can be","extended to this form:","φ2","ij = φij2","+∆j","i (8) where ∆j","i means the jth","diagonal element of ∆i which is defined by Equation 13. As zi is a binary vector, we only calculate the probability of zij =1and zij =0. q(zij =1)∝ exp{ln(πj)}∗","exp{− 1","2σ2","ε ( φ2 ij ∗ sT","j sj − 2φij ∗ sjT","∗ x−j","i )","} q(zij =0)∝ exp{ln(1 − πj)} (9) The expectations can be calculated as","ln(πj)=φ( αγ N + nj) − φ(α + M ) (10)","ln(1 − πj)=φ(α(1 − γ","N )+M − nj) − φ(α + M )","(11)","where nj = ∑M i=1 zij. Update for π p(πj|Z) ∝ p(πj|α, γ, N )p(Z|πj) Because of the conjugacy of the beta to Bernoulli distribution, the posterior of π is still a beta distribution:","πj ∼ Beta( αγ N + nj,α(1 − γ","N )+M − nj) (12) Update for Φ","p(φi|xi,Z,S) ∝ p(xi|φi,Z,S)p(φi|σ2 φ) The posterior is also a normal distribution with mean μi and covariance ∆i. ∆i =","( 1 σ2 ε S̃iT","S̃i + 1","σ2","φ I)−1 (13)","μi =∆i ( 1 σ2 ε S̃iT","xi) (14) Here S̃i ≡ S ◦ z̃i and z̃i ≡ [zi, ..., zi]T","is a K × N matrix with the vector zi repeated K(the number of the latent topics) times. S̃i = S ∗ z̃i (15) 740","S̃iT","S̃i =(ST","S) ◦ (zi ∗ ziT","+ Bcovi) (16) Bcovi =diag[zi1(1 − zi1), ..., ziN (1 − ziN )] (17)","Update for σ2 ε","p(σ2","ε |Φ ,X,Z,S) ∝ p(X|Φ ,Z,S,σ2","ε )p(σ2","ε ) By using a conjugate prior, inverse gamma prior InvGamma(u, v), the posterior can be calculated as a new inverse gamma distribution with parameters","u′ = u + MK/2","v′","= v + 1 2 M","∑","i=1 (||xi − S(zi ◦ φi)|| + ξi) (18) where","ξi = ∑N","j=1(z2","ij ∗ φ2","ij ∗ sT","j sj − zij2","∗ φij2","∗ sT","j sj)","+ ∑ j̸=l zij ∗ zil ∗ ∆i,jl ∗ sT","j sl","Update for σ2 φ","p(σ2","φ|Φ) ∝ p(Φ |σ2","φ)p(σ2","φ) By using a conjugate prior, inverse gamma prior InvGamma(e, f ), the posterior can be calculated as a new inverse gamma distribution with parameters e′ = e + MN/2 f ′","= f + 1","2 M","∑","i=1 (","(Φ) T","Φ+ trace(∆′","i))","(19)"]},{"title":"5 Experiments","paragraphs":["To test the capability of our BNP summarization systems, we design a series of experiments. The aim of the experiments mainly includes three aspects:","1. To demonstrate the summaries extracted by our model have good qualities and the summary length determined by the model is reasonable.","2. To give examples where varying summary length is necessary. 3. To observe the distribution of summary length. We evaluate the performance on the dataset of DUC2004 task2. The data contains 50 document clusters, with 10 news articles in each cluster. Besides, we construct three new datasets from the DUC2004 dataset to further prove the advantage of variable-length summarization. We separate each cluster in the original dataset into two parts where each has 5 documents, hence getting the Separate Dataset; Then we randomly combine two original clusters in the DUC2004 dataset, and get two datasets called Combined1 and Combined2. Thus each of the clusters in the combined datasets include 20 documents with two different themes. 5.1 Evaluation of Summary Qualities First, we implement our BNP summarization model on the DUC2004 dataset, with summary length not limited. At the topic analysis step, we use the HDP model and follow the inference in (Teh et al., 2006). For the sentence selection step, we use the variational inference described in Section 4, where the parameters in the beta process (5) are set as γ = 1,α =1. The summaries that we finally generate have an average length of 164 words. We design several popular unsupervised summarization systems and compare them with our model.","• The Random model selects sentences randomly for each document cluster.","• The MMR (Carbonell and Goldstein, 1998) strives to reduce redundancy while maintaining relevance. For generic summarization, we replace the query relevance with the relevance to documents.","• The Lexrank model (Erkan and Radev, 2004) is a graph-based method which choose sentences based on the concept of eigenvector centrality.","• The Linear Representation model (Ma and Wan, 2010) has the same assumption as ours and it can be seen as an approximation of the constant-length version of our model. 741                                                          Figure 1: Rouge-1 values on DUC2004 dataset.                                                          Figure 2: Rouge-2 values on DUC2004 dataset.                                                    Figure 3: Rouge-L values on DUC2004 dataset.","All the compared systems are implemented at different predefined lengths from 50 to 300 words. Then we evaluate the summaries with ROUGE4 tools (Lin and Hovy, 2003) in terms of the f-measure 4 we use ROUGE1.5.5 in this work. scores of Rouge-1 Rouge-2, and Rouge-L. The metric of Rouge f-measure takes into consideration the summary length in evaluation, so it is proper for our experiments. From Fig.1, Fig.2 and Fig.3, we can see that the result of BNP summarization (the dashed line) gets the second best value among all systems. It is only defeated by the Linear model but the result is comparable to the best in Fig.1 and Fig.3; while it exceeds other systems at all lengths. This proves the good qualities of our BNP summaries. The reason that the Linear system gets a little better result may be its weights for linear combination of summary sentences are guaranteed nonnegative while in our model the weights are zero-mean Gaussian variables. This may lead to less redundance in sentence selection for the Linear Representation model.","Turn to the length determination. We take advantage of the Linear Representation model to approximate the constant-length version of our model. Comparing the summaries generated at different predefined lengths, Fig.4 shows the the model gets the best performance (Rouge values) at the length around 164 words, the length learned by our BNP model. This result partly demonstrates our length determination is rational and it can be used as the recommended length for some constant-length summarization systems, such as the Linear .                                       Figure 4: Rate-dist value V.S. summary word length. 742 5.2 A New Evaluation Metric The Rouge evaluation requires golden standard summaries as the base. However, in many cases we cannot get the reference summaries. For example, when we implement experiments on our expanded datasets (the separate and combined clusters of documents), we do not have exact reference summaries. Louis and Nenkova (2009) advanced an automatic summary evaluation without human models. They used the Jensen-Shannon divergence(JSD) between the input documents and the summaries as a feature, and got high correlation with human evaluations and the rouge metric. Unfortunately, it was designed for comparison at a constant-length, which cannot meet our needs. To extend the JSD evaluation to compare varying-length summaries, we propose a new measure based on information theory, the rate-distortion (Cover and Thomas, 2006).","Rate-Distortion: The distortion function d(x, x̂) is a measure of the cost of representing the symbol x to a new symbol x̂; and the rate can indicate how much compression can be achieved. The problem of finding the minimum rate can be solved by minimizing the functional F [p(x̂|x)] = I(X; X̂)+βE(d(x, x̂)). (20) where I(X; X̂) denotes the mutual information. The rate-distortion theory is a fundamental theory for lossy data compression. Recently, it has also been successfully employed for text cluster-ing (Slonim, 2002) and document summarization (Ma and Wan, 2010). Slonim (2002) claims that the mutual information I(X; X̂) measures the compactness of the new representation. Thus the rate-distortion function is a trade-off between the compactness of new representation and the expected distortion. Specifically in summarization, the summaries can be seen as the new representation X̂ of original documents X. A good summary balances the compression ratio and the information loss, thus minimizing the function (20). So we use the function (20)(we set β =1) to compare which summary is a better compression. The JS-divergence (JSD), which has been proved to have high correlation with manual evaluation (Louis and Nenkova, 2009) for constant-length summary evaluation, is utilized as the distortion in the function. In the following sections, we simply call the values of the function (20) rate-dist. In fact, the rate-dist values can be seen as the JSD measure with length regularization.","To check the effectiveness of rate-dist measure, we evaluate all summaries generated in Section 5.1 with the new measure (the lower the better). Fig. 5 shows that the results accord with the ones in Fig. 1 and Fig. 3. Moreover, in Fig. 4, the curve of rate-dist values has a inverse tendency of Rouge measures (Rouge-1, Rouge-2, Rouge-L and Rouge-SU4 are all listed here), and the best performance also occurs around the summary length of 164 words. This even more clearly reveals that the BNP summarization achieves a perfect tradeoff between compactness and informativeness. Due to the accordance with rouge measures, it is promising to be regarded as an alternative to the rouge measures in case we do not have reference summaries.                                       Figure 5: Comparison of BNP Summarization with other systems using rate-dist measure. 5.3 Necessity of Varying Summary Length In this section, we discuss the necessity of length determination and how summary length changes according to the input data. As explained before, we generate three new datasets from the original DUC2004 dataset. Now we use them to indicate varying summary length is necessary when the input data varies a lot.","Table 1 shows the average summary length of different data sets. The results satisfy the intuitive expectation of summary length change. When we split a 10-document cluster into two 5-document parts, we expect the average summary length of the new clusters to be a little smaller than the original cluster but much larger than half of the original length, 743 because all the documents concentrate on the same themes. When we combine two clusters into one, the summary length should be smaller than the sum of the summary lengths of two original clusters due to some unavoidable common background information but much larger than the summary length of original clusters. Original Separate Combined1 Combined2 164 115 250 231 Table 1: Average summary length (number of words) on different datasets","We also run the Linear Representation system at different lengths on the new datasets and evaluate the qualities. As we do not have golden standard for the new datasets, so we only use the rate-dist measure here. Results in Table 2,3,4 show the summaries which do not change the predefined length 5","perform significantly worse than the BNP summarization. All the comparison is statistically significant. So varying summary length is necessary when the input changes a lot, and our model can just give a good match to the new data. This characteristic also can be used to give recommended summary length for extractive summarization systems when given unknown data. Predefined Unchanged BNP Length 665 bytes 164 words 115 words Rate-dist 0.4130 0.4404 0.4007 Table 2: Comparison of summary lengths on Separate Dataset. Predefined Unchanged BNP Length 665 bytes 164 words 250 words Rate-dist 0.3768 0.3450 0.3238 Table 3: Comparison of summary lengths on Combined1 Dataset.","Then we observe the summary length distributions and compression ratios according to document size(the length of the whole documents in a cluster). The average summary length increases (Fig. 6),","5","665 bytes is the DUC2004 requirement and 164 words is the best length on original data Predefined Unchanged BNP Length 665 bytes 164 words 231 words Rate-dist 0.3739 0.3464 0.3326 Table 4: Comparison of summary lengths on Combined2 Dataset. while the compression ratios decreases (Fig. 7) as document size grows. The rule of the compression ratio here agrees with the rule in (Goldstein et al., 1999), although that work is done for single-document summarization.                                                                       Figure 6: The distribution of summary word length.                                                                                 Figure 7: Compression ratio versus document word length. 744"]},{"title":"6 Conclusion and Future Work","paragraphs":["In this paper, we present a new problem of finding a proper summary length for multi-document summarization based on the document content. A Bayesian nonparametric model is proposed to solve this problem. We use the beta process as the prior to construct a Bayesian framework for summary sentence selection. Experimental results are shown on DUC2004 dataset, as well as some expanded datasets. We demonstrate the summaries we extract have good qualities and the length determination of our system is rational.","However, there is still much work to do for variable-length summarization. First, Our system is extractive-base summarization, which cannot achieve the perfect coherence and readability. A system which can determine the best length even for abstractive summarization will be better. Moreover, in this work we only consider the aspect of data compression and evaluate the performance using an information-theoretic measure. In future we may consider more human factors, and prove the summary length determined by our system agrees with human preference. In addition, in the experiments, we only use the imbalanced datasets as the example that intuitively needs varying the summary length. However, the data type is also important to impact the summary length. In future, we may extend the work by studying more cases that need varying summary length."]},{"title":"References","paragraphs":["Christopher M. Bishop. 2006. Pattern recognition and machine learning. . Vol. 4. No. 4. New York: springer.","Jaime Carbonell, and Jade Goldstein. 1998. The Use Of Mmr, Diversity-Based Reranking For Reordering Documents And Producing Summaries. Proceedings of the 21st annual international ACM SIGIR confer-ence on Research and development in information retrieval. ACM, 1998.","Asli Celikyilmaz and Dilek Hakkani-Tür. 2010. A Hybrid Hierarchical Model for Multi-Document Summarization. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 815-824.","Ying-Lan Chang, Jui-Jung Hung and Jen-Tzung Chien 2011. Bayesian Nonparametric Modeling Of Hierarchical Topics And Sentences. IEEE International Workshop on Machine Learning for Signal Processing, September 18-21, 2011, Beijing, China.","Thomas M. Cover, and Joy A. Thomas. 2006. Elements of information theory. Wiley-interscience, 2006.","William M. Darling and Fei Song. 2011. PathSum: A Summarization Framework Based on Hierarchical Topics. Canadian AI Workshop on Text Summarization, St. John’s, Newfoundland.","Samuel J. Gershman and David M. Blei. 2011. A Tutorial On Bayesian Nonparametric Models. Journal of Mathematical Psychology(2011).","Thomas L. Griffiths and Zoubin Ghahramani. 2005. Infinite Latent Feature Models and the Indian Buffet Process. Advances in Neural Information Processing Systems 18.","Jade Goldstein, Mark Kantrowitz, Vibhu Mittal and Jaime Carbonelly. 1999. Summarizing Text Documents: Sentence Selection and Evaluation Metrics. Proceedings of SIGIR’99 , pages 121-128.","Zhanying He, Chun Chen, Jiajun Bu, CanWang, Lijun Zhang, Deng Cai and Xiaofei He. 2012. Document Summarization Based on Data Reconstruction. Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence.","Michael Kaisser, Marti A. Hearst, John B. Lowe. 2008. Improving Search Results Quality by Customizing Summary Lengths. Proceedings of ACL-08: HLT, pages 701-709.","Chin-Yew Lin, Guihong Cao, Jianfeng Gao, and Jian-Yun Nie. 2006. An Information-Theoretic Approach to Automatic Evaluation of Summaries. Proceedings of NAACL2006, pages 463-470.","Chin-Yew Lin, and Eduard Hovy. 2003. Automatic evaluation of summaries using n-gram co-occurrence statistics. Proceedings of NAACL2003.","Annie Louis and Ani Nenkova. 2009. Automatically Evaluating Content Selection in Summarization without Human Models. Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 306-314. Singapore, 6-7 August 2009.","Tengfei Ma and Xiaojun Wan. 2010. Multi-document Summarization Using Minimum Distortion. IEEE 10th International Conference on Data Mining (ICDM).","Ani Nenkova and Kathleen McKeown. 2012. A survey of text summarization techniques. Mining Text Data, Chapter 3, Springer Science+Business Media, LLC (2012).","John Paisley and Lawrence Carin. 2009. Nonparametric Factor Analysis with Beta Process Priors. Proceedings of the 26th International Conference on Machine Learning, Montreal, Canada. 745","John Paisley, Aimee Zaas, Christopher W. Woods, Geoffrey S. Ginsburg and Lawrence Carin. 2010. A Stick-Breaking Construction of the Beta Process. Proceedings of the 27 th International Confer- ence on Machine Learning, Haifa, Israel, 2010.","Dragomir R. Radev and Weiguo Fan. 2000. Effective search results summary size and device screen size: Is there a relationship. Proceedings of the ACL-2000 workshop on Recent advances in natural language processing and information retrieval","Günes Erkan, and Dragomir R. Radev. 2004. LexRank: Graph-based Lexical Centrality as Salience in Text Summarization. Journal of Artificial Intelligence Research, 22 (2004) 457-479.","Noam Slonim. 2002. The Information Bottleneck: The-ory and Applications. PHD Thesis of the Hebrew University .","Simon Sweeney and Fabio Crestani. 2006. Effective search results summary size and device screen size: Is there a relationship. Information Processing and Management 42 (2006) 1056-1074.","Simon Sweeney, Fabio Crestani and David E. Losada. 2008. ’Show me more’: Incremental length summarisation using novelty detection. Information Processing and Management 44 (2008) 663-686.","Yee Whye Teh, Dilan Görür, and Zoubin Ghahramani. 2007. Stick-breaking Construction for the Indian Buffet Process. Proceedings of the International Conference on Artificial Intelligence and Statistics.","Y.W. Teh, M.I. Jordan, M.J. Beal and D.M. Blei. 2006. Hierarchical Dirichlet Processes. JASA , 101(476):1566-1581.","Romain Thibaux and Michael I. Jordan. 2009. Hierarchical Beta Processes and the Indian Buffet Process. AISTATS2007. 746"]}]}
