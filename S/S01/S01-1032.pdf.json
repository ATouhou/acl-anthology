{"sections":[{"title":"The University of Alicante Word Sense Disambiguation System* Andres Montoya and Armando Suarez Departamento de Lenguajes","paragraphs":["y"]},{"title":"Sistemas Informaticos Universidad de Alicante Alicante, Spain","paragraphs":["{montoyo"]},{"title":"I","paragraphs":["armando}@dlsi.ua.es"]},{"title":"Abstract","paragraphs":["The WSD system presented at SENSEVAL-2 uses a knowledge-based method for noun dis ambiguation and a corpus-based method for verbs and adjectives. The methods are, respec tively, Specification Marks and Maximum En tropy probability models. So, we can say that this is a hybrid system which joins an unsuper vised method with a supervised method. The whole system has been used in lexical sample english task and lexical sample spanish task."]},{"title":"1 Introduction","paragraphs":["In this paper a Word Sense Disambiguation sys tem based on Specification Marks (SM) and Maximum Entropy probability models {ME) is presented. SM is an unsupervised knowledge based method and has been applied to noun disambiguation. ME belongs to the statistical approach to WSD in NLP and uses a tagged cor pus in order to learn a probability model that can be used to predict the correct sense of a word. SM does not need a previously tagged corpus, it uses the semantic information stored in WordNet.","The weakness of supervised corpus-based ap proaches rely on availability of corpora and their dependency of the data which were used in the training phase. Knowledge-based approaches use previously acquire linguistic knowledge. This knowledge is extracted from human lex icographers experience and can be in form of electronic dictionary or lexicon. While their success seems poorest than statistical methods, they don't need neither an existing corpus nor a training phase and they can be more domain independent. * This paper has been partially supported by the Span ish Government (CICYT) project number TIC2000-0664-C02-02. 131","So, the University of Alicante system per forms the WSD task combining unsupervised with supervised methods. The whole system has been used in lexical sample English task and lexical sample Spanish task."]},{"title":"2 Specification Marks Framework","paragraphs":["The method we present here consists basically of the automatic sense-disambiguating of nouns that appear within the context of a sentence and whose different possible senses are quite re lated. Its context is the group of words that co-occur with it in the sentence and their rela tionship to the noun to be disambiguated. The disambiguation is resolved with the use of the WordNet lexical knowledge base.","The intuition underlying this approach is that the more similar two words are, the more infor mative the most specific concept that subsumes them both will be. In other words, their low est upper bound in the taxonomy. (A \"con cept\" here, corresponds to a Specification Mark (SM)). In other words, the more information two concepts share in common, the more similar they obviously are, and the information com monly shared by two concepts is indicated by the concept that subsumes them in the taxon omy.","The input for the WSD module will be the group of words W ="]},{"title":"{W1,","paragraphs":["W2, ... , Wn}· Each word wi is sought in WordNet, each one has an associated set Si = { Sil, Si2, ... , Sin} of pos sible senses. Furthermore, each sense has a set of concepts in the IS-A taxonomy (hyper nymy/Hyponymy relations). First, the concept that is common to all the senses of all the words that form the context is sought. We call this concept the Initial Specification Mark (ISM), and if it does not immediately resolve the ambi guity of the word, we descend from one level to another through WordNet 's hierarchy, as signing new Specification Marks. The number of concepts that contain the subhierarchy will then be counted for each Specification Mark. The sense that corresponds to the Specification Mark with highest number of words will then be chosen as the sense disambiguation of the noun in question, within its given context.","At this point, we should like to point out that after having evaluated the method, we subse quently discovered that it could be improved with a set of heuristics, providing even better results in disambiguation. The set of heuristics are Heuristic of Hypernym, Heuristic of Defini tion, Heuristic of Common Specification Mark, Heuristic of Gloss Hypernym, Heuristic of Hy ponym and Heuristic of Gloss Hyponym. De tailed explanation and evaluation of the method and heuristics can be found in (Montoya and Palomar, 2000; Montoya and Palomar, 2001), while its application to NLP tasks are addressed in (Montoya et al., 2001)."]},{"title":"3 Maximum Entropy Framework","paragraphs":["Maximum Entropy(ME) modeling is a frame work for integrating information from many heterogeneous information sources for classifica tion. ME probability models were successfully applied to some NLP tasks such as POS tagging or sentence boundary detection (Ratnaparkhi, 1998).","The WSD system presented in this paper is based on conditional ME probability mod els (Saiz-Noeda et al., 2001). It implements a supervised learning method consisting of the building of word sense classifiers through train ing on a semantically tagged corpus. A classifier obtained by means of a ME technique consists of a set of parameters or coefficients estimated by means of an optimization procedure. Each co efficient is associated to one feature observed in training data. A feature is a function that gives a measure for some characteristic in a context associated to a class. The main purpose is to obtain the probability distribution that maxi mizes the entropy, that is, maximum ignorance is assumed and nothing apart of training data is considered. As advantages of ME framework, knowledge-poor features applying and accuracy can be mentioned; ME framework allows a vir tually unrestricted ability to represent problem-132 specific knowledge in the form of features (Rat naparkhi, 1998).","Let us assume a set of contexts X and a set of classes C. The function c1 : X -+ C that performs the classification in a condi tional probability model p chooses the class with the highest conditional probability: c1 ( x) = argmaxcp(c!x), where x is a context and c a class. The features have the form of (1), where cp( x) is some observable characteristic1 . The conditional probability"]},{"title":"p(c!x)","paragraphs":["is defined as (2) where ai are the parameters or weights of each feature, and Z(x) is a constant to ensure that the sum of probabilities for each possible class in this context is equal to 1."]},{"title":"f","paragraphs":["(x c) = { 1 if"]},{"title":"d","paragraphs":["=?and cp(x) =true c! ' 0 otherwise (1) K"]},{"title":"p(c!x)","paragraphs":["= _1_"]},{"title":"IT","paragraphs":["a{i(x,c} (2) Z(x) i=l"]},{"title":"4 The system at Senseval-2","paragraphs":["The Spanish and English lexical sample tasks at the SENSEVAL-2 workshop had been performed by our system in three phases. The first one is a naive multi-word detection; the second one, the disambiguation of nouns by means of the SM method, and the third one, the disambigua tion of verbs and adjectives by means of the ME method.","In a previous step, training and test data had been tagged with Tree-Tagger(Schmid, 1994) for English files and Conexor's FDG Parser (Tapanainen and Jarvinen, ) for Spanish files in order to get the part-of-speech information and identify nouns, verbs and adjectives. Multi-words detection The multi-word detection has been performed by combining the words around the target word in each sample and consulting WordNet for En glish (examining the training data, we conclude that this is not necessary for Spanish data). If a multi-word is found in WordNet a multi-word instance is assigned and no further single word","1","The ME approach is not limited to binary fun tions, but the optimization procedure( Generalized Iter ative Scaling) used for the estimation of the parameters needs this kind of features. disambiguation will be done. This kind of in stances has been disambiguated with the first sense of WordNet (even if it is a polysemous one). Nouns with Specification Marks The second phase consist of noun classification, and has been performed by the SM method de scribed previously. Verbs and adjectives with Maximum Entropy The third and final phase, the verbs and ad jectives disambiguation, has been performed by the ME method. The SENSEVAL-2 training data has been used in order to obtain the classifica tion functions to be applied on the test data. The set of features defined for ME training is described below and it is based on features se lection made in {Ng and Lee, 1996) and (Escud ero et al., 2000).","The set of features corresponds to words around the word to classify and POS la bels at positions related to the target word in each sentence: wo, w_b w_2, W-3, W+b W+2, W+3, (w-2, W-I), (W-I, W+I), (w+b W+2), (w-3,w-2,w-d, (w-2, w_bw+I), (w-bw+I,W+2), (w+I, W+2,W+3), P-3, P-2, P-1, P+I, P+2, P+3· Each Wi is the lemma of the word at position i in the context (in collocations, at least one of the words must be a content word). Each Pi is the POS label at position i.","Other set of features consists of a surround ing nouns selection. This selection is doing by means of frequency information of nouns co occurring with a sense. Nouns co-occurring with a class in a"]},{"title":"K%","paragraphs":["of examples of that class in the corpus or more are selected to build a feature for each possible class2 •"]},{"title":"5 Senseval-2 results analysis","paragraphs":["Analyzing the first evaluation results of the English lexical sample task {fine-grained scoring) reported by SENSEVAL-2 committee (precision"]},{"title":"=","paragraphs":["0.421 and recall"]},{"title":"=","paragraphs":["0.411) , some conclusions can be extracted from them. The nouns disambiguation obtains the worst results (see table 1). We can mostly assure","2","For example, in a set of 100 examples of sense four of the noun \"interest\", if \"bank\" is observed 10 times or more (K = 10%) then a feature for each possible sense of \"interest\" is defined with \"bank\" . 133 that the reason is the kind of method used: knowledge-based for nouns and corpus-based for verbs and adjectives. POS Nouns Verbs Adjectives","precision 0.299 0.486 ~ 0.709 recall 0.292 0.480 0.635 Table 1: Results of the English Lexical Sample Task {Fine-grained)","The results of the Spanish lexical sample task (fine-grained scoring) reported by SENSEVAL-2 committee are precision = 0.514 and recall"]},{"title":"=","paragraphs":["0.503. Nevertheless, the nouns results rise to 56% of precision (table 2). It seems that the set of nouns selected for this task is easier to Specification Marks than English ones, maybe related to lexical resources used and the lan guage itself. However, the recall of nouns is too low because a implementation error causes that the accented words had not been recognize ( coraz6n, operaci6n and 6rgano ). POS Nouns Verbs Adjectives","precision recall 0.566 0.435 0.511 0.511 0.687 0.687 Table 2: Results of the Spanish Lexical Sample Task (Fine-grained)","The preprocessing of the train and test data are relevant. Some errors of the PO S-tagger had been detected and they affect some answer in stances. Multi-words are a not resolved prob lem. The detection and disambiguation method is too simple and causes too much errors. More preprocessing is necessary, as well: the con text information can be enriched and accuracy increased with entity recognition, full-parsing, and so on."]},{"title":"6 Conclusions","paragraphs":["The University of Alicante system presented at SENSEVAL-2 workshop joins the two general ap proaches to the WSD task: knowledge-based and corpus-based methods. The Specification Marks method belongs to the first one and Max imum Entropy-based method to the second one.","Specification Marks for nouns, and Maximum Entropy for verbs and adjectives had been used in order to process the test data of the En glish and the Spanish lexical sample tasks. The training and the test data had been used with a minimum preprocessing, just cleaning of XML tags in order to run the Tree-Tagger. Besides, the two WSD modules had been used in the same manner as for other corpora with minor modifications: no specific changes to the algo rithms used in both methods had been made for SENSEVAL-2, apart from the necessary modules to make data files available to the computer pro grams.","Due to the distinct approaches used in each POS, the whole system has been classified as supervised system. In the English task, the sys tem obtains a poor score when it is compared with other supervised systems, and a great re sult against the unsupervised systems (we have no such information of systems for Spanish). But the truth is that our system is unsuper vised for nouns but supervised for verbs and ad jectives. Therefore, comparing our results with the other systems must be done separating the results of nouns, verbs and adjectives."]},{"title":"7 Future and in progress work","paragraphs":["At this moment, the two methods presented here are being improved with new knowledge sources like full parsing information and domain categories that in order to decrease the Word Net granularity. The WSD system will be com pleted with other NLP software like N arne En tity recognition and multi-words detection mod ules.","Recent work in our research group indicates that it is possible to combine the two methods in a hybrid method that assign a sense to a context combining the answers of both methods with a relevant improvement of accuracy (Suarez and Montoya, 2001). Our intention is to extent this combination with the help of other well known WSD methods and to establish a voting method or some other manner of cooperation.","Our main objective is to develop a complete WSD system in order to help other NLP activ ities in our research group. The work presented here is our first attempt to participate at Sen seval and we hope to get the proper conclusions in order to improve our system and compete in the next Senseval."]},{"title":"References","paragraphs":["Gerard Escudero, Lluis Marquez, and Ger man Rigau. 2000. Boosting applied to word sense disambiguation. In Proceedings of the 12th Conference on Machine Learning ECML2000, Barcelona, Spain.","A. Montoya and M. Palomar. 2000. Word Sense Disambiguation with Specification Marks in Unrestricted Texts. pages 103-107.","A. Montoya and M. Palomar. 2001. Specifi cation Marks for Word Sense Disambigua tion: New Development. In Proceedings of 2nd International conference on Intelligent Text Processing and Computational Linguis tics (CICLing-2001}, pages 182-191.","A. Montoya, M. Palomar, and G. Rigau. 2001. WordNet Enrichment with Classification Sys tems. In ACL, editor, Proceedings of NAACL Workshop WordNet and Other Lexical Re sources: Applications, Extensions and Cus tomizations, Pittsburgh, PA, USA.","Hwee Tau Ng and Hian Beng Lee. 1996. In tegrating multiple knowledge sources to dis ambiguate word senses: An exemplar-based approach. In Proceedings 34th Annual Meet ing of the ACL-1996., San Francisco, USA.","Adwait Ratnaparkhi. 1998. Maximum Entropy Models for Natural Language Ambiguity Res olution. Ph.D. thesis, University of Pennsyl vania.","Maximiliano Saiz-Noeda, Armando Suarez, and Manuel Palomar. 2001. Semantic pattern learning through maximum entropy-based wsd technique. In Proceedings of CoNLL-2001, pages 23-29. Toulouse, France.","Helmut Schmid. 1994. Probabilistic part-of speech tagging using decision trees. In Pro ceedings International Conference on New Methods in Language Processing., pages 44-49, Manchester, UK.","Armando Suarez and Andres Montoya. 2001. Estudio de cooperaci6n entre metodos de desambiguaci6n lexica: Marcas de especifi cidad vs. maxima entropfa. Procesamiento Lenguaje Natural, 27(1):207-214, september.","Pasi Tapanainen and Timo Jarvinen. A non projective dependency parser. In Proceedings qf the Fifth Conference on Applied Natural Language Processing, pages 64-71. 134"]}]}