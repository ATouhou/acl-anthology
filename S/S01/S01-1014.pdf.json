{"sections":[{"title":"Supervised Sense Tagging using Support Vector Machines Clara Cabezas, Philip Resnik,","paragraphs":["and"]},{"title":"Jessica Stevens","paragraphs":["Dept. of Linguistics and Institute for Advanced Computer Studies University of Maryland, College Park, MD"]},{"title":"20742","paragraphs":["USA {clarac,resnik,stevenjc}@umiacs.umd.edu"]},{"title":"Abstract","paragraphs":["We describe the University of Maryland's su pervised sense tagger, which participated in the SENSEVAL-2 lexical sample evaluations for En glish, Spanish, and Swedish; we also present un official results for Basque. We designed a highly modular combination of language-independent feature extraction and supervised learning us ing support vector machines in order to permit rapid ramp-up, language independence, and ca pability for future expansion."]},{"title":"1 Introduction","paragraphs":["The SENSEVAL-2 exercise provided an unprece dented opportunity to explore word sense dis ambiguation (WSD) in a common evaluation framework for a large number of languages. In past work, we have focused on unsupervised methods for English, taking advantage of the WordN et hierarchy and sometimes also selec tional preferences between predicates and argu ments (Resnik, 1997; Resnik, 1999). In the cur rent exercise, however, WordNet-like sense hi erarchies were not necessarily going to be avail able for all languages, and the predominance of lexical selection tasks (rather than all- words tasks) suggested adopting a disambiguation ap proach capable of exploiting manually anno tated training data. These considerations mo tivated a system design based on supervised learning, where senses to be predicted did not need to be treated as part of a semantic hierar chy.","Our design was also motivated by the role of semantic selection techniques in our longer term research agenda. In the context of our group's work on cross-language information retrieval and machine translation applications (Resnik et al., 2001; Cabezas et al., 2001), lexical selection - that is, choosing the right target-language"]},{"title":"59","paragraphs":["word given a source-language word in context - is a crucial task. Because the lexical selec tion problem is extremely similar to sense selec tion, and because this was our first foray into supervised methods, we took advantage of the opportunity to construct an architecture that will support both tasks.","In the sections that follow, we lay out our system architecture, briefly summarize our SENSEVAL-2 results, and discuss our plans for future work."]},{"title":"2 System Architecture","paragraphs":["UMD's system follows the classic supervised learning paradigm that, for WSD, is perhaps best exemplified by Yarowsky's (1993) work. Each word in the vocabulary is considered an independent classification problem. First, an notated training instances for the ambiguous word are analyzed so that each instance can be represented as a collection of feature-value pairs labeled with the correct category. Then, these data are used for parameter estimation within a supervised learning framework in or der to produce a trained classifier. Finally, the trained classifier is given previously unseen test instances and for each instance it predicts what the appropriate category label should be. 2.1 Contextual Features We began by tokenizing all the training in stances using a simple language-specific tok enizer. Features were then defined in terms of the presence of tokens either within a wide con text or at a certain position to the right or left of the word being disambiguated.","In detail, let T be the set of unique tokens found in the full set of training data (all train ing instances), plus the special token UNKNOWN, which replaces any token in test data that was never seen during training. Define F wide = T. A feature"]},{"title":"f","paragraphs":["E F wide will be considered present and have a non-zero value if"]},{"title":"f","paragraphs":["appears any where in the wide context of the word being disambiguated. For example, if we were disam biguating the word training that appears in the first sentence of this paragraph, using the entire paragraph as the wide context, then there would be non-zero values for features WE, BEGAN, and every other word in the paragraph. That is, features correspond to surrounding words. 1","Let£"]},{"title":"=","paragraphs":["{L3,L2,Ll,Rl,R2,R3}, signifying the locations \"three tokens to the left\", \"two to kens to the left\", ... , \"three tokens to the right\", and define Fcolloc"]},{"title":"=","paragraphs":["{l:t"]},{"title":"ll","paragraphs":["E £ and t E"]},{"title":"T}.","paragraphs":["A feature l:t E Fcolloc will be considered present and have a non-zero value if token t appears at position l relative to the word being disam biguated. For example, if we were disambiguat ing the word training that appears in the first sentence of this section, there would be non-zero values for the features L3 : tokenizing, L 2 : all, L1: the, L1: instances, L2 :using, and L3: a. 2.2 Feature Weights The value associated with each feature is a weight indicating how useful the feature is likely to be in disambiguation, analogous to the term weights used in representing documents as fea ture vectors for information retrieval.","In detail, let us designate the full feature set as F = Fwide U Fcolloc' and let N:F ="]},{"title":"j.Fj.","paragraphs":["Clearly some features are more useful than others. For example, the feature into (word into appearing anywhere in the context) is unlikely to help distinguish among senses, although the feature R1: into (word into appearing one word to the right) might be useful for disambiguat ing among the senses of some verbs. In order to assign weights to features based on their likely utility, we follow a strategy similar to what is done in information retrieval, defining inverse category frequency (ICF), by analogy with in verse document frequency (IDF), as a function of how many distinct categories a feature ap pears with in training data.","1","For SENSEVAL-2, we defined the surrounding context for wide contexts as being anywhere within the test in stance, because instances comprised only a sentence or two. In a more general setting the context could be de fined as a window of ±50 words, ±100 words, the entire document, etc."]},{"title":"60","paragraphs":["Specifically, if we are disambiguating a word w with senses S = { s1, s2, ... , SNw}, then we de fine ICF"]},{"title":"wU)","paragraphs":["= -log( N ~/ N"]},{"title":"w)","paragraphs":["where N ~ is the number of distinct elements of S that ever co occur with feature"]},{"title":"f","paragraphs":["in the training data for word w. For example, if a word has five senses, and the feature L1 :the appears in some train ing instance for each of the five senses, then"]},{"title":"ICFw(LI","paragraphs":[":the) = -log(5/5) = 0, correctly in dicating that this feature is not at all useful for disambiguating among the five senses of this word. The lower N ~ is, the greater the value of the ICF"]},{"title":"wU)","paragraphs":["value and hence the greater weight accorded this feature.","Training and test instances are represented as N :F-ary feature vectors: given a training or test instance for a word w, the vector representa tion is defined by"]},{"title":"vw[f] =","paragraphs":["ICF"]},{"title":"wU)","paragraphs":["if"]},{"title":"f","paragraphs":["E"]},{"title":"F","paragraphs":["is present, and zero otherwise. 2.3 Learning Framework Once training and test instances are represented as feature vectors, it becomes possible to ex ploit any number of existing supervised learn ing algorithms. In general, such algorithms take a set"]},{"title":"{(vbci),(v2,c2), ... ,(vN,cN)}","paragraphs":["of training instances, and produce a classifier that takes a feature vector v as input and return a distri bution or confidence function over the possible categories.","For SENSEVAL-2, we selected support vec tor machines (SVMs) as the supervised learn ing framework. We were motivated by the fact that SVMs have been shown to achieve high per formance and work efficiently in environments where there are very large numbers of features, and also by the existence of a good off-the shelf implementation, SVM-Light, available for research purposes (Joachims, 1999; Joachims, 1998).2","SVM learning is appropriate for binary clas sification tasks, rather than the multi-way clas sification needed for disambiguating among"]},{"title":"n","paragraphs":["senses. For each word in the lexical sample tasks, therefore, we constructed a family of SVM classifiers, one for each of the word's Nw senses. All positive training examples for a","2","Hearst {1998) presents a collection of brief and illuminating discussions of SVMs; see http:/ fwww.computer.org/intelligent/ex1998/pdf/x4018.pdf. SVM-Light is available at http:/ Jwww-ai,cs.uni dortmund.de/ svm..light. Language"]},{"title":"I","paragraphs":["Precision"]},{"title":"(%) I","paragraphs":["Recall"]},{"title":"(%) I","paragraphs":["English (coarse) 64.3 64.3 English (fine) 56.8 56.8"]},{"title":"I","paragraphs":["Spanish (fine) 62.7 62.7"]},{"title":"I","paragraphs":["Swedish (mixed)"]},{"title":"I","paragraphs":["65.6 65.6"]},{"title":"I","paragraphs":["Swedish (fine)"]},{"title":"I","paragraphs":["61.1 61.1"]},{"title":"I","paragraphs":["Basque (fine)"]},{"title":"I","paragraphs":["70.3 70.3 Table 1: UMD-SST lexical sample results sense Si of w were treated as negative training examples for all the other senses Sj, j"]},{"title":"f:.","paragraphs":["i.","In the testing phase, we convert test instances for word w into feature vectors, and we then we run these vectors through the SVM classifiers for { St, s2, ... , SNw}· For each instance, we se lect the sense for which the SVM classifier's re sponse is most strongly \"yes\" (or, equivalently, most weakly \"no\")."]},{"title":"3 SENSEVAL-2 Results","paragraphs":["Table 1 shows the performance of UMD's su pervised sense tagger (UMD-SST) for the lex ical sample tasks in four languages. The fig ures for English, Spanish, and Swedish are offi cial SENSEVAL-2 results; the figures for Basque are unofficial results kindly computed by the Basque task organizers after SENSEVAL-2 be cause our Basque responses were not submitted in time for official evaluation.","In general, we were quite pleased with the re sults, particularly since this was our first time participating in SENSEVAL. UMD-SST turned in a solid performance in comparison with the baselines and other systems, with essentially no language-specific alterations necessary other than those required for tokenization. This en abled us to participate in system evaluation for more languages than any site except JHU. We consider this a good starting point for our fur ther investigations, which we now briefly de scribe."]},{"title":"4 Future Work","paragraphs":["Using the current system as a starting point, we are engaged in three lines of further investi gation: linguistically richer contextual features, corpus-dependent expansion of feature vectors, and lexical selection via supervised learning.","In our preliminary tests using training and development data, we experimented first with 61 using F wide as the feature set, and obtained sig nificant improvements when we added Fcolloc in order to capture collocations and other local contextual features. In our follow-up efforts we plan to use broad-coverage parsing to create a set of features augmented further by grammat ical relations, thus capturing collocations medi ated by syntactic structure. For example, al though our current feature vectors could not represent the presence of the word tagger as a nearby collocate of the word describe in the ab stract of this paper, syntactically richer repre sentations of this context for the verb describe would include the feature object='tagger'. Use of syntactic collocates will require broad coverage parsing in all the languages of inter est in order to identify grammatical relations; for this we will take advantage of our other work at Maryland on bootstrapping stochastic parsers for new languages using parallel corpora (Cabezas et al., 2001).","In our preliminary efforts we were not sur prised to find that sparseness of data was a problem. Although we expect that some improvements may be obtained by collapsing across word variants - e.g. via morphologi cal equivalence classes or stemming - we also plan to focus our efforts on semantic expansion, using document expansion techniques we have developed in our research on cross-language in formation retrieval (Levow et al., 2001). We have implemented a variant of the architecture in which training contexts are used as queries to a comparable corpus in order to retrieve re lated documents. The features from these docu ments are then added to the context representa tions, providing semantically enhanced feature vectors. Evaluation of this approach using SEN SEVAL data is in progress.","Our third avenue of investigation focuses on the use of our supervised WSD infrastructure to address problems of lexical selection in ma chine translation. Empirically, there is a close relationship between sense distinctions and pat terns of lexicalization across languages (Resnik and Yarowsky, 1999). And operationally, there is no real difference between labeling a word with a sense tag from a monolingual dictionary and labeling that word with a translation from a bilingual dictionary. Using WSD techniques for lexical selection primarily requires solving two problems. The first problem is acquisition of annotated training data, and in this case large corpora of translation-labeled words in context can be created by obtaining parallel corpora, performing word-level alignment, and labeling each word with its correspondent in the other language; this problem is already solved as part of our infrastructure for research on statistical machine translation (Cabezas et al., 2001). The second problem is one of scalability: the ap proach we have described requires a separate classifer for every sense (or, now, every possi ble word-level translation) of every source lan guage word. This remains an open issue, but we are optimistic about rapid developments in this area since scaling up to large vocabularies is a problem shared by everybody who wishes to use supervised WSD techniques in a broad-coverage setting."]},{"title":"5 Conclusions","paragraphs":["University of Maryland's sense tagger repre sents a classic instance of the supervised learn ing approach. At the same time, we have made architectural choices that promote language in dependence, modularity, extensibility, and scal ability, and in a relatively short time period we succeeded in putting together an implementa tion that performs quite credibly among an im pressive collection of competitors. We are en couraged by the results and we look forward to participating in further SENSEVAL exercises."]},{"title":"Acknowledgements","paragraphs":["This work was supported in part by De partment of Defense contract MDA90496C1250 and DARPA/ITO Cooperative Agreement N660010028910. We're very grateful to all the SENSEVAL-2 organizers and task organizers for their hard work, to Thorsten Joachims for mak ing SVM-Light available, and to David Mar tinez for computing our results for Basque."]},{"title":"References","paragraphs":["Clara Cabezas, Bonnie Dorr, and Philip Resnik. 2001. Spanish language processing at Univer sity of Maryland: Building infrastructure for multilingual applications. In Proceedings of the Second International Workshop on Span ish Language Processing and Language Tech nologies (SLPLT-2), Jaen, Spain, September."]},{"title":"62","paragraphs":["Marti A. Hearst. 1998. Trends and controver sies: Support vector machines. IEEE Intelli gent Systems, 13( 4 ):18-28.","Thorsten Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of the European Conference on Machine Learning. Springer.","Thorsten Joachims. 1999. Making large-scale SVM learning practical. In B. Scholkopf, C. Burges, and A. Smola, editors, Advances in Kernel Methods - Support Vector Learn ing. MIT Press.","Gina-Anne Levow, Douglas Oard, and Philip Resnik. 2001. Rapidly retargetable interac tive translingual retrieval. In Human Lan guage Technology Conference (HLT-2001}, San Diego, CA, March.","Philip Resnik and David Yarowsky. 1999. Distinguishing systems and distinguishing senses: New evaluation methods for word sense disambiguation. Natural Language En gineering, 5(2):113-133.","Philip Resnik, Douglas Oard, and Gina Levow. 2001. Improved cross-language retrieval us ing backoff translation. In Human Lan guage Technology Conference (HLT-2001), San Diego, March.","Philip Resnik. 1997. Selectional preference and sense disambiguation. In ANLP Work shop on Tagging Text with Lexical Semantics, Washington, D.C., April.","Philip Resnik. 1999. Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language. Journal of Artificial In telligence Research ( JAIR), 11:95-130.","David Yarowsky. 1993. One sense per colloca tion. ARPA Workshop on Human Language Technology, March. Princeton."]}]}