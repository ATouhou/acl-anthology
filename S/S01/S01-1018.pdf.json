{"sections":[{"title":"The UNED systems at","paragraphs":["SENSEVAL-2"]},{"title":"David Fermindez-Amor6s, Julio Gonzalo, Felisa Verdejo Depto. de Lenguajes","paragraphs":["y"]},{"title":"Sistemas Informaticos, UNED { david,julio,felisa }@lsi.uned.es . Abstract","paragraphs":["We have participated in the SENSEVAL-2 En glish tasks (all words and lexical sample) with an unsupervised system based on mutual infor mation measured over a large corpus (277 mil lion words) and some additional heuristics. A supervised extension of the system was also pre sented to the lexical sample task.","Our system scored first among unsupervised systems in both tasks: 56.9% recall in all words, 40.2% in lexical sample. This is slightly worse than the first sense heuristic for all. words and 3.6% better for the lexical sample, a strong in dication that unsupervised Word Sense Disam biguation remains being a strong challenge."]},{"title":"1 Introduction","paragraphs":["We advocate researching unsupervised tech niques for Word Sense Disambiguation (WSD). Supervised techniques offer better results in general but the setbacks, such as the problem of developing reliable training data, are very considerable. Also there's probably more to WSD than blind machine learning (a typical ap proach, although such systems produce interest ing baselines).","Within the unsupervised paradigm, we are in terested in performing in-depth measures of the disambiguation potential of different sources of information. We have previously investigated the informational value of semantic distance measures in (Fermindez-Amor6s et al., ) . For SENSEVAL-2, we have turned to investigate pure coocurrence information as a source of disam biguation evidence. In essence, our system com putes a matrix of mutual information for a fixed vocabulary and applies it to weight coocurrence counting between sense and context character istic vectors. 75","In the next section we describe the process of constructing the relevance matrix. In section 3 we present the particular heuristics used for the competing systems. In section 4 we show the results by system and heuristic and some base lines for comparison. Finally in the last sections we draw some conclusions about the exercise."]},{"title":"2 The Relevance matrix","paragraphs":["2.1 Corpus processing Before building our systems we have developed a resource we've called the relevance matrix. The raw data used to build the matrix comes from the Project Gutenberg (PG) 1.","At the time of the creation of the matrix the PG consisted of more than 3000 books of di verse genres. We have adapted these books for our purpose : First, language identification was used to filter books written in English; Then we stripped off the disclaimers. The result is a collection of around 1.3Gb of plain text.","Finally we tokenize, lemmatize, strip punctu ation and stop words and detect numbers and proper nouns. 2.2 Coocurrence matrix We have built a vocabulary of the 20000 most frequent words (or labels, as we have changed all the proper nouns detected to the label PROPER_NOUN and all numbers detected to NUMBER) in the text and a symmetric coocur rence matrix between these words within a con text of 61 words (we thought a broad context of radius 30 would be appropriate since we are trying to capture vague semantic relations). 2.3 Relevance matrix In a second step, we have built another sym metric matrix, which we have called relevance 1 http://promo.net/pg matrix, using a mutual information measure be tween the words (or labels), so that for two words a and b, the entry for them would be"]},{"title":"~i)~~l),","paragraphs":["where P(a) is the probability of find ing the word a in a random context of a given size. P(a"]},{"title":"n","paragraphs":["b) is the probability of finding both a and b in a random context of the fixed size. We've introduced a threshold of 2 below which we set the entry to zero for practical purposes. We think that this is a valuable resource that could be of interest for many other applications other than WSD. Also, it can only grow in qual ity since at the time of making this report the data in the PG has almost doubled in size."]},{"title":"3 Cascade of heuristics","paragraphs":["We have developed a very simple language in order to systematize the experiments. This lan guage allows the construction of WSD systems composed of different heuristics that are ap plied in cascade so that each word to be disam biguated is presented to the first heuristic, and if it fails to disambiguate, then the word is passed on to the second heuristic and so on. We can have several such systems running in parallel for efficiency reasons (the matrix has high memory requirements). Next we show the heuristics we have considered to build the systems","• Monosemous expressions. Monosemous expressions are simply unam biguous words in the case of the all words English task. In the case of the lexical sample English task, however, the annota tions include multiword expressions. We have implemented a multiword term de tector that considers the multiword terms from WordNet's index.sense file and detects them in the test file using a multilevel back tracking algorithm that takes account of the inflected and base forms of the compo nents of a particular multiword in order to maximize multiword detection. We tested this algorithm against the PG and found millions of these multiword terms. We restricted ourselves to the multiwords already present in the training file since there are, apparently, multiword expres sions that where overlooked during manual tagging (for instance the WordNet expres sion 'the_good_old_days' is not hand-tagged"]},{"title":"76","paragraphs":["as such in the test files)","• Statistical filter WordNet comes with a file, cntlist, literally 'file listing number of times each tagged sense occurs in a semantic concordance' so we use this to compute the relative prob ability of a sense given a word ( approxi mate in the case of collections other than SemCor). Using this information, we elimi nated the senses that had a probability un der 10% and if only one sense remains we choose it. Otherwise we go on to the next heuristic. In other words, we didn't apply complex techniques with words which are highly skewed in meaning 2 .","• Relevance filter This heuristic makes use of the relevance matrix. In order to assign a score to a sense, we count the coocurrences of words in the context of the word to be dis ambiguated with the words in the defini tion of the senses (the WordNet gloss to kenized, lemmatized and stripped out of stop words and punctuation signs) weight ing each coocurrence by the entry in the relevance matrix for the word to be disam biguated and the word whose coocurrences are being counted, i.e., if s is a sense of the word a whose definition is Sand C is the context in which a is to be disambiguated, then the score for s would be:"]},{"title":"L","paragraphs":["Rwafreq(w, C)freq(w, S)idf(w, a) wEC Where idf(w, a) = log"]},{"title":"!i.e,","paragraphs":["with N being the number of senses for word a and dw the number of sense glosses in which w appears. freq(w, C) is the frequency of word win the context C and freq ( w, S) is the frequency of w in the sense gloss"]},{"title":"S.","paragraphs":["The idea is to prime the occurrences of words that are relevant to the word being","2","Some people may argue that this is a supervised ap proach. In our opinion, the cntlist information does not make a system supervised per se, because a) It is stan dard information provided as part of the dictionary and b) We don't use the examples to feed or train any pro cedure. disambiguated and give low credit (possi bly none) to the words that are incidentally used in the context. Also, in the all words task (where POS tags from the TreeBank are provided) we have considered only the context words that have a POS tag compatible with that of the word being disambiguated. By com patible we mean nouns and nouns, nouns and verbs, nouns and adjectives, verbs and verbs, verbs and adverbs and vice versa. Roughly speaking, words that can have an intra-phrase relation. We also filtered out senses with low values in the cntlist file, and in any case we only considered at most the first six senses of a word.","• Enriching sense characteristic vectors The relevance filter provided very good re sults in our experiments with SemCor and SENSEVAL-1 data as far as precision is concerned, but the problem is that there is little overlapping between the defini tions of the senses and the contexts in terms of coocurrence (after removing stop words and computing idf) which means that the previous heuristic didn't disam biguate many words. To overcome this problem, we enrich the senses characteristic vectors adding for each word in the vector the words related to it via the relevance matrix weights. This corresponds to the algebraic notion of mul tiplying the matrix and the characteristic vector. In other words, if"]},{"title":"R","paragraphs":["is the relevance matrix and v our characteristic vector we would finally use Rv"]},{"title":"+","paragraphs":["v. This should increase the number of words disambiguated provided we eliminate the idf factor (which would be zero in most cases because now the sense characteristics vectors are not as sparse as before). When we also discard senses with low relative fre quency in SemCor we call this heuristic mixed filter.","• back off strategies For those cases that couldn't be covered by other heuristics we employed the first sense heuristic. In the case of the supervised sys tem for the English lexical sample task we thought of using the most frequent sense but didn't implement it due to lack of time."]},{"title":"4 Systems and Results","paragraphs":["• UNED-AW-U2 We won't delve into UNED-AW-U system as it is very similar to this one. This is an (arguably) unsupervised system for the English all words task. The heuristics we used and the results obtained for each of them are shown in Table 1. Heuristic Att. Score Prec Rec Monosemous exp 514 45500 88.5% 18.4% Statistical filter 350 27200 77.7% 11.0% Mixed filter 1256 50000 39.8% 20.2% Enriched Senses 77 4300 55.8% 3.1% First sense 249 13600 54.6% 5.5% Total 2446 140600 57.5% 56.9% Table 1: Unsupervised heuristics for English all words task If the individual heuristics are used as stan dalone WSD systems we would obtain the results in Table 2. System Att. Score Prec Recall First sense 2405 146900 61.1% 59.4% UNED~AW-U2 2446 140600 57.5% 56.9% Mixed filter 2120 122600 57.8% 49.6% Enriched senses 2122 108100 50.9% 43.7% Random 2417 89191.2 36.9% 36.0% Statistical filter 864 72700 84.1% 29.4% Table 2: UNED-AW-U2 vs baselines","In the lexical sample task, we weren't able to multiply by the relevance matrix due to time constraints, so in order to increase the coverage for the relevance filter heuristic we expanded the definitions of the senses with those of the first 5 levels of hyponyms. Also, we selected the ra dius of the context to be considered depending on the POS of the word being disambiguated. For nouns and verbs we used 25 words radius neighbourhood and for adjectives 5 words at each side.","• UNED-LS-U This is essentially the same system as UNED-AW-U2, in this case ap plied to the lexical sample task. The results are displayed in Table 3."]},{"title":"77","paragraphs":["Heuristic Att. Score Prec Recall Relevance filt 3039 113617 37.3% 26.2% First sense 1285 60000 46.7% 13.9% Total 4324 173617 40.2% 40.2% Table 3: Unsupervised heuristics for English lexical sample task","• UNED-LS-T This is a supervised variant of the previous systems. We have added the training ex amples to the definitions of the senses giv ing the same weight to the definition and to all the examples as a whole (i.e. defini tions are considered more interesting than examples) Heuristic Att. Score Prec Recall Relevance filt 4116 206150 50.1% 47.6% First sense 208 9300 44.7% 2.1% Total 4324 215450 49.8% 49.8% Table 4: Supervised heuristics for English lexi cal sample task"]},{"title":"5 Discussion and conclusions","paragraphs":["We've put a lot of effort into making the rele vance matrix but its performance in the WSD task is striking. The matrix is interesting and its application in the relevance filter heuristic is slightly better than simple coocurrence count ing, which proves that it doesn't discard rele vant words. The problem seems to lie in the fact that irrelevant words (with respect to the word to be disambiguated) rarely occur both in the context of the word and in the definition of the senses (if they appeared in the definition they wouldn't be so irrelevant) so the direct im pact of the information in the matrix is very weak. Likewise, relevant (via the matrix) words with respect to the word to be disambiguated occur often both in the context and in the defi nitions so the final result is very similar to sim ple coocurrence counting.","This problem only showed up in the lexical sample task systems. In the all words systems we were to enrich the sense definitions to make a more advantageous use of the matrix.","We were very confident that the relevance filter would yield good results as we have al-"]},{"title":"78","paragraphs":["ready evaluated it against the SENSEVAL-1 and SemCor data. We felt however that we could improve the coverage of the heuristic enrich ing the definitions multiplying by the matrix. A similar approach was used by Yarowsky (Yarowsky, 1992) and Schiitze (Schiitze and Pedersen, 1995) and it worked for them. This wasn't the case for us; still, we think the re source is well worth researching other ways of using it.","As for the overall scores, the unsupervised lexical sample obtained the highest recall of the unsupervised systems, which proves that care fully implementing simple techniques still pays off. In the all words task the UNED-WS-U2 had also the highest recall among the unsupervised systems (as characterized in the SENSEVAL-2 web descriptions), and the fourth overall. We'll train it with the examples in Semcor 1.6 and see how much we can gain."]},{"title":"6 Conclusions","paragraphs":["Our system scored first among unsupervised systems in both tasks: 56.9% recall in all words, 40.2% in lexical sample. This is slightly worse than the first sense heuristic for all words and 3.6% better for the lexical sample, a strong in dication that unsupervised Word Sense Disam biguation remains being a strong challenge."]},{"title":"References","paragraphs":["D. Fernandez-Amor6s, J. Gonzalo, and F. Verdejo. The role of conceptual relations in word sense disambiguation. In Applica tions of Natural Language to Information Systems (NLDB)'Ol, Madrid.","H. Schiitze and J. Pedersen. 1995. Information retrieval based on word senses. In Fourth An nual Symposium on Document Analysis and Information Retrieval, Las Vegas NV, pages 161-175.","D. Yarowsky. 1992. Using statistical models of roget's categories trained on large corpora. In COLING'92, Nantes, pages 454-460."]}]}