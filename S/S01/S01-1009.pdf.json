{"sections":[{"title":"SENSEVAL-2 Japanese Translation Task Sadao K urohashi University of Tokyo","paragraphs":["kuro©kc.t.u-tokyo.ac.jp"]},{"title":"Abstract","paragraphs":["This paper reports an overview of SENSEVAL-2 Japanese translation task. In this task, word senses are defined according to translation dis tinction. A translation Memory .· (TM) was constructed, which contains, for each Japanese head word, a list of typical Japanese expressions and their English translations. For each target word instance, a TM record best approximating that usage had to be submitted. Alternatively, submission could take the form of actual target word translations. 9 systems from 7 organiza tions participated in the task."]},{"title":"1 Introduction","paragraphs":["In written texts, words which have multiple senses can be classified into two categories; homonyms and polysemous words. Generally speaking, while homonymy sense distinction is quite clear, polysemy sense distinction is very subtle and hard. English texts contain many homonyms. On the other hand, Japanese texts in which most content words are written by ideograms rarely contain homonyms. That is, the main target in Japanese WSD is polysemy, which makes Japanese WSD task setup very hard. What sense distinction of polysemous words is reasonable and effective heavily de pends on how to use it, that is, an application ofWSD.","Considering such a situation, in addition to the ordinary dictionary task we organized an other task for Japanese, a translation task, in which word sense is defined according to trans lation distinction. Here, we set up the task as suming the example-based machine translation paradigm (Nagao, 1981). That is, first, a trans lation memory (TM) is constructed which con tains, for each Japanese head word, a list of typ ical Japanese expressions (phrases/sentences) 37 involving the head word and an English trans lation for each (Figure 1). We call a pair of Japanese and English expressions in the TM as a TM record. Given an evaluation document containing a target word, participants have to submit the TM record best approximating that usage.","Alternatively, submissions can take the form of actual target word translations, or transla tions of phrases or sentences including each tar get word. This allows existing rule-based ma chine translation (MT) systems to participate in the task, and we can compare TM based sys tems with existing MT systems.","For evaluation, we distributed newspaper ar ticles. The number of target words was 40, and 30 instances of each target word were provided, making for a total of 1,200 instances."]},{"title":"2 Construction of Translation Memory","paragraphs":["The translation memory (TM) was constructed in two steps:","1. By referring to the KWIC (Key Word In Context) of a target word, its typical Japanese expressions are picked up by lex icographers.","2. The Japanese expressions are translated by a translation company.","KWIC was made from the nine years vol ume of Mainichi Newspaper corpus. They are morphologically analyzed and segmented into phrase sequences, and then the 100 most fre quent phrase uni-grams, hi-grams (two types; the target word is in the first phrase or the sec ond phrase) and tri-grams (the target word is in the middle phrase) are provided to lexicogra phers (Figure 2).","'- It is impossible to participate. ~'fJl G ~i!U'flO)fiJYtHd:~:f!!t:: ~@)O)~~l:fd:~:f_!!iJ!~ ~ :fBtiJ!~~ 0) ~~:f!!~d:t~ \\;~ -1!f~:f!!O)t~t--~1J~ ~:f1!1£:iltl~ It is impossible to make use of the library in this hour. This bill is hard to pass. It is no wonder he got angry. the most natural way ~:FJI!t~~ ~:f!!t~Jm\\;)~l_., to work too much unreasonable demand passing by force","~:f!!~L' r:p 1£: ~ ~ to commit a forced double suicide Figure 1: An example of Translation Memory. Phrase uni-gram Phrase bi-gram","151 \"\" d: )0 19 ;: 7 ;: 0 597 \"\" d: 551 ~:f!!'IJ! 416 ~:f_!!~IJ 413 ~:f!!l: 403 ~:f_!!1£: 351 ~:FJI!o 138 ~:f_)!'IJ! ~~o 14 (:'\"(~ ~:fl!o 6 *~~O)~j: ~:f!!'IJ! ~~0 106 ~:f_!!~ t~v)o 13 ;: c~d: ~:f!!c"]},{"title":"s ;:","paragraphs":["e:r:~d: ~:f!!'fJ\\ G~ :f1!837J! 5 ~< 0)~ ~:f]!~j: f~V)o 101 ~:f_!! t~< 10 *~~O)~j: ~:f_!!iJ!","67 ~:f!!O) t~v) 10 e:--c~ ~:f!!J e: 5 ~~~d: ~:f!!~c.,r:pe: J;;.'\"(v)~o 4 1_, '\"( ~ ~:fJ!ld: f~ V~o 56 ~:f!!'IJ! ~~J c 9 \\;~-jO)~j: ~:f_!l'IJ~ Figure 2: An example of KWIC (numbers indicate phrase frequency).","The lexicographers pick up a typical expres sion of the target word from the KWIC. If its sense is context-independently clear, the expres sion is adopted as it is. If its sense is not clear, some pre/post expressions are supplemented by referring original sentences in the newspaper corpus.","Then, we asked a translation company to translate the Japanese expressions. As a re sult, a TM containing 320 head words and 6920 records was constructed (one head word has 21.6 records on average). The average number of words of a Japanese expression is 4.5."]},{"title":"3 Gold Standard Data and the Evaluation of Translations","paragraphs":["As a gold standard data of the task, 40 target words were chosen out of 320 TM words. Con sidering the possible comparison of the trans lation task and the dictionary task, 40 target words were fully overlapped with 100 target words of the dictionary task.","In the Japanese dictionary task, target words are classified into three categories according to the difficulty (difficult, intermediate, easy), based on the entropy of word sense distri bution in the training data of the dictionary 38 task(Shirai, 2001). 40 target words of the tran: lation task consists of 20 nouns and 20 verbs: difficult nouns and verbs, 10 intermediate nom and verbs, and 5 easy nouns and verbs.","For each target word, 30 instances were ch< sen from Mainichi Newspaper corpus (in tot 1,200 instances) and they are also overlappe with the dictionary task. Since the dictionar task uses 100 instances for each target won the translation task used 1st, 4th, 7th, ... 90t instances of the dictionary task.","As a gold standard data, zero or more ar propriate TM records were assigned to each ir stance by the same translation company. Ar propriate TM records were classified into tb following three classes:"]},{"title":"© :","paragraphs":["A TM record which can be used t translate the instance. POS, tense, plura singular, and subtle nuance do not nece: sarily match."]},{"title":"0 :","paragraphs":["If the instance is considered alone, tb English translation is correct, but usin the TM record in the given context is nc so good, for example, making very round about translation."]},{"title":"6. :","paragraphs":["If the instance is considered alone, the English translation is correct, but using the TM record in the given context is inappro priate.","Out of 1,200 instances, 34 instances (2.8%) were assigned no TM records (there was no ap propriate TM record). To one instance, on aver age, 6.6 records were assigned as©, 1.4 records as"]},{"title":"0,","paragraphs":["and 0.1 records as 6, in total8.1 records. If a system chooses a TM record randomly as an answer, the accuracy becomes 36.8% in case that all of ©,"]},{"title":"0","paragraphs":["and"]},{"title":"6.","paragraphs":["records are regarded as correct, and 29.0% in case that only © is re garded as correct (they are the baseline scores used in the next section).","In the gold standard data construction, 90 instances (9 words x 10 instances) were dealt with by two annotators doubly, and then their agreement were checked. For each instance one record is chosen randomly from annotator B's answers, and it was checked whether it is con tained in annotator A's answers (annotator A made the whole gold standard data). The agree ment was 86.6% in case that all of ©,"]},{"title":"0","paragraphs":["and"]},{"title":"6.","paragraphs":["records are regarded as correct, and 80.9% in case that only© is regarded as correct.","In the case that the submission is in the form of translation data, translation experts (the same company as constructed the TM and the gold standard data) were asked to rank the supplied translation ©,"]},{"title":"0","paragraphs":["or X. This evalua tion does not pay attention to the total transla tion, but just the appropriateness of the target instance translation."]},{"title":"4 Result","paragraphs":["In the Japanese translation task, 9 systems from 7 organizations submitted the answers. The characteristics of the systems are summarized as follows:","• AnonymX, Anonym Y Commercial, rule-based MT systems.","• CRL-NYU (Communications Research Laboratory & New York Univ.) TM records are classified according to the English head word, and each cluster is supplemented by several corpora. The system returns a TM record when the similarity between a TM record and an input sentence is very high. Otherwise, it returns the English head word of the most similar cluster by using several machine learning techniques.","• Ibaraki (Ibaraki Univ.) A training data was constructed manually from newspaper articles, 170 instances for each target word. Features were collected in 7-word window around the target word, and decision list method was used for learn ing.","• Stanford-Titechl (Stanford Univ. & Tokyo Institute of Technology) The system selects the appropriate TM record based on the character-bigram based Dice's coefficient. It also utilized the context of the other target word instances in the evaluation text.","• AnonymZ A sentence (TM records for learning, and an input for testing) is morphologically an alyzed and converted into a semantic tag sequence, and maximum entropy method was used for learning.","• ATR The system selects the most similar TM record based on the cosine similarity be tween context vectors, which were con structed from semantic features and syn tactic relations of neighboring words of the target word.","• Kyoto (Kyoto U niv.) The system selects the most similar TM record by bottom-up, shared-memory based matching algorithm.","• Stanford-Titech2 (Stanford Univ. & Tokyo Institute of Technology) The system selects the appropriate TM record based on the case-frame- based sim ilarity, using NTT Goi-Taikei thesaurus.","The results of all systems are shown in Fig ure 3. The left bar charts indicate the accuracy based on the lenient evaluation (©,"]},{"title":"0","paragraphs":["and"]},{"title":"6.","paragraphs":["in TM selection and © and"]},{"title":"0","paragraphs":["in MT are re garded as correct); the right bar charts indicate the accuracy based on the strict evaluation ( © is only regarded as correct both in TM selection and MT). Note that since the TM does not have 39 I Cl Lenient evaluation • Strict evaluatiQn I 100 oo~~~~~~~~~~~~~~~~~~ Figure 3: Result of the Japanese translation task. \" 80"]},{"title":"f-r","paragraphs":["fTI r- 1 .•"]},{"title":"I","paragraphs":["c--"]},{"title":"u .• n","paragraphs":["I r-"]},{"title":"J(l I","paragraphs":["- H"]},{"title":"w:•","paragraphs":["r-i I"]},{"title":"1!.1","paragraphs":["I I"]},{"title":"\"'","paragraphs":["H"]},{"title":",_ Tl","paragraphs":["I I 70 50 40 30 20 10 Figure 4: Scores for nouns and verbs. a hierarchical structure, there is no evaluation options such as fine, coarse, and mixed.","Figure 4 shows scores for nouns and verbs separately, and Figure 5 shows scores for dif ficult/intermediate/easy words. Both of them were evaluated by the lenient criteria.","In these figures, \"Agreement\" and \"Baseline\" were as described in the previous section. When the system judges that there is no appropri ate TM record for an instance, it can return \"UNASSIGNABLE\". In that case, if there is no appropriate TM record assigned in the gold standard data, the answer is regarded as cor rect.","Among TM selection systems, systems using some extra learning data outperformed other systems just using the TM. The comparison be tween TM selection systems and MT systems is not easy, but the result indicates the effec tiveness of the accumulated know-how of MT systems. However, the performance of the best TM selection system is not so different from MT 40 IDDiffieutt •!ntermidiate •Easy I Figure 5: Scores for difficulty classes. systems, which indicates the promising future oJ TM based techniques."]},{"title":"5 Conclusion","paragraphs":["This paper described an overview of SENSEVAL· 2 Japanese translation task. The data used ir this task are available at SENSEVAL-2 web site. We hope this valuable data helps improve WS.C and MT systems."]},{"title":"Acknowledgment","paragraphs":["I wish to express my gratitude to Mainichi Newspapers for providing articles. I would alsc like to thank Prof. Takenobu Tokunaga (Tokyc Institute of Technology) and Prof. Kiyoaki Shi rai (JAIST) and Dr. Kiyotaka Uchimoto (CRL) for their valuable advise about task organiza tion, Yuiko Igura (Kyoto Univ.) and Inter Group Corp. for data construction, and all par ticipants to the task."]},{"title":"References","paragraphs":["Makoto Nagao. 1981. A framework of mechan ical translation between Japanease and En glish by analogy priciple. In Proc. of the In ternational NATO Symposium on Artificia. and Human Intelligence.","Kiyoaki Shirai. 2001. SENSEVAL-2 Japanese dictionary task. In Proceedings of tht. SENSEVAL-2 Workshop."]}]}