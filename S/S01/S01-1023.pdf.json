{"sections":[{"title":"ATR-SLT System for SENSEVAL-2 Japanese Translation Task Tadashi K urnano, Hideki Kashioka","paragraphs":["and"]},{"title":"Hideki Tanaka","paragraphs":["ATR Spoken Language Translation Research Laboratories"]},{"title":"2-2-2","paragraphs":["Hikaridai Seika-cho Soraku-gun Kyoto"]},{"title":"619-0288","paragraphs":["JAPAN {tadashi.kumano, hideki.kashioka, hideki.tanaka}@atr;co.jp"]},{"title":"Abstract","paragraphs":["We propose a translation selection system based on the vector space model.","When each translation candidate of a word is given as a pair of expressions containing the word and its translation, selecting the transla tion of the word can be considered equivalent to selecting the expression having the most similar context among candidate expressions. The pro posed method expresses the context information in \"context vectors\" constructed from content words co-occurring with the target word. Con text vectors represent detailed information com posed of lexical attributes( word forms, semantic codes, etc.) and syntactic relations (syntactic dependency, etc.) of the co-occurring words.","We tested the proposed method with the SENSEVAL-2 Japanese translation task. Preci sion/recall was 45.8% to the gold standard m the experiment with the evaluation set."]},{"title":"1 Introduction","paragraphs":["The SENSEVAL-2 Japanese translation task de fines a sense of a Japanese word as an English translation. The same Japanese word in differ ent contexts may have different English trans lations; therefore, translation ambiguity arises.","Translation Memory (henceforth TM) defin ing word senses were given to the task partic ipants. Each target word has translation pairs of Japanese and English expressions as word sense candidates1. The target word is marked in the Japanese expression, but the correspond ing part is unspecified in the English expression. Hence, selecting the most appropriate transla tion of the target Japanese word in the evalua tion expression can be considered to be equiv alent to selecting the expression with the most similar context in the TM. This is equivalent to the word sense disambiguation problem in a single language. 1 Each target word has 21.6 pairs on average."]},{"title":"95","paragraphs":["Generally, word sense disambiguation uses context information, such as the frequency of words that co-occur with the target word. The context information is learned from the correctly-annotated training corpora. However, no training corpus was given for the task and the given TM had shorter contexts because the TM expressions were rather incomplete. There fore, instead of learning the co-occurring words with the target word from the training corpora, we extract detailed information from the TM expressions as context information. We utilize the information of co-occurring words with the target word (context words) as shown below.","• lexical attributes (word form, part-of speech, semantic codes on thesaurus, etc.)","• syntactic relations to the target word (de pendency relation, etc.)","We employed the vector space model, which is used for text retrieval (Salton and McGill, 1983) to calculate the similarity between the context word information of evaluation expressions and those of the TM. The detailed context informa tion are expressed as \"context vectors.\" We use cosine values between context vectors as a mea sure of similarity.","In this paper, we will explain first how to con struct \"context vectors,\" and then show the ac curacy of the selection experiment to the correct data (gold standard)."]},{"title":"2 Translation Selection Using Context Vectors 2.1 Context Vectors 2.1.1 Concept","paragraphs":["We will explain how to construct a context vec tor from an expression e1 with the target word"]},{"title":"\"rEI,","paragraphs":["(aida; interval)\", as an illustration. Figure 1 shows the expression, which con","tains the content words \":;Kpft}"]},{"title":"(fuuju;","paragraphs":["married couple)\","]},{"title":"\"-f-1:lt","paragraphs":["(kodomo; child)\", and"]},{"title":"\"JiiitL","paragraphs":["Table 1: Context Vectors Construction","Type ot syntactic relationship to the target word modifying target word modihed by target word target following all context in case relation: in case relation: word ... words words"]},{"title":"wu","paragraphs":["NU NJ ..."]},{"title":"wu","paragraphs":["NU JVJ . .. ( e1) fv:u.fu-no aida-ni kodomo-ga umarcru \":}cfrm (/) rs~ f: ~itt \"/J{ .ilEitL-0 (a baby is born to the couple)\" kodomo fuufu","¢ fuuju ¢ ¢ ¢ ¢ umareru ¢ aida ... kodomo umareru umareru"]},{"title":"(","paragraphs":["(e2) shigoto-no aida-wo nutte mirnai-ni iku \".f± $- (!) Fs~ ~ 'd;;. .-_;, l\""]},{"title":"J%1fv'","paragraphs":["f;: 1'1"]},{"title":"<","paragraphs":["(to visit in hospital at the interval during one's work)\"","nutte shiqoto","¢ shigoto ¢ ¢ nutte ¢ ¢ ¢ aida nutte ... mzmaz mimai","iku iku"]},{"title":"(","paragraphs":["'-v-\" '--v--\"' ~","Amodifying_TW Amodified_by_TW : Atarget: · · · : ),follow The ratio of vector components for each word attribute 6 ( umareru; be born)\", and shows that the phrases containing these content words have some syntactic dependencies.","We then prepare a table that enumerates all possible syntactic relations between target word and context words, as in Table 1. For each ex pression, we then insert corresponding words to the column for each syntactic relation. For ex ample, the row for e1 of Table 1 can be obtained by the enumeration of expression e1. If a syntac tic relation is applicable to several words, such as the relation \"following words\" in Table 1, all of them are enumerated in the same column. If no content word comes under the syntactic relation, it is assigned empty ("]},{"title":"¢).","paragraphs":["Each row of the table is designated a \"context vector\" Ce of a corresponding expression e. 2.1.2 Calculation of Context Vectors In the preceding section, the table was explained as if it had context words in its elements, but \"word attribute vectors\" of context words are assigned to them practically. Hence, context vectors are the conjunctions of \"word attribute vectors.\" Each word attribute vector aw of a word w expresses lexical attributes of w, such as POS or semantic code. Word attribute vectors have a fixed dimension number, and each ele- ( couple between child is born ) fuufu-no aida-ni kodomo-ga umareru Expression: ~~W"]},{"title":"(])","paragraphs":["~"]},{"title":"(::","paragraphs":["-=f-1~ f:J\\ ~a::tL{)","'---\"' ........ '---\"' j(","Syntactic NO ~","D d . Nl GA epen enc1es: Figure 1: Syntactic Dependencies m Expres SIOn e 1"]},{"title":"96","paragraphs":["ment has a non-negative value. The procedure for constructing word attribute vectors will be described below in Section 2.1.3.","When several context words fall under the same syntactic relation like kodomo and umareru as we can sec in the \"following words\" relation in Table 1, the word vectors assigned to the relation is calculated by selecting the max imum value for every vector component among values of all words in that relation. The calcu lation named vecmax is defined as follows: where vecmax ai"]},{"title":"= (b1,","paragraphs":["b2, ... ,"]},{"title":"bn),","paragraphs":["z=l. .. m { ai is a n-dimensional vector, aij is a j-th element of vector ai, and bj"]},{"title":"=","paragraphs":["_max aij· z=l. .. m","When joining word attribute vectors into a context vector, each word attribute vector is given a weight in order to get a certain ratio of vector components for each syntactic relation. This is necessary to specify the degree of the contribution to the context vectors according to the type of syntactic relation. For example, as suming that the ratio of the vector components is specified using Asyn_rel ( syn_rel denotes a spe cific syntactic relation type) as shown in Ta ble 1, the context vector Ce1 of the expression e1 will be calculated as follows:"]},{"title":"EB","paragraphs":["Amodifying_TW · lafuuful"]},{"title":"EB","paragraphs":["afuufu aumareru"]},{"title":"EB","paragraphs":["Amodified_by_ TW ·"]},{"title":"I I EB .. ·","paragraphs":["aumareru Table 2: Constructing Word Attribute Vectors","u-ma-re-ru afuufu = ( TJe_form TJ e_pron 0 0 akodorno = ( 0 TJe_fonn 0 0 'T]e_pron 0 0 0 a.umar·ertl == ( 0 0 TJe_fonn 0 0 'T]e_pron 0 7]po.s","Type of syntactiC attriDute Semantic"]},{"title":"Coae","paragraphs":["N86 N85 N74 N72 N5 N4 0 0 !1flJ?"]},{"title":"7 7 Jf","paragraphs":["~ ~ ~· ~ ~ '!)_scm",".,g 79 0 0 0 0 0 0 ffi \\ aaida w /\\target · -","1","-- 1 EB · .. a aida","vecmax ai iE { kodomo, umareru} I","vecmax ail iE{ kodomo, umareru} EB Ajollow · EB"]},{"title":">-au·","paragraphs":["vecmax ai iE {fuufu, kodomo, umareru}"]},{"title":"I","paragraphs":["vecmax ai ~- iE {fuufu,kodomo, umareru} 2.1.3 Word Attribute Vectors For lexical attributes, we prepare another table similar to that for context words described in the previous section. Table 2 shows that theta ble enumerates attributes for all words appear ing for each lexical attribute. For each word, values are assigned to the column correspond ing to the lexical attribute. The value zero is as signed to the column when the lexical attribute is not applicable to the word. In Table 2, the lexical attributes of each context word in ex pression e1 are expressed in each row. The row is called \"word lexical attributes\" aw of the cor responding word w.","We employ the semantic codes of a Japanese thesaurus as the semantic attributes. A seman tic code may have superordinates because a the saurus represents semantic relations on the hi erarchical tree structure. For example, the word fuufu has semantic codes on seven levels, from \"Noun 7 4'' on the leaf node to \"Noun 1\" on the top, in the thesaurus \"Nihongo Goi Taikei (Ike hara et al., 1997)\" that we used. We treat all semantic codes as semantic attributes of word attribute vectors, and assign values to the cor responding elements equally.","Each lexical attribute of a word attribute vec tor should be assigned a value, the ratio of com ponent vectors for each word lexical attribute being the specific value Tfword_attr ( word_attr de-N3 N2 'Nl P26 Pl7 Pl6 Pl ..."]},{"title":";Jf","paragraphs":[":]!!'"]},{"title":"7","paragraphs":["0 0 0 0 0 ~ !jf1"]},{"title":"~","paragraphs":["0 0 0 0 0 0 0 0 ~"]},{"title":"7f 7","paragraphs":["~ 0 notes a specific word attribute type) in Table 2. Semantic attributes may have multiple compo nents to be assigned values, each component should be normalized by the number of the com ponents (See Table 2). 2.2 Translation Selection To select an appropriate translation for an eval uation expression containing a target Japanese word, we need to compare the context vector of the evaluation expression with the context vec tors of all candidate Japanese expressions in the TM. We then choose the candidate whose cosine value to the context vector of the evaluation ex pression is the maximum.","Each expression should have a unique con text vector in order to compare context vectors. But context words, like target words, have am biguity, and they have several candidates for se mantic codes in the thesaurus. It seems unac ceptable that the method requires disambigua tion of context words before disambiguation of the target word. Therefore, we decided not to disambiguate context words before constructing the context vector. Instead, we construct \"con text vector candidates\" from all combinations of the context word candidates. All combina tions of the context vector candidates are used for calculating similarity, and the combination that has the maximum value is selected as the pair of the evaluation and the TM expressions. We can resolve ambiguity of context words when selecting the translation of the target word."]},{"title":"3 Description of Participating System","paragraphs":["3.1 Resources, etc. Our system used the following resources in ad dition to the given TM and evaluation set."]},{"title":"97","paragraphs":["Table 3: Employed Parameters","word attribute type ratio syntactic relation type ratio Emergent Word Form 1 Pronunciation 1","modifying target word (case relation: specific) 3","(case relation: non-specific) 1 Standard Form 4 modified by target word (case relation: specific) 3 (standard) Pronunciation 4 (case relation: non-specific) 1 Part-Of-Speech 0 target word 2 Conjugated Form 1 the phrase containing target word 2 Semantic Code 12 preceding target word 1","following target word 1","all content words 2","Japanese Morphological Analyzer:","JUMAN (Kurohashi and Nagao, 1998)","Japanese Syntactic Analyzer:","KNP (Kurohashi, 1998)","Thesaurus:","Nihongo Goi Taikei (Ikehara et al., 1997) 3.2"]},{"title":"Parameters","paragraphs":["The following parameters have significant ef fects on the accuracy of our method.","1. The 77word_attr ratio of vector compo nents specified for each word attribute when making word attribute vectors (Sec tion 2.1.3)","2. The Asyn_rel ratio of the vector components specified for each syntactic relation when joining word attribute vectors into context vectors (Section 2.1.2)","However, we did not optimize the parameters in our participating system, because of the task specification that no training corpus was given and the time limitations in the course of system development. Parameters were given manually by considering the parameter functions. All of the lexical and syntactic attributes and parame ters that represent the ratio between attributes, which our participating system employed, are shown in Table 3."]},{"title":"4 Evaluation","paragraphs":["Our participating system marked both the pre cision and the recall at 45.8% of the correct data (the gold standard) in the evaluation corpus se lection. However, our participating system had some serious bugs in the vector normalization process. After correcting the bugs, we made another selection experiment using the same pa rameters described in Section 3.2. The accu racy of the corrected system was 49.3% (nouns: 50.0%, predicates: 48.5%)."]},{"title":"98 5 Summary","paragraphs":["We proposed a translation selection method for the SENSEVAL-2 Japanese translation task. The proposed method calculates the similarity be tween an evaluation expression containing the target word and Japanese expressions contain ing the same word in the TM. For calculating similarity, \"context vectors\" are constructed. Context vectors represent lexical attributes of context words and syntactic relations between context words and the target word. The system employed the proposed method with an accu racy of 49.3% after bug elimination.","Future plans are as follows.","1. To optimize parameters using the gold standard. We would like to use the opti mized parameters to study the relation be tween context information type and accu racy on translation selection. In addition, we will examine whether employed lexical and syntactic attributes are appropriate for the task.","2. To apply the machine learning method to the task, preparing the training corpora. We will make use of the detailed context information proposed, the lexical and syn tactic attributes, at machine learning."]},{"title":"References","paragraphs":["S. Ikehara, M. Miyazaki, S. Shirai, A. Yokoo, H. Nakaiwa, K. Ogura, Y. Oyama, and Y. Hayashi, editors. 1997. Nihongo Goi Taikei, volume 1-5. Iwanami Shoten. (in Japanese).","S. Kurohashi and M. Nagao, 1998. Japanese Mor phological Analysis System JUMAN version 3.61. Kyoto University. (in Japanese).","S. Kurohashi, 1998. Japanese Syntactic Analysis System KNP version 2.0 b6 user's manual. Kyoto University. (in Japanese).","G. Salton and M. J. McGill. 1983. Introduction to Modern Information Retrieval. McGraw-Hill."]}]}