{"sections":[{"title":"A Text Understander that Learns","paragraphs":["Udo Hahn &: Klemens Schnattinger Computational Linguistics Lab, Freiburg University Werthmannplatz 1, D-79085 Freiburg, Germany"]},{"title":"{hahn, schnatt inger}@col ing. uni-freiburg, de","paragraphs":["Abstract We introduce an approach to the automatic acquisition of new concepts fi'om natural language texts which is tightly integrated with the underlying text understanding process. The learning model is centered around the 'quality' of different forms of linguistic and conceptual evidence which underlies the incremental generation and refinement of alternative concept hypotheses, each one capturing a different conceptual read-ing for an unknown lexical item. 1 Introduction The approach to learning new concepts as a result of understanding natural language texts we present here builds on two different sources of evidence -- the prior knowledge of the domain the texts are about, and grammatical constructions in which unknown lexical items occur. While there may be many reasonable interpretations when an unknown item occurs for the very first time in a text, their number rapidly decreases when more and more evidence is gathered. Our model tries to make explicit the reasoning processes behind this learning pattern.","Unlike the current mainstream in automatic linguistic knowledge acquisition, which can be characterized as quantitative, surface-oriented bulk processing of large corpora of texts (Hindle, 1989; Zernik and Jacobs, 1990; Hearst, 1992; Manning, 1993), we propose here a"]},{"title":"knowledge-intensive","paragraphs":["model of concept learning from"]},{"title":"few,","paragraphs":["positive-only examples that is tightly integrated with the non-learning mode of text understanding. Both learning and understanding build on a given core ontology in the format of terminological assertions and, hence, make abundant use of terminological reasoning. The 'plain' text understanding mode can be considered as the instantiation and continuous filling d~udr s,y ~ trw"]},{"title":"~","paragraphs":["Hyl~si~ space- j Hyputhcsis t spal.'c-n I","Q*mlifi~r Q*mlity ~,l~*Ine Figure 1: Architecture of the Text Learner of roles with respect to"]},{"title":"single concepts","paragraphs":["already available in the knowledge base. Under learning conditions, however, a"]},{"title":"set of alternative concept hypotheses","paragraphs":["has to be maintained for each unknown item, with each hypothesis denoting a newly created conceptual interpretation tentatively associated with the unknown item.","The underlying methodology is summarized in Fig. 1. The"]},{"title":"text parser","paragraphs":["(for an overview, cf. BrSker et al. (1994)) yields information from the grammatical constructions in which an unknown lexical item (symbolized by the black square) occurs in terms of the corresponding"]},{"title":"de- pendency parse tree.","paragraphs":["The kinds of syntactic constructions (e.g., genitive, apposition, comparative), in which unknown lexical items appear, are recorded and later assessed relative to the credit they lend to a particular hypothesis. The conceptual interpretation of parse trees involving unknown lexical items in the"]},{"title":"domain knowl- edge base","paragraphs":["leads to the derivation of"]},{"title":"concept hy- potheses,","paragraphs":["which are further enriched by conceptual annotations. These reflect structural patterns of consistency, mutual justification, analogy, etc. relative to already available concept descriptions in the domain knowledge base or other hypothesis spaces. This kind of initial evidence, in particular its predictive \"goodness\" for the learning task, is represented by corresponding sets of"]},{"title":"linguistic","paragraphs":["and"]},{"title":"conceptual qual-","paragraphs":["476 iSyntax Semantics CMD C ~ QD z CuD CZuD z VR.C {d e A z [ RZ(d) C_ C z} RnS R z nS z cln"]},{"title":"{(d,d')en","paragraphs":["z l d e C z} RIG {(d, d') • n z I d' • C z) Table l: Some Concept and Role Terms Axiom Semantics A - C A z = C z a : C a z E C z Q - R QZ = RZ a R b (a z, b z) E R z Table 2: Axioms for Concepts and Roles ity labels. Multiple concept hypotheses for each unknown lexical item are organized in terms of corresponding hypothesis spaces, each of which holds different or further specialized conceptual readings.","The quality machine estimates the overall credibility of single concept hypotheses by tak-ing the available set of quality labels for each hypothesis into account. The final computa-tion of a preference order for the entire set of competing hypotheses takes place in the qualifier, a terminological classifier extended by an evaluation metric for quality-based selection criteria. The output of the quality machine is a ranked list of concept hypotheses. The ranking yields, in decreasing order of significance, either the most plausible concept classes which classify the considered instance or more general concept classes subsuming the considered concept class (cf. Schnattinger and Hahn (1998) for details). 2 Methodological Framework In this section, we present the major methodological decisions underlying our approach. 2.1 Terminological Logics We use a standard terminological, KL-ONEstyle concept description language, here referred to as C:D£ (for a survey of this paradigm, cf. Woods and Schmolze (1992)). It has several constructors combining atomic concepts, roles and individuals to define the terminological the-ory of a domain. Concepts are unary predicates, roles are binary predicates over a domain A, with individuals being the elements of A. We assume a common set-theoretical semantics for C7)£ - an interpretation Z is a function that assigns to each concept symbol (the set A) a subset of the domain A, Z : A -+ 2 n, to each role symbol (the set P) a binary relation of A, Z : P --+ 2 ~×n, and to each individual symbol (the set I) an element of A, Z : I --+ A.","Concept terms and role terms are defined in-ductively. Table 1 contains some constructors and their semantics, where C and D denote concept terms, while R and S denote roles. R z (d) represents the set of role fillers of the individual d, i.e., the set of individuals e with (d, e) E R z.","By means of terminological axioms (for a subset, see Table 2) a symbolic name can be introduced for each concept to which are assigned necessary and sufficient constraints using the definitional operator '\"= . A finite set of such axioms is called the terminology or TBox. Concepts and roles are associated with concrete individuals by assertional axioms (see Table 2; a, b denote individuals). A finite set of such axioms is called the world description or ABox. An interpretation Z is a model of an ABox with regard to a TBox, iff Z satisfies the assertional and terminological axioms.","Considering, e.g., a phrase such as 'The switch of the Itoh-Ci-8 ..', a straightforward translation into corresponding terminological concept descriptions is illustrated by: (el) switch.1 : SWITCH (P2) Itoh-Ci-8 HAS-SWITCH switch.1 (P3) HAS-SWITCH --","(OuTPUTDEV LJ INPUTDEV U IHAS-PARTISwITCH","STORAGEDEV t3 COMPUTER)","Assertion P1 indicates that the instance switch.1 belongs to the concept class SWITCH. P2 relates Itoh-Ci-8 and switch.1 via the relation HAS-SWITCH. The relation HAS-SWITCH is defined, finally, as the set of all HAS-PART relations which have their domain restricted to the disjunction of the concepts OUTPUTDEV, INPUTDEV, STORAGEDEV or COMPUTER and their range restricted to SWITCH.","In order to represent and reason about concept hypotheses we have to properly extend the formalism of C~£. Terminological hypotheses, in our framework, are characterized by the following properties: for all stipulated hypotheses (1) the same domain A holds, (2) the same concept definitions are used, and (3) only different assertional axioms can be established. These conditions are sufficient, because each hypothesis is based on a unique discourse entity (cf. (1)), which can be directly mapped to associated instances (so concept definitions are stable (2)). Only relations (including the ISA-relation) among the instances may be different (3). 477 Axiom Semantics"]},{"title":"(a : C)h a z E C zn (aRb)h (a z,b z) ER zh","paragraphs":["Table 3: Axioms in"]},{"title":"CDf.. hvp°","paragraphs":["Given these constraints, we may annotate each assertional axiom of the form 'a : C' and 'a R b' by a corresponding hypothesis label h so that (a :"]},{"title":"C)h","paragraphs":["and"]},{"title":"(a R b)h","paragraphs":["are valid terminological expressions. The extended terminological language (cf. Table 3) will be called"]},{"title":"CD£ ~y~°.","paragraphs":["Its semantics is given by a special interpretation function"]},{"title":"Zh","paragraphs":["for each hypothesis h, which is applied to each concept and role symbol in the canonical way:"]},{"title":"Zh","paragraphs":[": A --+ 2zx;"]},{"title":"Zh","paragraphs":[": P --+ 2 AxA. Notice that the instances a, b are interpreted by the interpretation function Z, because there exists only one domain £x. Only the interpretation of the concept symbol C and the role symbol R may be different in each hypothesis h.","Assume that we want to represent two of the four concept hypotheses that can be derived from (P3),"]},{"title":"viz. Itoh-Ci-Sconsidered","paragraphs":["as a storage device or an output device. The corresponding ABox expressions are then given by:"]},{"title":"( Itoh-Ci-8","paragraphs":["HAS-SWITCH"]},{"title":"switch.1)h, (Itoh-Ci-8","paragraphs":[": STORAGEDEV)h 1"]},{"title":"( Itoh-C i-8","paragraphs":["HAS-SWITCH"]},{"title":"switch.1)h2 (Itoh-Ci-8","paragraphs":[": OUTPUTDEV)h~ The semantics associated with this ABox","fi'agment has the following form: ~h, (HAS-SWITCH) -\""]},{"title":"{(Itoh-Ci-8, switch.l)},","paragraphs":["Zhx (STORAGEDEV) m"]},{"title":"{Itoh-Ci-8},","paragraphs":["Zha (OuTPUTDEV) \"- 0 Zh~(HAS-SWITCH) :"]},{"title":"{(Itoh-Ci-8, switch.l)},","paragraphs":["Zh2(STORAGEDEV) = 0, :~h..(OUTPUTDEV) :"]},{"title":"{Itoh-Ci-8}","paragraphs":["2.2"]},{"title":"Hypothesis Generation","paragraphs":["Rules As mentioned above, text parsing and concept acquisition from texts are tightly coupled. Whenever, e.g., two nominals or a nominal and a verb are supposed to be syntactically related in the regular parsing mode, the semantic in-terpreter simultaneously evaluates the conceptual compatibility of the items involved. Since these reasoning processes are fully embedded in a terminological representation system, checks are made as to whether a concept denoted by one of these objects is allowed to fill a role of the other one. If one of the items involved is unknown, i.e., a lexical and conceptual gap is encountered, this interpretation mode generates initial concept hypotheses about the class membership of the unknown object, and, as a consequence of inheritance mechanisms holding for concept taxonomies, provides conceptual role information for the unknown item.","Given the structural foundations of terminological theories, two dimensions of conceptual learning can be distinguished -- the taxonomic one by which new concepts are located in conceptual hierarchies, and the aggregational one by which concepts are supplied with clusters of conceptual relations (these will be used subsequently by the terminological classifier to determine the current position of the item to be learned in the taxonomy). In the following, let"]},{"title":"target.con","paragraphs":["be an unknown concept denoted by the corresponding lexical item"]},{"title":"tar- get.lex, base.con","paragraphs":["be a given knowledge base concept denoted by the corresponding lexical item"]},{"title":"base.lex,","paragraphs":["and let"]},{"title":"target.lex","paragraphs":["and"]},{"title":"base.lex","paragraphs":["be related by some dependency relation. Further-more, in the hypothesis generation rules below variables are indicated by names with leading '?'; the operator TELL is used to initiate the creation of assertional axioms in"]},{"title":"C7)£ hyp°.","paragraphs":["Typical linguistic indicators that can be exploited for"]},{"title":"taxonomic","paragraphs":["integration are appositions"]},{"title":"('.. the printer","paragraphs":["@A@ .. '), exemplification phrases"]},{"title":"('.. printers like the @A @ .. ')","paragraphs":["or nominal compounds"]},{"title":"( '.. the @A @ printer .. 1.","paragraphs":["These constructions almost unequivocally determine '@A@'"]},{"title":"(target.lex)","paragraphs":["when considered as a proper name 1 to denote an instance of a PRINTER"]},{"title":"(tar- get.con),","paragraphs":["given its characteristic dependency relation to"]},{"title":"'printer' (base.lex),","paragraphs":["the conceptual correlate of which is the concept class PRINTER"]},{"title":"(base.con).","paragraphs":["This conclusion is justified independent of conceptual conditions, simply due to"]},{"title":"the","paragraphs":["nature of these linguistic constructions.","The generation of corresponding concept hypotheses is achieved by the rule sub-hypo (Table 4). Basically, the type of"]},{"title":"target.con","paragraphs":["is carried over from"]},{"title":"base.con","paragraphs":["(function type-of). In addi-tion, the syntactic"]},{"title":"label","paragraphs":["is asserted which characterizes the grammatical construction figuring as the structural source for that particular hy-","1Such a part-of-speech hypothesis can be derived from the inventory of valence and word order specifications underlying the dependency grammar model we use (BrSker et al., 1994). 478 sub-hypo"]},{"title":"(target.con, base.con, h, label) ?type","paragraphs":[":="]},{"title":"type-of(base.con)","paragraphs":["TELL"]},{"title":"(target.con : ?type)h add-label((target.con : ?type)h ,label)","paragraphs":["Table 4: Taxonomic Hypothesis Generation Rule pothesis (h denotes the identifier for the selected hypothesis space), e.g., APPOSITION, EXEMPLI-FICATION, or NCOMPOUND.","The"]},{"title":"aggregational","paragraphs":["dimension of terminological theories is addressed, e.g., by grammatical constructions causing case frame assignments. In the example '.. @B@"]},{"title":"is equipped with 32 MB of RAM ..',","paragraphs":["role filler constraints of the verb form"]},{"title":"'equipped'","paragraphs":["that relate to its PATIENT role carry over to '@B~'. After subsequent semantic interpretation of the entire verbal complex, '@B@' may be anything that can be equipped with memory. Constructions like prepositional phrases ( '.. @C@"]},{"title":"from IBM.. ')","paragraphs":["or genitives ('.."]},{"title":"IBM's","paragraphs":["@C@ .. ~ in which either"]},{"title":"target.lex","paragraphs":["or"]},{"title":"base.lex","paragraphs":["occur as head or modifier have a similar effect. Attachments of prepositional phrases or relations among nouns in genitives, however, open a wider interpretation space for '@C~' than for '@B~', since verbal case frames provide a higher role selectivity than PP attachments or, even more so, genitive NPs. So, any concept that can reasonably be related to the concept IBM will be considered a potential hypothesis for '@C~-\", e.g., its departments, products, Fortune 500 ranking.","Generalizing from these considerations, we state a second hypothesis generation rule which accounts for aggregational patterns of concept learning. The basic assumption behind this rule, perm-hypo (cf. Table 5), is that"]},{"title":"target.con","paragraphs":["fills (exactly) one of the n roles of"]},{"title":"base.con","paragraphs":["it is currently permitted to fill (this set is determined by the function porto-filler). Depend-ing on the actual linguistic construction one encounters, it may occur, in particular for PP and NP constructions, that one cannot decide on the correct role yet. Consequently, several alternative hypothesis spaces are opened and"]},{"title":"target.co~","paragraphs":["is assigned as a potential filler of the i-th role (taken from"]},{"title":"?roleSet,","paragraphs":["the set of admitted roles) in its corresponding hypothesis space. As a result, the classifier is able to derive a suitable concept hypothesis by specializ-ing"]},{"title":"target.con","paragraphs":["according to the value restriction of"]},{"title":"base.con's","paragraphs":["i-th role. The function member-of"]},{"title":"?roleSet :=perm-f iller( target.con, base.con, h)","paragraphs":["?r :="]},{"title":"[?roleSet I FORALL ?i","paragraphs":[":=?r DOWNTO 1 DO"]},{"title":"?rolel","paragraphs":[":= member-of"]},{"title":"( ?roleSet ) ?roleSet :=?roleSet \\ {?rolei}","paragraphs":["IF ?i = 1 THEN"]},{"title":"?hypo","paragraphs":[":= h ELSE"]},{"title":"?hypo","paragraphs":[":= gen-hypo(h) TELL"]},{"title":"(base.con ?rolei target.con)?hypo","paragraphs":["add-label ((base.con"]},{"title":"?rolei target.con)?hypo, label )","paragraphs":["Table 5: Aggregational Hypothesis Generation Rule selects a role from the set"]},{"title":"?roleSet; gen-hypo","paragraphs":["creates a new hypothesis space by asserting the given axioms of h and outputs its identifier. Thereupon, the hypothesis space identified by"]},{"title":"?hypo","paragraphs":["is augmented through a TELL operation by the hypothesized assertion. As for"]},{"title":"sub-hypo, perm-hypo","paragraphs":["assigns a syntactic quality label (function add-label) to each"]},{"title":"i-th","paragraphs":["hypothesis indicating the type of syntactic construction in which"]},{"title":"target.lex","paragraphs":["and"]},{"title":"base.lex","paragraphs":["are related in the text, e.g., CASEFRAME, PPATTACH or GENITIVENP.","Getting back to our example, let us assume that the target"]},{"title":"Itoh-Ci-8","paragraphs":["is predicted already as a PRODUCT as a result of preceding interpretation processes, i.e.,"]},{"title":"Itoh-Ci-8","paragraphs":[": PRODUCT holds. Let PRODUCT be defined as: PRODUCT -- VHAS-PART.PHYSICALOBJECT I-1 VHAS-SIZE.SIZE [\"1 VHAS-PRICE.PRICE i-I VHAS-WEIGHT.WEIGHT","At this level of conceptual restriction, four roles have to be considered for relating the target"]},{"title":"Itoh-Ci-8","paragraphs":["- as a tentative PRODUCT - to the base concept SWITCH when interpreting the phrase"]},{"title":"'The switch of the Itoh-Ci-8 .. '.","paragraphs":["Three of them, HAS-SIZE, HAS-PRICE, and HAS-WEIGHT, are ruled out due to the violation of a simple integrity constraint ('switch'does not denote a measure unit). Therefore, only the role HAS-PART must be considered in terms of the expression"]},{"title":"Itoh-Ci-8","paragraphs":["HAS-PART"]},{"title":"switch.1","paragraphs":["(or, equivalently,"]},{"title":"switch.1","paragraphs":["PART-OF"]},{"title":"Itoh-Ci-8).","paragraphs":["Due to the definition of HAS-SWITCH (cf. P3, Subsection 2.1), the instantiation of HAS-PART is specialized to HAS-SWITCH by the classifier, since the range of the HAS-PART relation is already restricted to SWITCH (P1). Since the classifier aggressively pushes hypothesizing to be maximally specific, the disjunctive concept referred to in 479 the domain restrictiou of the role HAS-SWITCH is split into four distinct hypotheses, two of which are sketched below. Hence, we assume"]},{"title":"Itoh-Ci-8","paragraphs":["to deuote either a STORAGEDEvice or an OUTPUTDEvice or an INPUTDEvice or a COMPUTER (note that we also include parts of the IS-A hierarchy in the example below)."]},{"title":"(Itoh-Ci-8","paragraphs":[": STORAGEDEV)h,,"]},{"title":"(Itoh-Ci-8","paragraphs":[": DEVICE)h~,..,"]},{"title":"( Itoh-C i-8","paragraphs":["HAS-SWITCH"]},{"title":"switch.1)h~ (Itoh-Ci-8","paragraphs":[": OUTPUTDEv)h~,"]},{"title":"(Itoh-Ci-8","paragraphs":[": DEVICE)h2,..,"]},{"title":"(Itoh-Ci-8","paragraphs":["HAS-SWITCH"]},{"title":"swilch.1)h~,...","paragraphs":["2.3 Hypothesis Annotation Rules In this section, we will focus on the quality assessment of concept hypotheses which occurs at the knowledge base level only; it is due to the operation of hypothesis annotation rules which continuously evaluate the hypotheses that have been derived from linguistic evidence.","The M-Deduction rule (see Table 6) is triggered for any repetitive assignment of the same role filler to one specific conceptual relation that occurs in different hypothesis spaces. This rule captures the assu,nption that a role filler which has been"]},{"title":"multiply","paragraphs":["derived at different occasions must be granted more strength than one which has been derived at a single occasion only. EXISTS"]},{"title":"Ol,O2, R, hl,h~. :","paragraphs":["(Ol"]},{"title":"R o2)hl","paragraphs":["A (Ol"]},{"title":"R o2)h~ A hi ~ h~","paragraphs":["TELL (ol R o~_)h~ : M-DEDUCTION Table 6: The Rule M-Deduction","Considering our example at the end of subsec-tion 2.2, for"]},{"title":"'Itoh-Ci-8'","paragraphs":["the concept hypotheses STORAGEDEV and OUTPUTDEV were derived independently of each other in different hypothesis spaces. Hence, DEVICE as their common superconcept has been multiply derived by the classifier in each of these spaces as a result of transitive closure computations, too. Accordingly, this hypothesis is assigned a high degree of confidence by the classifier which derives the conceptual quality label M-DEDUCTION:"]},{"title":"(Itoh-Ci-8","paragraphs":[": DEVICE)hi A"]},{"title":"(Itoh-Ci-8","paragraphs":[": DEVICE)h~"]},{"title":"=:=> (Itoh-Ci-8","paragraphs":[": DEVICE)hi : M-DEDUCTION","The C-Support rule (see Table 7) is triggered whenever, within the same hypothesis space, a hypothetical relation, RI, between two instances can be justified by another relation, R2, involving the same two instances, but where the role fillers occur in 'inverted' order (R1 and R2 need not necessarily be semantically inverse relations, as with"]},{"title":"'buy'","paragraphs":["and"]},{"title":"'sell~.","paragraphs":["This causes the generation of the quality label C-SuPPORT which captures the inherent symmetry between concepts related via quasi-inverse relations. EXISTS Ol, 02, R1, R2, h :"]},{"title":"(ol R1 o2)h ̂(02 R2 ol)h ̂ftl # R~","paragraphs":["~=~ TELL (Ol R1 o2)h : C-SuPPORT Table 7: The Rule C-Support Example:"]},{"title":"(Itoh","paragraphs":["SELLS"]},{"title":"ltoh-Ci-8)h A (Itoh-Ci-8","paragraphs":["DEVELOPED-BY"]},{"title":"Itoh)h (ltoh","paragraphs":["SELLS"]},{"title":"ltoh-Ci-8)h","paragraphs":[": C-SuPPORT","Whenever an already filled conceptual relation receives an additional, yet different role filler in the same hypothesis space, the AddFiller rule is triggered (see Table 8). This application-specific rule is particularly suited to our natural language understanding task and has its roots in the distinction between mandatory and optio,lal case roles for (ACTION) verbs. Roughly, it yields a negative assessment in terms of the quality label ADDFILLER for any attempt to fill the same mandatory case role more than once (unless coordinations are involved). Iu contradistinction, when the same role of a non-ACTION concept (typically denoted by nouns) is multiply filled we assign the positive quality label SUPPORT, since it reflects the conceptual proximity a relation induces on its component fillers, provided that they share a common, non-ACTION concept class.","EXISTS 01,02, 03, R, h : (01 R"]},{"title":"02)h","paragraphs":["A (01 R 03)h A (01 : ACTION)h ===V I TELL (01 R"]},{"title":"o~_)h","paragraphs":[": ADDFILLER Table 8: The Rule AddFiller We give examples both for the assignmeut of an ADDFILLER as well as for a SUPPORT label: Examples:"]},{"title":"(produces.1","paragraphs":[": ACTION)h A"]},{"title":"(produces.1","paragraphs":["AGENT"]},{"title":"ltoh)h A (produces.1","paragraphs":["AGENT"]},{"title":"IBM)h (produces.1","paragraphs":["AGENT"]},{"title":"Itoh)h","paragraphs":[": ADDFILLER"]},{"title":"(ltoh-Ci-8","paragraphs":[": PRINTER)h A"]},{"title":"(Itoh-Ct","paragraphs":[": PRINTER)h A"]},{"title":"(Itoh","paragraphs":["SELLS"]},{"title":"Itoh-Ci-8)h A (Itoh","paragraphs":["SELLS"]},{"title":"Itoh-Ct)h A (ltoh","paragraphs":[": -~AcTION)h"]},{"title":"(Itoh-Ci-8","paragraphs":[": PRINTER)h : SUPPORT 480 2.4 Quality Dimensions The criteria from which concept hypotheses are derived differ in the dimension from which they are drawn (grammatical vs. conceptual evidence), as well as the strength by which they lend support to the corresponding hypotheses (e.g., apposition vs. genitive, multiple deduc-tion vs. additional role filling, etc.). In order to make these distinctions explicit we have developed a \"quality calculus\" at the core of which lie the definition of and inference rules for quality labels (cf. Schnattinger and Hahn (1998) for more details). A design methodology for specific quality calculi may proceed along the following lines: (1) Define the dimensions from which quality labels can be drawn. In our application, we chose the set I:Q := {ll,..., Ira} of linguistic quality labels and CQ := {cl,...,c~} of conceptual quality labels. (2) Determine a partial ordering p among the quality labels from one dimension reflecting different degrees of strength among the quality labels. (3) Determine a total ordering among the dimensions.","In our application, we have empirical evidence to grant linguistic criteria priority over conceptual ones. Hence, we state the following constraint: Vl E LQ, Vc E CQ : l >p c The dimension I:Q. Linguistic quality labels reflect structural properties of phrasal patterns or discourse contexts in which unknown lexical items occur 2 -- we here assume that the type of grammatical construction exercises a particular interpretative force on the unknown item and, at the same time, yields a particular level of credibility for the hypotheses being derived. Taking the considerations from Subsection 2.2 into account, concrete examples of high-quality labels are given by APPOSITION or NCOMPOUND labels. Still of good quality but already less constraining are occurrences of the unknown item in a CASEFRAME construction. Finally, in a PPATTACH or GENITIVENP construction the unknown lexical item is still less constrained. Hence, at the quality level, these latter two labels (just as the first two labels we considered) form an equivalence class whose elements cannot be further discriminated. So we end up with the following quality orderings:","2In the future, we intend to integrate additional types of constraints, e.g., quality criteria reflecting the degree of completeness vs. partiality of the parse. NCOMPOUND ----p APPOSITION NCOMPOUND >p CASEFRAME APPOSITION >p CASEFRAME CASEFRAME >p GENITIVENP CASEFRAME >p PPATTACH GENITIVENP =p PPATTACH The dimension CQ. Conceptualquality labels result from comparing the conceptual representation structures of a concept hypothesis with already existing representation structures in the underlying domain knowledge base or other concept hypotheses from the viewpoint of structural similarity, compatibility, etc. The closer the match, the more credit is lent to a hypothesis. A very positive conceptual quality label, e.g., is M-DEDUCTION, whereas ADDFILLER is a negative one. Still positive strength is expressed by SUPPORT or C-SuPPORT, both being indistinguishable, however, from a quality point of view. Accordingly, we may state: M-DEDUCTION >p SUPPORT ~{-DEDUCTION >p C-SuPPORT SUPPORT --p C-SuPPORT SUPPORT >p ADDFILLEK C-SuPPORT >p ADDFILLER"]},{"title":"2.5 Hypothesis","paragraphs":["Ranking Each new clue available for a target concept to be learned results in the generation of additional linguistic or conceptual quality labels. So hypothesis spaces get incrementally augmented by quality statements. In order to select the most credible one(s) among them we apply a two-step procedure (the details of which are explained in Schnattinger and Hahn (1998)). First, those concept hypotheses are chosen which have accumulated the greatest amount of high-quality labels according to the linguistic dimension £:Q. Second, further hypotheses are selected from this linguistically plausible candidate set based on the quality ordering underlying CQ.","We have also made considerable efforts to evaluate the performance of the text learner based on the quality calculus. In order to account for the incrementality of the learning process, a new evaluation measure capturing the system's on-line learning accuracy was defined, which is sensitive to taxonomic hierarchies. The results we got were consistently favorable, as our system outperformed those closest in spirit, CAMILLE (Hastings, 1996) and ScIsoR (Rau et 481 al., 1989), by a gain in accuracy on the order of 8%. Also, the system requires relatively few hypothesis spaces (2 to 6 on average) and prunes the concept search space radically, requiring only a few examples (for evaluation details, cf. Hahn and Schnattinger (1998)). 3 Related Work We are not concerned with lexical acquisition from very large corpora using surface-level collocational data as proposed by Zernik and Jacobs (1990) and Velardi et al. (1991), or with hyponym extraction based on entirely syntactic criteria as in Hearst (1992) or lexico-semantic associations (e.g., Resnik (1992) or Sekine et al. (1994)). This is mainly due to the fact that these studies aim at a shallower level of learning (e.g., selectional restrictions or thematic relations of verbs), while our focus is on much more fine-grained conceptual knowledge (roles, role filler constraints, integrity conditions).","Our approach bears a close relationship, however, to the work of Mooney (1987), Berwick (1989), Rau et al. (1989), Gomez and Segami (1990), and Hastings (1996), who all aim at the automated learning of word meanings from con-text using a knowledge-intensive approach. But our work differs from theirs in that the need to cope with several competing concept hypotheses and to aim at a reason-based selection in terms of the quality of arguments is not an issue in these studies. Learning from real-world texts usually provides the learner with only sparse and fragmentary evidence, such that multiple hypotheses are likely to be derived and a need for a hypothesis evaluation arises. 4 Conclusion We have introduced a solution for the semantic acquisition problem on the basis of the automatic processing of expository texts. The learning methodology we propose is based on the incremental assignment and evaluation of the quality of linguistic and conceptual evidence for emerging concept hypotheses. No specialized learning algorithm is needed, since learning is a reasoning task carried out by the classifier of a terminological reasoning system. However, strong heuristic guidance for selecting between plausible hypotheses comes from linguistic and conceptual quality criteria. Acknowledgements. We would like to thank our colleagues in the CLIF group for fruitful discussions, in particular Joe Bush who polished the text as a native speaker. K. Schnattinger is supported by a grant from DFG (Ha 2097/3-1).","References","R. Berwick. 1989. Learning word meanings from examples. In D. Waltz, editor, Semantic Structures., pages 89-124. Lawrence Erlbaum.","N. BrSker, U. Hahn, and S. Schacht. 1994. Concurrent lexicalized dependency parsing: the PARSETALK model. In Proc. of the COLING'94. Vol. I, pages 379-385.","F. Gomez and C. Segami. 1990. Knowledge acquisition from natural language for expert systems based on classification problem-solving methods. Knowledge Acquisition, 2(2):107-128.","U. Hahn and K. Schnattinger. 1998. Towards text knowledge engineering. In Proc. of the AAAI'98.","P. Hastings. 1996. Implications of an automatic lexical acquisition system. In S. Wermter, E. Riloff, and G. Scheler, editors, Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing, pages 261-274. Springer.","M. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. of the COLING'92. Vol.2, pages 539-545.","D. Hindle. 1989. Acquiring disambiguation rules from text. In Proc. of the A CL'89, pages 26-29.","C. Manning. 1993. Automatic acquisition of large subcategorization dictionary from corpora. In Proc. of the A CL'93, pages 235-242.","R. Mooney. 1987. Integrated learning of words and their underlying concepts. In Proe. of the CogSci'87, pages 974-978.","L. Rau, P. Jacobs, and U. Zernik. 1989. Information extraction and text summarization using linguistic knowledge acquisition. Information Processing","Management, 25(4):419-428.","P. Resnik. 1992. A class-based approach to lexical discovery. In Proe. of the A CL '92, pages 327-329.","K. Schnattinger and U. Hahn. 1998. Quality-based learning. In Proc. of the ECAI'98, pages 160-164.","S. Sekine, J. Carroll, S. Ananiadou, and J. Tsujii. 1994. Automatic learning for semantic colloca-tion. In Proc. of the ANLP'94, pages 104-110.","P. Velardi, M. Pazienza, and M. Fasolo. 1991. How to encode semantic knowledge: a method for meaning representation and computer-aided acquisition. Computational Linguistics, 17:153-170.","W. Woods and J. Schmolze. 1992. The KL-ONE family. Computers ~ Mathematics with Applications, 23(2/5):133-177.","U. Zernik and P. Jacobs. 1990. Tagging for learning: collecting thematic relations from corpus. In Proc. of the COLING'90. Vol. 1, pages 34-39. 482"]}]}
