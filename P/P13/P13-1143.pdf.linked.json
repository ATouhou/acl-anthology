{"sections":[{"title":"","paragraphs":["Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1456–1465, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Grammatical Error Correction Using Integer Linear Programming Yuanbin WuDepartment of Computer ScienceNational University of Singapore 13 Computing DriveSingapore 117417wuyb@comp.nus.edu.sg Hwee Tou NgDepartment of Computer ScienceNational University of Singapore 13 Computing DriveSingapore 117417nght@comp.nus.edu.sgAbstract","paragraphs":["We propose a joint inference algorithm for grammatical error correction. Different from most previous work where different error types are corrected independently, our proposed inference process considers all possible errors in a uni\\u{2}ed framework. We use integer linear programming (ILP) to model the inference process, which can easily incorporate both the power of exist-ing error classi\\u{2}ers and prior knowledge on grammatical error correction. Experimental results on the Helping Our Own shared task show that our method is competitive with state-of-the-art systems."]},{"title":"1 Introduction","paragraphs":["Grammatical error correction is an important task of natural language processing (NLP). It has many potential applications and may help millions of people who learn English as a second language (ESL). As a research \\u{2}eld, it faces the challenge of processing ungrammatical language, which is different from other NLP tasks. The task has received much attention in recent years, and was the focus of two shared tasks on grammatical error correction in 2011 and 2012 (Dale and Kilgarriff, 2011; Dale et al., 2012).","To detect and correct grammatical errors, two different approaches are typically used \\u{97} knowledge engineering or machine learning. The \\u{2}rst relies on handcrafting a set of rules. For example, the superlative adjective best is preceded by the article the . In contrast, the machine learning approach formulates the task as a classi\\u{2}cation problem based on learning from training data. For example, an article classi\\u{2}er takes a noun phrase (NP) as input and predicts its article using class labels a/an , the , or ε (no article).","Both approaches have their advantages and disadvantages. One can readily handcraft a set of rules to incorporate various prior knowledge from grammar books and dictionaries, but rules often have exceptions and it is dif\\u{2}cult to build rules for all grammatical errors. On the other hand, the machine learning approach can learn from texts written by ESL learners where grammatical errors have been annotated. However, training data may be noisy and classi\\u{2}ers may need prior knowledge to guide their predictions.","Another consideration in grammatical error correction is how to deal with multiple errors in an input sentence. Most previous work deals with errors individually: different classi\\u{2}ers (or rules) are developed for different types of errors (article classi\\u{2}er, preposition classi\\u{2}er, etc). Classi\\u{2}ers are then deployed independently. An example is a pipeline system, where each classi\\u{2}er takes the output of the previous classi\\u{2}er as its input and proposes corrections of one error type.","One problem of this pipeline approach is that the relations between errors are ignored. For example, assume that an input sentence contains a cats . An article classi\\u{2}er may propose to delete a , while a noun number classi\\u{2}er may propose to change cats to cat . A pipeline approach will choose one of the two corrections based purely on which error classi\\u{2}er is applied \\u{2}rst. Another problem is that when applying a classi\\u{2}er, the surrounding words in the context are assumed to be correct, which is not true if grammatical errors appear close to each other in a sentence.","In this paper, we formulate grammatical error correction as a task suited for joint inference. Given an input sentence, different types of errors are jointly corrected as follows. For every possible error correction, we assign a score which measures how grammatical the resulting sentence is if the correction is accepted. We then choose a set of corrections which will result in a corrected sentence that is judged to be the most grammatical.","The inference problem is solved by integer lin-1456 ear programming (ILP). Variables of ILP are indicators of possible grammatical error corrections, the objective function aims to select the best set of corrections, and the constraints help to enforce a valid and grammatical output. Furthermore, ILP not only provides a method to solve the inference problem, but also allows for a natural integration of grammatical constraints into a machine learning approach. We will show that ILP fully utilizes individual error classi\\u{2}ers, while prior knowledge on grammatical error correction can be easily expressed using linear constraints. We evaluate our proposed ILP approach on the test data from the Helping Our Own (HOO) 2011 shared task (Dale and Kilgarriff, 2011). Experimental results show that the ILP formulation is competitive with state-of-the-art grammatical error correction systems.","The remainder of this paper is organized as follows. Section 2 gives the related work. Section 3 introduces a basic ILP formulation. Sections 4 and 5 improve the basic ILP formulation with more constraints and second order variables, respectively. Section 6 presents the experimental results. Section 7 concludes the paper."]},{"title":"2 Related Work","paragraphs":["The knowledge engineering approach has been used in early grammatical error correction systems (Murata and Nagao, 1993; Bond et al., 1995; Bond and Ikehara, 1996; Heine, 1998). However, as noted by (Han et al., 2006), rules usually have exceptions, and it is hard to utilize corpus statistics in handcrafted rules. As such, the machine learning approach has become the dominant approach in grammatical error correction.","Previous work in the machine learning approach typically formulates the task as a classi\\u{2}cation problem. Article and preposition errors are the two main research topics (Knight and Chander, 1994; Han et al., 2006; Tetreault and Chodorow, 2008; Dahlmeier and Ng, 2011). Features used in classi- \\u{2}cation include surrounding words, part-of-speech tags, language model scores (Gamon, 2010), and parse tree structures (Tetreault et al., 2010). Learning algorithms used include maximum entropy (Han et al., 2006; Tetreault and Chodorow, 2008), averaged perceptron, na ¤\\u{11}ve Bayes (Rozovskaya and Roth, 2011), etc. Besides article and preposition errors, verb form errors also attract some attention recently (Liu et al., 2010; Tajiri et al., 2012).","Several research efforts have started to deal with correcting different errors in an integrated manner (Gamon, 2011; Park and Levy, 2011; Dahlmeier and Ng, 2012a). Gamon (2011) uses a high-order sequential labeling model to detect various errors. Park and Levy (2011) models grammatical error correction using a noisy channel model, where a prede\\u{2}ned generative model produces correct sentences and errors are added through a noise model. The work of (Dahlmeier and Ng, 2012a) is probably the closest to our current work. It uses a beam-search decoder, which iteratively corrects an input sentence to arrive at the best corrected output. The difference between their work and our ILP approach is that the beam-search decoder returns an approximate solution to the original inference problem, while ILP returns an exact solution to an approximate inference problem.","Integer linear programming has been successfully applied to many NLP tasks, such as dependency parsing (Riedel and Clarke, 2006; Martins et al., 2009), semantic role labeling (Punyakanok et al., 2005), and event extraction (Riedel and Mc-Callum, 2011)."]},{"title":"3 Inference with First Order Variables","paragraphs":["The inference problem for grammatical error correction can be stated as follows: \\u{93}Given an input sentence, choose a set of corrections which results in the best output sentence.\\u{94} In this paper, this problem will be expressed and solved by integer linear programming (ILP).","To express an NLP task in the framework of ILP requires the following steps: 1. Encode the output space of the NLP task using integer variables; 2. Express the inference objective as a linear objective function; and 3. Introduce problem-speci\\u{2}c constraints to re- \\u{2}ne the feasible output space.","In the following sections, we follow the above formulation. For the grammatical error correction task, the variables in ILP are indicators of the corrections that a word needs, the objective function measures how grammatical the whole sentence is if some corrections are accepted, and the constraints guarantee that the corrections do not con\\u{3}ict with each other. 1457 3.1 First Order Variables Given an input sentence, the main question that a grammatical error correction system needs to an-swer is: What corrections at which positions? For example, is it reasonable to change the word cats to cat in the sentence A cats sat on the mat ? Given the corrections at various positions in a sentence, the system can readily come up with the corrected sentence. Thus, a natural way to encode the output space of grammatical error correction requires in-formation about sentence position, error type (e.g., noun number error), and correction (e.g., cat ). Suppose s is an input sentence, and |s| is its length (i.e., the number of words in s). De\\u{2}ne \\u{2}rst order variables : Zk l,p ∈ {0, 1}, (1) where p∈ {1, 2, . . . , |s|} is a position in a sentence, l∈ L is an error type, k∈ {1, 2, . . . , C(l)} is a correction of type l. L: the set of error types, C(l): the number of corrections for error type l.","If Zk l,p = 1, the word at position p should be corrected to k that is of error type l. Otherwise, the word at position p is not applicable for this correction. Deletion of a word is represented as k = ε. For example, Za Art ,1 = 1 means that the article (Art) at position 1 of the sentence should be a . If Za Art ,1 = 0, then the article should not be a . Table 1 contains the error types handled in this work, their possible corrections and applicable positions in a sentence. 3.2 The Objective Function The objective of the inference problem is to \\u{2}nd the best output sentence. However, there are exponentially many different combinations of corrections, and it is not possible to consider all combinations. Therefore, instead of solving the original inference problem, we will solve an approximate inference problem by introducing the following decomposable assumption: Measuring the output quality of multiple corrections can be decomposed into measuring the quality of the individual corrections.","Let s′","be the resulting sentence if the correction Zk l,p is accepted for s, or for simplicity denoting it as","s Zk l,p −−→ s′",". Let wl,p,k ∈ R, measure how grammatical","s′ is. De\\u{2}ne the objective function as","max ∑ l,p,k wl,p,kZk","l,p. This linear objective function aims to select a set of Zk","l,p, such that the sum of their weights is the largest among all possible candidate corrections, which in turn gives the most grammatical sentence under the decomposable assumption.","Although the decomposable assumption is a strong assumption, it performs well in practice, and one can relax the assumption by using higher order variables (see Section 5).","For an individual correction Zk l,p, we measure the quality of","s′ based on three factors: 1. The language model score","h(s′ , LM ) of s′","based on a large web corpus; 2. The con\\u{2}dence scores","f (s′ , t) of classi\\u{2}ers, where t ∈ E and E is the set of classi\\u{2}ers. For example, an article classi\\u{2}er trained on well-written documents will score every article in s′ , and measure the quality of","s′ from the perspective of an","article \\u{93}expert\\u{94}. 3. The disagreement scores","g(s′ , t) of classi- \\u{2}ers, where t ∈ E. A disagreement score measures how ungrammatical","s′ is from the perspective of a classi\\u{2}er. Take the article classi\\u{2}er as an example. For each article instance in s′ , the classi\\u{2}er computes the difference between the maximum con\\u{2}dence score among all possible choices of articles, and the con\\u{2}dence score of the observed article. This difference represents the disagreement on the observed article by the article classi\\u{2}er or \\u{93}expert\\u{94}. De\\u{2}ne the maximum difference over all article instances in","s′ to be the article classi\\u{2}er disagreement score of s′ . In general, this score is large if the sentence","s′ is more ungram-","matical. The weight wl,p,k is a combination of these scores:","wl,p,k = νLM h(s′",", LM ) + ∑","t∈E λtf (s′",", t)","+ ∑ t∈E μtg(s′",", t), (2) where νLM , λt, and μt are the coef\\u{2}cients. 3.3 Constraints An observation on the objective function is that it is possible, for example, to set Za Art ,p = 1 and 1458 Type l Correction k C(l) Applicable Variables article a, the, ε 3 article or NP","Za","Art ,p, Zthe","Art ,p, Zε","Art ,p preposition on, at, in, . . . |confusion set | preposition","Zon","Prep ,p, Zat","Prep ,p, Zin","Prep ,p, . . . noun number singular, plural 2 noun Zsingular Noun",",p , Zplural Noun ,p punctuation punctuation symbols |candidates | determined by rules Zoriginal Punct",",p , Zcand1 Punct",",p, Zcand2 Punct ,p,. . . spelling correctly spelled |candidates | determined by a","Zoriginal","Spell ,p , Zcand1","Spell ,p, Zcand2","Spell ,p,. . . words spell checker Table 1: Error types and corrections. The Applicable column indicates which parts of a sentence are applicable to an error type. In the \\u{2}rst row, ε means deleting an article. Zthe Art ,p = 1, which means there are two corrections a and the for the same sentence position p, but ob-","viously only one article is allowed. A simple constraint to avoid these con\\u{3}icts is","∑","k Zk l,p = 1, ∀ applicable l, p It reads as follows: for each error type l, only one output k is allowed at any applicable position p (note that Zk l,p is a Boolean variable).","Putting the variables, objective function, and constraints together, the ILP problem with respect to \\u{2}rst order variables is as follows:","max ∑ l,p,k wl,p,kZk","l,p (3) s.t. ∑","k Zk l,p = 1, ∀ applicable l, p (4) Zk l,p ∈ {0, 1} (5) The ILP problem is solved using lp solve 1 , an integer linear programming solver based on the revised simplex method and the branch-and-bound method for integers. 3.4 An Illustrating Example To illustrate the ILP formulation, consider an example input sentence s: A cats sat on the mat . (6) First, the constraint (4) at position 1 is:","Za","Art ,1 + Zthe","Art ,1 + Zε","Art ,1 = 1, which means only one article in {a, the, ε} is se-","lected. 1 http://lpsolve.sourceforge.net/ Next, to compute wl,p,k, we collect language model score and con\\u{2}dence scores from the article ( ART ), preposition ( PREP ), and noun number ( NOUN ) classi\\u{2}er, i.e., E = {ART , PREP , NOUN }. The weight for Zsingular Noun ,2 is: wNoun ,2,singular","= νLM h(s′ , LM )+","λART f(s′ , ART ) + λPREP f(s′",", PREP",") + λNOUN f(s′ , NOUN )+","μART g(s′ , ART ) + μPREP g(s′",", PREP",") + μNOUN g(s′ , NOUN ). where","s Zsingular Noun ,2 −−−−→ s′","= A cat sat on the mat . The con\\u{2}dence score","f (s′ , t) of classi\\u{2}er t is the average of the con\\u{2}dence scores of t on the applicable instances in s′ . For example, there are two article instances in s′ , located at position 1 and 5 respectively, hence,","f(s′",", ART )= 1 2 \\u{0} f(s′","[1], 1, ART ) + f(s′","[5], 5, ART )\\u{1}","= 1 2 \\u{0} f(a , 1, ART ) + f(the , 5, ART )\\u{1}",". Here, the symbol","ft(s′ [p], p, ART ) refers to the con\\u{2}dence score of the article classi\\u{2}er at position p, and s′","[p] is the word at position","p of s′ . Similarly, the disagreement score","g(s′ , ART ) of","the article classi\\u{2}er is g(s′",", ART ) = max(g1, g2) g1= arg max","k f(k, 1, ART ) − f(a , 1, ART ) g2= arg max","k f(k, 5, ART ) − f(the , 5, ART ) Putting them together, the weight for Zsingular Noun ,2 is: wNoun ,2,singular","= νLM h(s′ , LM )","+ λART","2 \\u{0}","f(a , 1, ART ) + f(the , 5, ART )\\u{1}","+ λPREP f(on , 4, PREP )","+ λNOUN 2 \\u{0}","f(cat , 2, NOUN ) + f(mat , 6, NOUN )\\u{1}","+ μART g(s′",", ART )","+ μPREP g(s′",", PREP )","+ μNOUN g(s′",", NOUN ) 1459 Input A cats sat on the mat Corrections The, ε cat at, in a, ε mats Za Art ,1 Zsingular","Noun ,2","Zon","Prep ,4 Za","Art ,5 Zsingular","Noun ,6 Variables Zthe Art ,1 Zplural","Noun ,2","Zat","Prep ,4 Zthe","Art ,5 Zplural","Noun ,6 Zε Art ,1 Zin Prep ,4 Zε","Art ,5 Table 2: The possible corrections on example (6). 3.5 Complexity The time complexity of ILP is determined by the number of variables and constraints. Assume that for each sentence position, at most K classi- \\u{2}ers are applicable 2 . The number of variables is","O(K|s|C(l∗ )), where","l∗ = arg maxl∈LC(l). The number of constraints is O(K|s|)."]},{"title":"4 Constraints for Prior Knowledge","paragraphs":["4.1 Modi\\u{2}cation Count Constraints In practice, we usually have some rough gauge of the quality of an input sentence. If an input sentence is mostly grammatical, the system is expected to make few corrections. This requirement can be easily satis\\u{2}ed by adding modi\\u{2}ca-tion count constraints.","In this work, we constrain the number of modi\\u{2}- cations according to error types. For the error type l, a parameter Nl controls the number of modi\\u{2}- cations allowed for type l. For example, the modi\\u{2}cation count constraint for article corrections is ∑","p,k Zk Art ,p ≤ NArt , where k ̸= s[p]. (7) The condition ensures that the correction k is different from the original word in the input sentence. Hence, the summation only counts real modi\\u{2}cations. There are similar constraints for preposition, noun number, and spelling corrections: ∑","p,k Zk Prep ,p≤ NPrep , where k ̸= s[p], (8) ∑","p,k Zk Noun ,p≤ NNoun , where k ̸= s[p], (9) ∑","p,k Zk Spell ,p≤ NSpell , where k ̸= s[p]. (10) 2 In most cases, K = 1. An example of K > 1 is a noun that requires changing the word form (between singular and plural) and inserting an article, for which K = 2. 4.2 Article-Noun Agreement Constraints An advantage of the ILP formulation is that it is relatively easy to incorporate prior linguistic knowledge. We now take article-noun agreement as an example to illustrate how to encode such prior knowledge using linear constraints.","A noun in plural form cannot have a (or an ) as its article. That two Boolean variables Z1 and Z2 are mutually exclusive can be handled using a simple inequality Z1 + Z2 ≤ 1. Thus, the following inequality correctly enforces article-noun agreement: Za Art ,p1 + Zplural","Noun ,p2 ≤ 1, (11) where the article at p1 modi\\u{2}es the noun at p2. 4.3 Dependency Relation Constraints Another set of constraints involves dependency relations, including subject-verb relation and determiner-noun relation. Speci\\u{2}cally, for a noun n at position p, we check the word w related to n via a child-parent or parent-child relation. If w be-longs to a set of verbs or determiners ( are, were, these, all ) that takes a plural noun, then the noun n is required to be in plural form by adding the following constraint: Zplural Noun ,p = 1. (12) Similarly, if a noun n at position p is required to be in singular form due to subject-verb relation or determiner-noun relation, we add the following constraint: Zsingular Noun ,p = 1. (13)"]},{"title":"5 Inference with Second Order Variables","paragraphs":["5.1 Motivation and De\\u{2}nition To relax the decomposable assumption in Section 3.2, instead of treating each correction separately, one can combine multiple corrections into a single correction by introducing higher order variables. 1460 Consider the sentence A cat sat on the mat. When measuring the gain due to Zplural Noun ,2 = 1 (change cat to cats ), the weight wNoun ,2,plural is likely to be small since A cats will get a low language model score, a low article classi\\u{2}er con- \\u{2}dence score, and a low noun number classi\\u{2}er con\\u{2}dence score. Similarly, the weight wArt ,1,ε of Zε Art ,1 (delete article A ) is also likely to be small because of the missing article. Thus, if one considers the two corrections separately, they are both unlikely to appear in the \\u{2}nal corrected output.","However, the correction from A cat sat on the mat. to Cats sat on the mat. should be a reasonable candidate, especially if the context indicates that there are many cats (more than one) on the mat. Due to treating corrections separately, it is dif\\u{2}cult to deal with multiple interacting corrections with only \\u{2}rst order variables.","In order to include the correction ε Cats , one can use a new set of variables, second order variables . To keep symbols clear, let Z = {Zu|Zu = Zk l,p, ∀l, p, k} be the set of \\u{2}rst order variables, and wu = wl,p,k be the weight of","Zu = Zk l,p. De\\u{2}ne a second order variable Xu,v: Xu,v = Zu ∧ Zv, (14) where Zu and Zv are \\u{2}rst order variables:","Zu ≜ Zk1 l1,p1, Zv ≜ Zk2","l2,p2. (15) The de\\u{2}nition of Xu,v states that a second order variable is set to 1 if and only if its two component \\u{2}rst order variables are both set to 1. Thus, it combines two corrections into a single correction. In the above example, a second order variable is introduced:","Xu,v = Zε Art ,1 ∧ Zplural","Noun ,2,","s Xu,v −−−→ s′","= Cats sat on the mat . Similar to \\u{2}rst order variables, let wu,v be the weight of Xu,v. Note that de\\u{2}nition (2) only depends on the output sentence s′ , and the weight of the second order variable wu,v can be de\\u{2}ned in the same way:","wu,v = νLM h(s′",", LM ) + ∑","t∈E λtf (s′",", t)","+ ∑ t∈E μtg(s′",", t). (16) 5.2 ILP with Second Order Variables A set of new constraints is needed to enforce consistency between the \\u{2}rst and second order variables. These constraints are the linearization of de\\u{2}nition (14) of Xu,v:","Xu,v = Zu ∧ Zv ⇔ Xu,v ≤ Zu","Xu,v ≤ Zv","Xu,v ≥ Zu + Zv − 1","(17)","A new objective function combines the weights","from both \\u{2}rst and second order variables:","max ∑","l,p,k wl,p,kZk","l,p + ∑","u,v wu,vXu,v. (18)","In our experiments, due to noisy data, some weights of second order variables are small, even if both of its \\u{2}rst order variables have large weights and satisfy all prior knowledge constraints. They will affect ILP proposing good corrections. We \\u{2}nd that the performance will be better if we change the weights of second order variables to w′","u,v, where w′ u,v ≜ max{wu,v, wu, wv}. (19)","Putting them together, (20)-(25) is an ILP formulation using second order variables, where X is the set of all second order variables which will be explained in the next subsection.","max ∑","l,p,k wl,p,kZk l,p + ∑","u,v w′","u,vXu,v (20) s.t. ∑","k Zk l,p = 1, ∀ applicable l, p (21) Xu,v ≤ Zu, (22) Xu,v ≤ Zv, (23) Xu,v ≥ Zu + Zv − 1, ∀Xu,v ∈ X (24)","Xu,v, Zk l,p ∈ {0, 1} (25) 5.3 Complexity and Variable Selection Using the notation in section 3.5, the number of second order variables is","O(|Z|2 ) =","O(K2 |s|2 C(l∗",")2",") and the number of constraints is","O(K2 |s|2 C(l∗",")2","). More generally, for variables","with higher order h ≥ 2, the number of variables","(and constraints) is O(Kh","|s|h","C(l∗",")h",").","Note that both the number of variables and the","number of constraints increase exponentially with","increasing variable order. In practice, a small","subset of second order variables is suf\\u{2}cient to 1461 Data set Sentences Words Edits Dev set 939 22,808 1,264 Test set 722 18,790 1,057 Table 3: Overview of the HOO 2011 data sets. Corrections are called edits in the HOO 2011 shared task. achieve good performance. For example, noun number corrections are only coupled with nearby article corrections, and have no connection with distant or other types of corrections.","In this work, we only introduce second order variables that combine article corrections and noun number corrections. Furthermore, we require that the article and the noun be in the same noun phrase. The set X of second order variables in Equation (24) is de\\u{2}ned as follows: X ={Xu,v = Zu ∧ Zv|l1 = Art , l2 = Noun , s[p1], s[p2] are in the same noun phrase }, where l1, l2, p1, p2 are taken from Equation (15)."]},{"title":"6 Experiments","paragraphs":["Our experiments mainly focus on two aspects: how our ILP approach performs compared to other grammatical error correction systems; and how the different constraints and the second order variables affect the ILP performance. 6.1 Evaluation Corpus and Metric We follow the evaluation setup in the HOO 2011 shared task on grammatical error correction (Dale and Kilgarriff, 2011). The development set and test set in the shared task consist of conference and workshop papers taken from the Association for Computational Linguistics (ACL). Table 3 gives an overview of the data sets.","System performance is measured by precision, recall, and F measure:","P = # true edits # system edits",", R = # true edits # gold edits",", F = 2P R P + R .","(26)","The dif\\u{2}culty lies in how to generate the system edits from the system output. In the HOO 2011 shared task, participants can submit system edits directly or the corrected plain-text system output. In the latter case, the of\\u{2}cial HOO scorer will extract system edits based on the original (ungrammatical) input text and the corrected system output text, using GNU Wdiff 3 . Consider an input sentence The data is similar with test set. taken from (Dahlmeier and Ng, 2012a). The gold-standard edits are with → to and ε → the . That is, the grammatically correct sentence should be The data is similar to the test set. Suppose the corrected output of a system to be evaluated is exactly this perfectly corrected sentence The data is similar to the test set. However, the of\\u{2}cial HOO scorer using GNU Wdiff will automatically extract only one system edit with → to the for this system output. Since this single system edit does not match any of the two gold-standard edits, the HOO scorer returns an F measure of 0,","even though the system output is perfectly correct. In order to overcome this problem, the Max-Match","( M 2 ) scorer was proposed in (Dahlmeier and Ng, 2012b). Given a set of gold-standard edits, the original (ungrammatical) input text, and the corrected system output text, the","M 2 scorer searches for the system edits that have the largest overlap with the gold-standard edits. For the above example, the system edits automatically determined by the M 2","scorer are identical to the gold-standard edits, resulting in an F measure of 1 as we would expect. We will use the","M 2 scorer in this paper to determine the best system edits. Once the system edits are found, P , R, and F are computed using the standard de\\u{2}nition (26). 6.2 ILP Con\\u{2}guration 6.2.1 Variables The \\u{2}rst order variables are given in Table 1. If the inde\\u{2}nite article correction a is chosen, then the \\u{2}nal choice between a and an is decided by a rule-based post-processing step. For each preposition error variable Zk Prep ,p, the correction k is restricted to a pre-de\\u{2}ned confusion set of prepositions which depends on the observed preposition at position p. For example, the confusion set of on is { at, for, in, of }. The list of prepositions corrected by our system is about, among, at, by, for, in, into, of, on, over, to, under, with, and within . Only selected positions in a sentence (determined by rules) undergo punctuation correction. The spelling correction candidates are given by a spell checker. We used GNU Aspell 4 in our","work. 3 http://www.gnu.org/software/wdiff/ 4 http://aspell.net 1462 6.2.2 Weights As described in Section 3.2, the weight of each variable is a linear combination of the language model score, three classi\\u{2}er con\\u{2}dence scores, and three classi\\u{2}er disagreement scores. We use the Web 1T 5-gram corpus (Brants and Franz, 2006) to compute the language model score for a sentence. Each of the three classi\\u{2}ers (article, preposition, and noun number) is trained with the multi-class con\\u{2}dence weighted algorithm (Crammer et al., 2009). The training data consists of all non-OCR papers in the ACL Anthology 5 , minus the documents that overlap with the HOO 2011 data set. The features used for the classi\\u{2}ers follow those in (Dahlmeier and Ng, 2012a), which include lexical and part-of-speech n-grams, lexical head words, web-scale n-gram counts, dependency heads and children, etc. Over 5 million training examples are extracted from the ACL Anthology for use as training data for the article and noun number classi\\u{2}ers, and over 1 million training examples for the preposition classi\\u{2}er.","Finally, the language model score, classi\\u{2}er con\\u{2}dence scores, and classi\\u{2}er disagreement scores are normalized to take values in [0, 1], based on the HOO 2011 development data. We use the following values for the coef\\u{2}cients: νLM = 1 (language model); λt = 1 (classi\\u{2}er con\\u{2}dence); and μt = −1 (classi\\u{2}er disagreement). 6.2.3 Constraints In Section 4, three sets of constraints are in-troduced: modi\\u{2}cation count (MC), article-noun agreement (ANA), and dependency relation (DR) constraints. The values for the modi\\u{2}cation count parameters are set as follows: NArt = 3, NPrep = 2, NNoun = 2, and NSpell = 1. 6.3 Experimental Results We compare our ILP approach with two other systems: the beam search decoder of (Dahlmeier and Ng, 2012a) which achieves the best published performance to date on the HOO 2011 data set, and UI Run1 (Rozovskaya et al., 2011) which achieves the best performance among all participating systems at the HOO 2011 shared task. The results are given in Table 4.","The HOO 2011 shared task provides two sets of gold-standard edits: the original gold-standard edits produced by the annotator, and the of\\u{2}cial gold-5 http://aclweb.org/anthology-new/ System Original Of\\u{2}cial P R F P R F UI Run1 40.86 11.21 17.59 54.61 14.57 23.00 Beam search 30.28 19.17 23.48 33.59 20.53 25.48 ILP 20.54 27.93 23.67 21.99 29.04 25.03 Table 4: Comparison of three grammatical error correction systems. standard edits which incorporated corrections proposed by the HOO 2011 shared task participants. All three systems listed in Table 4 use the M 2 scorer to extract system edits. The results of the beam search decoder and UI Run1 are taken from Table 2 of (Dahlmeier and Ng, 2012a).","Overall, ILP inference outperforms UI Run1 on both the original and of\\u{2}cial gold-standard edits, and the improvements are statistically signi\\u{2}cant at the level of signi\\u{2}cance 0.01. The performance of ILP inference is also competitive with the beam search decoder. The results indicate that a grammatical error correction system bene\\u{2}ts from corrections made at a whole sentence level, and that joint correction of multiple error types achieves state-of-the-art performance.","Table 5 provides the comparison of the beam search decoder and ILP inference in detail. The main difference between the two is that, except for spelling errors, ILP inference gives higher recall than the beam search decoder, while its precision is lower. This indicates that ILP inference is more aggressive in proposing corrections.","Next, we evaluate ILP inference in different con\\u{2}gurations. We only focus on article and noun number error types. Table 6 shows the performance of ILP in different con\\u{2}gurations. From the results, MC and DR constraints improve precision, indicating that the two constraints can help to restrict the number of erroneous corrections. In-cluding second order variables gives the best F measure, which supports our motivation for introducing higher order variables.","Adding article-noun agreement constraints (ANA) slightly decreases performance. By examining the output, we \\u{2}nd that although the overall performance worsens slightly, the agreement requirement is satis\\u{2}ed. For example, for the input We utilize search engine to . . . , the output without ANA is We utilize a search engines to . . . but with ANA is We utilize the search engines to . . . , while the only gold edit inserts a . 1463 Original Of\\u{2}cial Error type Beam search ILP Beam search ILP P R F P R F P R F P R F Spelling 36.84 0.69 1.35 60.00 0.59 1.17 36.84 0.66 1.30 60.00 0.57 1.12 + Article 19.84 12.59 15.40 18.54 14.75 16.43 22.45 13.72 17.03 20.37 15.61 17.68 + Preposition 22.62 14.26 17.49 17.61 18.58 18.09 24.84 15.14 18.81 19.24 19.68 19.46 + Punctuation 24.27 18.09 20.73 20.52 23.50 21.91 27.13 19.58 22.75 22.49 24.98 23.67 + Noun number 30.28 19.17 23.48 20.54 27.93 23.67 33.59 20.53 25.48 21.99 29.04 25.03 Table 5: Comparison of the beam search decoder and ILP inference. ILP is equipped with all constraints (MC, ANA, DR) and default parameters. Second order variables related to article and noun number error types are also used in the last row. Setting Original Of\\u{2}cial P R F P R F Art+Nn,","1st ord. 17.19 19.37 18.22 18.59 20.44 19.47 + MC 17.87 18.49 18.17 19.23 19.39 19.31 + ANA 17.78 18.39 18.08 19.04 19.11 19.07 + DR 17.95 18.58 18.26 19.23 19.30 19.26","+ 2nd ord. 18.75 18.88 18.81 20.04 19.58 19.81 Table 6: The effects of different constraints and second order variables."]},{"title":"7 Conclusion","paragraphs":["In this paper, we model grammatical error correction as a joint inference problem. The inference problem is solved using integer linear programming. We provide three sets of constraints to incorporate additional linguistic knowledge, and introduce a further extension with second order variables. Experiments on the HOO 2011 shared task show that ILP inference achieves state-of-the-art performance on grammatical error correction."]},{"title":"Acknowledgments","paragraphs":["This research is supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Of\\u{2}ce."]},{"title":"References","paragraphs":["Francis Bond and Satoru Ikehara. 1996. When and how to disambiguate? countability in machine translation. In Proceedings of the International Seminar on Multimodal Interactive Disambiguation .","Francis Bond, Kentaro Ogura, and Tsukasa Kawaoka. 1995. Noun phrase reference in Japanese-to-English machine translation. In Proceedings of the 6th International Conference on Theoretical and Methodological Issues in Machine Translation .","Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram corpus version 1.1. Technical report, Google Research.","Koby Crammer, Mark Dredze, and Alex Kulesza. 2009. Multi-class con\\u{2}dence weighted algorithms. In Proceedings of EMNLP .","Daniel Dahlmeier and Hwee Tou Ng. 2011. Grammatical error correction with alternating structure optimization. In Proceedings of ACL .","Daniel Dahlmeier and Hwee Tou Ng. 2012a. A beam-search decoder for grammatical error correction. In Proceedings of EMNLP .","Daniel Dahlmeier and Hwee Tou Ng. 2012b. Better evaluation for grammatical error correction. In Proceedings of NAACL .","Robert Dale and Adam Kilgarriff. 2011. Helping Our Own: The HOO 2011 pilot shared task. In Proceedings of the 13th European Workshop on Natural Language Generation .","Robert Dale, Ilya Anisimoff, and George Narroway. 2012. HOO 2012: A report on the preposition and determiner error correction shared task. In Proceedings of the Seventh Workshop on Innovative Use of NLP for Building Educational Applications , pages 54\\u{96}62.","Michael Gamon. 2010. Using mostly native data to correct errors in learners’ writing. In Proceedings of NAACL . 1464","Michael Gamon. 2011. High-order sequence model-ing for language learner error detection. In Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications .","Na-Rae Han, Martin Chodorow, and Claudia Leacock. 2006. Detecting errors in English article usage by non-native speakers. Natural Language Engineer-ing , 12(2).","Julia Heine. 1998. De\\u{2}niteness predictions for Japanese noun phrases. In Proceedings of ACL-COLING .","Kevin Knight and Ishwar Chander. 1994. Automated postediting of documents. In Proceedings of AAAI .","Xiaohua Liu, Bo Han, Kuan Li, Stephan Hyeonjun Stiller, and Ming Zhou. 2010. SRL-based verb selection for ESL. In Proceedings of EMNLP .","Andre Martins, Noah Smith, and Eric Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of ACL-IJCNLP .","Masaki Murata and Makoto Nagao. 1993. Determina-tion of referential property and number of nouns in Japanese sentences for machine translation into English. In Proceedings of the 5th International Conference on Theoretical and Methodological Issues in Machine Translation .","Y. Albert Park and Roger Levy. 2011. Automated whole sentence grammar correction using a noisy channel model. In Proceedings of ACL .","Vasin Punyakanok, Dan Roth, Wen tau Yih, and Dav Zimak. 2005. Learning and inference over constrained output. In Proceedings of IJCAI .","Sebastian Riedel and James Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proceedings of EMNLP .","Sebastian Riedel and Andrew McCallum. 2011. Fast and robust joint models for biomedical event extraction. In Proceedings of EMNLP .","Alla Rozovskaya and Dan Roth. 2011. Algorithm selection and model adaptation for ESL correction tasks. In Proceedings of ACL .","Alla Rozovskaya, Mark Sammons, Joshua Gioja, and Dan Roth. 2011. University of Illinois system in HOO text correction shared task. In Proceedings of the 13th European Workshop on Natural Language Generation .","Toshikazu Tajiri, Mamoru Komachi, and Yuji Matsumoto. 2012. Tense and aspect error correction for ESL learners using global context. In Proceedings of ACL .","Joel R. Tetreault and Martin Chodorow. 2008. The ups and downs of preposition error detection in ESL writing. In Proceedings of COLING .","Joel Tetreault, Jennifer Foster, and Martin Chodorow. 2010. Using parse features for preposition selection and error detection. In Proceedings of ACL . 1465"]}],"references":[{"authors":[{"first":"Francis","last":"Bond"},{"first":"Satoru","last":"Ikehara"}],"year":"1996","title":"When and how to disambiguate? countability in machine translation"},{"authors":[{"first":"Francis","last":"Bond"},{"first":"Kentaro","last":"Ogura"},{"first":"Tsukasa","last":"Kawaoka"}],"year":"1995","title":"Noun phrase reference in Japanese-to-English machine translation"},{"authors":[{"first":"Thorsten","last":"Brants"},{"first":"Alex","last":"Franz"}],"year":"2006","title":"Web 1T 5-gram corpus version 1"},{"authors":[{"first":"Koby","last":"Crammer"},{"first":"Mark","last":"Dredze"},{"first":"Alex","last":"Kulesza"}],"year":"2009","title":"Multi-class con\\u{2}dence weighted algorithms"},{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2011","title":"Grammatical error correction with alternating structure optimization"},{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012a","title":"A beam-search decoder for grammatical error correction"},{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012b","title":"Better evaluation for grammatical error correction"},{"authors":[{"first":"Robert","last":"Dale"},{"first":"Adam","last":"Kilgarriff"}],"year":"2011","title":"Helping Our Own: The HOO 2011 pilot shared task"},{"authors":[{"first":"Robert","last":"Dale"},{"first":"Ilya","last":"Anisimoff"},{"first":"George","last":"Narroway"}],"year":"2012","title":"HOO 2012: A report on the preposition and determiner error correction shared task"},{"authors":[{"first":"Michael","last":"Gamon"}],"year":"2010","title":"Using mostly native data to correct errors in learners’ writing"},{"authors":[{"first":"Michael","last":"Gamon"}],"year":"2011","title":"High-order sequence model-ing for language learner error detection"},{"authors":[{"first":"Na-Rae","last":"Han"},{"first":"Martin","last":"Chodorow"},{"first":"Claudia","last":"Leacock"}],"year":"2006","title":"Detecting errors in English article usage by non-native speakers"},{"authors":[{"first":"Julia","last":"Heine"}],"year":"1998","title":"De\\u{2}niteness predictions for Japanese noun phrases"},{"authors":[{"first":"Kevin","last":"Knight"},{"first":"Ishwar","last":"Chander"}],"year":"1994","title":"Automated postediting of documents"},{"authors":[{"first":"Xiaohua","last":"Liu"},{"first":"Bo","last":"Han"},{"first":"Kuan","last":"Li"},{"first":"Stephan","middle":"Hyeonjun","last":"Stiller"},{"first":"Ming","last":"Zhou"}],"year":"2010","title":"SRL-based verb selection for ESL"},{"authors":[{"first":"Andre","last":"Martins"},{"first":"Noah","last":"Smith"},{"first":"Eric","last":"Xing"}],"year":"2009","title":"Concise integer linear programming formulations for dependency parsing"},{"authors":[{"first":"Masaki","last":"Murata"},{"first":"Makoto","last":"Nagao"}],"year":"1993","title":"Determina-tion of referential property and number of nouns in Japanese sentences for machine translation into English"},{"authors":[{"first":"Y.","middle":"Albert","last":"Park"},{"first":"Roger","last":"Levy"}],"year":"2011","title":"Automated whole sentence grammar correction using a noisy channel model"},{"authors":[{"first":"Vasin","last":"Punyakanok"},{"first":"Dan","last":"Roth"},{"first":"Wen","middle":"tau","last":"Yih"},{"first":"Dav","last":"Zimak"}],"year":"2005","title":"Learning and inference over constrained output"},{"authors":[{"first":"Sebastian","last":"Riedel"},{"first":"James","last":"Clarke"}],"year":"2006","title":"Incremental integer linear programming for non-projective dependency parsing"},{"authors":[{"first":"Sebastian","last":"Riedel"},{"first":"Andrew","last":"McCallum"}],"year":"2011","title":"Fast and robust joint models for biomedical event extraction"},{"authors":[{"first":"Alla","last":"Rozovskaya"},{"first":"Dan","last":"Roth"}],"year":"2011","title":"Algorithm selection and model adaptation for ESL correction tasks"},{"authors":[{"first":"Alla","last":"Rozovskaya"},{"first":"Mark","last":"Sammons"},{"first":"Joshua","last":"Gioja"},{"first":"Dan","last":"Roth"}],"year":"2011","title":"University of Illinois system in HOO text correction shared task"},{"authors":[{"first":"Toshikazu","last":"Tajiri"},{"first":"Mamoru","last":"Komachi"},{"first":"Yuji","last":"Matsumoto"}],"year":"2012","title":"Tense and aspect error correction for ESL learners using global context"},{"authors":[{"first":"Joel","middle":"R.","last":"Tetreault"},{"first":"Martin","last":"Chodorow"}],"year":"2008","title":"The ups and downs of preposition error detection in ESL writing"},{"authors":[{"first":"Joel","last":"Tetreault"},{"first":"Jennifer","last":"Foster"},{"first":"Martin","last":"Chodorow"}],"year":"2010","title":"Using parse features for preposition selection and error detection"}],"cites":[{"authors":[{"last":"Dale"},{"last":"Kilgarriff"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Robert","last":"Dale"},{"first":"Adam","last":"Kilgarriff"}],"year":"2011","title":"Helping Our Own: The HOO 2011 pilot shared task"}},{"authors":[{"last":"Dale"},{"last":"al."}],"year":"2012","style":0,"reference":{"authors":[{"first":"Robert","last":"Dale"},{"first":"Ilya","last":"Anisimoff"},{"first":"George","last":"Narroway"}],"year":"2012","title":"HOO 2012: A report on the preposition and determiner error correction shared task"}},{"authors":[{"last":"Dale"},{"last":"Kilgarriff"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Robert","last":"Dale"},{"first":"Adam","last":"Kilgarriff"}],"year":"2011","title":"Helping Our Own: The HOO 2011 pilot shared task"}},{"authors":[{"last":"Murata"},{"last":"Nagao"}],"year":"1993","style":0,"reference":{"authors":[{"first":"Masaki","last":"Murata"},{"first":"Makoto","last":"Nagao"}],"year":"1993","title":"Determina-tion of referential property and number of nouns in Japanese sentences for machine translation into English"}},{"authors":[{"last":"Bond"},{"last":"al."}],"year":"1995","style":0,"reference":{"authors":[{"first":"Francis","last":"Bond"},{"first":"Kentaro","last":"Ogura"},{"first":"Tsukasa","last":"Kawaoka"}],"year":"1995","title":"Noun phrase reference in Japanese-to-English machine translation"}},{"authors":[{"last":"Bond"},{"last":"Ikehara"}],"year":"1996","style":0,"reference":{"authors":[{"first":"Francis","last":"Bond"},{"first":"Satoru","last":"Ikehara"}],"year":"1996","title":"When and how to disambiguate? countability in machine translation"}},{"authors":[{"last":"Heine"}],"year":"1998","style":0,"reference":{"authors":[{"first":"Julia","last":"Heine"}],"year":"1998","title":"De\\u{2}niteness predictions for Japanese noun phrases"}},{"authors":[{"last":"Han"},{"last":"al."}],"year":"2006","style":0,"reference":{"authors":[{"first":"Na-Rae","last":"Han"},{"first":"Martin","last":"Chodorow"},{"first":"Claudia","last":"Leacock"}],"year":"2006","title":"Detecting errors in English article usage by non-native speakers"}},{"authors":[{"last":"Knight"},{"last":"Chander"}],"year":"1994","style":0,"reference":{"authors":[{"first":"Kevin","last":"Knight"},{"first":"Ishwar","last":"Chander"}],"year":"1994","title":"Automated postediting of documents"}},{"authors":[{"last":"Han"},{"last":"al."}],"year":"2006","style":0,"reference":{"authors":[{"first":"Na-Rae","last":"Han"},{"first":"Martin","last":"Chodorow"},{"first":"Claudia","last":"Leacock"}],"year":"2006","title":"Detecting errors in English article usage by non-native speakers"}},{"authors":[{"last":"Tetreault"},{"last":"Chodorow"}],"year":"2008","style":0,"reference":{"authors":[{"first":"Joel","middle":"R.","last":"Tetreault"},{"first":"Martin","last":"Chodorow"}],"year":"2008","title":"The ups and downs of preposition error detection in ESL writing"}},{"authors":[{"last":"Dahlmeier"},{"last":"Ng"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2011","title":"Grammatical error correction with alternating structure optimization"}},{"authors":[{"last":"Gamon"}],"year":"2010","style":0,"reference":{"authors":[{"first":"Michael","last":"Gamon"}],"year":"2010","title":"Using mostly native data to correct errors in learners’ writing"}},{"authors":[{"last":"Tetreault"},{"last":"al."}],"year":"2010","style":0,"reference":{"authors":[{"first":"Joel","last":"Tetreault"},{"first":"Jennifer","last":"Foster"},{"first":"Martin","last":"Chodorow"}],"year":"2010","title":"Using parse features for preposition selection and error detection"}},{"authors":[{"last":"Han"},{"last":"al."}],"year":"2006","style":0,"reference":{"authors":[{"first":"Na-Rae","last":"Han"},{"first":"Martin","last":"Chodorow"},{"first":"Claudia","last":"Leacock"}],"year":"2006","title":"Detecting errors in English article usage by non-native speakers"}},{"authors":[{"last":"Tetreault"},{"last":"Chodorow"}],"year":"2008","style":0,"reference":{"authors":[{"first":"Joel","middle":"R.","last":"Tetreault"},{"first":"Martin","last":"Chodorow"}],"year":"2008","title":"The ups and downs of preposition error detection in ESL writing"}},{"authors":[{"last":"Rozovskaya"},{"last":"Roth"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Alla","last":"Rozovskaya"},{"first":"Dan","last":"Roth"}],"year":"2011","title":"Algorithm selection and model adaptation for ESL correction tasks"}},{"authors":[{"last":"Liu"},{"last":"al."}],"year":"2010","style":0,"reference":{"authors":[{"first":"Xiaohua","last":"Liu"},{"first":"Bo","last":"Han"},{"first":"Kuan","last":"Li"},{"first":"Stephan","middle":"Hyeonjun","last":"Stiller"},{"first":"Ming","last":"Zhou"}],"year":"2010","title":"SRL-based verb selection for ESL"}},{"authors":[{"last":"Tajiri"},{"last":"al."}],"year":"2012","style":0,"reference":{"authors":[{"first":"Toshikazu","last":"Tajiri"},{"first":"Mamoru","last":"Komachi"},{"first":"Yuji","last":"Matsumoto"}],"year":"2012","title":"Tense and aspect error correction for ESL learners using global context"}},{"authors":[{"last":"Gamon"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Michael","last":"Gamon"}],"year":"2011","title":"High-order sequence model-ing for language learner error detection"}},{"authors":[{"last":"Park"},{"last":"Levy"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Y.","middle":"Albert","last":"Park"},{"first":"Roger","last":"Levy"}],"year":"2011","title":"Automated whole sentence grammar correction using a noisy channel model"}},{"authors":[{"last":"Dahlmeier"},{"last":"Ng"}],"year":"2012a","style":0,"reference":{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012a","title":"A beam-search decoder for grammatical error correction"}},{"authors":[{"last":"Gamon"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Michael","last":"Gamon"}],"year":"2011","title":"High-order sequence model-ing for language learner error detection"}},{"authors":[{"last":"Park"},{"last":"Levy"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Y.","middle":"Albert","last":"Park"},{"first":"Roger","last":"Levy"}],"year":"2011","title":"Automated whole sentence grammar correction using a noisy channel model"}},{"authors":[{"last":"Dahlmeier"},{"last":"Ng"}],"year":"2012a","style":0,"reference":{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012a","title":"A beam-search decoder for grammatical error correction"}},{"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","style":0,"reference":{"authors":[{"first":"Sebastian","last":"Riedel"},{"first":"James","last":"Clarke"}],"year":"2006","title":"Incremental integer linear programming for non-projective dependency parsing"}},{"authors":[{"last":"Martins"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"Andre","last":"Martins"},{"first":"Noah","last":"Smith"},{"first":"Eric","last":"Xing"}],"year":"2009","title":"Concise integer linear programming formulations for dependency parsing"}},{"authors":[{"last":"Punyakanok"},{"last":"al."}],"year":"2005","style":0,"reference":{"authors":[{"first":"Vasin","last":"Punyakanok"},{"first":"Dan","last":"Roth"},{"first":"Wen","middle":"tau","last":"Yih"},{"first":"Dav","last":"Zimak"}],"year":"2005","title":"Learning and inference over constrained output"}},{"authors":[{"last":"Riedel"},{"last":"Mc-Callum"}],"year":"2011","style":0},{"authors":[{"last":"Dale"},{"last":"Kilgarriff"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Robert","last":"Dale"},{"first":"Adam","last":"Kilgarriff"}],"year":"2011","title":"Helping Our Own: The HOO 2011 pilot shared task"}},{"authors":[{"last":"Dahlmeier"},{"last":"Ng"}],"year":"2012a","style":0,"reference":{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012a","title":"A beam-search decoder for grammatical error correction"}},{"authors":[{"last":"Dahlmeier"},{"last":"Ng"}],"year":"2012b","style":0,"reference":{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012b","title":"Better evaluation for grammatical error correction"}},{"authors":[{"last":"Brants"},{"last":"Franz"}],"year":"2006","style":0,"reference":{"authors":[{"first":"Thorsten","last":"Brants"},{"first":"Alex","last":"Franz"}],"year":"2006","title":"Web 1T 5-gram corpus version 1"}},{"authors":[{"last":"Crammer"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"Koby","last":"Crammer"},{"first":"Mark","last":"Dredze"},{"first":"Alex","last":"Kulesza"}],"year":"2009","title":"Multi-class con\\u{2}dence weighted algorithms"}},{"authors":[{"last":"Dahlmeier"},{"last":"Ng"}],"year":"2012a","style":0,"reference":{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012a","title":"A beam-search decoder for grammatical error correction"}},{"authors":[{"last":"Dahlmeier"},{"last":"Ng"}],"year":"2012a","style":0,"reference":{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012a","title":"A beam-search decoder for grammatical error correction"}},{"authors":[{"last":"Rozovskaya"},{"last":"al."}],"year":"2011","style":0,"reference":{"authors":[{"first":"Alla","last":"Rozovskaya"},{"first":"Mark","last":"Sammons"},{"first":"Joshua","last":"Gioja"},{"first":"Dan","last":"Roth"}],"year":"2011","title":"University of Illinois system in HOO text correction shared task"}},{"authors":[{"last":"Dahlmeier"},{"last":"Ng"}],"year":"2012a","style":0,"reference":{"authors":[{"first":"Daniel","last":"Dahlmeier"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2012a","title":"A beam-search decoder for grammatical error correction"}}]}
