{"sections":[{"title":"String Transformation Learning Giorgio Satta","paragraphs":["Dipartimento di Elettronica e Informatica Universith di Padova via Gradenigo, 6/A 1-35131 Padova, Italy"]},{"title":"satt a@dei, unipd, it","paragraphs":["John C. Henderson","Department of Computer Science Johns Hopkins University Baltimore, MD 21218-2694"]},{"title":"j hndrsn~cs, j hu. edu","paragraphs":["Abstract String transformation systems have been introduced in (Brill, 1995) and have several applications in natural language processing. In this work we consider the computational problem of automatically learning from a given corpus the set of transformations presenting the best evidence. We introduce an original data structure and efficient algorithms that learn some families of transformations that are relevant for part-of-speech tagging and phonological rule systems. We also show that the same learning problem becomes NP-hard in cases of an unbounded use of don't care symbols in a transformation. 1 Introduction Ordered sequences of rewriting rules are used in several applications in natural language processing, including phonological and morphological systems (Kaplan and Kay, 1994), morphological disambiguation, part-of-speech tagging and shallow syntactic parsing (Brill, 1995), (Karlsson et ah, 1995). In (Brill, 1995) a learning paradigm, called error-driven learning, has been introduced for automatic induction of a specific kind of rewriting rules called transformations, and it has been shown that the achieved accuracy of the resulting transformation systems is competitive with that of existing systems.","In this work we further elaborate on the error-driven learning paradigm. Our main contribution is summarized in what follows. We consider some families of transformations and design efficient algorithms for the associated learning problem that improve existing methods. Our results are achieved by exploiting a data structure originally introduced in this work. This allows us to simultaneously represent and test the search space of all possible transformations. The transformations we investigate make use of classes of symbols, in order to generalize regularities in rule applications. We also show that when an unbounded number of these symbol classes are allowed within a transformation, then the associated learning problem becomes NP-hard.","The notation we use in the remainder of the paper is briefly introduced here. ~3 denotes a fixed, finite alphabet and e the null string. E* and E+ are the set of all strings and all non-null strings over E, respectively. Let w 6 E*. We denote by Iwl the length ofw. Let w ="]},{"title":"uxv; uis","paragraphs":["aprefix and v is a suffix of w; when x is non-null, it is called a factor of w. The suffix of w of length i is denoted"]},{"title":"suffi(w),","paragraphs":["for O < i _< Iwl. Assume that x is non-null, and"]},{"title":"w = uixsuffi(w )","paragraphs":["for ~ > 0 different values of i but not for ~ + 1, or x is not a factor of w and ~ = 0. Then we say that ~ is the"]},{"title":"statistic","paragraphs":["of factor z in w. 2 The learning paradigm The learning paradigm we adopt is called error-driven learning and has been originally proposed in (Brill, 1995) for part of speech tagging applications. We briefly introduce here the basic assump-tions of the approach.","A string transformation is a rewriting rule denoted as u -* v, where u and v are strings such that [u[ = Ivt. This means that ifu appears as a factor of some string w, then u should be replaced by v in w. The application of the transformation might be conditioned by the requirement that some additionally specified pattern matches some part of the string w to be rewritten.","We now describe how transformations can be automatically learned. A pair of strings"]},{"title":"(w, w')","paragraphs":["is an aligned pair if IT[ ="]},{"title":"]w'[.","paragraphs":["When w ="]},{"title":"uzsuffi(w), w' = u'x'suffi(w' )","paragraphs":["and"]},{"title":"Ixl","paragraphs":["= Ix'l, we say that factors x and x' occur at"]},{"title":"aligned positions","paragraphs":["within (w, w'). A multi-set of aligned pairs is called an aligned corpus. Let (w, w ') be an aligned pair and let 7- be some transformation of the form u --~ v. The positive evidence of v (w.r.t. (w, w')) is the number of different positions at which factors u and v are aligned within (w, w'). The negative evidence of r (w.r.t. w, w ~) is the number of different positions at which factors u and u are aligned within 444 ¢ a ~ ( C $' $"]},{"title":"-a.,","paragraphs":["al (p","$ cl q~ $, [1,2~ Figure 1: Trie and suffix tree for string w ="]},{"title":"accbacac$.","paragraphs":["Pair [i, j] denotes the factor of w starting at position i and ending at position j (hence [1, 2] denotes"]},{"title":"ac). (w, w').","paragraphs":["Intuitively speaking, positive (negative) evidence is a count of how many times we will do well (badly, respectively) when using v on w in trying to get w'. The score associated with v is the difference between the positive evidence and the negative evidence of r. This extends to an aligned corpus in the obvious way. We are interested in the set of transformations that are associated with the highest score in a given aligned corpus, and will develop algorithms to find such a set in the next sections. 3 Data Structures This section introduces two data structures that are basic to the development of the algorithms presented in this paper. 3.1 Suffix trees We briefly present here a data structure that is well known in the text processing literature; the reader is referred to (Crochemore and Rytter, 1994) and (Apostolico, 1985) for definitions and further references.","Let w be some non-null string. Throughout the paper we assume that the rightmost symbol of w is an end-marker not found at any other position in the string. The suffix tree associated with w is a \"compressed\" trie of all strings"]},{"title":"suffi(w), 1 <i< Iwl.","paragraphs":["Edges are labeled by factors of w which are encoded by means of two natural numbers denoting endpoints in the string. An example is reported in Figure 1. An implicit node is a node not explicitly represented in the suffix tree, that splits the label of some edge at a given position. (Each implicit node corresponds to some node in the original trie having only one child.) We denote by"]},{"title":"parent(p)","paragraphs":["the parent node of (implicit) node p and by"]},{"title":"label(p, q)","paragraphs":["the label of the edge spanning (implicit) nodes p and q. Throughout the paper, we take the dominance rela-tion between nodes to be reflexive, unless we write proper dominance. We also say that implicit node q immediately dominates node p if q splits the arc between"]},{"title":"parent(p)","paragraphs":["and p. Of main interest here are","the following properties of suffix trees: • if node p has children Pl .... ,"]},{"title":"Pd,","paragraphs":["then d _> 2 and strings"]},{"title":"label(p, pi)","paragraphs":["differ one from the other at","the leftmost symbol;",". all and only the factors of w are represented by","paths from the root to some (implicit) node;","• the statistic of factor u of w is the number of","leaves dominated by the (implicit) node ending","the path representing u. In the remainder of the paper, we sometimes identify an (implicit) node of a suffix tree with the factor represented by the path from the root to that node.","The suffix tree and the statistics of all factors of w can be constructed/computed in time O([w[), as reported in (Weiner, 1973) and (McCreight, 1976). McCreight algorithm uses two basic functions to scan paths in the suffix tree under construction. These functions are briefly introduced here and will be exploited in the next subsection. Below, p is a node in a tree and u is a non-null string. function"]},{"title":"Slow_scan(p,","paragraphs":["u): Starting at p, scan u symbol by symbol. Return the {implicit) node corresponding to the last matching symbol. The next function runs faster than"]},{"title":"Slow_scan,","paragraphs":["and can be used whenever we already know that u is an (implicit) node in the tree (u completely matches some path ill the tree). function"]},{"title":"Fast_scan(p,","paragraphs":["u): Starting at p, scan u by iteratively (i) finding the edge between the current node and one of its children, that has the same first symbol as the suffix of u yet to be scanned, and (ii) skipping a prefix of u equal to the length of the selected edge label. Return the (implicit) node u. 445 [1,2~"]},{"title":"/ \\\"-M9,91","paragraphs":["d/[8,9] t::7~~ Na[~ /[8.9]/[6.9]"]},{"title":"9,9]","paragraphs":["7(13)~(2) . [3~] N\"~ \"91 Figure 2: Suffix tree aligmnent for strings w ="]},{"title":"accbacac$, w' = acabacba$","paragraphs":["and the identity homomorphism"]},{"title":"h(a) = a, h(b) = b, h(c) = c.","paragraphs":["Each a-link is denoted by indexing the incident nodes with the same integer number; if the incident node is an implicit node, then we add between parentheses the relative position w.r.t. the arc label. From each node"]},{"title":"au","paragraphs":["in the suffix tree,"]},{"title":"au","paragraphs":["some factor, McCreight's algorithm creates a pointer, called an s-link, to node u which necessarily exists in the suffix tree. We write q ="]},{"title":"s-link(p)","paragraphs":["if there is an s-link from"]},{"title":"ptoq.","paragraphs":["3.2 Suffix tree alignment In the next section each transformation will be associated with several strings. Given an input text, we will compute transformation scores by computing statistics of these strings. This can easily be done using suffix trees,"]},{"title":"and","paragraphs":["by pairing statistics corresponding to the same transformation. The latter task can be done using the data structure originally introduced here.","A total function h : E ~ E ~, ~ and E' two alphabets, is called a (restricted) homomorphism. We extend h to a string function in the usual way by posing h(¢) = s and"]},{"title":"h(au) = h(a)h(u),","paragraphs":["a E E and u E E*. Given"]},{"title":"w,w' E","paragraphs":["E +, we need to pair each factor u of w with factor"]},{"title":"h(u)","paragraphs":["possibly occurring in w ~. To solve this problem, we construct the suffix trees"]},{"title":"T,T'","paragraphs":["for"]},{"title":"w,w',","paragraphs":["respectively. Then we establish an a-link (a pointer) from each node u of T, u some factor, to the (implicit) node"]},{"title":"h(u)","paragraphs":["of T ~, if"]},{"title":"h(u)","paragraphs":["exists. Furthermore, if factor"]},{"title":"ua","paragraphs":["with a E E is an (implicit) node of T such that"]},{"title":"h(u)","paragraphs":["but not"]},{"title":"h(ua)","paragraphs":["are (implicit) nodes of"]},{"title":"T',","paragraphs":["we create node u in T (if u was an implicit node) and establish an a-link from u to (implicit) node"]},{"title":"h(u)","paragraphs":["of T'. Note that the total number of a-links is"]},{"title":"O(Iwl).","paragraphs":["The resulting data structure is called here suffix tree aligmnent. An example is reported in Figure 2.","We now specify a method to compute suffix tree alignments. In what follows p,p~ are tree nodes and u is a non-null string. Crucially, we assume we can access the s-links of T and T'. Paths u and v in T and T', respectively, are aligned if v ="]},{"title":"h(u).","paragraphs":["The next two functions are used to move a-links up and down two aligned paths. function"]},{"title":"Move_link_down(p,p',u):","paragraphs":["Starting at. p and p', simultaneously scan u and h(u), respectively, using function"]},{"title":"Slow_scan.","paragraphs":["Stop as soon as a symbol is not matched. At each encountered node of T and at the (implicit) node of T corresponding to the last successful match, create an a-link to the paired (implicit) node of T'. Return the pair of nodes in the lastly created a-link Mong with the length of the successfully matched prefix of u. In the next function, we use function"]},{"title":"Fast_scan","paragraphs":["introduced in Section 3.1, but we run it upward the tree (with the obvious modifications). function"]},{"title":"Move_link_up(p,p'):","paragraphs":["Starting at p and p', simultaneously scan the paths to the roots of T and T', respectively, using function"]},{"title":"Fast_scan.","paragraphs":["Stop as soon as a node of T is encountered that already ha.s an a-link. At each encountered node of T create an a-link to the paired (implicit) node of"]},{"title":"T'.","paragraphs":["We also need a function that \"shifts\" a-links to a new pair of aligned paths. This is done using s-links. The next auxiliary function takes care of those (implicit) nodes for which the s-link is missing. (This is the case for implicit nodes of T ~ and for some nodes of T that have been newly created.) We rest on the property that the parent node of any such (implicit) node always has an s-link, when it differs from the root. function"]},{"title":"Up_link_down(p):","paragraphs":["If"]},{"title":"s-link(p)","paragraphs":["is defined then return"]},{"title":"s-link(p).","paragraphs":["Else, let pl ="]},{"title":"parent(p).","paragraphs":["If Pl is not the root node, let P2 ="]},{"title":"s-link(p1)","paragraphs":["and return (implicit) node"]},{"title":"FasLscan(p2,1abel(pl,p)).","paragraphs":["If Pl is the root node, return (implicit) node"]},{"title":"Fast_scan(p1, sufflZab~l(p~,p )i_ l ( label(pl , p) ).","paragraphs":["function"]},{"title":"Shifl_link(p,p'):","paragraphs":["Pl ="]},{"title":"Up_link_down(p), P'I = Up_linLdown(p').","paragraphs":["Return (Pl,P~).","We can now present the algorithm for the construction of suffix tree alignments. Algorithm 1 Let T and T' be the suffix trees for strings w and w', respectively:"]},{"title":"( bl~l ' Gl ' d) ,-- Move_link_down(root","paragraphs":["of T, 446"]},{"title":"I il ab' I bi I a-linkl 9 - ac","paragraphs":["1, 2 8 C C --"]},{"title":"7 e cba 4 6 ba bac 5 5 ac aca 6 4 ca ca 7","paragraphs":["3 a ac --"]},{"title":"2 c c 8 1 e $ -","paragraphs":["Figure 3: The table reports the values of 8bi, bi and the established a-links at each iteration of Algorithm 1, when constructing the suffix tree aligmnent in Figure 2. To denote a-links we use the same integer numbers as in Figure 2. root"]},{"title":"of T',","paragraphs":["for i from ]w I - 1 downto 1 do begin"]},{"title":"(sbi, sb;) ~-- Shift_link(bi+l,","paragraphs":["b;+l)"]},{"title":"M ove_link_up( sbi , sb~ ) ( b, , dd) Move_link_do n( ab, , abe, s wl-d(w)) d.--d+dd","paragraphs":["end end In Figure 3 a sample run of Algorithm 1 is schematically represented.","In the next section we use the following properties of Algorithm 1:","• after T and"]},{"title":"T'","paragraphs":["have been processed, for every node p ofT representing factor u of w, (implicit) node"]},{"title":"a-link(p)","paragraphs":["of T ~ is defined if and only if"]},{"title":"a-link(p)","paragraphs":["represents factor"]},{"title":"h(u)","paragraphs":["of w'; • the algorithm can be executed in time"]},{"title":"O(Iwl + Iw'l).","paragraphs":["The first property above can be proved as follows. For 1 < i < Iwl,"]},{"title":"bi","paragraphs":["in Algorithm 1 is (the node representing) the longest prefix of"]},{"title":"suffi(w )","paragraphs":["such that"]},{"title":"h(bi)","paragraphs":["is an (implicit) node of T' (is a factor of w'). This can be proved by induction on"]},{"title":"[w I -i,","paragraphs":["using the definition of"]},{"title":"Move_link_down","paragraphs":["and of s-link. We then observe that, if u is a node of T, then factor u is a prefix of some"]},{"title":"suffi(w )","paragraphs":["and either u dominates bi or"]},{"title":"bi","paragraphs":["properly dominates u in T. If u dominates"]},{"title":"bi,","paragraphs":["then"]},{"title":"• h(u)","paragraphs":["must be an (implicit) node ofT'. In this case an a-link is established from u to"]},{"title":"h(u)","paragraphs":["by"]},{"title":"Move_link_up","paragraphs":["or"]},{"title":"Move_link_down,","paragraphs":["depending on whether u dominates or is dominated by sbi in T. If bi properly dominates"]},{"title":"u, h(u)","paragraphs":["does not occur in"]},{"title":"w'.","paragraphs":["In this case, node u is never reached by the algorithm and no a-link is established for this node.","The proof of the linear time result is rather long, we only give an outline here. The interesting case is the function"]},{"title":"Shift_link,","paragraphs":["which is executed"]},{"title":"Iwl-","paragraphs":["1 times by the algorithm. When executed once on nodes p and"]},{"title":"if, Shift_link","paragraphs":["uses time 0(1) if"]},{"title":"s-link(p)","paragraphs":["and"]},{"title":"s-link(p ~)","paragraphs":["are both defined. In all other cases, it uses an amount of time proportional to the number of (implicit) nodes visited by function"]},{"title":"FasLscan,","paragraphs":["which is called through function"]},{"title":"Up_link_down.","paragraphs":["We use an amortization technique and charge a constant amount of time to the symbols in w and"]},{"title":"w',","paragraphs":["for each node visited in this way. Consider the execution of Shifl_link(bi+l, b~+l) for some i, 1 < i < Iw[- 1. Assume that, correspondingly,"]},{"title":"Fast_scan","paragraphs":["visits nodes ul,...,Ud of T in this order, with d __ 1 and each uj some factor of w. Then we have that each uj is a (proper) prefix of uj+l, and Ud ="]},{"title":"sbi.","paragraphs":["For each u j, 1 < j _< d- 1, we charge a constant amount of time to the symbol in w \"corresponding\" to the last symbol of uj. The visit to Ud, on the other hand, is charged to the ith symbol of w. (Note that charging the visit to ud to the symbol in w \"corresponding\" to the last symbol of Ud does not work, since in the case of sbi ---\" bi the same symbol would be charged again at the next iteration of the for-cycle.) It is not difficult to see that, in this way, each symbol of w is charged at most once. A similar argument works for visits to nodes of"]},{"title":"T'","paragraphs":["by"]},{"title":"Fast_scan,","paragraphs":["which are charged to symbols of u?. This shows that the time used by all executions of"]},{"title":"Shift_link","paragraphs":["is 0(Iwl + Iw'l).","Suffix trees and suffix tree alignments can be generalized to finite multi-sets of strings, each string ending with the same end-marker not found at any other position. In this case each leaf holds a record, called count, of the number of times the corresponding suffix appears in the entire multi-set, which will be propagated appropriately when computing factor statistic. Most important here, all of the above results still hold for these generalizations. In the next section, we will deal with the multi-set case. 4 Transformation learning This section deals with the computational problem of learning string transformations from an aligned corpus. We show that some families of transformations can be efficiently learned exploiting the data structures of Section 3. We also consider more general kinds of transformations and show that for this class the learning problem is NP-hard. 4.1 Data representation We introduce a representation of aligned corpora that reduces the problem of computing the positive/negative evidence of transformations to the problem of computing factor statistics.","Let"]},{"title":"(w, w')","paragraphs":["be an aligned pair, w = al.. \"an and"]},{"title":"w'=a'l...a,~;","paragraphs":["withaiEEforl<i<n, andn>_ 1. We define w×w' = (al,a~).\"(a~,a~). (1) 447 Note that w x w ~ is a string over the new alphabet E x E. Let N > 1 and let L = {(wl, w~),...,"]},{"title":"(Wg,","paragraphs":["W~v)} be an aligned corpus. We represent L as a string multi-set over alphabet E x E: L× = {w x w' I (w,w') E L}, (2) where w x w ~ appears in Lx as many times as (w, w ~) appears in L. 4.2 Learning algorithms Let L be an aligned corpus with N aligned pairs over a fixed alphabet E, and let n be the length of the longest string in a pair in L. We start by considering plain transformations of the form u --* v, (3) where u, v E E +, lul = Ivl, We want to find"]},{"title":"all","paragraphs":["instances of strings"]},{"title":"u, v E E*","paragraphs":["such that, in L, u ~ v has score greater or equal than the score of any other transformation. Existing methods for this problem are data-driven. They consider all pairs of factors (with lengths bounded by n) occurring at aligned positions within some pair in L, and update the positive and the negative evidence of the associated transformations. They thus consider"]},{"title":"O(Nn 2)","paragraphs":["factor pairs, where each pair takes time"]},{"title":"O(n)","paragraphs":["to be read/stored. We conclude that these methods use an amount of time O(Nn3). We can improve on this by using suffix tree alignments.","Let Lx be defined as in (2) and let hi : (E x E) (E x E) be the homomorphism specified as: h~((a,b)) = (a,a). Recall that, each suffix of a multi-set of strings is represented by a leaf in the associated suffix-tree, because of the use of the end-marker, and that each leaf stores the count of the occurrences of the corresponding suffix in the source multi-set. We schematically specify our first learning algorithm below. Algorithm 2 Step 1: construct two copies Tx and T x of the suffix tree associated with L× and align them using hi; Step 2: visit trees T× and T~ in post-order, and annotate each node p with the number"]},{"title":"e(p)","paragraphs":["computed as the sum of the counts at leaves that p dominates; Step 3: annotate each node p of T× with the score"]},{"title":"e(p) - e(p'),","paragraphs":["where p' ="]},{"title":"a-link(p)","paragraphs":["if"]},{"title":"a-link(p)","paragraphs":["is an actual node, p~ is the node immediately dominated by"]},{"title":"a-link(p)","paragraphs":["if"]},{"title":"a-link(p)","paragraphs":["is an implicit node, and"]},{"title":"e(p ~)","paragraphs":["= 0 if"]},{"title":"a-link(p)","paragraphs":["is undefined; make a list of the nodes with the highest annotated score. Let p be a node of Tx associated with factor u x v. Integer"]},{"title":"e(p)","paragraphs":["computed at Step 2 is the number of times a suffix having u x v as a prefix appears in strings in Lx. Thus"]},{"title":"e(p)","paragraphs":["is the number of different positions at which factors u and v are aligned within Lx and hence the positive evidence of transformation u --~ v w.r.t. L, as defined in Section 2. Similarly,"]},{"title":"e(#)","paragraphs":["is the statistic of factor u >< u and hence the negative evidence of u --+ v (as well as the negative evidence of all transformations having u as left-hand side). It follows that Algorithm 2 records, at Step 3, the transformations having the highest score in L among all transformations represented by nodes of Tx. It is not difficult to see that the remaining transformations, denoted by implicit nodes of Tx, do not have score greater than the one above. The latter transformations with highest score, if any, can be easily recovered by visiting the implicit nodes that immediately dominate the nodes of Tx recorded at Step 3.","A complexity analysis of Algorithm 2 is straightforward. Step 1 can be executed in time"]},{"title":"O(Nn),","paragraphs":["as discussed in Section 3. Since the size of Tx and T~< is"]},{"title":"O(Nn)~","paragraphs":["all other steps can be easily executed in linear time. Hence Algorithm 2 runs in time"]},{"title":"O(Nn).","paragraphs":["We now turn to a more general kind of transformations. In several natural language processing applications it is useful to generalize over some transformations of the form in (3), by using classes of symbols in E. Let t > 1 and let C1, •.., Ct be a partition of E (each"]},{"title":"Ci ~-O).","paragraphs":["Consider F = {C1,...,"]},{"title":"Ct}","paragraphs":["as an alphabet. We say that string"]},{"title":"al...ad E ~+","paragraphs":["matches string"]},{"title":"Ci,...Cid E","paragraphs":["F + if ak E Cik for 1 < k < d. We define transformations 1","u 7 -* v--, (4) u, v E E +, lut = Ivt, 7 E F +, and assume the following interpretation. An occurrence of string u must be rewritten to v in a text whenever u is followed by a substring matching 7. String 7 is called the right context of the transformation. The positive evidence for such transformation is the number of positions at which factors"]},{"title":"ux","paragraphs":["and vx ~ are aligned within the corpus, for all possible x, x ~ E E + with x matching 7. (We do not require x = x', since later transformations can change the right context.) The negative evidence for the transformation is the number of positions at which factors"]},{"title":"ux","paragraphs":["and"]},{"title":"ux ~","paragraphs":["are aligned within the corpus, x, x ¢ as above.","We are not aware of any learning method for transformations of the form in (4). A naive method for this task would consider all factor pairs appearing at aligned positions in some pair in L. The left component of each factor must then be split into a string in E + and a string in F +, to represent a transformation in the desired form. Overall, there are"]},{"title":"O(Nn 3)","paragraphs":["possible transformations, and we need time"]},{"title":"O(n)","paragraphs":["to read/store each transformation. Then the method uses an amount of time"]},{"title":"O(Nn4).","paragraphs":["Again, we can improve on this. We need a representation for right context strings. Define homomorphism h2 :(E X E)---+ F as","h~((a,~)) = C, a~C.","1In generative phonology (4) is usually written as u ---+ v / _ 7. Our notation can more easily be generalized, as it is needed in some transformation systems. 448 (h2 is well defined since r is a partition of E.) Let also Lr = {h2(w x w') I w x w' e Lx}, where"]},{"title":"h2(w x w')","paragraphs":["appears in Lr as many times as w x w' appears in L x. uxv / \\ ~q Figure 4: At Step 3 of Algorithm 3, triple (q, e, e') is inserted in v(p) if the relations depicted above are realized, where dashed arrows denote a-links, black circles denote nodes, and white circles denote nodes that might be implicit. Integer e > 0 is a count of the paths from node q downward, having the form y x y' with a prefix of y matching 7. Similarly, e ~ is a count of the paths from node q~ downward satisfying the same matching condition with 7. The matching condition is enforced by the fact that the above paths have their ending leaf nodes a-linked to a leaf node of Tr dominated by node p.","Below we link a suffix-tree to more than one suffix-tree. In the notation of a-links we then use a subscript indicating the suffix tree of the target node, in order to distinguish among different linkings. We now schematically specify the learning algorithm; additional computational details will be provided later in the discussion of the complexity. Algorithm 3 Step 1: construct two copies Tx and T~ of the suffix tree associated with L× and construct the suffix tree Tr associated with Lr; Step 2: align Tx with T\" using hi and align the resulting suffix trees Tx and T~ with Tr using h~; Step 3: for each node p of Tr, store a set v(p) including all triples (q, e, e') such that (see Figure 4):","• q is a node of Tx such that"]},{"title":"a-linkTr(q)","paragraphs":["properly dominates p","• e > 0 is the sum of the counts at leaves of Tx dominated by q that have an a-link to a leaf of Tr dominated by p","• if ql ="]},{"title":"a_linkT, x (q)","paragraphs":["is defined, e' is the sum of the counts at leaves of T x dominated by q' that have an a-link to a leaf of Tr dominated by p; otherwise, e ~ = 0; Step 4: find all pairs (p,q), p a node of Tr and (q, e, e') E v(p), such that e - e ~ is greater than or equal to any other el - e~, (ql, el, el) in some r(pl). We next show that if pair (p, q) is found at Step 4, then q represents a factor u x v, p represents a factor"]},{"title":"h2(u","paragraphs":["x v)7, and transformation u7 ~ v -- has the highest score among all transformations represented by nodes of Tx and Tr. Similarly to the case of Algorithm 2, this is the highest score achieved in L, and other transformations with the same score can be obtained from some of the implicit nodes immediately dominating p and q.","Let p aid q be defined as in Step 3 above. Assume that q represents a factor u x v of some string in L× and p represents a factor 87 E F* of some string in Lr, where [81 ="]},{"title":"lul.","paragraphs":["Since"]},{"title":"a-linkTr(q)","paragraphs":["dominates p, we must have"]},{"title":"h2(u","paragraphs":["x v) = 8. Consider a suffix (u x v)(z x"]},{"title":"x')(y x y')","paragraphs":["appearing in ~ > 0 strings in Lx, such that"]},{"title":"h2(x","paragraphs":["x x') = 7. (This means that x matches 7, and there are at least ~ positions at which u --+ v has been applied with a right-context of %) We have that string"]},{"title":"h2((u x v)(x","paragraphs":["x x')(y x y')) ="]},{"title":"&Th2(y x y')","paragraphs":["must be a suffix of some strings in Lr. It follows that (u x"]},{"title":"v)(x x z')(y x y')","paragraphs":["is a leaf of Tx with a count of ~,"]},{"title":"~Th2(y","paragraphs":["x y') is a leaf of Tr, and there is an a-link between these two nodes. Leaf"]},{"title":"(u x v)(x x z')(y × y')","paragraphs":["is dominated by q, and leaf"]},{"title":"&Th2(y x y')","paragraphs":["is dominated by p. Then, at Step 3, integer ~ is added to e. Since no condition has been imposed above on string x' and on suffix (y x y'), we conclude that the final value ofe must be the positive evidence of transformation u7 --+ v --. A similar argument shows that the negative evidence of this transformation is stored in e'. It then follows that, at Step 4, Algorithm 3 finds the transformations with the highest score among those represented by nodes of Tx and Tr.","Algorithm 3 can be executed in time"]},{"title":"O(Nn2).","paragraphs":["We only outline a proof of this property here, by focusing on Step 3. To execute this step we visit Tr in post order. At leaf node p, we consider the set"]},{"title":"F(p)","paragraphs":["of all leaves q of Tx such that p ="]},{"title":"a-linkT× (q),","paragraphs":["and the set"]},{"title":"F~(p)","paragraphs":["of all leaves q~ of T~ such that"]},{"title":"p = a-linkTx (q').","paragraphs":["For each (implicit) node of T\" that dominates some node in"]},{"title":"F~(p)","paragraphs":["and that is the target of some a-link (from some source node of Tx), we record the sum of the counts of the dominated nodes in"]},{"title":"Fl(p).","paragraphs":["This can be done in time"]},{"title":"O(IF'(p)l n).","paragraphs":["For each node q of Tx dominating some node in"]},{"title":"F(p),","paragraphs":["we store in v(p) the triple"]},{"title":"(q,e, e'),","paragraphs":["since"]},{"title":"a-linkTr(q)","paragraphs":["necessarily dominates p. We let e > 0 be the sum of the counts of the dominated nodes in"]},{"title":"F(p),","paragraphs":["and let e' be the value retrieved from the a-link to T', if any. This takes time"]},{"title":"O(IF(P)l n).","paragraphs":["When p ranges over the leaves of 449 Tr, we have ~-~p"]},{"title":"IF(p)I = EC, IF'(p)I","paragraphs":["="]},{"title":"O(Nn).","paragraphs":["We then conclude that sets r(p) for all leaves p of Tr can be computed in time O(Nn2). At internal node p with children Pi, 1 < i _< d, d > 1, we assume that sets r(pi)'s have already been computed. Assume that for some i we have (q, ei, e~) E r(pl) and a-linkTr(q) does not immediately dominate Pi. If","' to e, respectively; (q, e, e') E r(p), we add ei, e i e', otherwise, we insert (q, el, e{) in r(p). We can then compute sets r(p) for all internal nodes p of Tr using an amount of time }-'~p Ir(p)t = O(Nn=). 4.3 General transformations We have mentioned that the introduction of classes of alphabet symbols allows abstraction over plain transformations that is of interest to natural language applications. We generalize here transformations in (47 by letting 7 be a string over E U F. More precisely, we assume 7 has the form: \"1 = uo~iul..-u~-i~'a~, (5) where u0,ud E ~*, ui E ~+ and ~j E F + for 1 _ i_< d-1 and l_<j_< d, and d>_ 1. The notion of matching previously defined is now extended in such a way that, for a, b E P,, a matches b if a = b. Then the interpretation of the resulting transformation is the usual one. The parameter d in (5) is called the number of alternations of the transformation. We have established the following results:","• transformations with a bounded number of al-","ternations can be learned in polynomial time;","• learning transformations with an unbounded","number of alternations is NP-hard. Again, we only give an outline of the proof below.","The first result is easy to show, by observing that in an aligned corpus there are polynomially many occurrences of transformations with a bounded number of alternations. The second result holds even if we restrict ourselves to IEI = 2 and Irl = 1, that is if we use a don~t care symbol. Here we introduce a decision problem associated with the optimiza-tion problem of learning the transformations with the highest, score, and outline an NP-completeness proof. TRANSFORMATION SCORING (TS) Instance: (L,K), with L an aligned corpus, K a positive integer. Question: Is there a transformation that has score greater than or equal to K w.r.t. L? Membership in NP is easy to establish for TS. To show NP-hardness, we consider the CLIQUE decision problem for undirected, simple, connected graphs and transform such a problem to the TS problem. (The NP-completeness for .the used restric-tion of the CLIQUE problem (Garey and Johnson, 1979) is easy to establish.) Let (G,K') be an instance of the CLIQUE problem as above, G = (V, E) and K' > 0. Without loss of generality, we assume that V = {1,2,...,q}. Let E = {a,b}; we construct an instance of the TS problem (L, K} over E as follows. For each {i, j} E V with i < j let wi,j = ai-lbaJ-i-lba q-j. (6) We add to the aligned corpus L: 1. one instance of pair Pi,j = (awl j, bwi,j) for each","i < j, {i,j} E E; 2. q2 instances of pair Pi,j = (awi,j,"]},{"title":"awi,j)","paragraphs":["for each i,j E Y with i < j and {i,j} ~ E;","3. q2 instances of pair Pa = (aaa, ban). Also, we set K = q2 + (~'). The above instance of TS can easily be constructed in polynomial deterministic time with respect to the length of (G, K'}.","It is easy to show that when (G, K') is a positive instance of the source problem, then the corresponding instance of TS is satisfied by at least one transformation. Assume now that there exists a transformation r having score greater equal than K > 0, w.r.t.L. Since the replacement of a with b is the only rewriting that appears in pairs of L, r must have the form a7 --+ b --. If 7 includes some occurrence of b, then r cannot match Pa and the positive evidence of r will not exceed IEI < (3) < K, contrary to our assumption. We then conclude that 7 has the form (? denotes the don't care symbol): aJl-l?aJ~-ji-1 ? ...?.aq'-Ja, where V\" = {ji,...,Jd} C_ V, d > 0 and q' < q. If there exists i, j E V\" such that {-i, j} ~ E, then r would match some pair Pi,j E L and it would have negative evidence smaller or equal than q2. Since the positive evidence of r cannot exceed q2 + IEI, r would have a score not exceeding IEI < (q) < If, contrary to our assumption. Then r matches no pair Pij E L and, for each i,j E V\", we have {i,j} E E.","= K' (K') Since K - q2 ( 2 ), at least pairs Pi,j E L are matched by r. We therefore conclude that d > K' and that V\" is a clique in G of size greater equal than K'. This concludes our outline of the proof. 5 Concluding remarks With some minor technical changes to function Up_link_down, we can align a suffix tree with itself (w.r.t. a given homomorphism). In this way we improve space performance of Algorithms 2 and 3, avoiding the construction of two copies of the same suffix tree. Algorithm 3 can trivially be adapted to learn transformations in (4) where a left context is specified in place of a right context. The algorithm can also be used to learn traditional phonological rules of the form a --* b / _7, where a,b are single phonemes and \"/is a sequence over {C, V}, the classes of consonants and vowels. In this case the 450 algorithm runs in time"]},{"title":"O(Nn)","paragraphs":["(for fixed alphabet). We leave it as an open problem whether rules of the form in (4) can be learned in linear time.","We have been concerned with learning the best transformations that should be applied at a given step. An ordered sequence of transformations can be learned by iteratively learning a single transformation and by processing the aligned corpus with the transformation just learned (Brill, 1995). Dynamic techniques for processing the aligned corpus were first proposed in (Ramshaw and Marcus, 1996) to re-edit the corpus only where needed. Those authors report that this is not space efficient if transformation learning is done by independently test-ing all possible transformations in the search space (as in (Brill, 1995)). The suffix tree alignment data structure allows simultaneous scoring for all transformations. We can now take advantage of this and design dynamical algorithms that re-edit a suffix tree alignment only where needed, on the line of a similar method for suffix trees in (McCreight, 1976).","An alternative data structure to suffix trees for the representations of string factors, called DAWG, has been presented in (Blumer et al., 1985). We point out here that, because a DAWG is an acyclic graph rather than a tree, straightforward ways of defining alignment between two DAWGs results in a quadratic number of a-links, making DAWGs much less attractive than suffix trees for factor alignment. We believe that suffix tree alignments are a very flexible data structure, and that other transformations could be efficiently learned using these structures.","We do not regard the result in Section 4.3 as a negative one, since general transformations specified as in (5) seem too powerful for the proposed applications in natural language processing, and learning might result in corpus overtraining.","Other than transformation based systems the methods presented in this paper can be used for learning rules of constraint grammars (Karlsson et al., 1995), phonological rule systems as in (Kaplan and Kay, 1994), and in general those grammatical systems using constraints represented by means of rewriting rules. This is the case whenever we can encode the alphabet of the corpus in such a way that alignment is possible. Acknowledgements Part of the present research was done while the first author was visiting the Center for Language and Speech Processing, Johns Hopkins University, Baltimore, MD. The second author is a member of the Center for Language and Speech Processing. This work was funded in part by NSF grant IRI-9502312. The authors are indebted to Eric Brill for technical discussions on topics related to this paper."]},{"title":"References","paragraphs":["Apostolico, A. 1985. The myriad virtues of suffix trees. In A. Apostolico and Z. Galil, editors,"]},{"title":"Combinatorial Algorithms on Words,","paragraphs":["volume 12. Springer-Verlag, Berlin, Germany, pages 85-96. NATO Advanced Science Institutes, Seires F.","Blumer, A., J. Blumer, D. Haussler, A. Ehrenfeucht, M. Chen, and J. Seiferas. 1985. The smallest automaton recognizing the subwords of a text."]},{"title":"The- oretical Computer Science,","paragraphs":["40:31-55.","Brill, E. 1995. Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging."]},{"title":"Computational Linguistics.","paragraphs":["Crochemore, M. and W. Rytter. 1994."]},{"title":"Text Algo- rithms.","paragraphs":["Oxford University Press, Oxford, UK. Garey, M. R. and D. S. Johnson. 1979."]},{"title":"Computers and Intractability.","paragraphs":["Freeman and Co., New York, NY.","Kaplan, R. M. and M. Kay. 1994. Regular models of phonological rule sistems."]},{"title":"Computational Lin- guistics,","paragraphs":["20(3):331-378.","Karlsson, F., A. Voutilainen, J. Heikkil~, and A. Anttila. 1995."]},{"title":"Constraint Grammar. A Language Independent System for Parsing Unre- stricted Text.","paragraphs":["Mouton de Gruyter.","McCreight, E. M. 1976. A space-economical suffix tree construction algorithm."]},{"title":"Journal of the Asso- ciation for Computing Machinery,","paragraphs":["23(2):262-272.","Ramshaw, L. and M. P. Marcus. 1996. Explor-ing the nature of transformation-based learning. In J. Klavans and P. Resnik, editors,"]},{"title":"The Bal- ancing Act--Combining Symbolic and Statistical Approaches to Language.","paragraphs":["The MIT Press, Cambridge, MA, pages 135-156.","Weiner, P. 1973. Linear pattern-matching algorithms. In"]},{"title":"Proceedings of the i4th IEEE Annual Symposium on Switching and Automata Theory,","paragraphs":["pages 1-11, New York, NY. Institute of Electrical and Electronics Engineers. 451"]}]}
