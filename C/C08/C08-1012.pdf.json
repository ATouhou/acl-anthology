{"sections":[{"title":"","paragraphs":["Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 89–96 Manchester, August 2008"]},{"title":"Are Morpho-Syntactic Features More Predictive for the Resolution of Noun Phrase Coordination Ambiguity than Lexico-Semantic Similarity Scores? Ekaterina Buyko and Udo Hahn Jena University Language & Information Engineering (JULIE) Lab F ürstengraben 30, 07743 Jena, Germany ekaterina.buyko|udo.hahn@uni-jena.de Abstract","paragraphs":["Coordinations in noun phrases often pose the problem that elliptified parts have to be reconstructed for proper semantic interpretation. Unfortunately, the detection of coordinated heads and identification of elliptified elements notoriously lead to ambiguous reconstruction alternatives. While linguistic intuition suggests that semantic criteria might play an important, if not superior, role in disambiguating resolution alternatives, our experiments on the re-annotated WSJ part of the Penn Treebank indicate that solely morpho-syntactic criteria are more predictive than solely lexico-semantic ones. We also found that the combination of both criteria does not yield any substantial improvement."]},{"title":"1 Introduction","paragraphs":["Looking at noun phrases such as","‘cat and dog owner’","‘novels and travel books’ their proper coordination reading (and asymmetric distribution of coordinated heads) as","‘cat owner’ AND ‘dog owner’","‘novels’ AND ‘travel books’ seems to be licensed by the striking semantic similarity between ‘cat’ and ‘dog’, and ‘novels’ and ‘books’, respectively. If this were a general rule, then automatic procedures for the resolution of coordination ambiguities had to rely on the a priori provision of potentially large amounts of semantic","c⃝ 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. background knowledge to make this similarity explicit. Furthermore, any changes in languages or domains where such resources were missing (or, were incomplete) would severely hamper coordination analysis.","Indeed, previous research has gathered lot of evidence that conjoined elements tend to be semantically similar. The important role of semantic similarity criteria for properly sorting out conjuncts was first tested by Resnik (1999). He introduced an information-content-based similarity measure that uses WORDNET (Fellbaum, 1998) as a lexico-semantic resource and came up with the claim that semantic similarity is helpful to achieve higher coverage in coordination resolution for coordinated noun phrases of the form ‘noun1 and noun2 noun3’ than similarity measures based on morphological information only.","In a similar vein, Hogan (2007b) inspected WORDNET similarity and relatedness measures and investigated their role in conjunct identification. Her data reveals that several measures of semantic word similarity can indeed detect conjunct similarity. For the majority of these similarity measures, the differences between the mean similarity of coordinated elements and non-coordinated ones were statistically significant. However, it also became evident that these were only slight differences, and not all coordinated heads were semantically related as evidenced, e.g., by ‘work’/‘harmony’ in ‘hard work and harmony’. The significance tests did also not reveal particularly useful measures for conjunct identification.","Rus et al. (2002) in an earlier study presented an alternative heuristics-based approach to conjunct identification for coordinations of the form ‘noun1 and noun2 noun3’. They exploit, e.g., look-ups in WORDNET for a compound noun as a con-89 cept, and for the sibling relation between nouns in the coordination and report bracketing precision of 87.4% on 525 candidate coordinations. Although the authors demonstrated that WORDNET was really helpful in coordination resolution, the evaluation was only conducted on compound nouns extracted from WORDNET’s noun hierachy and, furthermore, the senses of nouns were manually tagged in advance for the experiments.","Despite this preference for semantic criteria, one might still raise the question how far non-semantic criteria might guide the resolution of noun phrase coordination ambiguities, e.g., by means of the distribution of resolution alternatives in a large corpus or plain lexical or morpho-syntactic criteria. This idea has already been explored before by various researchers from different methodological angles including distribution-based statistical approaches (e.g., Chantree et al. (2005), Nakov and Hearst (2005)), similarity-based approaches incorporating orthographical, morpho-syntactic, and syntactic similarity criteria (e.g., Agarwal and Boggess (1992), Okumura and Muraki (1994)), as well as a combination of distribution information and syntactic criteria (Hogan, 2007a).","Statistical approaches enumerate all candidate conjuncts and calculate the respective likelihood according to a distribution estimated on a corpus. For the coordination ‘movie and television industry’ the distributional similarity of ‘movie’ and ‘industry’ and the collocation frequencies of the pairs [‘movie’ - ‘industry’] and [‘television’ - ‘industry’] would be compared against each other. However, for such an approach only an F-measure under 50% was reported (Chantree et al., 2005). Unsupervised Web-distribution-based algorithms (Nakov and Hearst, 2005) achieved 80% on the disambiguation of coordinations of the fixed form ‘noun1 and noun2 noun3’. Hogan (2007a) presented a method for the disambiguation of noun phrase coordination by modelling two sources of information, viz. distribution-based similarity between conjuncts and the dependency between conjunct heads. This method was incorporated in Bikel’s parsing model (Bikel, 2004) and achieved an increase in NP coordination dependency F-score from 69.9% to 73.8%.","Similarity-based approaches consider those elements of a coordination as conjuncts which are most ‘similar’ under syntactic, morphological, or even semantic aspects. Agarwal and Boggess (1992) include in their NP coordination analysis syntactic and some semantic information about candidate conjuncts and achieve an accuracy boost up to 82%. Okumura and Muraki (1994) estimate the similarity of candidate conjuncts by means of a similarity function which incorporates syntactic, orthographical, and semantic information about the conjuncts. The model provides about 75% accuracy.","The resolution of coordination ambiguity can also be tried at parsing time. Charniak and Johnson (2005), e.g., supply a discriminative reranker that uses e.g., features to capture syntactic parallelism across conjuncts. The reranker achieves an F-score of 91%.","Recently, discriminative learning-based approaches were proposed, which exploit only lexical, morpho-syntactic features and the symmetry of conjuncts. Shimbo and Hara (2007) incorporate morpho-syntactic and symmetry features in a discriminative learning model and end up with 57% F-measure on the GENIA corpus (Ohta et al., 2002). Buyko et al. (2007) employ Conditional Random Fields (Lafferty et al., 2001) and successfully tested this technique in the biomedical domain for the identification and resolution of elliptified conjuncts. They evaluate on the GENIA corpus and report an F-score of 93% for the reconstruction of the elliptical conjuncts employing lexical and morpho-syntactic criteria only. At least two questions remain — whether the latter approach can achieve similar results in the newswire language domain (and is thus portable), and whether the incorporation of additional semantic criteria in this approach might boost the resolution rate, or not (and is thus possibly more parsimonious). The latter question is the main problem we deal with in this paper."]},{"title":"2 Data Sets for the Experiments 2.1 Coordination Annotation in the PENN TREEBANK","paragraphs":["For our experiments, we used the WSJ part of the PENN TREEBANK (Marcus et al., 1993). Some researchers (e.g., Hogan (2007a)) had recently found several inconsistencies in its annotation of the bracketing of coordinations in NPs. These bugs were shown to pose problems for training and test-ing of coordination resolution and parsing tools. Fortunately, a re-annotated version has been provided by Vadas and Curran (2007), with a focus 90 on the internal structure of NPs. They added additional bracketing annotation for each noun phrase in the WSJ section of the PENN TREEBANK as-suming a right-bracketing structure in NPs. In addition, they introduced tags, e.g., ‘NML’ for explicitly marking any left-branching constituents as in","(NP (NML (JJ industrial) (CC and) (NN food)) (NNS goods)) where ‘industrial’ and ‘food’ are conjuncts. In the example","(NP (DT some) (NN food) (CC and) (NN household) (NNS goods)) the structure of the noun phrase is already correct and should not be annotated further, since ‘household goods’ is already right-most and is coordinated with ‘food’. Still, in the original PENN TREEBANK annotation, we find annotations of noun phrases such as","(NP (NN royalty) (CC and) (NP (NN rock) (NNS stars))) that remain unchanged after the re-annotation process. 2.2 Coordination Corpus We, first, extracted a set of 3,333 non-nested NP coordinations involving noun compounds and one conjunction, with a maximal number of nine nouns (no prepositional phrases were considered). We focused on two patterns in the re-annotated WSJ portion: (1) Noun phrases containing at least two nouns and a conjunction as sister nodes as in","(NP (NML (NN movie) (CC and) (NN book)) (NNS pirates)) or in","(NP (DT some) (NN food) (CC and) (NN household) (NNS goods)) (2) Noun phrases containing at least two noun phrases and a conjunction as sister nodes (as they remained unchanged from the original PENN TREEBANK version). Thereby, the second noun phrase contains at least two nouns as sister nodes as in","(NP (NP (NNP France)) (CC and) (NP (NNP Hong) (NNP Kong)))","We removed from this original set NPs which could not be reduced to the following pattern:1","1","These are typically coordinations of the form ‘(W )N1 and N2’, e.g., ‘government sources and lobbyists’, where W is a sequence of i tokens (i ≥ 0). 646 coordinations of this type occurred in the WSJ portion of the PTB.","(W ) N1 and (W ) N2 N3, where (W ) is a sequence of i tokens with i ≥ 0 as in ‘street lampsN1 and ficusN2 treesN3’.","The remaining major data set (A) then contained 2,687 NP coordinations. A second data set (B) was formed, which is a proper subset of A and contained only those coordination structures that match the following pattern:","(X ) N1 and (W ) N2 N3, where (X ) is defined as a sequence of i tokens (i ≥ 0) with all part-of-speech (POS) tags except nouns and (W ) defined as above; e.g., ‘a happy catN1 and dogN2 ownerN3’. Test set B contains, in our opinion, a selection of less ‘hard’ coordinations from the set A, and includes 1,560 items.","All these patterns focus on three forms of conjunctions, namely ‘and’, ‘or’, and ‘but not’, which connect two conjuncts (the extension of which varies in our data from one up to maximally eight tokens as in ‘London’s “Big Bang” 1986 deregulation and Toronto’s “Little Bang” the same year’.","The remainders from the conjunctions and the two conjuncts in a coordinated NP are called shared elements (e.g., ‘owner’ and ‘a happy’ in the above example). It is evident that the correct recognition of conjunct boundaries allows for the proper identification of the shared elements.","Set A contains 1,455 coordinations where N1 and N3 are coordinated (e.g, ‘food and household goods’) and 1,232 coordinations where N1 and N2 are coordinated (e.g., ‘cotton and acetate fibers’). Set B consists of 643 coordinations where N1 and N3 are coordinated and 917 coordinations where N1 and N2 are coordinated.","The extracted data sets were converted into an IO representation of tokens labeled as ‘C’ for conjunct, ‘CC’ for conjunction, and ‘S’ for the shared element(s). The noun phrase ‘cotton and acetate fibers’, e.g., is represented as a sequence ‘C CC C S’, while ‘food and household goods’ is represented as a sequence ‘C CC C C’."]},{"title":"3 Methods","paragraphs":["We here compare three different approaches to the resolution of noun phrase coordination ambiguity, viz. ones relying solely on morpho-syntactic information, solely on lexico-semantic information, and a cumulative combination of both. As far as semantic information is concerned we make use of various WORDNET similarity measures. 91 3.1 Baselines We used three baselines for resolving noun phrase coordination ambiguities — one incorporating only lexico-semantic information, the WordNet Similarity baseline, and two alternative ones incorporating only morpho-syntactic and syntactic parse information, the Number Agreement and the Bikel Parser baseline, respectively. 3.1.1 WORDNET Similarity (WN) Baseline","Our lexico-semantic baseline comes with WORDNET semantic similarity scores of putatively coordinated nouns. For our experiments, we used the implementation of WORDNET similarity and relatedness measures provided by Ted Pedersen.2","The following similarity measures were considered: two measures based on path lenghts between concepts (path and lch (Leacock et al., 1998)), three measures based on information content, i.e., corpus-based measures of the specificity of a concept (res (Resnik, 1999), lin (Lin, 1998), and jcn (Jiang and Conrath, 1997)). Furthermore, we used two relatedness measures, namely, lesk (Banerjee and Pedersen, 2003) and vector (Patwardhan et al., 2003), which score the similarity of the glosses of both concepts. We applied these similarity measures to any pair of putatively coordinated nouns in the noun phrases from our data sets, A and B. To determine potential conjuncts we calculate two similarity scores relative to the structures discussed in Section 2.2:","s1 = sim(N1, N2) and s2 = sim(N1, N3)","Our final score is the maximum over both scores which is then the semantic indicator for the most plausible resolution of the coordination. 3.1.2 Number Agreement (NA) Baseline","We compared here the number agreement between selected nouns (see Resnik (1999)). Accordingly, N1 and N2 are coordinated, if number(N1) = number(N2) AND number(N1) ̸= number(N3), while N1 and N3 are coordinated, if number(N1) = number(N3) AND number(N1) ̸= number(N2). 3.1.3 Post-Processing Heuristics","In the WN and NA baselines, after the detection of coordinated elements we used simple heuristics to tag the remaining part of the noun phrase. If N1 and N2 were hypothesized to be coordinated, then all tokens preceding N1 were tagged as","2","http://www.d.umn.edu/∼tpederse/ shared elements, N3 was tagged as shared element as well, while all tokens between the conjunction and N2 were tagged as conjuncts. For example, in ‘a happy dogN1 and catN2 ownerN3’ we identify ‘dog’ and ‘cat’ as coordinated elements and tag ‘a happy’ and ‘owner’ as shared elements. The final resolution looks like ‘S S C CC C S’. If N1 and N3 were hypothesized to be coordinated, then all other elements except conjunctions were tagged as parts of conjuncts, as well. 3.1.4 Bikel Parser (BP) Baseline","We used the well-known Bikel Parser (Bikel, 2004) in its original version and the one used by Collins (2003). We trained both of them only with NPs extracted from the re-annotated version of WSJ (see Section 2) and converted the bracketing output of the parsers to the IO representation for NP coordinations for further evaluations. 3.2 Chunking of Conjuncts with CRFs The approach to conjunct identification presented by Buyko et al. (2007) employs Conditional Random Fields (CRF) (Lafferty et al., 2001),3","which assign a label to each token of coordinated NPs according to its function in the coordination: ‘C’ for conjuncts, ‘CC’ for conjunctions, and ‘S’ for shared elements. Since non-nested conjuncts can be assumed to be in a sequential order, sequential learning approaches (instead of single position classification approaches) seem appropriate here.","Buyko et al. (2007) report an F-measure of 93% on conjunct identification in the GENIA corpus. They use a feature set including lexical (words), and morpho-syntactic features (POS tags, morpho-syntactic similarity of putative conjuncts), but exclude any semantic criteria. The morpho-syntactic similarity features were generated from a rule-based approach to conjunct identification using the maximal symmetry of conjuncts as constituted by their respective POS annotation.","We here intend to apply this approach for resolving coordination ambiguities involving noun compounds in the newswire language such as ‘president and chief executive’. This restricts the spectrum of considered coordinations in noun phrases to more complicated cases than those considered by Buyko et al. (2007). We will thus test the various resolution models under harder test conditions, 3","They employ the linear-chain CRF implementation from the MALLET toolsuite available at http://mallet.cs. umass.edu/index.php/Main_Page 92 Feature Class Description default feature prior probability distribution over the","possible argument labels lexical word morpho-syntactic the token’s POS tag; output labels of the morpho-syntactic similarity (‘C’,‘CC’ and ‘S’) (see Buyko et al. (2007)); output labels of the number agreement baseline (‘C’, ‘CC’ and ‘S’)","semantic WN output labels of the WORDNET similarity baseline (‘C’, ‘CC’ and ‘S’)","contextual conjunctions of all features of neighbor-ing tokens (two tokens to the left and one token to the right) Table 1: Feature Classes Used for Conjunct Identification since Buyko et al. consider, e.g., adjective coordinations in noun phrases such as ‘positive and negative IL-2 regulator’ that are predominant in the biomedical language domain.","We also propose in this work an extension of the feature space in terms of lexico-semantic features (see Table 1), information that originates from similarity computations on WORDNET data. Further-more, we do not use orthographical features of the original approach as they are well suited only for the biomedical language domain."]},{"title":"4 Results and Error Analysis","paragraphs":["To evaluate the different approaches to conjunct identification, we used recall and precision scores since they are well suited for the evaluation of segmentation tasks. Two types of decisions were evaluated – the assignment of ‘C’ labels denoting conjuncts in terms of the F-measure, and (given the tagged conjuncts) the accuracy of the complete coordination resolution. A coordination is resolved properly only, if all tokens of both conjuncts are correctly identified.","We carried out a ten-fold cross-validation of all ML-based methods (Bikel parser (Bikel, 2004) and CRF-based conjunct identification (Buyko et al., 2007)). For the evaluation of the NA and WN baselines, we tested their performance on the complete data sets, A and B (see Section 2).","As Table 2 depicts the NA baseline achieved an accuracy of 28.4% on A (36.6% on B), the Bikel parser reached 77.2% on A (73.4% in B), while the WN baseline got in its best run (vector measure) an accuracy of 41.7% on A (49.6% on B). These results already reveal that parsing almost dramatically outperforms the coordination resolution based on the NA similarity by up to 35.5% points. The results of the WN baseline indicate that the best similarity measure for conjunct identification is the vector similarity (Patwardhan et al., 2003) that scores the similarity between the glosses of the concepts.","Our error analysis of the WN baseline on the test set A reveals that its low accuracy has various reasons. First, about 37% of the coordinations could not be resolved due to the absence of at least one noun involved in the coordination from the WORDNET. These coordinations usually include named entities such as person and organization names (e.g., ‘brothers Francis and Gilbert Gros’). These coverage gaps have clearly a negative effect on the resolution results for all WORDNET similarity measures.","To find out errors which are specific for the considered similarity measures, we have chosen the res measure and inspected the analysis results on all noun phrases where nouns are covered by WORDNET. The remaining set of coordinations contains 1,740 noun phrases. 1,022 coordinations (59%) of this set were completely resolved by the WN baseline, while 1,117 coordinations (64% of the remaining part, 41.5% of the test set A) could be at least partly resolved. Obviously, the coordinated heads are properly detected by the res measure but our heuristics for tagging the remaining modifiers (see Subsection 3.1.3) fail to provide the correct conjunct boundaries.","623 coordinations (36%) were mis-classified by the res measure. A closer look at this data reveals two types of errors. The first and minor type is the misleading selection of putatively coordinated heads N1, N2, and N3. We presuppose in the WN baseline that the heads appear right-most in the noun phrase, although that