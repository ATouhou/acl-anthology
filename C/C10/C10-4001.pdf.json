{"sections":[{"title":"","paragraphs":["Coling 2008: Paraphrases and Applications–Tutorial notes, pages 1–87, Beijing, August 2010"]},{"title":"Paraphrases and Applications","paragraphs":["Shiqi Zhao Baidu, Inc. Haifeng Wang Baidu, Inc."]},{"title":"Outline • Part I – Introduction– Introduction –","paragraphs":["Paraphrase Identification"]},{"title":"–","paragraphs":["Paraphrase Extraction"]},{"title":"• Part II –","paragraphs":["Paraphrase Generation"]},{"title":"–","paragraphs":["Applications of ParaphrasesApplications of Paraphrases"]},{"title":"–","paragraphs":["Evaluation of Paraphrases"]},{"title":"–","paragraphs":["Conclusions and Future work 1"]},{"title":"• Paraphrase –","paragraphs":["Noun"]},{"title":"Definition –","paragraphs":["Noun"]},{"title":"•","paragraphs":["Alternative expressions of the same meaning"]},{"title":"–","paragraphs":["Verb"]},{"title":"•","paragraphs":["Generate paraphrases for the input expression"]},{"title":"• “same meaning”? –","paragraphs":["Quite subjective"]},{"title":"–","paragraphs":["Different degrees of strictness"]},{"title":"–","paragraphs":["Depend on applications Paraphrase (noun): Alternative expressions of the same meaning Korean Kim Yuna won gold with a world-record score in women's figure skating at the Vancouver Olympics Thursday. Korean figure skater Kim Yuna has won the gold medal of women’s figure skating at the Winter Olympics in Vancouver Kim Yu-Na (19) is a South Korean ice skater who took the gold medal at the Vancouver Olympics. Kim Yuna, a South Korean figure skater has won the gold medal at the on-going Winter Olympics 2010. Yuna Kim of South Korea won the women's figure skating gold medal at the Vancouver Olympics in record fashion. 2 Paraphrase (verb): Generate paraphrases for an input S. Automatic S paraphrase generation T1 T2 T3 T4"]},{"title":"Classification of Paraphrases • According to granularity –","paragraphs":["Surface paraphrases"]},{"title":"–","paragraphs":["Surface paraphrases"]},{"title":"•","paragraphs":["Lexical level"]},{"title":"•","paragraphs":["Phrase level"]},{"title":"•","paragraphs":["Sentence level"]},{"title":"•","paragraphs":["Discourse level"]},{"title":"–","paragraphs":["Structural paraphrases"]},{"title":"•","paragraphs":["Pattern level"]},{"title":"•","paragraphs":["Pattern level"]},{"title":"•","paragraphs":["Collocation level 3"]},{"title":"Examples","paragraphs":["• Lexical paraphrases (generally synonyms) – solve and resolve","• Paraphrase phrases – look after and take care of","• Paraphrase sentences – The table was set up in the carriage shed. – The table was laid under the cart-shed.","• Paraphrase patterns [X] considers [Y]– [X] considers [Y] – [X] takes [Y] into consideration","• Paraphrase collocations – (turn on, OBJ, light) – (switch on, OBJ, light)"]},{"title":"• According to paraphrase style –","paragraphs":["Trivial change"]},{"title":"Classification of Paraphrases –","paragraphs":["Trivial change"]},{"title":"–","paragraphs":["Phrase replacement"]},{"title":"–","paragraphs":["Phrase reordering"]},{"title":"–","paragraphs":["Sentence split & merge"]},{"title":"–","paragraphs":["Complex paraphrases 4"]},{"title":"Examples","paragraphs":["• Trivial change – all the members of and all members of","• Phrase replacement – He said there will be major cuts in the salaries of high-level civil servants. – He said there will be major cuts in the salaries of senior officials.","• Phrase reordering – Last night, I saw Tom in the shopping mall. – I saw Tom in the shopping mall last night.","• Sentence split & mergeSentence split & merge – He bought a computer, which is very expensive. – (1) He bought a computer. (2) The computer is very expensive.","• Complex paraphrases – He said there will be major cuts in the salaries of high-level civil servants. – He claimed to implement huge salary cut to senior civil servants."]},{"title":"Applications of Paraphrases •","paragraphs":["Machine Translation (MT)"]},{"title":"–","paragraphs":["Simplify input sentences"]},{"title":"•","paragraphs":["Summarization"]},{"title":"–","paragraphs":["Sentence clustering"]},{"title":"–","paragraphs":["Alleviate data sparseness"]},{"title":"–","paragraphs":["Parameter tuning"]},{"title":"–","paragraphs":["Automatic evaluation"]},{"title":"•","paragraphs":["Question Answering (QA)"]},{"title":"–","paragraphs":["Question reformulation"]},{"title":"•","paragraphs":["Information Extraction (IE)"]},{"title":"–","paragraphs":["IE pattern expansion"]},{"title":"–","paragraphs":["Automatic evaluation"]},{"title":"•","paragraphs":["Natural Language Generation (NLG)"]},{"title":"–","paragraphs":["Sentence rewriting"]},{"title":"•","paragraphs":["Others"]},{"title":"–","paragraphs":["Changing writing style"]},{"title":"–","paragraphs":["Text simplificationIE pattern expansion"]},{"title":"•","paragraphs":["Information Retrieval (IR)"]},{"title":"–","paragraphs":["Query reformulation p"]},{"title":"–","paragraphs":["Identifying plagiarism"]},{"title":"–","paragraphs":["Text steganography"]},{"title":"–","paragraphs":["...... 5"]},{"title":"Research on Paraphrasing • Paraphrase identification –","paragraphs":["Identify (sentential) paraphrases"]},{"title":"–","paragraphs":["Identify (sentential) paraphrases"]},{"title":"• Paraphrase extraction –","paragraphs":["Extract paraphrase instances (different granularities)"]},{"title":"• Paraphrase generation –","paragraphs":["Generate (sentential) paraphrases"]},{"title":"• Ph liti• Paraphrase applications –","paragraphs":["Apply paraphrases in other areas"]},{"title":"Textual Entailment – A Similar Direction • Textual entailment: –","paragraphs":["A directional relation between two text fragments"]},{"title":"–","paragraphs":["A directional relation between two text fragments"]},{"title":"• T","paragraphs":[": the entailing text"]},{"title":"• H","paragraphs":[": the entailed hypothesis"]},{"title":"– T","paragraphs":["entails H if, typically, a human reading T would infer that H is most likely true."]},{"title":"–","paragraphs":["Compare entailment with paraphrase"]},{"title":"•","paragraphs":["P h i bidi i l il"]},{"title":"•","paragraphs":["Paraphrase is bidirectional entailment 6"]},{"title":"Text Entailment – A Similar Direction • Recognizing Textual Entailment Track (RTE) –","paragraphs":["RTE 1 (2004) to RTE 5 (2009)"]},{"title":"–","paragraphs":["RTE-1 (2004) to RTE-5 (2009)"]},{"title":"–","paragraphs":["RTE-6 (2010) is in progress"]},{"title":"• Example: – T:","paragraphs":["A shootout at the Guadalajara airport in May, 1993, killed Cardinal Juan Jesus Posadas Ocampo."]},{"title":"– H:","paragraphs":["Juan Jesus Posadas Ocampo died in 1993H: Juan Jesus Posadas Ocampo died in 1993."]},{"title":"Outline • Part I –","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Introduction"]},{"title":"– Paraphrase Identification –","paragraphs":["Paraphrase Extraction"]},{"title":"• Part II –","paragraphs":["Paraphrase Generation"]},{"title":"–","paragraphs":["Applications of ParaphrasesApplications of Paraphrases"]},{"title":"–","paragraphs":["Evaluation of Paraphrases"]},{"title":"–","paragraphs":["Conclusions and Future work 7"]},{"title":"Paraphrase Identification • Specially refers to sentential paraphrase identificationidentification –","paragraphs":["Given any pair of sentences, automatically identifies whether these two sentences are paraphrases"]},{"title":"• Paraphrase identification is not trivial Susan often goes to see movies with her boyfriend.Susan often goes to see movies with her boyfriend. Susan never goes to see movies with her boyfriend. He said there will be major cuts in the salaries of high-level civil servants. He claimed to implement huge salary cut to senior civil servants. Overview • Classification based methods –","paragraphs":["Reviewed as a binary classification problem i e"]},{"title":"–","paragraphs":["Reviewed as a binary classification problem, i.e., input s1 and s2 to a classifier and output 0/1"]},{"title":"–","paragraphs":["Compute the similarities between s1 and s2 at different levels, which are then used as classification features"]},{"title":"• Alignment based methods –","paragraphs":["Align s1 and s2 first, and score the sentence pair g ,p based on the alignment results"]},{"title":"•","paragraphs":["Alignment based on ITG"]},{"title":"•","paragraphs":["Alignment based on quasi-synchronous dependency grammars 8"]},{"title":"Classification based Methods • Brockett and Dolan, 2005 –","paragraphs":["Features:"]},{"title":"–","paragraphs":["Features:"]},{"title":"•","paragraphs":["String similarity features"]},{"title":"–","paragraphs":["Sentence length, word overlap, edit distance, ..."]},{"title":"•","paragraphs":["Morphological variants"]},{"title":"–","paragraphs":["Word pairs with the same stem"]},{"title":"•","paragraphs":["WordNet lexical mappings"]},{"title":"–","paragraphs":["Synonym pairs / word-hypernym pairs from WordNet orbit | orbital operation | procedure"]},{"title":"•","paragraphs":["Word association pairs"]},{"title":"–","paragraphs":["Automatically learned synonym pairs"]},{"title":"–","paragraphs":["Classifier"]},{"title":"•","paragraphs":["SVM classifier vendors | suppliers"]},{"title":"Classification based Methods (cont’) • Finch et al., 2005 –","paragraphs":["Using MT evaluation techniques to compute sentence"]},{"title":"–","paragraphs":["Using MT evaluation techniques to compute sentence similarities, which are then used as classification features"]},{"title":"•","paragraphs":["WER, PER, BLEU, NIST"]},{"title":"•","paragraphs":["Feature vector vec(s1, s2)"]},{"title":"–","paragraphs":["vec1(s1, s2): s1 as reference, s2 as MT system output;"]},{"title":"–","paragraphs":["vec2(s1, s2): s2 as reference, s1 as MT system output;( , ) , yp;"]},{"title":"–","paragraphs":["vec(s1, s2): average of vec1(s1, s2) and vec2(s1, s2):"]},{"title":"–","paragraphs":["Classifier"]},{"title":"•","paragraphs":["SVM classifier 9"]},{"title":"Classification based Methods (cont’) • Malakasiotis, 2009 –","paragraphs":["Combining multiple classification features"]},{"title":"–","paragraphs":["Combining multiple classification features"]},{"title":"•","paragraphs":["String similarity (various levels)"]},{"title":"–","paragraphs":["Tokens, stems, POS tags, nouns only, verbs only, ..."]},{"title":"•","paragraphs":["Different measures"]},{"title":"–","paragraphs":["Edit distance, Jaro-Winkler distance, Manhattan distance..."]},{"title":"•","paragraphs":["Synonym similarity"]},{"title":"–","paragraphs":["Treat synonyms in two sentences as identical words"]},{"title":"•","paragraphs":["Syntax similarity"]},{"title":"–","paragraphs":["Dependency parsing of two sentences and compute the overlap of dependencies"]},{"title":"–","paragraphs":["Classifier"]},{"title":"•","paragraphs":["Maximum Entropy classifier"]},{"title":"Alignment based Methods • Wu, 2005 –","paragraphs":["Conduct alignment based on Inversion Transduction"]},{"title":"–","paragraphs":["Conduct alignment based on Inversion Transduction Grammars (ITG)"]},{"title":"•","paragraphs":["Sensitive to the differences in sentence structures"]},{"title":"•","paragraphs":["Without using any thesaurus to deal with lexical variation"]},{"title":"–","paragraphs":["Performance is comparable to the classification based methods Al f ll i i i t t l t il t"]},{"title":"–","paragraphs":["Also performs well in recognizing textual entailment 10"]},{"title":"Alignment based Methods (cont’) • Das and Smith, 2009 –","paragraphs":["Conduct alignment based on Quasi-SynchronousConduct alignment based on Quasi Synchronous Dependency Grammar (QG)"]},{"title":"•","paragraphs":["Alignment between two dependency trees"]},{"title":"•","paragraphs":["Assumption: the dependency trees of two paraphrase sentences should be aligned closely"]},{"title":"–","paragraphs":["Why does it work? About 120 potential jurors were being asked to complete a lengthy questionnaire . Align words that are not identical"]},{"title":"–","paragraphs":["Performs competitively with classification based methods The jurors were taken into the courtroom in groups of 40 and asked to fill out a questionnaire ."]},{"title":"A Summary • Classification based method is still the mainstream method since:mainstream method, since: –","paragraphs":["Binary classification problem is well defined;"]},{"title":"–","paragraphs":["Classification algorithms and tools are readily available;"]},{"title":"–","paragraphs":["It can combine various features in a simple way;"]},{"title":"–","paragraphs":["It achieves state-of-the-art performance.p 11"]},{"title":"References •","paragraphs":["Brockett and Dolan. 2005. Support Vector Machines for Paraphrase Identification and Corpus Construction."]},{"title":"•","paragraphs":["Fi h t l 2005 U i M hi T l ti E l ti T h i t"]},{"title":"•","paragraphs":["Finch et al. 2005. Using Machine Translation Evaluation Techniques to Determine Sentence-level Semantic Equivalence."]},{"title":"•","paragraphs":["Wu. 2005. Recognizing Paraphrases and Textual Entailment using Inversion Transduction Grammars."]},{"title":"•","paragraphs":["Malakasiotis. 2009. Paraphrase Recognition Using Machine Learning to Combine Similarity Measures."]},{"title":"•","paragraphs":["Das and Smith. 2009. Paraphrase Identification as Probabilistic Quasi-Synchronous Recognition.yg"]},{"title":"Outline • Part I –","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Paraphrase Identification"]},{"title":"– Paraphrase Extraction • Part II –","paragraphs":["Paraphrase Generation"]},{"title":"–","paragraphs":["Applications of ParaphrasesApplications of Paraphrases"]},{"title":"–","paragraphs":["Evaluation of Paraphrases"]},{"title":"–","paragraphs":["Conclusions and Future work 12 Corpora Assumption Algorithm"]},{"title":"Three Elements for Paraphrase Extraction","paragraphs":["• thesauri • monolingual parallel corpora • monolingual comparable corpora • bilingual parallel • Different translation versions preserve the meaning of the original source • Comparable news articles may contain distinct descriptions • co-training • classification • logistic regression • clustering • word alignment •...... corpora • large web corpora • search engine query logs • dictionary glosses •...... of the same facts • Multiple phrases that align with the same foreign phrase may have the same meaning • Distributional hypothesis •......"]},{"title":"Outline • Part I –","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Paraphrase Identification"]},{"title":"– Paraphrase Extraction • From Thesauri •","paragraphs":["From Monolingual Parallel Corpora"]},{"title":"•","paragraphs":["From Monolingual Comparable Corpora"]},{"title":"•","paragraphs":["F Bili l P ll l C"]},{"title":"•","paragraphs":["From Bilingual Parallel Corpora"]},{"title":"•","paragraphs":["From Large Web Corpora"]},{"title":"•","paragraphs":["From Other Resources 13"]},{"title":"Method Overview • Extract words with specific semantic relations as paraphrasesparaphrases –","paragraphs":["Most common: synonyms"]},{"title":"–","paragraphs":["Other relations: hypernyms, hyponyms..."]},{"title":"• Widely used thesauri –","paragraphs":["In English"]},{"title":"•","paragraphs":["WordNetWordNet"]},{"title":"–","paragraphs":["In other languages"]},{"title":"•","paragraphs":["E.g., HowNet, Tongyici Cilin in Chinese"]},{"title":"Pros and Cons • Pros –","paragraphs":["Existing resources"]},{"title":"–","paragraphs":["Existing resources"]},{"title":"–","paragraphs":["High quality"]},{"title":"•","paragraphs":["Thesauri are hand crafted"]},{"title":"• Cons –","paragraphs":["Language limitation"]},{"title":"•","paragraphs":["Thesauri are not available in many languagesygg"]},{"title":"–","paragraphs":["Difficult to update 14"]},{"title":"Outline • Part I –","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Paraphrase Identification"]},{"title":"– Paraphrase Extraction •","paragraphs":["From Thesauri"]},{"title":"• From Monolingual Parallel Corpora •","paragraphs":["From Monolingual Comparable Corpora"]},{"title":"•","paragraphs":["F Bili l P ll l C"]},{"title":"•","paragraphs":["From Bilingual Parallel Corpora"]},{"title":"•","paragraphs":["From Large Web Corpora"]},{"title":"•","paragraphs":["From Other Resources"]},{"title":"Method Overview • Corpus –","paragraphs":["Multiple translations of the same foreign literary work"]},{"title":"–","paragraphs":["Multiple translations of the same foreign literary work"]},{"title":"• Assumption –","paragraphs":["Different translation versions preserve the meaning of the original source, but may use different expressions 15 Vingt mille lieues sous les mers (in French)"]},{"title":"Example 20000 Leagues Under the Sea (different English translation versions) ...... Sentence Alignment and Preprocessing • Barzilay and McKeown, 2001 –","paragraphs":["Collected 11 English translations for 5 foreign novels"]},{"title":"–","paragraphs":["Collected 11 English translations for 5 foreign novels"]},{"title":"•","paragraphs":["E.g., Madame Bovary, Fairy Tale, Twenty Thousand Leagues under the sea..."]},{"title":"–","paragraphs":["Sentence alignment"]},{"title":"•","paragraphs":["A dynamic programming algorithm"]},{"title":"•","paragraphs":["Produced 44,562 pairs of parallel sentences"]},{"title":"•","paragraphs":["Precision is 94 5%Precision is 94.5%"]},{"title":"–","paragraphs":["Other preprocessing"]},{"title":"•","paragraphs":["POS tagging and chunking"]},{"title":"•","paragraphs":["Phrases are the atomic units in paraphrase extraction 16"]},{"title":"Paraphrase Phrase Extraction • Barzilay and McKeown, 2001 (cont’) –","paragraphs":["Extracting paraphrase phrases"]},{"title":"–","paragraphs":["Extracting paraphrase phrases"]},{"title":"•","paragraphs":["Assumption: phrases in aligned sentences which appear in similar contexts are paraphrases"]},{"title":"•","paragraphs":["Method: co-training"]},{"title":"–","paragraphs":["Iteratively learn contexts and paraphrases Left context right contextparaphrases My imagination melted into hazy drowsiness , and I soon fell into an uneasy slumber . My imagination wandered into vague unconsciousness , and I soon fell into a deep sleep ."]},{"title":"Pros and Cons • Pros –Easy to align monolingual parallel sentences–Easy to align monolingual parallel sentences • Cons –Domain limitation •","paragraphs":["Limited in literary works"]},{"title":"–Scale limitation •","paragraphs":["Th i f th i l ti l ll"]},{"title":"•","paragraphs":["The size of the corpus is relatively small"]},{"title":"–Context dependence •","paragraphs":["E.g., “John said” and “he said” 17"]},{"title":"Outline • Part I –","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Paraphrase Identification"]},{"title":"– Paraphrase Extraction •","paragraphs":["From Thesauri"]},{"title":"•","paragraphs":["From Monolingual Parallel Corpora"]},{"title":"• From Monolingual Comparable Corpora •","paragraphs":["F Bili l P ll l C"]},{"title":"•","paragraphs":["From Bilingual Parallel Corpora"]},{"title":"•","paragraphs":["From Large Web Corpora"]},{"title":"•","paragraphs":["From Other Resources"]},{"title":"Method Overview • Corpus –","paragraphs":["News articles that report the same event within a brief"]},{"title":"–","paragraphs":["News articles that report the same event within a brief period of time"]},{"title":"•","paragraphs":["Produced by different news agencies"]},{"title":"• Assumption –","paragraphs":["Comparable news articles may contain distinct descriptions of the same facts 18"]},{"title":"Example Comparable documents d1 d2 Procedure News corpus Paraphrase phrases Paraphrase patterns Paraphrase generation Identify comparable documents corpus Extract paraphrase phrases Extract paraphrase patterns MT-based paraphrase generation phrases patterns model Extract parallel sentences Comparable documents Parallel corpus","paragraphs":["19"]},{"title":"Identify Comparable Documents • Input –","paragraphs":["News articles from different news agencies"]},{"title":"–","paragraphs":["News articles from different news agencies"]},{"title":"•","paragraphs":["E.g., CNN, New York Times, Washington Post..."]},{"title":"• Processing –","paragraphs":["Method-1: Retrieve documents on a given topic or event"]},{"title":"•","paragraphs":["Needs predefined topics or events"]},{"title":"–","paragraphs":["Method-2: Cluster documents"]},{"title":"•","paragraphs":["Content similarity; time interval"]},{"title":"• Output –","paragraphs":["Corpus of comparable documents"]},{"title":"Extract Parallel (Paraphrase) Sentences • Input –","paragraphs":["Corpus of comparable documents"]},{"title":"–","paragraphs":["Corpus of comparable documents"]},{"title":"• Processing –","paragraphs":["Sentence clustering"]},{"title":"•","paragraphs":["Method-1: based on an assumption: first sentences of a news article usually summarize its content"]},{"title":"•","paragraphs":["Method-2: based on computing the content similarity"]},{"title":"• Output –","paragraphs":["Corpus of parallel (paraphrase) sentences 20"]},{"title":"Extract Paraphrase Patterns •","paragraphs":["Using NEs as anchors"]},{"title":"–","paragraphs":["Shinyama et al., 2002y,"]},{"title":"–","paragraphs":["Basic idea: paraphrase sentences should contain comparable NEs Comparable NEs Slots of the same type paraphrases"]},{"title":"Extract Paraphrase Patterns •","paragraphs":["Multiple-sequence alignment"]},{"title":"–","paragraphs":["Barzilay and Lee, 2003y, backbone slot 21"]},{"title":"Pros and Cons • Pros –","paragraphs":["Language independent"]},{"title":"–","paragraphs":["Language-independent"]},{"title":"•","paragraphs":["Comparable news can be found in many languages"]},{"title":"• Cons –","paragraphs":["Domain-dependent"]},{"title":"•","paragraphs":["Paraphrases are extracted from specific domains or topics"]},{"title":"–","paragraphs":["Sentence clusteringg"]},{"title":"•","paragraphs":["Either too strict or too loose"]},{"title":"Outline • Part I –","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Paraphrase Identification"]},{"title":"– Paraphrase Extraction •","paragraphs":["From Thesauri"]},{"title":"•","paragraphs":["From Monolingual Parallel Corpora"]},{"title":"•","paragraphs":["From Monolingual Comparable Corpora"]},{"title":"• F Bili l P ll l C• From Bilingual Parallel Corpora •","paragraphs":["From Large Web Corpora"]},{"title":"•","paragraphs":["From Other Resources 22"]},{"title":"Method Overview • Corpus –","paragraphs":["A parallel corpus of the source language and a"]},{"title":"–","paragraphs":["A parallel corpus of the source language and a foreign language"]},{"title":"• Assumption –","paragraphs":["Multiple phrases that align with the same foreign phrase may have the same meaning"]},{"title":"• The method is also termed as “pivot approach”The method is also termed as pivot approach Example source language foreign language (pivot language)(pivot language) Alignment ...... different parts ...... different places ......","paragraphs":["不同 地方 ...... 不同 地区 ei ej cm cn ...... various locations ...... ...... ek 23"]},{"title":"A Simple Version • Takao et al., 2002 –","paragraphs":["Basic idea:"]},{"title":"–","paragraphs":["Basic idea:"]},{"title":"•","paragraphs":["Generating lexical paraphrases using 2-way dictionaries"]},{"title":"•","paragraphs":["English word e1 can be translated to a Japanese word j with an E-J dic. D1, and then j can be translated back to an English word e2 with a J-E dictionary D2. e1 and e2 are extracted as paraphrases"]},{"title":"Extracting Paraphrase Phrases • Bannard and Callison-Burch, 2005 –","paragraphs":["Word alignment and phrase extraction"]},{"title":"–","paragraphs":["Word alignment and phrase extraction"]},{"title":"–","paragraphs":["Basic assumption:"]},{"title":"•","paragraphs":["If two English phrases e1 and e2 can be aligned with the same foreign phrase f, e1 and e2 are likely to be paraphrases."]},{"title":"–","paragraphs":["Paraphrase probability:","21221̂arg max ( | )eeepee≠= Pivot in a foreign language21 21 12arg max ( | ) ( | ) ee","ee f p fepe f ≠ ≠="]},{"title":"∑ Translation probability language","paragraphs":["24 ...should take the matter into consideration... ...应当考虑这种情况... take the matter into consideration Bannard & Callison-Burch (2005) ’s results: ...must take the matter into account... ...必须考虑这种情况... The consideration of this matter will... 考虑这种情况会... take the matter into account take the matter into consideration the consideration of this matter the consideration of this mattertake the matter into account He’ll take the matter into consideration 他将考虑这一问题 We need to consider this matter 大家需要考虑这一问题 consider this mattertake the matter into consideration"]},{"title":"Add Syntactic Constraints • Callison-Burch, 2008 –","paragraphs":["Basic idea:Basic idea:"]},{"title":"•","paragraphs":["Two paraphrase phrases should have the same syntactic type."]},{"title":"–","paragraphs":["Paraphrase probability: 22 1 2 12211 :()()̂arg max ( | , ( )) arg max ( | ( )) ( | ( )) ee e se seepeese pf ese pe fse ≠∧ = = ="]},{"title":"∑ given the syntactic type –","paragraphs":["Syntactic constraints are also used when substituting paraphrases in sentences 22 1 2 1 11 2 1 :()()arg max ( | , ())( | , ()) ee e se se f pf ese pe fse ≠∧ =="]},{"title":"∑","paragraphs":["25 ...should take the matter into consideration... ...应当考虑这种情况... take the matter into consideration take the matter into account Callison-Burch (2008) ’s results: ...must take the matter into account... ...必须考虑这种情况... The consideration of this matter will... 考虑这种情况会... take the matter into account take the matter into consideration the consideration of this matter the consideration of this mattertake the matter into account He’ll take the matter into consideration 他将考虑这一问题 We need to consider this matter 大家需要考虑这一问题 consider this mattertake the matter into consideration"]},{"title":"Learning Paraphrases from Graphs • Kok and Brockett, 2010 –","paragraphs":["Basic idea:"]},{"title":"–","paragraphs":["Basic idea:"]},{"title":"•","paragraphs":["Convert aligned phrases into a graph, extract paraphrases based on random walks and hitting times 26 ...should take the matter into consideration... ...应当考虑这种情况... take the matter into consideration Kok and Brockett (2010) ’s results: ...must take the matter into account... ...必须考虑这种情况... The consideration of this matter will... 考虑这种情况会... take the matter into account consider this mattertake the matter into account He’ll take the matter into consideration 他将考虑这一问题 We need to consider this matter 大家需要考虑这一问题 consider this mattertake the matter into consideration"]},{"title":"Extracting Paraphrase Patterns • Zhao et al., 2008 –","paragraphs":["Basic idea:"]},{"title":"–","paragraphs":["Basic idea:"]},{"title":"•","paragraphs":["Generate paraphrase patterns that include part-of-speech slots."]},{"title":"–","paragraphs":["Paraphrase probability: 21 12","1( | ) exp[ ( , , )]N","ii","ciscore e e h e e cλ =="]},{"title":"∑∑","paragraphs":["112 1 212 2 312 1 412 2 (, ,) (| ) (, ,) ( |) (, ,) (| ) (, ,) ( |) MLE MLE LW LW hee c score ce heec score e c heec score ce heec score e c = = = = Based on maximum likelihood estimation Based on lexical weighting 27 take demand into take market demand into consideration Inducing English patterns Inducing Chinese patterns Example demand market into consideration take into considerationNN NN take into considerationNN × 考虑 市场 需求 take NN into consideration 考虑 × × NN consider NN×NN 考虑 × NN Extract paraphrase patterns take NN into consideration & consider NN ...should take the matter into consideration... ...应当考虑这种情况... take [NN] into consideration take [NN] into account Zhao et al (2008) ’s results: ...must take the matter into account... ...必须考虑这种情况... The consideration of this matter will... 考虑这种情况会... H ’ll t k th tt i t id ti take [NN] into consideration the consideration of [NN] the consideration of [NN]take [NN] into account He’ll take the matter into consideration 他将考虑这一问题 We need to consider this matter 大家需要考虑这一问题 consider [NN]take [NN] into consideration 28"]},{"title":"Pros and Cons • Pros –","paragraphs":["The method proves effective hence it’s widely used"]},{"title":"–","paragraphs":["The method proves effective, hence it s widely used"]},{"title":"•","paragraphs":["High precision"]},{"title":"•","paragraphs":["Large scale"]},{"title":"• Cons –","paragraphs":["Language limitation"]},{"title":"•","paragraphs":["Cannot work where the large-scale bilingual parallel corpora are not available"]},{"title":"Outline • Part I –","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Paraphrase Identification"]},{"title":"– Paraphrase Extraction •","paragraphs":["From Thesauri"]},{"title":"•","paragraphs":["From Monolingual Parallel Corpora"]},{"title":"•","paragraphs":["From Monolingual Comparable Corpora"]},{"title":"•","paragraphs":["F Bili l P ll l C"]},{"title":"•","paragraphs":["From Bilingual Parallel Corpora"]},{"title":"• From Large Web Corpora •","paragraphs":["From Other Resources 29"]},{"title":"Method Overview • Corpus –","paragraphs":["Large corpus of web documents"]},{"title":"–","paragraphs":["Large corpus of web documents"]},{"title":"–","paragraphs":["Or directly based on web mining"]},{"title":"• Assumption –","paragraphs":["Distributional hypothesis"]},{"title":"•","paragraphs":["If two words / phrases / patterns often occur in similar contexts, their meanings tend to be similar"]},{"title":"Example Shakespeare Chekhov Merchant of Venice War and Peace X wrote Y Maupassant Hugo Gorky Tagore Murakami Tolstoy Yasunari Notre Dame de Paris War and Peace Romeo and Juliet Madame Bovary Madame Bovary similar similarparaphrases X is the author of Y Shakespeare Maupassant Hugo Gorky Hemingway Balzac Merchant of Venice Notre Dame de Paris The Old Man and Sea Romeo and Juliet","paragraphs":["30"]},{"title":"Extracting Lexical Paraphrases (Word Clustering) • Lin, 1998 –","paragraphs":["Basic idea"]},{"title":"–","paragraphs":["Basic idea"]},{"title":"•","paragraphs":["Measure words’ similarity based on the distributional pattern of words"]},{"title":"–","paragraphs":["Corpus"]},{"title":"•","paragraphs":["A (dependency) parsed corpus"]},{"title":"–","paragraphs":["Word similarity Mutual information 12 12 12(, ) ( ) ( ) 12 12(, ) ( ) (, ) ( ) (( ,, ) ( ,, )) (, ) (,,) ( ,,) rr rr rw T w T w rw T w rw T w Iw rw Iw rw sim w w Iw rw Iw rw ∈∩ ∈∈ + = +"]},{"title":"∑ ∑∑ Extracting Syntactic Paraphrase Patterns •","paragraphs":["Lin and Pantel, 2001"]},{"title":"–","paragraphs":["Basic idea: extended distributional hypothesisyp"]},{"title":"–","paragraphs":["Corpus: a large corpus of parsed monolingual sentences"]},{"title":"–","paragraphs":["pattern pairs X solves Y X finds solution toa"]},{"title":"–","paragraphs":["Pattern similarity 12 1 2 1 2(, ) ( , ) ( , )sim p p sim SlotX SlotX sim SlotY SlotY=× Y Similarity of the slot fillers 31"]},{"title":"Extracting Surface Paraphrases • Bhagat and Ravichandran, 2008 –","paragraphs":["Basic idea is the same as the above work"]},{"title":"–","paragraphs":["Basic idea is the same as the above work"]},{"title":"–","paragraphs":["Corpus:"]},{"title":"•","paragraphs":["a large corpus of monolingual sentences without parsing"]},{"title":"–","paragraphs":["150GB, 25 billion words"]},{"title":"–","paragraphs":["Surface paraphrases"]},{"title":"•","paragraphs":["Pairs of n-grams Eg “X acquired Y” and “X completed the acquisition of Y”"]},{"title":"–","paragraphs":["E.g., X acquired Y” and X completed the acquisition of Y”"]},{"title":"–","paragraphs":["Techniques"]},{"title":"•","paragraphs":["Apply locality sensitive hashing (LSH) to speed up the computation"]},{"title":"Learning Unary Paraphrase Patterns • Szpector and Dagan, 2008 –","paragraphs":["Binary paraphrase patterns (most of the previous work)"]},{"title":"–","paragraphs":["Binary paraphrase patterns (most of the previous work)"]},{"title":"•","paragraphs":["Each pattern has two slots at both ends"]},{"title":"–","paragraphs":["E.g., “X solves Y” and “X found a solution to Y”"]},{"title":"–","paragraphs":["Unary paraphrase patterns"]},{"title":"•","paragraphs":["Each pattern has a single slot"]},{"title":"–","paragraphs":["E.g., “X take a nap” and “X sleep”"]},{"title":"–","paragraphs":["Method sleep kids in room"]},{"title":"–","paragraphs":["Method"]},{"title":"•","paragraphs":["The same with the above works"]},{"title":"–","paragraphs":["Based on distributional hypothesis room the X sleep 32"]},{"title":"Extracting Paraphrases based on Web Mining • Ravichandran and Hovy, 2002 –","paragraphs":["Basic idea"]},{"title":"•","paragraphs":["Learn paraphrase patterns with search engines"]},{"title":"–","paragraphs":["Corpus"]},{"title":"•","paragraphs":["The whole internet"]},{"title":"–","paragraphs":["Method"]},{"title":"•","paragraphs":["Extract paraphrase patterns for each type, e.g., “BIRTHDAY”"]},{"title":"•","paragraphs":["Provide hand-crafted seeds, e.g., “Mozart, 1756”"]},{"title":"•","paragraphs":["Retrieve sentences containing the seeds from the web with a g search engine"]},{"title":"•","paragraphs":["Extract patterns, e.g.,"]},{"title":"–","paragraphs":["born in <ANSWER> , <NAME>"]},{"title":"–","paragraphs":["<NAME> was born on <ANSWER> ,"]},{"title":"–","paragraphs":["......"]},{"title":"Pros and Cons • Pros –","paragraphs":["Language independent"]},{"title":"–","paragraphs":["Language independent"]},{"title":"• Cons –","paragraphs":["For methods based on large web corpora"]},{"title":"•","paragraphs":["Computation complexity is high"]},{"title":"–","paragraphs":["Needs to process an extremely large corpus"]},{"title":"–","paragraphs":["Needs to compute pairwise similarity for all candidates"]},{"title":"–","paragraphs":["For methods based on web mining"]},{"title":"•","paragraphs":["Extract paraphrase patterns type by type"]},{"title":"•","paragraphs":["Needs to prepare seeds beforehand 33"]},{"title":"Outline • Part I –","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Introduction"]},{"title":"–","paragraphs":["Paraphrase Identification"]},{"title":"– Paraphrase Extraction •","paragraphs":["From Thesauri"]},{"title":"•","paragraphs":["From Monolingual Parallel Corpora"]},{"title":"•","paragraphs":["From Monolingual Comparable Corpora"]},{"title":"•","paragraphs":["F Bili l P ll l C"]},{"title":"•","paragraphs":["From Bilingual Parallel Corpora"]},{"title":"•","paragraphs":["From Large Web Corpora"]},{"title":"• From Other Resources Paraphrasing with Search Engine Query Logs • Zhao et al., 2010 –","paragraphs":["Corpus"]},{"title":"–","paragraphs":["Corpus"]},{"title":"•","paragraphs":["Query logs (queries and titles) of a search engine"]},{"title":"–","paragraphs":["Assumption"]},{"title":"•","paragraphs":["If a query q hits a title t, then q and t are likely to be paraphrases"]},{"title":"•","paragraphs":["If queries q1 and q2 hit the same title t, then q1 and q2 are likely to be paraphrasesypp"]},{"title":"•","paragraphs":["If a query q hits titles t1 and t2, then t1 and t2 are likely to be paraphrases 34"]},{"title":"Example","paragraphs":["关于 草原 的 诗词 描写 草原 的 诗句 q1 t1 赞美大草原的诗q2 Paraphrases: <q1, t1> <q1, t2> <2t1> query-title 有关 草原 的 诗歌 ...... ...... t2 <q2, t1> <q1,q2> <t1,t2> query-query title-title"]},{"title":"Method •","paragraphs":["Step-1: extracting <q, t> paraphrases"]},{"title":"–","paragraphs":["Extracting candidate <q, t> pairs from query logsg q, pqyg"]},{"title":"–","paragraphs":["Paraphrase validation based on binary classification"]},{"title":"•","paragraphs":["Combining multiple features"]},{"title":"•","paragraphs":["Step-2: extracting <q, q> paraphrases"]},{"title":"–","paragraphs":["Extracting candidate <q, q> from <q, t> paraphrases"]},{"title":"–","paragraphs":["Paraphrase validation based on binary classification"]},{"title":"•","paragraphs":["Step-3: extracting <t, t> paraphrases Step 3 e t act g t, t pa ap ases"]},{"title":"–","paragraphs":["Extracting candidate <t, t> from <q, t> paraphrases"]},{"title":"–","paragraphs":["Paraphrase validation based on binary classification 35"]},{"title":"Pros and Cons • Pros –","paragraphs":["No scale limitation"]},{"title":"–","paragraphs":["No scale limitation"]},{"title":"•","paragraphs":["Query logs keep growing"]},{"title":"•","paragraphs":["A large volume of paraphrases can be extracted"]},{"title":"–","paragraphs":["Query logs reflect web users’ real needs"]},{"title":"• Cons –","paragraphs":["Query logs data are only available in IR companiesyg y p"]},{"title":"–","paragraphs":["User queries are noisy"]},{"title":"•","paragraphs":["Spelling mistakes, grammatical errors..."]},{"title":"Extracting Paraphrases from Dictionary Glosses • Corpus –","paragraphs":["Glosses of dictionaries"]},{"title":"–","paragraphs":["Glosses of dictionaries"]},{"title":"• Assumption –","paragraphs":["A word and its definition (gloss) in the dictionary have the same meaning 36"]},{"title":"Example (Encarta Dictionary) hurricane severe storm high wind fast and force person or thing Method • Prune and reformulate the definitions –","paragraphs":["For a verb v extracts the head of the definition (h)"]},{"title":"–","paragraphs":["For a verb v, extracts the head of the definition (h) and h’s adverb modifier m as v’s paraphrase"]},{"title":"•","paragraphs":["Kaji et al., 2002"]},{"title":"–","paragraphs":["Rule based method for extracting the appropriate part from the definition"]},{"title":"•","paragraphs":["Higashinaka and Nagao, 2002"]},{"title":"•","paragraphs":["Eg w should not be in def; ignore contents in parentheses"]},{"title":"•","paragraphs":["E.g., w should not be in def; ignore contents in parentheses in def; avoid double negation... 37"]},{"title":"Pros and Cons • Pros –","paragraphs":["Explain unfamiliar words with simpler definitions"]},{"title":"–","paragraphs":["Explain unfamiliar words with simpler definitions"]},{"title":"• Cons –","paragraphs":["Transformation of person, number, tense president head of company presidents heads of company head of companies E.g., presidents head of companies heads of companies"]},{"title":"References •","paragraphs":["From monolingual parallel corpora"]},{"title":"–","paragraphs":["Barzilay and McKeown. 2001. Extracting Paraphrases from a Parallel Corpus."]},{"title":"•","paragraphs":["From monolingual comparable corpora"]},{"title":"–","paragraphs":["Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo. 2002. Automatic Paraphrase Acquisition from News Articles."]},{"title":"–","paragraphs":["Regina Barzilay and Lillian Lee. 2003. Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment."]},{"title":"–","paragraphs":["Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised Construction of Large Paraphrase Corpora: Exploiting MassivelyConstruction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources. 38"]},{"title":"References (cont’) •","paragraphs":["From bilingual parallel corpora"]},{"title":"–","paragraphs":["Takao et al. 2002. Comparing and Extracting Paraphrasing Words with 2-Way Bilingual Dictionaries."]},{"title":"–","paragraphs":["Bannard and Callison-Burch. 2005. Paraphrasing with Bilingual Parallel Corpora."]},{"title":"–","paragraphs":["Callison-Burch. 2008. Syntactic Constraints on Paraphrases Extracted from Parallel Corpora."]},{"title":"–","paragraphs":["Kok and Brockett. 2010. Hitting the Right Paraphrases in Good Time."]},{"title":"–","paragraphs":["Zhao et al. 2008. Pivot Approach for Extracting Paraphrase Patterns from bilingual corporafrom bilingual corpora."]},{"title":"References (cont’) •","paragraphs":["From large web corpora"]},{"title":"–","paragraphs":["Lin. 1998. Automatic Retrieval and Clustering of Similar Words."]},{"title":"–","paragraphs":["Lin and Pantel. 2001. Discovery of Inference Rules for Question Answering."]},{"title":"–","paragraphs":["Bhagat and Ravichandran. 2008. Large Scale Acquisition of Paraphrases for Learning Surface Patterns."]},{"title":"–","paragraphs":["Szpector and Dagan. 2008. Learning Entailment Rules for Unary Templates."]},{"title":"–","paragraphs":["Ravichandran and Hovy. 2002. Learning Surface Text Patterns for a Question Answering SystemQuestion Answering System. 39"]},{"title":"References (cont’) •","paragraphs":["From other resources"]},{"title":"–","paragraphs":["Zhao et al. 2010. Paraphrasing with Search Engine Query Logs."]},{"title":"–","paragraphs":["Kaji et al. 2002. Verb Paraphrase based on Case Frame Alignment."]},{"title":"–","paragraphs":["Higashinaka and Nagao. 2002. Interactive Paraphrasing Based on Linguistic Annotation."]},{"title":"Cffee Beak!Coffee Break!","paragraphs":["40"]},{"title":"Outline • Part 2 – Paraphrase Generation– Paraphrase Generation • Rule based Method •","paragraphs":["Thesaurus based Method"]},{"title":"•","paragraphs":["NLG based Method"]},{"title":"•","paragraphs":["MT based Method"]},{"title":"•","paragraphs":["Pivot based Method"]},{"title":"–","paragraphs":["Applications of ParaphrasesApplications of Paraphrases"]},{"title":"–","paragraphs":["Evaluation of Paraphrases"]},{"title":"–","paragraphs":["Conclusions and Future work"]},{"title":"Rule based Method • Two types: –","paragraphs":["Based on hand crafted rules"]},{"title":"–","paragraphs":["Based on hand-crafted rules"]},{"title":"•","paragraphs":["Widely used in early studies of paraphrase generation"]},{"title":"•","paragraphs":["McKeown, 1979; Zong et al., 2001; Tetsuro et al., 2001; Zhang and Yamamoto, 2002......"]},{"title":"–","paragraphs":["Based on automatically extracted rules"]},{"title":"•","paragraphs":["Extract paraphrase patterns from corpora"]},{"title":"•","paragraphs":["Barzilay and Lee 2003 Zhao et al 2009Barzilay and Lee, 2003, Zhao et al., 2009...... 41"]},{"title":"Based on Hand-crafted Rules Sentence analysis - morphological - syntactic - semantic -... Rule matching & Paraphrase generation S T Paraphrase rule base Compile paraphrase rules •","paragraphs":["Examples of paraphrase rules"]},{"title":"–","paragraphs":["Change the positions of adverbials"]},{"title":"Based on Hand-crafted Rules","paragraphs":["Change the positions of adverbials"]},{"title":"•","paragraphs":["He booked a single room in Beijing yesterday. => – Yesterday, he booked a single room in Beijing."]},{"title":"–","paragraphs":["Split a compound sentence into a group of simple sentences"]},{"title":"•","paragraphs":["He booked a single room in Beijing yesterday => – He booked a single room in Beijing. – He booked a single room yesterday. – He booked a room."]},{"title":"–","paragraphs":["Rewrite a sentence using hand-crafted patterns"]},{"title":"• Can","paragraphs":["I have a cup of tea? => – May I have a cup of tea? – I would like a cup of tea, please. – Give me a cup of tea. 42"]},{"title":"Based on Automatically Extracted Rules •","paragraphs":["Studies on paraphrase patterns extraction has been introduced above"]},{"title":"•","paragraphs":["Some of them have tried to apply the extracted paraphrase patterns in paraphrase generation"]},{"title":"–","paragraphs":["Complex paraphrase patterns"]},{"title":"•","paragraphs":["Barzilay and Lee, 2003"]},{"title":"•","paragraphs":["E.g.,"]},{"title":"–","paragraphs":["Short and simple paraphrase patterns"]},{"title":"•","paragraphs":["Zhao et al., 2009"]},{"title":"•","paragraphs":["E.g., consider [NN] and take [NN] into consideration"]},{"title":"Pros and Cons •","paragraphs":["Methods based on hand-crafted rules"]},{"title":"–","paragraphs":["Pros"]},{"title":"•","paragraphs":["Can design paraphrase rules for specific applications and requirements"]},{"title":"–","paragraphs":["Cons"]},{"title":"•","paragraphs":["It is time-consuming to construct paraphrase rules"]},{"title":"•","paragraphs":["Problem of rules conflict"]},{"title":"•","paragraphs":["Coverage of paraphrase rules is limited"]},{"title":"•","paragraphs":["Methods based on automatically extracted rules P"]},{"title":"–","paragraphs":["Pros"]},{"title":"•","paragraphs":["Can generate paraphrases with structural changes"]},{"title":"–","paragraphs":["Cons"]},{"title":"•","paragraphs":["Coverage of paraphrase rules is limited 43"]},{"title":"References •","paragraphs":["McKeown. 1979. Paraphrasing Using Given and New Information in a Question-Answer System."]},{"title":"•","paragraphs":["Z t l 2001 A h t S k Chi P h i B d"]},{"title":"•","paragraphs":["Zong et al. 2001. Approach to Spoken Chinese Paraphrasing Based on Feature Extraction."]},{"title":"•","paragraphs":["Tetsuro et al.. 2001. KURA: A Transfer-Based Lexico-Structural Paraphrasing Engine."]},{"title":"•","paragraphs":["Zhang and Yamamoto. 2002. Paraphrasing of Chinese Utterances."]},{"title":"•","paragraphs":["Barzilay and Lee. 2003. Learning to Paraphrase - An Unsupervised Approach Using Multiple-Sequence Alignment."]},{"title":"•","paragraphs":["Zhao et al. 2009. Application-driven Statistic Paraphrase Generation.Zhao et al. 2009. Application driven Statistic Paraphrase Generation."]},{"title":"Outline • Part 2 – Paraphrase Generation– Paraphrase Generation •","paragraphs":["Rule based Method"]},{"title":"• Thesaurus based Method •","paragraphs":["NLG based Method"]},{"title":"•","paragraphs":["MT based Method"]},{"title":"•","paragraphs":["Pivot based Method"]},{"title":"–","paragraphs":["Applications of ParaphrasesApplications of Paraphrases"]},{"title":"–","paragraphs":["Evaluation of Paraphrases"]},{"title":"–","paragraphs":["Conclusions and Future work 44"]},{"title":"Thesaurus based Method • Also known as lexical substitution –","paragraphs":["Substitute words in a sentence with their synonyms"]},{"title":"–","paragraphs":["Substitute words in a sentence with their synonyms that fit in the given context"]},{"title":"–","paragraphs":["SemEval-2007: English lexical substitution task"]},{"title":"–","paragraphs":["SemEval-2010: Cross-lingual lexical substitution"]},{"title":"–","paragraphs":["Example:"]},{"title":"•","paragraphs":["There will be major cuts in the salaries of high level civilThere will be major cuts in the salaries of high-level civil servants."]},{"title":"•","paragraphs":["There will be major cuts in the wages of high-level civil servants."]},{"title":"Thesaurus based Method • Include two stages – Stage 1:","paragraphs":["extract candidate substitutes from"]},{"title":"– Stage-1:","paragraphs":["extract candidate substitutes from predefined inventories."]},{"title":"•","paragraphs":["E.g., WordNet"]},{"title":"– Stage-2:","paragraphs":["find substitutes that fit in the given context"]},{"title":"•","paragraphs":["Using language model or web data (e.g., Google 5-gram) for evaluating the fitness in the context"]},{"title":"•","paragraphs":["Disambiguation may also be usefulDisambiguation may also be useful 45"]},{"title":"Stage-1: Candidate Extraction • Various thesauri have been tried –","paragraphs":["WordNet:"]},{"title":"–","paragraphs":["WordNet:"]},{"title":"•","paragraphs":["the most commonly used"]},{"title":"–","paragraphs":["Others:"]},{"title":"•","paragraphs":["Encarta, Roget, Oxford American Writer’s Thesaurus..."]},{"title":"• Extracting different information as candidates –","paragraphs":["Synsets (all synsets vs. best synset)y(y y)"]},{"title":"–","paragraphs":["Hypernyms, similar-to, also-see..."]},{"title":"–","paragraphs":["Words in glosses Example: WordNet different synsets 46 Example: Encarta definition of the synsetdefinition of the synset synset"]},{"title":"Stage-2: Substitute Selection • Rank the candidates and select the one fits best in the given contextin the given context • Context constraints –","paragraphs":["Semantic constraints"]},{"title":"•","paragraphs":["Select substitutes with the correct meaning wrt the given context"]},{"title":"–","paragraphs":["Syntactic constraints"]},{"title":"•","paragraphs":["The sentence generated after substitution should keep grammatical 47"]},{"title":"SubFinder: A Lexical Substitution System • SubFinder –","paragraphs":["University of North Texas"]},{"title":"–","paragraphs":["University of North Texas"]},{"title":"–","paragraphs":["Performs well in SemEval-2007 English lexical substitution task"]},{"title":"• Candidate extraction –","paragraphs":["WordNet"]},{"title":"–","paragraphs":["EncartaEncarta"]},{"title":"–","paragraphs":["Others"]},{"title":"•","paragraphs":["Prove to be useless"]},{"title":"SubFinder: A Lexical Substitution System • Substitute selection (5 ranking methods R1~R5) –","paragraphs":["Language modelLanguage model"]},{"title":"•","paragraphs":["Google 1T 5-gram (R1)"]},{"title":"•","paragraphs":["Query search engine (R2)"]},{"title":"–","paragraphs":["Latent semantic analysis (LSA) (R3)"]},{"title":"•","paragraphs":["Rank a candidate by its relatedness to the context sentence"]},{"title":"–","paragraphs":["Word sense disambiguation (WSD) (R4)"]},{"title":"•","paragraphs":["Disambiguate the target word and select the synset of the right sense"]},{"title":"–","paragraphs":["Pivot approach (R5)"]},{"title":"•","paragraphs":["Check whether a candidate substitute can be generated via a 2-way translation 48"]},{"title":"SubFinder: A Lexical Substitution System • Combine R1~R5: –","paragraphs":["Voting mechanism"]},{"title":"–","paragraphs":["Voting mechanism"]},{"title":"–","paragraphs":["Contribution of each ranking method is not analyzed 1 ()","iimm m rankings c score c r λ ∈="]},{"title":"∑ Ranks according to R1-R5","paragraphs":["Contribution of each ranking method is not analyzed"]},{"title":"Pros and Cons • Pros –","paragraphs":["Based on existing inventories"]},{"title":"–","paragraphs":["Based on existing inventories"]},{"title":"• Cons –","paragraphs":["Cannot generate structural paraphrases"]},{"title":"–","paragraphs":["Language limitation"]},{"title":"• Question","paragraphs":["Ht diff tth i?"]},{"title":"–","paragraphs":["How to merge different thesauri?"]},{"title":"•","paragraphs":["Thesauri have different forms of synset clustering 49"]},{"title":"References •","paragraphs":["McCarthy and Navigli. 2007. SemEval-2007 Task 10: English Lexical Substitution Task."]},{"title":"•","paragraphs":["H t l 2007 UNT S bFi d C bi i K l d S f"]},{"title":"•","paragraphs":["Hassan et al. 2007. UNT: SubFinder: Combining Knowledge Sources for Automatic Lexical Substitution."]},{"title":"•","paragraphs":["Yuret. 2007. KU: Word Sense Disambiguation by Substitution."]},{"title":"•","paragraphs":["Giuliano et al. 2007. FBK-irst: Lexical Substitution Task Exploiting Domain and Syntagmatic Coherence."]},{"title":"•","paragraphs":["Martinez et al. 2007. MELB-MKB: Lexical Substitution System based on Relatives in Context."]},{"title":"•","paragraphs":["Kauchak and Barzilay. 2006. Paraphrasing for Automatic Evaluation.Kauchak and Barzilay. 2006. Paraphrasing for Automatic Evaluation."]},{"title":"Outline • Part 2 – Paraphrase Generation– Paraphrase Generation •","paragraphs":["Rule based Method"]},{"title":"•","paragraphs":["Thesaurus based Method"]},{"title":"• NLG based Method •","paragraphs":["MT based Method"]},{"title":"•","paragraphs":["Pivot based Method"]},{"title":"–","paragraphs":["Applications of ParaphrasesApplications of Paraphrases"]},{"title":"–","paragraphs":["Evaluation of Paraphrases"]},{"title":"–","paragraphs":["Conclusions and Future work 50"]},{"title":"Overview • Two steps –","paragraphs":["(1) analysis and (2) generation"]},{"title":"–","paragraphs":["(1) analysis and (2) generation NLU NLG R s tparaphrases"]},{"title":"NLG based Methods • Kozlowski et al., 2003 –","paragraphs":["Generate single sentence paraphrases"]},{"title":"–","paragraphs":["Generate single-sentence paraphrases"]},{"title":"–","paragraphs":["Input: predicate/argument structure"]},{"title":"•","paragraphs":["Not natural language sentences"]},{"title":"–","paragraphs":["Based on lexico-grammatical resources"]},{"title":"•","paragraphs":["Map elementary semantic structures with syntactic realization 51"]},{"title":"NLG based Methods (cont’) •","paragraphs":["Power and Scott, 2005"]},{"title":"–","paragraphs":["Concerning larger-scale Rhetorical structure treeConcerning larger scale","paraphrases"]},{"title":"•","paragraphs":["Paraphrases of multiple sentences or even the whole text"]},{"title":"•","paragraphs":["Paraphrases vary not only at lexical and syntactic levels, but also in document structure and generator Different realizations document structure and layout"]},{"title":"–","paragraphs":["Problem:"]},{"title":"•","paragraphs":["The input is not natural language texts t1 t2 t3 tn"]},{"title":"NLG based Methods (cont’) • Power and Scott, 2005 (cont’) –","paragraphs":["Example:"]},{"title":"–","paragraphs":["Example: reason NUCLEUS: recommend(doctors, elixir) SATELLITE: conjunction 1: quick-results(elixir) 2: few-side-effects(elixir) Rhetorical structure tree Doctors recommend Elixir since it gives quick results and it has few side effects. solution1 (1) Elixir gives quick results. (2) Elixir has few side effects. (3) Therefore, it is recommended","by doctors. solution2 52"]},{"title":"NLG based Methods (cont’) • Fujita et al., 2005 –","paragraphs":["Paraphrase light verb constructions (LVC) in"]},{"title":"–","paragraphs":["Paraphrase light-verb constructions (LVC) in sentences"]},{"title":"•","paragraphs":["LVC: consists of a light-verb that syntactically governs a deverbal noun"]},{"title":"–","paragraphs":["Semantic representation"]},{"title":"•","paragraphs":["LCS: Lexical Conceptual Structure"]},{"title":"–","paragraphs":["Procedure"]},{"title":"–","paragraphs":["Procedure"]},{"title":"•","paragraphs":["Semantic analysis"]},{"title":"•","paragraphs":["Semantic transformation"]},{"title":"•","paragraphs":["Surface generation"]},{"title":"Pros and Cons • Pros –","paragraphs":["It simulates human being’s behavior when generating"]},{"title":"–","paragraphs":["It simulates human being s behavior when generating paraphrases:"]},{"title":"•","paragraphs":["Step-1: understand the meaning of a sentence"]},{"title":"•","paragraphs":["Step-2: generate a new sentence expressing the meaning"]},{"title":"• Cons –","paragraphs":["Both deep analysis of sentences and NLG are difficult to realize 53"]},{"title":"References •","paragraphs":["Kozlowski et al. 2003. Generation of single-sentence paraphrases from predicate/argument structure using lexico-grammatical resources."]},{"title":"•","paragraphs":["P d S tt 2005 A t ti ti f l lh"]},{"title":"•","paragraphs":["Power and Scott. 2005. Automatic generation of large-scale paraphrases."]},{"title":"•","paragraphs":["Fujita et al. 2005. Exploiting Lexical Conceptual Structure for Paraphrase Generation."]},{"title":"Outline • Part 2 – Paraphrase Generation– Paraphrase Generation •","paragraphs":["Rule based Method"]},{"title":"•","paragraphs":["Thesaurus based Method"]},{"title":"•","paragraphs":["NLG based Method"]},{"title":"• MT based Method •","paragraphs":["Pivot based Method"]},{"title":"–","paragraphs":["Applications of ParaphrasesApplications of Paraphrases"]},{"title":"–","paragraphs":["Evaluation of Paraphrases"]},{"title":"–","paragraphs":["Conclusions and Future work 54"]},{"title":"Machine Translation vs. Paraphrase Generation Translations t Language L1 Language L2 Translations t Paraphrasings Language L1 t For both machine translation and paraphrase generation: (1) t should preserve the meaning of s (2) t should be a fluent sentence Paraphrase Generation as Machine Translation • Quirk et al., 2004 –","paragraphs":["First recast paraphrase generation as a monolingual"]},{"title":"–","paragraphs":["First recast paraphrase generation as a monolingual machine translation task Paraphrase generationst A typical MT model (source channel model) PT paraphrase table From comparable news articles 55"]},{"title":"Paraphrase Generation as Machine Translation (cont’) • Model –","paragraphs":["Source channel model"]},{"title":"–","paragraphs":["Source channel model"]},{"title":"*argmax(|) arg max ( | ) ( )","paragraphs":["t t"]},{"title":"tpts ps t pt = = Language model “Translation” model (based on a phrasal paraphrase table) • Paraphrase table –","paragraphs":["Monolingual parallel sentences"]},{"title":"Paraphrase Generation as Machine Translation (cont’) –","paragraphs":["Monolingual parallel sentences"]},{"title":"•","paragraphs":["Extracted from comparable news articles"]},{"title":"•","paragraphs":["139K pairs"]},{"title":"–","paragraphs":["Word alignment & phrase pair extraction"]},{"title":"•","paragraphs":["With Giza++"]},{"title":"• Limitation –","paragraphs":["Lack of monolingual parallel corpora to train the paraphrase table!!! 56"]},{"title":"• Zhao et al., 2008 –","paragraphs":["Combine multiple resources to train the paraphrase"]},{"title":"Paraphrase Generation as Machine Translation (cont’) –","paragraphs":["Combine multiple resources to train the paraphrase table Paraphrase generationst Log-linear model PT1 Multiple paraphrase tables PT2 PTn... From various resources"]},{"title":"Paraphrase Generation as Machine Translation (cont’) • Model –","paragraphs":["Log linear model"]},{"title":"–","paragraphs":["Log-linear model __ 1*argmax{ (,) (,)}N","TM i TM i LM LM","t ithtshtsλλ ==+"]},{"title":"∑ N paraphrase tables, each feature corresponds to a paraphrase table Language model","paragraphs":["_ 1(, ) log ( , ) iK","TM i i k k khts scorets =="]},{"title":"∏","paragraphs":["57"]},{"title":"Paraphrase Generation as Machine Translation (cont’) •","paragraphs":["Paraphrase tables"]},{"title":"– PT1","paragraphs":[": from word clusters"]},{"title":"•","paragraphs":["Volumes of the PTs: PT1: from word clusters (Lin, 1998)"]},{"title":"– PT2","paragraphs":[": from monolingual parallel corpora"]},{"title":"– PT3","paragraphs":[": from monolingual comparable corpora"]},{"title":"– PT4","paragraphs":[": from bilingual parallel corporacorpora"]},{"title":"– PT5","paragraphs":[": from Encarta dictionary glosses"]},{"title":"– PT6","paragraphs":[": from clusters of similar user queries Proves most useful!"]},{"title":"• Differences between machine translation and paraphrase generation (Zhao et al 2009): Paraphrase Generation vs. Machine Translation paraphrase generation (Zhao et al., 2009): MT has a unique purpose PG has distinct purposes in different applications Machine Translation (MT) Paraphrase Generation (PG) In MT, all words in a sentence hldbt ltd In PG, not all words need to be hdshould be translated paraphrased In MT, the bilingual parallel data are easy to collect In PG, multiple resources need to be combined In MT, automatic evaluation metrics (e.g., BLEU) are available In PG, automatic evaluation metrics are not available","paragraphs":["58"]},{"title":"Application-driven Statistical Paraphrase Generation • Zhao et al., 2009 –","paragraphs":["Propose a statistical model for paraphrase generation"]},{"title":"–","paragraphs":["Propose a statistical model for paraphrase generation"]},{"title":"–","paragraphs":["Generate different paraphrases in different applications Paraphrase planningstSentence","preprocessing Paraphrase generation A The given application PT1 Multiple paraphrase tables PT2 PTn... Also combine multiple resources Self-paraphrase PT: allows words to keep unchanged in paraphrasing"]},{"title":"• Paraphrase planning –","paragraphs":["When an application A is given only the paraphrase"]},{"title":"Application-driven Statistical Paraphrase Generation (cont’) –","paragraphs":["When an application A is given, only the paraphrase pairs that can achieve A are kept Paraphrase application: sentence compression The US government should take the overall situation into consideration and actively promote bilateral high-tech trades. Example: The US government The US administration The US government on overall situation overall interest overall picture overview situation as a whole whole situation ...... take [NN_1] into consideration consider [NN_1] take into account [NN_1] take account of [NN_1] take [NN_1] into account take into consideration [NN_1] ...... <promote, OBJ, trades> <sanction, OBJ, trades> <stimulate, OBJ, trades> <strengthen, OBJ, trades> <support, OBJ, trades> <sustain, OBJ, trades> 59"]},{"title":"• Model: –","paragraphs":["Log linear model"]},{"title":"Application-driven Statistical Paraphrase Generation (cont’) –","paragraphs":["Log-linear model 1 21 1 (|) ( log ( , )) log ( | ) ii i K kkkk","kk J","lm j j j j pst pt t t λφ λ = − − = = +"]},{"title":"∑∑ ∑ ts","paragraphs":["Paraphrase model Language model 1 (,) I","um i i i stλμ =+"]},{"title":"∑","paragraphs":["Usability model (defined for each application)"]},{"title":"References •","paragraphs":["Lin. 1998. Automatic Retrieval and Clustering of Similar Words."]},{"title":"•","paragraphs":["Quirk et al. 2004. Monolingual Machine Translation for Paraphrase GtiGeneration."]},{"title":"•","paragraphs":["Finch et al. 2004. Paraphrasing as Machine Translation."]},{"title":"•","paragraphs":["Zhao et al. 2008. Combining Multiple Resources to Improve SMT-based Paraphrasing Model."]},{"title":"•","paragraphs":["Zhao et al. 2009. Application-driven Statistical Paraphrase Generation. 60"]},{"title":"Outline • Part 2 – Paraphrase Generation– Paraphrase Generation •","paragraphs":["Rule based Method"]},{"title":"•","paragraphs":["Thesaurus based Method"]},{"title":"•","paragraphs":["NLG based Method"]},{"title":"•","paragraphs":["MT based Method"]},{"title":"• Pivot based Method","paragraphs":["Aliti fP h"]},{"title":"–","paragraphs":["Applications of Paraphrases"]},{"title":"–","paragraphs":["Evaluation of Paraphrases"]},{"title":"–","paragraphs":["Conclusions and Future work"]},{"title":"Overview • Basic idea –","paragraphs":["We can generate a paraphrase t for a sentence s by"]},{"title":"–","paragraphs":["We can generate a paraphrase t for a sentence s by translating s into a foreign language, and then translating it back into the source language. stSource language MT1 p MT2 Pivot language MT engines 61"]},{"title":"• Example: Overview (cont’) What toxins are most hazardous to expectant mothers?English • Single-pivot What toxins are most hazardous to expectant mothers? Che tossine sono più pericolose alle donne incinte? English Italian What toxins are more dangerous to pregnant women?English g p –","paragraphs":["Using a single pivot language"]},{"title":"• Multi-pivot –","paragraphs":["Using multiple pivot languages"]},{"title":"Pivot based Methods • Duboue and Chu-Carroll, 2006 –","paragraphs":["Applied in QA systems"]},{"title":"–","paragraphs":["Applied in QA systems"]},{"title":"•","paragraphs":["Paraphrase the input questions so as to improve the coverage in answer extraction"]},{"title":"–","paragraphs":["Pivot languages"]},{"title":"•","paragraphs":["11"]},{"title":"–","paragraphs":["MT engines"]},{"title":"•","paragraphs":["2: Babelfish (B) and Google MT (G)"]},{"title":"•","paragraphs":["2: Babelfish (B) and Google MT (G)"]},{"title":"•","paragraphs":["4 combinations: B+B, B+G, G+G, G+B 62"]},{"title":"Pivot based Methods (cont’) • Duboue and Chu-Carroll, 2006 (cont’) –","paragraphs":["Given a list of automatically generated paraphrases"]},{"title":"–","paragraphs":["Given a list of automatically generated paraphrases, we need to select a best one."]},{"title":"•","paragraphs":["For QA, we need to select the paraphrase that can find the answer more easily than the original question. Features for paraphrase selection (in a classification framework)","SUM IDF The sum of the IDF scores for all terms in the original question and the h(f h ith i f ti t )paraphrase. (prefer paraphrases with more informative terms)","Lengths Number of query terms for each of the paraphrase and the original question. (prefer shorter paraphrases) Cosine Distance The distance between the vectors of both questions, IDF-weighted. (filter paraphrases that diverge too much from the original) Answer Types Whether answer types, as predicted by the question analyzer, are the same or overlap. (the answer type should be the same)"]},{"title":"Pivot based Methods (cont’) • Max, 2009 –","paragraphs":["Paraphrasing sub sentential fragments"]},{"title":"–","paragraphs":["Paraphrasing sub-sentential fragments"]},{"title":"•","paragraphs":["Allows the exploitation of context during both source-pivot translation and pivot-source back-translation","context constraints context constraints paraphrase 63"]},{"title":"Pivot based Methods (cont’) • Max, 2009 (cont’) –","paragraphs":["Application"]},{"title":"–","paragraphs":["Application"]},{"title":"•","paragraphs":["Text revision"]},{"title":"–","paragraphs":["Pivot language"]},{"title":"•","paragraphs":["English"]},{"title":"–","paragraphs":["Paraphrases are acquired for French sub-sentences"]},{"title":"–","paragraphs":["MT engine"]},{"title":"•","paragraphs":["S t t SMT (St t l 2007)"]},{"title":"•","paragraphs":["Source context aware SMT (Stroppa et al., 2007)"]},{"title":"Pivot based Methods (cont’) • Zhao et al., 2010 3 MT engines: (1) Google translator (GG), (2) Microsoft translator (MS), (3) Systran translator (ST) 6 pivot languages: (1) French (F) (2) German (G)French (F), (2) German (G), (3) Spanish (S), (4) Italian (I), (5) Portuguese (P), (6) Chinese (C) 54 combinations","paragraphs":["64"]},{"title":"Pivot based Methods (cont’) • Zhao et al., 2010 (cont’) –","paragraphs":["Produce a high quality paraphrase using the list of"]},{"title":"–","paragraphs":["Produce a high-quality paraphrase using the list of candidates Source he said there will be major cuts in the salaries of high-level civil servants (GG, G, MS) he said there are significant cuts in the salaries of high-level officials (GG, F, GG) he said there will be significant cuts in the salaries of top civil level (GG, P, GG) he said there will be big cuts in salaries of high-level civil (MS, C, MS) he said that there will be a major senior civil service pay cut(MS, C, MS) he said that there will be a major senior civil service pay cut (MS, S, GG) he said there will be significant cuts in the salaries of senior officials (MS, F, ST) he said there will be great cuts in the wages of the high level civils servant (ST, G, GG) he said that there are major cuts in the salaries of senior government officials ...... ...... Good paraphrases Bad paraphrases"]},{"title":"• Zhao et al., 2010 (cont’) –","paragraphs":["Two techniques for producing high quality"]},{"title":"Pivot based Methods (cont’) –","paragraphs":["Two techniques for producing high-quality paraphrases using the candidates"]},{"title":"•","paragraphs":["Selection-based technique"]},{"title":"–","paragraphs":["Select a best paraphrase from the 54 candidates based on Minimum Bayes Risk (MBR)"]},{"title":"•","paragraphs":["Decoding-based technique"]},{"title":"–","paragraphs":["Train a MT model using the 54 candidates, and generates a hihinew paraphrase with it 65"]},{"title":"References •","paragraphs":["Duboue and Chu-Carroll. 2006. Answering the Question You Wish They Had Asked: The Impact of Paraphrasing for Question Answering."]},{"title":"•","paragraphs":["St t l 2007 E l iti S Si il it f SMT i C t t"]},{"title":"•","paragraphs":["Stroppa et al. 2007. Exploiting Source Similarity for SMT using Context-informed Features."]},{"title":"•","paragraphs":["Max. 2009. Sub-sentential Paraphrasing by Contextual Pivot Translation."]},{"title":"•","paragraphs":["Zhao et al. 2010. Leveraging Multiple MT Engines for Paraphrase Generation."]},{"title":"Outline • Part 2 Ph G ti–Paraphrase Generation –Applications of Paraphrases • Paraphrasing for MT •","paragraphs":["Other Applications"]},{"title":"–Evaluation of Paraphrases –Conclusions and Future work","paragraphs":["66"]},{"title":"Paraphrasing for MT • Applications: –","paragraphs":["Translate unknown terms (phrases)"]},{"title":"–","paragraphs":["Translate unknown terms (phrases)"]},{"title":"–","paragraphs":["Expand training data"]},{"title":"–","paragraphs":["Rewrite input sentences"]},{"title":"–","paragraphs":["Improve automatic evaluation"]},{"title":"–","paragraphs":["Tune parameters"]},{"title":"Translate Unknown Terms (Phrases) • Basic idea: –","paragraphs":["In SMT when encountering an unknown source term"]},{"title":"–","paragraphs":["In SMT, when encountering an unknown source term (phrase), we can substitute a paraphrase for it and then proceed using the translation of that paraphrase f1 -> f1’ f2 ->f2’ paraphrase table f1 -> e1 f2 ->e2 SMT phrase table new phrase pairf2 -> f2 ... fi -> fj ... fm -> fm’ f2 -> e2 ... fj -> ej ... fn -> en unknown phrase fi pp fi -> ej 67"]},{"title":"Translate Unknown Terms (Phrases) (cont’) • Callison-Burch et al., 2006 –","paragraphs":["Paraphrases are extracted from bilingual parallel"]},{"title":"–","paragraphs":["Paraphrases are extracted from bilingual parallel corpora using the pivot approach"]},{"title":"–","paragraphs":["New phrase pairs generated through paraphrasing are incorporated into the phrase table"]},{"title":"•","paragraphs":["The paraphrase probability is added as a new feature function: paraphrase 21 1 12 ( | ) If phrase table entry ( , )","( , ) is generated from ( , ) 1Otherwise p ff ef","he f e f⎧ ⎪ = ⎨ ⎪ ⎩ pp probability"]},{"title":"Translate Unknown Terms (Phrases) (cont’) • Marton et al., 2009 –","paragraphs":["Paraphrases are extracted from monolingual corpora"]},{"title":"–","paragraphs":["Paraphrases are extracted from monolingual corpora, based on distributional hypothesis f Unknown phrase L1__R1 L2__R2 ... contexts paraphrase phrases f1 f2 ..."]},{"title":"–","paragraphs":["Combine the new phrase pairs in the phrase table 12 1 1 2 ( , ) If phrase table entry ( , )","( , ) is generated from ( , ) 1Otherwise ffpsim DP DP e f","he f e f⎧ ⎪ = ⎨ ⎪ ⎩ Context similarity 68"]},{"title":"• Mirkin et al., 2009 –","paragraphs":["Use not only paraphrases but also entailment rules"]},{"title":"Translate Unknown Terms (Phrases) (cont’) –","paragraphs":["Use not only paraphrases but also entailment rules"]},{"title":"•","paragraphs":["From WordNet"]},{"title":"–","paragraphs":["Paraphrases: synonyms in WordNet"]},{"title":"–","paragraphs":["Entailment rules: hypernyms in WordNet paraphrase generation paraphrase selection s generated para. list top-k para. SMT t top-n tran. translation","selectiongeneration selection WordNet synonyms hypernyms context model selection language model"]},{"title":"• Onishi et al., 2010 –","paragraphs":["Using paraphrase lattices for SMT"]},{"title":"Translate Unknown Terms (Phrases) (cont’) –","paragraphs":["Using paraphrase lattices for SMT"]},{"title":"• Step-1:","paragraphs":["Paraphrase the input sentence, and generate a paraphrase lattice"]},{"title":"–","paragraphs":["Paraphrases are extracted from bilingual parallel corpora based on the pivot approach"]},{"title":"• Step-2:","paragraphs":["Give the paraphrase lattice as the input to the lattice decoder 69"]},{"title":"• Effectiveness –","paragraphs":["When the training data of SMT is small"]},{"title":"Translate Unknown Terms (Phrases) (cont’) –","paragraphs":["When the training data of SMT is small"]},{"title":"•","paragraphs":["Effective☺"]},{"title":"–","paragraphs":["Problem of unknown terms is more serious when the training data is small"]},{"title":"–","paragraphs":["When the training data of SMT is large"]},{"title":"•","paragraphs":["Ineffective"]},{"title":"–","paragraphs":["Unknown terms can be covered by adding more training datayg g"]},{"title":"Expand Training Data • Enlarge training data via paraphrasing the source-side sentences in the parallel corpussource-side sentences in the parallel corpus Original training data e1 e2 ... en f1 f2 ... fn English Foreign expanded training data e1 e2 ... f1 f2 ... f English Foreign en fn e1’ e2’ ... en’ paraphrasing en e1’ e2’ ... en’ fn f1 f2 ... fn","paragraphs":["70"]},{"title":"Rewrite Input Sentences • Paraphrase the sentence to be translated, so as to make it more translatableto make it more translatable –","paragraphs":["Yamamoto, 2002; Zhang and Yamamoto, 2002"]},{"title":"•","paragraphs":["Rule-based Paraphraser for simplifying the source sentences"]},{"title":"–","paragraphs":["Shimohata et al., 2004"]},{"title":"•","paragraphs":["Shorten long sentences and sentences with redundant information in a speech translation system"]},{"title":"Improve Automatic Evaluation • Automatic evaluation of MT –","paragraphs":["Based on counting the overlaps between the"]},{"title":"–","paragraphs":["Based on counting the overlaps between the references and machine outputs"]},{"title":"•","paragraphs":["E.g., BLEU, NIST..."]},{"title":"–","paragraphs":["Only computing the surface similarity is limited"]},{"title":"•","paragraphs":["A meaning may be expressed in a way that is not included in the references"]},{"title":"–","paragraphs":["Human references are expensive to produce"]},{"title":"–","paragraphs":["Human references are expensive to produce"]},{"title":"–","paragraphs":["Solution: paraphrase the references so as to include as many correct expressions as possible! 71"]},{"title":"Improve Automatic Evaluation (cont’) • Kauchak and Barzilay, 2006 –","paragraphs":["Find a paraphrase of the reference that is closer inFind a paraphrase of the reference that is closer in wording to the system output"]},{"title":"•","paragraphs":["Extract candidates from WordNet synonyms It is hard to believe that such tremendous changes have taken place for those people and lands that I have never stopped missing while living abroad. For someone born here but has been sentimentally attached to a foreign country far Correct Wrong Reference System output"]},{"title":"–","paragraphs":["Filter the invalid substitution given the context"]},{"title":"•","paragraphs":["Binary classification"]},{"title":"–","paragraphs":["Features: context n-grams and local collocations from home, it is difficult to believe this kind of changes.Reference"]},{"title":"Improve Automatic Evaluation (cont’) • Zhou et al., 2006 –","paragraphs":["ParaEval: Compute the similarity of reference and"]},{"title":"–","paragraphs":["ParaEval: Compute the similarity of reference and system output using paraphrases"]},{"title":"•","paragraphs":["Paraphrases are learned from bilingual parallel corpora with a pivot approach"]},{"title":"–","paragraphs":["Two-tier matching strategy for SMT evaluation"]},{"title":"•","paragraphs":["First tier: paraphrase match"]},{"title":"•","paragraphs":["Second tier: unigram match for words not matched bySecond tier: unigram match for words not matched by paraphrases 72"]},{"title":"Tune Parameters • Madnani et al. 2007 –","paragraphs":["Similar to the studies using paraphrases to improve"]},{"title":"–","paragraphs":["Similar to the studies using paraphrases to improve automatic evaluation of MT"]},{"title":"–","paragraphs":["Parameter tuning in SMT also needs references"]},{"title":"•","paragraphs":["Parameter estimation of SMT:"]},{"title":"–","paragraphs":["optimize BLEU on a development set"]},{"title":"–","paragraphs":["Expand the references automatically via paraphrasing"]},{"title":"•","paragraphs":["Ph ti"]},{"title":"•","paragraphs":["Paraphrase generation"]},{"title":"–","paragraphs":["Paraphrase resources are acquired based on a pivot approach"]},{"title":"–","paragraphs":["Recast paraphrase generation as a monolingual MT problem and decode with a typical SMT decoder"]},{"title":"References •","paragraphs":["Translate unknown terms (phrases)"]},{"title":"–","paragraphs":["Callison-Burch et al. 2006. Improved Statistical Machine Translation Using Paraphrases."]},{"title":"–","paragraphs":["Marton et al. 2009. Improved Statistical Machine Translation Using Monolingually-Derived Paraphrases."]},{"title":"–","paragraphs":["Mirkin et al. 2009. Source-Language Entailment Modeling for Translating Unknown Terms."]},{"title":"–","paragraphs":["Onishi et al. 2010. Paraphrase Lattice for Statistical Machine Translation."]},{"title":"•","paragraphs":["Expand training dataExpand training data"]},{"title":"–","paragraphs":["Nakov. 2008. Improved Statistical Machine Translation Using Monolingual Paraphrases."]},{"title":"–","paragraphs":["Bond et al. 2008. Improving Statistical Machine Translation by Paraphrasing the Training Data. 73"]},{"title":"References (cont’) •","paragraphs":["Rewrite input sentences"]},{"title":"–","paragraphs":["Yamamoto. 2002. Machine Translation by Interaction between Paraphraser and Transfer."]},{"title":"–","paragraphs":["Zhang and Yamamoto. 2002. Paraphrasing of Chinese Utterances."]},{"title":"–","paragraphs":["Shimohata et al. 2004. Building a Paraphrase Corpus for Speech Translation."]},{"title":"•","paragraphs":["Improve automatic evaluation"]},{"title":"–","paragraphs":["Kauchak and Barzilay. 2006. Paraphrasing for Automatic Evaluation."]},{"title":"–","paragraphs":["Zhou et al. 2006. Re-evaluating Machine Translation Results with Ph S tParaphrase Support."]},{"title":"•","paragraphs":["Tune parameters"]},{"title":"–","paragraphs":["Madnani et al. 2007. Using Paraphrases for Parameter Tuning in Statistical Machine Translation."]},{"title":"Outline • Part 2 Ph G ti–Paraphrase Generation –Applications of Paraphrases •","paragraphs":["Paraphrasing for MT"]},{"title":"• Other Applications –Evaluation of Paraphrases –Conclusions and Future work","paragraphs":["74"]},{"title":"Paraphrasing for QA • Goal: –","paragraphs":["Alleviate the problem of word mismatch between"]},{"title":"–","paragraphs":["Alleviate the problem of word mismatch between questions and answers"]},{"title":"• Two directions: –","paragraphs":["Paraphrase questions"]},{"title":"•","paragraphs":["Rewrite a question into a group of paraphrases, so as to improve the coverage in answer extraction"]},{"title":"–","paragraphs":["Paraphrase answer extraction patterns"]},{"title":"•","paragraphs":["Generate answer extraction patterns as many as possible"]},{"title":"Paraphrasing for QA • Ravichandran and Hovy, 2002. –","paragraphs":["Mining paraphrase patterns from the web"]},{"title":"–","paragraphs":["Mining paraphrase patterns from the web"]},{"title":"•","paragraphs":["Using hand-crafted seeds (e.g., (Mozart, 1756) for BIRTHDAY)"]},{"title":"•","paragraphs":["Mining patterns containing the seeds Question taxonomy BIRTHDAY 1.00 <NAME> ( <ANSWER> -) 0.85 <NAME> was born on <ANSWER>, 0.60 <NAME> was born in <ANSWER>","scores Paraphrase patterns 0.60 NAME was born in ANSWER 0.59 <NAME> was born <ANSWER> 0.53 <ANSWER> <NAME> was born 0.50 – <NAME> ( <ANSWER> 0.36 <NAME> ( <ANSWER> - Given seed (Mozart, 1756) 75"]},{"title":"Paraphrasing for Summarization • Improve automatic evaluation of summaries –","paragraphs":["Zhou et al 2006"]},{"title":"–","paragraphs":["Zhou et al., 2006"]},{"title":"–","paragraphs":["Similar to the automatic evaluation of MT"]},{"title":"•","paragraphs":["Measure the similarity between references and system outputs using paraphrase match as well as exact match"]},{"title":"• Improve sentence clustering –","paragraphs":["Barzilay et al., 1999"]},{"title":"–","paragraphs":["Considering paraphrase match when Computing sentence similarity"]},{"title":"Other Applications • Paraphrasing for NLG –","paragraphs":["Text revision and transformation"]},{"title":"–","paragraphs":["Text revision and transformation"]},{"title":"•","paragraphs":["Dras, 1997"]},{"title":"–","paragraphs":["Text transformation in order to meet external constraints, such as length and readability"]},{"title":"• Paraphrasing for IR –","paragraphs":["Query rewriting"]},{"title":"•","paragraphs":["Z k d R k tti 2002"]},{"title":"•","paragraphs":["Zukerman and Raskutti. 2002."]},{"title":"–","paragraphs":["Paraphrase user queries with WordNet synonyms 76"]},{"title":"Other Applications (cont’) • Writing style transformation –","paragraphs":["Kaji et al 2004"]},{"title":"–","paragraphs":["Kaji et al., 2004"]},{"title":"•","paragraphs":["Paraphrasing predicates from written language to spoken language"]},{"title":"• Text simplification –","paragraphs":["Carroll et al. 1999"]},{"title":"•","paragraphs":["Simplifying texts for language-impaired readers or non-native kspeakers"]},{"title":"• Identify plagiarism –","paragraphs":["Uzuner et al. 2005"]},{"title":"•","paragraphs":["Using paraphrases to better identify plagiarism"]},{"title":"References •","paragraphs":["Paraphrasing for QA"]},{"title":"–","paragraphs":["Ravichandran and Hovy. 2002. Learning Surface Text Patterns for a Question Answering System."]},{"title":"–","paragraphs":["Duboue and Chu-Carroll. 2006. Answering the Question You Wish They Had Asked: The Impact of Paraphrasing for Question Answering."]},{"title":"•","paragraphs":["Paraphrasing for summarization"]},{"title":"–","paragraphs":["Barzilay et al. 1999. Information Fusion in the Context of Multi-Document Summarization."]},{"title":"–","paragraphs":["Zhou et al. 2006. ParaEval: Using Paraphrases to Evaluate Summaries AutomaticallyAutomatically."]},{"title":"•","paragraphs":["Paraphrasing for NLG"]},{"title":"–","paragraphs":["Dras. 1997. Reluctant Paraphrase: Textual Restructuring under an Optimisation Model. 77"]},{"title":"References (cont’) •","paragraphs":["Paraphrasing for IR"]},{"title":"–","paragraphs":["Zukerman and Raskutti. 2002. Lexical Query Paraphrasing for Document Retrieval."]},{"title":"•","paragraphs":["Writing style transformation"]},{"title":"–","paragraphs":["Kaji et al. 2004. Paraphrasing Predicates from Written Language to Spoken Language Using the Web."]},{"title":"•","paragraphs":["Text simplification"]},{"title":"–","paragraphs":["Carroll et al. 1999. Simplifying Text for Language-Impaired Readers."]},{"title":"•","paragraphs":["Identify plagiarism"]},{"title":"–","paragraphs":["Uzuner et al. 2005. Using Syntactic Information to Identify Plagiarism."]},{"title":"Outline • Part 2 Ph G ti–Paraphrase Generation –Applications of Paraphrases •","paragraphs":["Paraphrasing for MT"]},{"title":"•","paragraphs":["Other Applications"]},{"title":"–Evaluation of Paraphrases –Conclusions and Future work","paragraphs":["78"]},{"title":"Evaluation of Paraphrases • No widely accepted evaluation criteria – Problem 1:","paragraphs":["Researchers define various evaluation"]},{"title":"– Problem-1:","paragraphs":["Researchers define various evaluation methods in their studies"]},{"title":"•","paragraphs":["Difficult to make a direct comparison among different works"]},{"title":"– Problem-2:","paragraphs":["Human evaluation is commonly used"]},{"title":"•","paragraphs":["Human evaluation is rather subjective"]},{"title":"•","paragraphs":["Difficult to replicate"]},{"title":"Evaluation of Paraphrase Identification • Human evaluation • A tomatic e al ation• Automatic evaluation –","paragraphs":["Brockett and Dolan, 2005"]},{"title":"– A","paragraphs":["lignment Error Rate (AER)"]},{"title":"•","paragraphs":["AER is indicative of how far the corpus is from providing a solution under a standard SMT tool","||||AP AS∩+∩|||| ||AP AS AER AS∩+∩ = + Automatic alignment POSSIBLE + SURE alignment in the gold standard SURE alignment in the gold standard 79"]},{"title":"Evaluation of Lexical Substitution • Automatic evaluation –","paragraphs":["McCarthy and Navigli 2007"]},{"title":"–","paragraphs":["McCarthy and Navigli, 2007"]},{"title":"–","paragraphs":["Construction of gold standard data"]},{"title":"•","paragraphs":["Five annotators, who are native speakers"]},{"title":"•","paragraphs":["For each test word, each annotator provides up to three substitutes"]},{"title":"–","paragraphs":["Evaluation:"]},{"title":"•","paragraphs":["Precision and Recall"]},{"title":"•","paragraphs":["Precision and Recall"]},{"title":"Evaluation of Paraphrase Phrases • Human evaluation –","paragraphs":["Ask judges:"]},{"title":"–","paragraphs":["Ask judges:"]},{"title":"•","paragraphs":["Whether paraphrases were approximately conceptual equivalent"]},{"title":"•","paragraphs":["Whether the paraphrases were roughly interchangeable given the genre"]},{"title":"•","paragraphs":["Whether the substitutions preserved the meaning and remained grammatical"]},{"title":"•","paragraphs":["......"]},{"title":"–","paragraphs":["The criteria above are vaguely defined and not easy to reproduce 80"]},{"title":"Evaluation of Paraphrase Phrases (cont’) • Automatic evaluation –","paragraphs":["Callison Burch et al 2008"]},{"title":"–","paragraphs":["Callison-Burch et al., 2008"]},{"title":"–","paragraphs":["Data:"]},{"title":"•","paragraphs":["Parallel sentences, in which paraphrases are annotated through manual alignment (gold standard)"]},{"title":"–","paragraphs":["Two fashions of evaluation"]},{"title":"•","paragraphs":["Calculate how well an automatic paraphrasing technique can align the paraphrases in a sentence pairalign the paraphrases in a sentence pair"]},{"title":"•","paragraphs":["Calculate the lower-bound precision and relative recall of a paraphrasing technique (which extracts paraphrases from other resources)"]},{"title":"Evaluation of Paraphrase Phrases (cont’)","paragraphs":["• Alignment precision and recall • Lower-bound precision and relative recall Manual alignment 12 12 Pr","12 12 ,","12 , |(,,) (,,)| |(,,)| ec ee C ee C Align PP e e S PP e e M PP e e S <>∈ <>∈","= ∩"]},{"title":"∑ ∑ System alignment Manual alignment","paragraphs":["R1 , Pr","|(,) (,,)| |(,)|MET EF sG Cp s MET","LB ecision para p s para p s G","para p s<>∈∈ − = ∩"]},{"title":"∑∑ Paraphrase acquired with a method MET Paraphrase in the gold standard set","paragraphs":["12 12 Re","12 12 ,","12 , |(,,) (,,)| |(,,)| call ee C ee C Align PP e e S PP e e M PP e e M <>∈ <>∈ = ∩"]},{"title":"∑ ∑","paragraphs":["R1 , 1 Re Re","|(,) (,,)| |(,,)| MET EF sG Cp s REF","lcall para p s para p s G","para p s G<>∈∈ − = ∩"]},{"title":"∑∑","paragraphs":["81"]},{"title":"Evaluation of Paraphrase Patterns • Human evaluation –","paragraphs":["Paraphrase patterns cannot be evaluated without"]},{"title":"–","paragraphs":["Paraphrase patterns cannot be evaluated without context information"]},{"title":"•","paragraphs":["E.g., X acquire Y, X buy Y"]},{"title":"–","paragraphs":["Correct or not? It depends on what fill in slots X and Y"]},{"title":"•","paragraphs":["Common view:"]},{"title":"–","paragraphs":["A pair of paraphrase patterns is considered correct if the judge could think of contexts under which it holds"]},{"title":"•","paragraphs":["Problem:"]},{"title":"–","paragraphs":["Different judges may think of totally distinct contexts, thus the agreement among the judges could be low"]},{"title":"Evaluation of Paraphrase Patterns (cont’) • Szpektor et al., 2007 –","paragraphs":["Evaluate paraphrase patterns (and entailment rules)"]},{"title":"–","paragraphs":["Evaluate paraphrase patterns (and entailment rules) with instances rather than directly evaluate patterns"]},{"title":"•","paragraphs":["Judges are presented not only with a pair of patterns, but also a sample of sentences that match its left-hand side"]},{"title":"•","paragraphs":["Judges assess whether two patterns are paraphrases under each specific example"]},{"title":"•","paragraphs":["A pair of paraphrase patterns is considered as correct only when the percentage of correct examples is high enough 82"]},{"title":"Evaluation of Paraphrase Generation • Human evaluation –","paragraphs":["Similar to human evaluation of SMT"]},{"title":"–","paragraphs":["Similar to human evaluation of SMT"]},{"title":"–","paragraphs":["Criteria (Zhao et al., 2009, 2010)"]},{"title":"• Adequacy","paragraphs":[": If the meaning of the source sentence is preserved in the paraphrase?"]},{"title":"• Fluency","paragraphs":[": if the generated paraphrase is well-formed?"]},{"title":"• Usability","paragraphs":["(Zhao et al., 2009): If the paraphrase meets the requirement of the given application?qgpp"]},{"title":"• Paraphrase rate","paragraphs":["(Zhao et al., 2009): How different the paraphrase is from the source sentence?"]},{"title":"Evaluation of Paraphrase Generation (cont’) •","paragraphs":["Three scales for adequacy, fluency, and usability (Zhao et al., 2009),) Adequacy 1 The meaning is evidently changed. 2 The meaning is generally preserved. 3 The meaning is completely preserved. Fluency 1 The paraphrase t is incomprehensible. 2 t is comprehensible. 3 t is a flawless sentence. 1 t is opposite to the application p rpose"]},{"title":"•","paragraphs":["Five scales for adequacy and fluency (Zhao et al., 2010) Usability 1 t is opposite to the application purpose. 2 t does not achieve the application. 3 t achieves the application. 83"]},{"title":"Evaluation of Paraphrase Generation (cont’) • Paraphrase rate (Zhao et al., 2010): –","paragraphs":["PR 1: based on word overlap rate"]},{"title":"–","paragraphs":["PR-1: based on word overlap rate"]},{"title":"–","paragraphs":["PR-2: based on edit distance (, ) 1( ) 1 ()OL S T PR T LS =− Word overlap rate Number of words in the source sen. (, ) 2( ) ()EDST PR T LS = Edit distance"]},{"title":"Evaluation of Paraphrase Generation (cont’) • Two questions: – Q1:","paragraphs":["Why not adopt automatic MT methods here e g"]},{"title":"– Q1:","paragraphs":["Why not adopt automatic MT methods here, e.g., BLEU, NIST, TER...?"]},{"title":"• Reason-1:","paragraphs":["It is much more difficult to construct human references in paraphrase generation than MT"]},{"title":"• Reason-2:","paragraphs":["Paraphrases that change less will get larger scores in criteria like BLEU"]},{"title":"– Q2:","paragraphs":["How to combine the evaluation of paraphrase Q pp quality and paraphrase rate?"]},{"title":"•","paragraphs":["They seem to be incompatible 84"]},{"title":"Evaluation within Applications • Evaluate the role of a paraphrasing module within a certain application systema certain application system –","paragraphs":["E.g., in MT, examine whether a paraphrasing module helps to alleviate the unknown term problem"]},{"title":"–","paragraphs":["E.g., in QA, whether paraphrasing the answer patterns can improve the coverage of answer extraction"]},{"title":"• Problems: –","paragraphs":["Whether the result can hold for a different application?"]},{"title":"–","paragraphs":["How to evaluate the role of the paraphrase module independently (not influenced by other modules)?"]},{"title":"References •","paragraphs":["Brockett and Dolan. 2005. Support Vector Machines for Paraphrase Identification."]},{"title":"•","paragraphs":["S kt t l 2007 I t bdElti fEtil tRl"]},{"title":"•","paragraphs":["Szpektor et al. 2007. Instance-based Evaluation of Entailment Rule Acquisition."]},{"title":"•","paragraphs":["McCarthy and Navigli. 2007. SemEval-2007 Task 10: English Lexical Substitution Task."]},{"title":"•","paragraphs":["Callison-Burch et al. 2008. ParaMetric: An Automatic Evaluation Metric for Paraphrasing."]},{"title":"•","paragraphs":["Zhao et al. 2009. Application-driven Statistical Paraphrase Generation."]},{"title":"•","paragraphs":["Zhao et al. 2010. Leveraging Multiple MT Engines for ParaphraseZhao et al. 2010. Leveraging Multiple MT Engines for Paraphrase Generation. 85"]},{"title":"Outline • Part 2 Ph G ti–Paraphrase Generation –Applications of Paraphrases •","paragraphs":["Paraphrasing for MT"]},{"title":"•","paragraphs":["Other Applications"]},{"title":"–Evaluation of Paraphrases –Conclusions and Future work Conclusions and Future Work • Conclusions –","paragraphs":["Paraphrasing is important in various research areas"]},{"title":"–","paragraphs":["Paraphrasing is important in various research areas"]},{"title":"–","paragraphs":["Many different kinds of corpora and data resources have been investigated for paraphrase extraction"]},{"title":"–","paragraphs":["Paraphrase generation is a task similar to MT, but not the same"]},{"title":"–","paragraphs":["Paraphrase evaluation is problematic. Automatic evaluation methods are in need 86"]},{"title":"Conclusions and Future Work (cont’) • Future work –","paragraphs":["Paraphrase extraction"]},{"title":"–","paragraphs":["Paraphrase extraction"]},{"title":"•","paragraphs":["Improve the quality of the extracted paraphrases"]},{"title":"–","paragraphs":["Paraphrase generation"]},{"title":"•","paragraphs":["Application-driven paraphrase generation"]},{"title":"–","paragraphs":["Paraphrase application"]},{"title":"•","paragraphs":["Apply paraphrasing techniques in commercial NLP systems, rather than merely in labsrather than merely in labs"]},{"title":"–","paragraphs":["Paraphrase evaluation"]},{"title":"•","paragraphs":["Come up with evaluation methods that can be widely accepted"]},{"title":"Thanks! QA","paragraphs":["87"]}]}