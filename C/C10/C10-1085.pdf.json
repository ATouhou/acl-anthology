{"sections":[{"title":"","paragraphs":["Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 752–760, Beijing, August 2010"]},{"title":"Automatic analysis of semantic similarity in comparable text through syntactic tree matching Erwin Marsi TiCC, Tilburg University e.c.marsi@uvt.nl Emiel Krahmer TiCC, Tilburg University e.j .krahmer@uvt.nl Abstract","paragraphs":["We propose to analyse semantic similarity in comparable text by matching syntactic trees and labeling the alignments according to one of five semantic similarity relations. We present a Memory-based Graph Matcher (MBGM) that performs both tasks simultaneously as a combination of exhaustive pairwise classification using a memory-based learner, followed by global optimization of the alignments using a combinatorial optimization algorithm. The method is evaluated on a monolingual treebank consisting of comparable Dutch news texts. Results show that it performs substantially above the baseline and close to the human reference."]},{"title":"1 Introduction","paragraphs":["Natural languages allow us to express essentially the same underlying meaning as many alternative surface forms. In other words, there are of-ten many similar ways to say the same thing. This characteristic poses a problem for many natural language processing applications. Automatic summarizers, for example, typically rank sentences according to their informativity and then extract the top n sentences, depending on the required compression rate. Although the sentences are essentially treated as independent of each other, they typically are not. Extracted sentences may have substantial semantic overlap, result-ing in unintended redundancy in the summaries. This is particularly problematic in the case of multi-document summarization, where sentences extracted from related documents are very likely to express similar information in different ways (Radev and McKeown, 1998). Therefore, if semantic similarity between sentences could be detected automatically, this would certainly help to avoid redundancy in summaries.","Similar arguments can be made for many other NLP applications. Automatic duplicate and plagiarism detection beyond obvious string overlap requires recognition of semantic similarity. Automatic question-answering systems may benefit from clustering semantically similar candidate an-swers. Intelligent document merging software, which supports a minimal but lossless merge of several revisions of the same text, must handle cases of paraphrasing, restructuring, compression, etc. Recognizing textual entailments (Dagan et al., 2005) could arguably be seen as a specific instance of detecting semantic similarity.","In addition to merely detecting semantic similarity, we can ask to what extent two expressions share meaning. For instance, the meaning of one sentence can be fully contained in that of another, the meaning of one sentence can overlap only partly with that of another, etc. This requires an analysis of the semantic similarity between a pair of expressions. Like detection, automatic analysis of semantic similarity can play an important role in NLP applications. To return to the case of multi-document summarization, analysing the semantic similarity between sentences extracted from different documents provides the basis for sentence fusion, a process where a new sentence is generated that conveys all common information from both sentences without introducing redundancy (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005b). 752","Analysis of semantic similarity can be approached from different angles. A basic approach is to use string similarity measures such as the Levenshtein distance or the Jaccard similarity coefficient. Although cheap and fast, this fails to account for less obvious cases such as synonyms or syntactic paraphrasing. At the other extreme, we can perform a deep semantic analysis of two expressions and rely on formal reasoning to derive a logical relation between them. This approach suffers from issues with coverage and robustness commonly associated with deep linguistic processing. We therefore think that the middle ground between these two extremes offers the best option. In this paper we present a new method for analysing semantic similarity in comparable text. It relies on a combination of morphological and syntactic analysis, lexical resources such as word nets, and machine learning from examples. We propose to analyse semantic similarity between sentences by aligning their syntax trees, where each node is matched to the most similar node in the other tree (if any). In addition, we label these alignments according to the type of similarity relation that holds between the aligned phrases. The labeling supports further processing. For instance, Marsi & Krahmer (2005b; 2008) describe how to generate different types of sentence fusions on the basis of this relation labeling.","In the next Section we provide a more formal definition of the task of matching syntactic trees and labeling alignments, followed by a discusion of related work in Section 3. Section 4 describes a parallel, monolingual treebank used for developing and testing our approach. In Section 5 we propose a new algorithm for simultaneous node alignment and relation labeling. The results of several evaluation experiments are presented in Section 6. We finish with a conclusion."]},{"title":"2 Problem statement","paragraphs":["Aligning a pair of similar syntactic trees is the process of pairing those nodes that are most similar. More formally: let v be a node in the syntactic tree T of sentence S and v′","a node in the syntactic tree T ′","of sentence S′",". A labeled node alignment is a tuple < v, v′",", r > where r is a label from a set of relations. A labeled tree alignment is a set of labeled node alignments. A labeled tree matching is a tree alignment in which each node is aligned to at most one other node.","For each node v, its terminal yield STR(v) is defined as the sequence of all terminal nodes reachable from v (i.e., a substring of sentence S). Aligning node v to v′","with label r indicates that relation r holds between their yields STR(v) and STR(v′","). We label alignments according to a small set of semantic similarity relations. As an example, consider the following Dutch sentences:","(1) a. Dagelijks Daily koffie coffee vermindert diminishes risico risk op on Alzheimer Alzheimer en and Dementie. Dementia.","b. Drie Three koppen cups koffie coffee per a dag day reduceert reduces kans chance op on Parkinson Parkinson en and Dementie. Dementia. The corresponding syntax trees and their (partial) alignment is shown in Figure 1. We distinguish the following five mutually exclusive similarity relations:","1. v equals v′","iff lower-cased STR(v) and lower-cased STR(v′",") are identical – example: Dementia equals Dementia;","2. v restates v′","iff STR(v) is a proper para-phrase of STR(v′",") – example: diminishes restates reduces;","3. v generalizes v′","iff STR(v) is more general than STR(v′",") – example: daily coffee generalizes three cups of coffee a day;","4. v specifies v′","iff STR(v) is more specific than STR(v′",") – example: three cups of coffee a day specifiesdailly coffee;","5. v intersects v′","iff STR(v) and STR(v′",") share meaning, but each also contains unique information not expressed in the other – example: Alzheimer and Dementia intersects Parkinson and Dementia.","Our interpretation of these relations is one of common sense rather than strict logic, akin to the definition of entailment employed in the RTE challenge (Dagan et al., 2005). Note also that relations are prioritized: equals takes precedence 753 smain np vermindert np Dagelijks koffie np Generalizes reduceert Restates risico pp op conj Altzheimer en Dementie conj Intersects Dementie Equals smain np Drie koppen koffie pp per dag kans pp op Parkinson en Figure 1: Example of two aligned and labeled syntactic trees. For expository reasons the alignment is not exhaustive. over restates, etc. Furthermore, equals, restates and intersects are symmetrical, whereas generalizes is the inverse of specifies. Finally, nodes containing unique information, such as Alzheimer and Parkinson, remain unaligned."]},{"title":"3 Related work","paragraphs":["Many syntax-based approaches to machine translation rely on bilingual treebanks to extract transfer rules or train statistical translation models. In order to build bilingual treebanks a number of methods for automatic tree alignment have been developed, e.g., (Gildea, 2003; Groves et al., 2004; Tinsley et al., 2007; Lavie et al., 2008). Most related to our approach is the work on discriminative tree alignment by Tiedemann & Kotzé (2009). However, these algorithms assume that source and target sentences express the same information (i.e. parallel text) and cannot cope with comparable text where parts may remain un-aligned. See (MacCartney et al., 2008) for further arguments and empirical evidence that MT alignment algorithms are not suitable for aligning parallel monolingual text.","MacCartney, Galley, and Manning (2008) describe a system for monolingual phrase alignment based on supervised learning which also exploits external resources for knowledge of semantic relatedness. In contrast to our work, they do not use syntactic trees or similarity relation labels. Partly similar semantic relations are used in (Mac-Cartney and Manning, 2008) for modeling semantic containment and exclusion in natural language inference. Marsi & Krahmer (2005a) is closely related to our work, but follows a more complicated method: first a dynamic programming-based tree alignment algorithm is applied, followed by a classification of similarity relations using a supervised-classifier. Other differences are that their data set is much smaller and consists of parallel rather than comparable text. A major drawback of this algorithmic approach it that it cannot cope with crossing alignments. We are not aware of other work that combines alignment with semantic relation labeling, or algorithms which perform both tasks simultaneously."]},{"title":"4 Data collection","paragraphs":["For developing our alignment algorithm we use the DAESO corpus1",". This is a Dutch parallel monolingual treebank of 1 million words, half of which were manually annotated. The corpus consists of pairs of sentences with different levels of semantic overlap, ranging from high (different Dutch translations of books from Darwin, Montaigne and Saint-Exupéry) to low (different press releases from the two main news agencies in The Netherlands, ANP and NOVUM). For this paper, we concentrate on the latter part of the DAESO corpus, where the proportion of Equals and Restates is relatively low. This corpus seg-ment consists of 8,248 pairs of sentences, contain-ing 162,361 tokens (ignoring punctuation). All sentences were tokenized and tagged, and subsequently parsed by the Alpino dependency parser for Dutch (Bouma et al., 2001). Two annota-1 http://daeso.uvt.nl 754 Alignment: Labeling: Eq: Re: Spec: Gen: Int: Macro: Micro:","Words: F: 95.38 95.48 58.50 65.81 65.00 25.85 62.11 88.72 SD: 2.16 2.69 7.63 13.05 11.25 18.74","Full trees: F: 88.31 95.83 71.38 60.21 66.71 62.67 71.36 81.92 SD: 1.15 2.27 3.77 7.63 8.17 6.14 Table 1: Average F-scores (in percentages, with Standard Deviations) for the six human annotators on alignment and semantic relation labeling, for words and for full syntactic trees. tors determined which sentences in the comparable news reports contained semantic overlap. Six other annotators produced manual alignments of words and phrases in matched sentence pairs, which resulted in 86,227 aligned pairs of nodes.","A small sample of 10 similar press releases comprising a total of 48 sentence pairs was independently annotated by all six annotators to determine inter-annotator agreement. We used precision, recall and F-score on alignment. To calculate these scores for relation labeling, we simply restrict the set of alignments to those labeled with a particular relation, ignoring all others. Likewise, we restrict these sets to terminal node alignments in order to get scores on word alignment.","Given the six annotations A1, . . . , A6, we repeatedly took one as the T rue annotation against which the five other annotations were evaluated. We then computed the average scores over these 6 ∗ 5 = 30 scores (note that with this procedure, precision, recall and F score end up being equal). Table 1 summarizes the results, both for word alignments and for full syntactic tree alignment. It can be seen that for alignment of words an average F-score of over 95 % was obtained, while alignment for full syntactic trees results in an F-score of 88%. For relation labeling, the scores differed per relation, as is to be expected: the average F-score for Equals was over 95% for both word and full tree alignment2",", and for the other relations average F-scores between 0.6 and 0.7 were","2","At first sight, it may seem that labeling Equals is a trivial and deterministic task, for which the F-score should always be close to 100%. However, the same word may occur multiple times in the source or target sentences, which introduces ambiguity. This frequently occurs with function words such as determiners and prepositions. Moreover, choosing among several equivalent Equals alignments may sometimes involve a somewhat arbitrary decision. This situation arises, for instance, when a proper noun is mentioned just once in the source sentence but twice in the target sentence. obtained. The exception to note is Intersects on word level, which only occurred a few times according to a few of the annotators. The macro and micro (weighted) F-score averages on labeled alignment are 62.11% and 88.72% for words, and 71.36% and 81.92% for full syntactic trees."]},{"title":"5 Memory-based Graph Matcher","paragraphs":["In order to automatically perform the alignment and labeling tasks described in Section 2, we cast these tasks simultaneously as a combination of exhaustive pairwise classification using a supervised machine learning algorithm, followed by global optimization of the alignments using a combinatorial optimization algorithm. Input to the tree matching algorithm is a pair of syntactic trees consisting of a source tree Ts and a target tree Tt. Step 1: Feature extraction For each possible pairing of a source node ns in tree Ts and a target node nt in tree Tt, create an instance consisting of feature values extracted from the input trees. Features can represent properties of individual nodes, e.g. the category of the source node is NP, or relations between nodes, e.g. source and target node share the same part-of-speech. Step 2: Classification A generic supervised classifier is used to predict a class label for each instance. The class is either one of the semantic similarity relations or the special class none, which is interpreted as no alignment. Our implementation employs the memory-based learner TiMBL (Daelemans et al., 2009), a freely available, efficient and enhanced implementation of k-nearest neighbour classification. The classifier is trained on instances derived according to Step 1 from a parallel treebank of aligned and labeled syntactic trees. 755 Step 3: Weighting Associate a cost with each prediction so that high costs indicate low confidence in the predicted class and vice versa. We use the normalized entropy of the class labels in the set of nearest neighbours (H) defined as H = −","∑ c∈C p(c) log2 p(c)","log2|C| (1) where C is the set of class labels encountered in the set of nearest neighbours (i.e., a subset of the five relations plusnone), and p(c) is the probabil-ity of class c, which is simply the proportion of instances with class label c in the set of nearest neighbours. Intuitively this means that the cost is zero if all nearest neighbours are of the same class, whereas the cost goes to 1 if the nearest neighbours are equally distributed over all possible classes. Step 4: Matching The classification step will usually give rise to one-to-many alignment of nodes. In order to reduce this to just one-to-one alignments, we search for a node matching which minimizes the sum of costs over all alignments. This is a well-known problem in combinatorial optimization known as the Assignment Problem. The equivalent in graph-theoretical terms is a minimum weighted bipartite graph matching. This problem can be solved in polynomial time (O(n3",")) using e.g., the Hungarian algorithm (Kuhn, 1955). The output of the algorithm is the labeled tree matching obtained by removing all node alignments labeled with the special none relation."]},{"title":"6 Experiments 6.1 Experimental setup","paragraphs":["Word alignment and full tree alignments are conceptually different tasks, which require partly different features and may have different practical applications. These are therefore addressed in separate experiments.","Table 2 summarizes the respective sizes of development and the held-out test set in terms of number of aligned graph pairs, number of aligned node pairs and number of tokens. The percentage of aligned nodes over all graphs is calculated relative to the number of nodes over all graphs. Since","Data Graph Node Tokens Aligned pairs pairs nodes (%) word develop 2 664 13 027 45 149 15.71 word test 547 2 858 10 005 14.96 tree develop 2 664 22 741 45 149 47.20 tree test 547 4 894 10 005 47.05 Table 2: Properties of develop and test data sets Data Eq Re Spec Gen Int word develop 84.92 6.15 2.10 1.77 5.07 word test 85.62 6.09 2.17 1.99 4.13 tree develop 56.61 6.57 7.52 6.38 22.91 tree test 58.40 7.11 7.40 6.38 20.72 Table 3: Distribution of semantic similarity relations for word alignment and for full tree alignments in both develop and test data sets alignments involving non-terminal nodes are ignored in the task of word alignment, the number of aligned node pairs and the percentage of aligned nodes is lower in the word develop and word test sets. Table 3 gives the distribution of semantic relations in the development and test set, for word and tree alignment. It can be observed that the distribution if fairly skewed with Equals being the majority class, even more so for word alignments. Another thing to notice is that Intersects are much more frequent at the level of non-terminal alignments.","Development was carried out using 10-fold cross validation on the development data and consequently reported scores on the development data are averages over 10 folds. Only two parameters were coarsely optimized on the development set. First, the amount of downsampling of the none class varied between 0.1 or 0.5. Second, the parameter k of the memory-based classifier – the number of nearest neighbours taken into account during classification – ranged from 1 to 15. Optimal settings were finally applied when testing on the held-out data.","A simple greedy alignment procedure served as baseline. For word alignment, identical words are aligned as Equals and identical roots as Restates. For full tree alignment, this is extended to the level of phrases so that phrases with identical words are aligned as Equals and phrases with identical roots as Restates. The baseline does not predict Spec-756 ifies, Generalizes or Intersects relations, as that would require a more involved, knowledge-based approach.","All features used are described in Table 4. The word-based features rely on pure string processing and require no linguistic preprocessing. The morphology-based features exploit the limited amount of morphological analysis provided by the Alpino parser (Bouma et al., 2001). For instance, it provides word roots and decomposes compound words. Likewise the part-of-speech-based features use the coarse-grained part-of-speech tags assigned by the Alpino parser. The lexical-semantic features rely on the Cornetto database (Vossen et al., 2008), a recent extension to the Dutch WordNet, to look-up synonym and hypernym relations among source and target lemmas. Unfortunately there is no word sense disambiguation module to identify the correct senses. In addition, a background corpus of over 500M words of (mainly) news text provides the word counts required to calculate the Lin similarity measure (Lin, 1998). The syntax-based features use the syntactic structure, which is a mix of phrase-based and dependency-based analysis. The phrasal features express similarity between the terminal yields of source and target nodes. With the exception of same-parent-lc-phrase, these features are only used for full tree alignment, not for word alignment. 6.2 Results on word alignment We evaluate our alignment model in two steps: first focussing on word alignment and then on full tree alignment. Table 5 summarizes the results for MBGM on word alignment (50% downsampling and k = 3), which we compare statistically to the baseline performance, and informally with the human scores reported in Table 1 in Section 4 (note that the human scores are only for a subset of the data used for automatic evaluation).","The first thing to observe is that the MBGM scores on the development and tests sets are very similar throughout. For predicting word alignments, the MBGM system performs significantly better than the baseline system (t(18) = 17.72, p < .0001). On the test set, MBGM obtains an F-score of nearly 89%, which is almost exactly halfway 