{"sections":[{"title":"Acquiring an Ontology for a Fundamental Vocabulary Francis Bond","paragraphs":["∗"]},{"title":"and Eric Nichols","paragraphs":["∗∗"]},{"title":"and Sanae Fujita","paragraphs":["∗"]},{"title":"and Takaaki Tanaka","paragraphs":["∗"]},{"title":"* fbond,fujita,takaakig@cslab.kecl.ntt.co.jp ** eric-n@is.naist.jp * NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation ** Nara Advanced Institute of Science and Technology Abstract","paragraphs":["In this paper we describe the extraction of thesaurus information from parsed dictionary denition sentences. The main data for our experiments comes from Lexeed, a Japanese semantic dictionary, and the Hinoki treebank built on it. The dictionary is parsed using a head-driven phrase structure grammar of Japanese. Knowledge is extracted from the semantic representation (Minimal Recursion Semantics). This makes the extraction process language independent."]},{"title":"1 Introduction","paragraphs":["In this paper we describe a method of acquiring a thesaurus and other useful information from a machine-readable dictionary. The research is part of a project to construct a fundamental vocabulary knowledge-base of Japanese: a resource that will include rich syntactic and semantic descriptions of the core vocabulary of Japanese. In this paper we describe the automatic acquisition of a thesaurus from the dictionary denition sentences. The basic method has a long pedigree (Copestake, 1990; Tsurumaru et al., 1991; Rigau et al., 1997). The main dierence from earlier work is that we use a mono-stratal grammar (Head-Driven Phrase Structure Grammar: Pollard and Sag (1994)) where the syntax and semantics are represented in the same structure. Our extraction can thus be done directly on the semantic output of the parser.","In the rst stage, we extract the thesaurus backbone of our ontology, consisting mainly of hypernym links, although other links are also extracted (e.g., domain). We also link our","∗∗","Some of this research was done while the second author was visiting the NTT Communication Science Laboratories extracted thesaurus to an existing ontology of Japanese: the Goi-Taikei ontology (Ikehara et al., 1997). This allows us to use tools that exploit the Goi-Taikei ontology, and also to extend it and reveal gaps.","The immediate application for our ontology is in improving the performance of stochastic models for parsing (see Bond et al. (2004) for further discussion) and word sense disambigua-tion. However, this paper discusses only the construction of the ontology.","We are using the Lexeed semantic database of Japanese (Kasahara et al. (2004), next section), a machine readable dictionary consisting of headwords and their denitions for the 28,000 most familiar open class words of Japanese, with all the denitions using only those 28,000 words (and some function words). We are parsing the denition sentences using an HPSG Japanese grammar and parser and treebanking the results into the Hinoki treebank (Bond et al., 2004). We then train a statistical model on the treebank and use it to parse the remain-ing denition sentences, and extract an ontology from them.","In the next phase, we will sense tag the denition sentences and use this information and the thesaurus to build a model that combines syntactic and semantic information. We will also produce a richer ontology | by combining information for word senses not only from their own denition sentences but also from denition sentences that use them (Dolan et al., 1993), and by extracting selectional preferences. Once we have done this for the core vocabulary, we will look at ways of extending our lexicon and ontology to less familiar words.","In this paper we present the details of the ontology extraction. In the following section we give more information about Lexeed and the Hinoki treebank.We then detail our method for extracting knowledge from the parsed dictionary denitions (x 3). Finally, we discuss the results and outline our future research (x 4)."]},{"title":"2 Resources","paragraphs":["2.1 The Lexeed Semantic Database of","Japanese The Lexeed Semantic Database of Japanese is a machine readable dictionary that covers the most common words in Japanese (Kasahara et al., 2004). It is built based on a series of psycholinguistic experiments where words from two existing machine-readable dictionaries were presented to multiple subjects who ranked them on a familiarity scale from one to seven, with seven being the most familiar (Amano and Kondo, 1999). Lexeed consists of all open class words with a familiarity greater than or equal to v e. The size, in words, senses and dening sentences is given in Table 1. Table 1: The Size of Lexeed Headwords 28,300 Senses 46,300 Dening Sentences 81,000","The denition sentences for these sentences were rewritten by four dieren t analysts to use only the 28,000 familiar words and the best denition chosen by a second set of analysts. Not all words were used in denition sentences: the dening vocabulary is 16,900 dieren t words (60% of all possible words were actually used in the denition sentences). An example entry for the word ","doraiba \\driver\" is given in Figure 1, with English glosses added. The underlined material was not in Lexeed originally, we extract it in this paper. doraiba \\driver\" has a familiarity of 6.55, and three senses. The rst sense was originally dened as just the synonym nejimawashi \\screwdriver\", which has a familiarity below 5.0. This was rewritten to the explanation: \\A tool for inserting and removing screws\". 2.2 The Hinoki Treebank In order to produce semantic representations we are using an open source HPSG grammar of Japanese: JACY (Siegel and Bender, 2002), which we have extended to cover the dictionary denition sentences (Bond et al., 2004). We have treebanked 23,000 sentences using the [incr tsdb()] proling environment (Oepen and Carroll, 2000) and used them to train a parse ranking model for the PET parser (Callmeier, 2002) to selectively rank the parser output. These tools, and the grammar, are available from the Deep Linguistic Processing with HPSG Initiative (DELPH-IN: http://www.delph-in. net/).","We use this parser to parse the dening sentences into a full meaning representation using minimal recursion semantics (MRS: Copestake et al. (2001))."]},{"title":"3 Ontology Extraction","paragraphs":["In this section we present our work on creating an ontology. Past research on knowledge acquisition from denition sentences in Japanese has primarily dealt with the task of automatically generating hierarchical structures. Tsurumaru et al. (1991) developed a system for automatic thesaurus construction based on information derived from analysis of the terminal clauses of denition sentences. It was successful in classifying hyponym, meronym, and synonym relationships between words. However, it lacked any concrete evaluation of the accuracy of the hierarchies created, and only linked words not senses. More recently Tokunaga et al. (2001) created a thesaurus from a machine-readable dictionary and combined it with an existing thesaurus (Ikehara et al., 1997).","For other languages, early work for English linked senses exploiting dictionary domain codes and other heuristics (Copestake, 1990), and more recent work links senses for Spanish and French using more general WSD techniques (Rigau et al., 1997). Our goal is similar. We wish to link each word sense in the fundamental vocabulary into an ontology. The ontology is primarily a hierarchy of hyponym (is-a) relations, but also contains several other relationships, such as abbreviation, synonym and domain.","We extract the relations from the semantic output of the parsed denition sentences. The output is written in Minimal Recursion Semantics (Copestake et al., 2001). Previous work has successfully used regular expressions, both for 2 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 Headword","doraiba-POS noun Lexical-type noun-lex Familiarity 6.5 [1{7] Sense 1 2 6 6 6 6 6 6 6 6 4 Definition 2 6 6 6 4","S1","/","/","screw turn (screwdriver)","S1′","","/","/","/","/","/","/","/","/","/","A tool for inserting and removing screws . 3 7 7 7 5 Hypernym","1 equipment \\tool\" Sem. Class h942:tooli ( 893:equipment) 3 7 7 7 7 7 7 7 7 5 Sense 2 2 6 6 6 6 4 Definition \"","S1","/ /","/","/","/","Someone who drives a car # Hypernym","1 hito \\person\" Sem. Class h292:driveri ( 4:person) 3 7 7 7 7 5 Sense 3 2 6 6 6 6 6 6 6 6 6 6 6 4 Definition 2 6 6 6 4","S1","/","/","/","/","/","/","/","/","In golf, a long-distance club.","S2","/ /","/","A number one wood . 3 7 7 7 5 Hypernym","2 kurabu \\club\" Sem. Class h921:leisure equipmenti ( 921) Domain","1 gorufu \\golf\" 3 7 7 7 7 7 7 7 7 7 7 7 5 3 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 5 Figure 1: Entry for the Word doraiba- \\driver\" (with English glosses) English (Barnbrook, 2002) and Japanese (Tsurumaru et al., 1991; Tokunaga et al., 2001). Regular expressions are extremely robust, and relatively easy to construct. However, we use a parser for four reasons. The rst is that it makes our knowledge acquisition more language independent. If we have a parser that can produce MRS, and a machine readable dictionary for that language, the knowledge acquisition system can easily be ported. The second reason is that we can go on to use the parser and acquisition system to acquire knowledge from non-dictionary sources. Fujii and Ishikawa (2004) have shown how it is possible to identify denitions semi automatically, however these sources are not as standard as dictionaries and thus harder to parse using only regular expressions. The third reason is that we can more easily acquire knowledge beyond simple hypernyms, for example, identifying synonyms through common denition patterns as proposed by Tsuchiya et al. (2001). The nal reason is that we are ultimately interested in language understanding, and thus wish to develop a parser. Any eort spent in building and rening regular expressions is not reusable, while creating and improving a grammar has intrinsic value. 3.1 The Extraction Process To extract hypernyms, we parse the rst denition sentence for each sense. The parser uses the stochastic parse ranking model learned from the Hinoki treebank, and returns the MRS of the rst ranked parse. Currently, just over 80% of the sentences can be parsed.","An MRS consists of a bag of labeled elementary predicates and their arguments, a list of scoping constraints, and a pair of relations that provide a hook into the representation | a label, which must outscope all the handles, and an index (Copestake et al., 2001). The MRSs for the denition sentence for doraiba 2 and its English equivalent are given in Figure 2. The hook’s label and index are shown rst, followed by the list of elementary predicates. The gure omits some details (message type and scope have been suppressed).","hh0; x1fh0 : prpstn rel(h1) h1 : hito(x1) h2 : udef (x1; h1; h6) h3 : jidosha(x2) h4 : udef (x2; h3; h7) h5 : unten(u1; x1; x2)gi","hh1; x1fh : prpstn rel(h0) h1 : person(x1) h2 : some(x1; h1; h6) h3 : car(x2) h4 : indef (x1; h3; h7) h5 : drive(u1; x1; x2)gi","  somebody who drives a car Figure 2: Simplied MRS represntations for doraiba 2","In most cases, the rst sentence of a dictionary denition consists of a fragment headed by the same part of speech as the headword. Thus the noun driver is dened as an noun phrase. The fragment consists of a genus term (somebody ) and dieren tia (who drives a car ).1","The genus term is generally the most semantically salient word in the denition sentence: the word with the same index as the index of the hook. For example, for sense 2 of the word",""," ",""," doraiba, the hypernym is  hito \\person\" (Figure 2). Although the actual hypernym is in very dieren t positions in the Japanese and English denition sentences, it is the hook in both the semantic representations.","For some denition sentences (around 20%), further parsing of the semantic representation is necessary. The most common case is where the index is linked to a coordinate construction. In that case, the coordinated elements have to be extracted, and we build two relationships. Other common cases are those where the relationship between the headword and the genus is given explicitly in the denition sentence: for example in (1), where the relationship is given as abbreviation. We initially process the rela-tion,","ryaku \\abbreviation\", yielding the coordinate structure. This in turn gives two words: arupusu \\alps\" and ","nihon arupusus \\Japanese Alps\". Our system thus produces two relations: abbreviation(  ,   ) and abbreviation(  , ","). As can be seen from this example, special cases can embed each other, which makes the use of regular expressions dicult. (1)  : a: a:  arupusu alps  , ,  matawa or   nihon-arupusu japan alps 1 Also know as superordinate and discriminator or","restriction.  no adn ","ryaku","abbreviation","a: an abbreviation for the Alps or the","Japanese Alps","The extent to which non-hypernym relations are included as text in the denition sentences, as opposed to stored as separate elds, varies from dictionary to dictionary. For knowledge acquisition from open text, we can not expect any labeled features, so the ability to extract information from plain text is important.","We also extract information not explicitly labeled, such as the domain of the word, as in Figure 3. Here the adpositional phrase representing the domain has wide scope | in eect the denition means \\In golf, [a driver3 is] a club for playing long strokes\". The phrase that species the domain should modify a non-expressed predicate. To parse this, we added a construction to the grammar that allows an NP fragment heading an utterance to have an adpositional modier. We then extract these modiers and take the head of the noun phrase to be the domain. Again, this is hard to do reliably with regular expressions, as an initial NP followed by","could be a copula phrase, or a PP that at-taches anywhere within the denition | not all such initial phrases restrict the domain. Most of the domains extracted fall under a few superordinate terms, mainly sport, games and religion. Other, more general domains, are marked explicitly in Lexeed as features. Japanese equivalents of the following words have a sense marked as being in the domain golf: approach, edge, down, tee, driver, handicap, pin, long shot .","We summarize the links acquired in Table 2, grouped by coarse part of speech. The rst three lines show hypernym relations: implicit hypernyms (the default); explicitly indicated hypernyms, and implicitly indicated hyponyms. UTTERANCE VP V[COPULA] PP NP PP PP N CASE-P PUNCT N NMOD-P N","","","    ","","","","","","","","","",""," /  ","","","/","","","","","       ",""," golf in , long-distance adn club Figure 3: Parse for Sense3 of Driver The second three names show other relations: abbreviations, names and domains. Implicit hypernyms are by far the most common relations: fewer than 10% of entries are marked with an explicit relationship. Relation Noun Verbal Verb Other Type Noun Implicit 21,245 5,467 6,738 5,569 Hypernym 230 5 9 Hyponym 194 5 5 Abbreviation 423 35 76 Name 121 5 Domain 922 170 141 Table 2: Acquired Knowledge 3.2 Verication with Goi-Taikei We veried our results by comparing the hypernym links to the manually constructed Japanese ontology Goi-Taikei. It is a hierarchy of 2,710 semantic classes, dened for over 264,312 nouns (Ikehara et al., 1997). Because the semantic classes are only dened for nouns (including verbal nouns), we can only compare nouns. Senses are linked to Goi-Taikei semantic classes by the following heuristic: look up the semantic classes C for both the headword (wi) and the genus term(s) (wg). If at least one of the index word’s semantic classes is subsumed by at least one of the genus’ semantic classes, then we consider their relationship conrmed (1). 9(ch; cg) : fch cg; ch 2 C(wh); cg 2 C(wg)g","(1) In the event of an explicit hyponym relation-","ship indicated between the headword and the genus, the test is reversed: we look for an instance of the genus’ class being subsumed by the headword’s class (cg ch). Our results are summarized in Table 3. The total is 58.5% (15,888 conrmed out of 27,146). Adding in the named and abbreviation relations, the coverage is 60.7%. This is comparable to the coverage of Tokunaga et al. (2001), who get a coverage of 61.4%, extracting relations using regular expressions from a dieren t dictionary. 3.3 Extending the Goi-Taikei In general we are extracting pairs with more information than the Goi-Taikei hierarchy of 2,710 classes. For 45.4% of the conrmed relations both the headword and its genus term were in the same Goi-Taikei semantic class. In particular, many classes contain a mixture of class names and instance names:","buta niku \\pork\" and","niku \\meat\" are in the same class, as are","   doramu \\drum\" and ","dagakki \\percussion instrument\", which we can now distinguish. This conation has caused problems in applications such as ques-tion answering as well as in fundamental research on linking syntax and semantics (Bond and Vatikiotis-Bateson, 2002).","An example of a more detailed hierarchy deduced from Lexeed is given in 4. All of the words come from the same Goi-Taikei semantic class: h842:condimenti, but are given more structure by the thesaurus we have induced. There are still some inconsistencies: ketchup is directly under condiment, while tomato sauce and tomato ketchup are under sauce. This reects the structure of the original machine readable dictionary."]},{"title":"4 Discussion and Further Work","paragraphs":["From a language engineering point of view, we found the ontology extraction an extremely useful check on the output of the grammar/parser. Treebanking tends to focus on the syntactic structure, and it is all too easy to miss a malformed semantic structure. Parsing the semantic output revealed numerous oversights, especially in binding arguments in complex rules and lexical entries.","It also reveals some gaps in the Goi-Taikei coverage. For the word",""," ","","","doraiba \\driver\" (shown in Figure 1), the rst two hypernyms are conrmed. However,",""," ",""," in Relation Noun Verbal Noun Implicit 56.66% (12,037/21,245) 64.55% (3,529/5,467) Hypernym 56.52% (134/230) 0% (0/5) Hyponym 94.32% (183/194) 100% (5/5) Subtotal 57.01% (12,354/21,669) 64.52% (3,534/5,477) Table 3: Links Conrmed by Comparison with Goi-Taikei","","","","","","","    ","","","","","","","","1","tomato ketchup","","","","","","","","  ","","","","","","",""," 1","white sauce","","","","","","  ","","","","","","",""," 1 meat sauce","","","   ","",""," 2 sauce","","","","","","","  ","","","","","","","1","tomato sauce","","","","  ","","","",""," 1 ketchup","","","  ","","","1 condiment    1","salt","","      ","","","1","curry powder","","  ","",""," 1 curry","","","  ",""," 1 spice","","","","     ","",""," 1 spice Figure 4: Renemen t of the class condiment. GT only has two semantic classes: h942:tooli and h292:driveri. It does not have the semantic class h921:leisure equipmenti. Therefore we cannot conrm the third link, even though it is correct, and the domain is correctly extracted. Further Work There are four main areas in which we wish to extend this research: improving the grammar, extending the extraction process itself, further exploiting the extracted relations and creating a thesaurus from an English dictionary.","As well as extending the coverage of the grammar, we are investigating making the semantics more tractable. In particular, we are investigating the best way to represent the semantics of explicit relations such as","isshu \\a kind of\".2 2","These are often transparent nouns: those nouns which are transparent with regard to collocational or selection relations between their dependent and the exter-","We are extending the extraction process by adding new explicit relations, such as teineigo \\polite form\". For word senses such as driver3, where there is no appropriate Goi-Taikei class, we intend to estimate the semantic class by using the denition sentence as a vector, and looking for words with similar denitions (Kasahara et al., 1997).","We are extending the extracted relations in several ways. One way is to link the hypernyms to the relevant word sense, not just the word. If we know that"," ","","club \\kurabu\" is a hypernym of h921:leisure equipmenti, then it rules out the card suit \\clubs\" and the \\association of people with similar interests\" senses. Other heuristics have been proposed by Rigau et al. (1997). Another way is to use the thesaurus to predict which words name explicit relationships which need to be extracted separately (like abbreviation)."]},{"title":"5 Conclusion","paragraphs":["In this paper we described the extraction of thesaurus information from parsed dictionary denition sentences. The main data for our experiments comes from Lexeed, a Japanese semantic dictionary, and the Hinoki treebank built on it. The dictionary is parsed using a head-driven phrase structure grammar of Japanese. Knowledge is extracted from the semantic representation. Comparing our results with the Goi-Taikei hierarchy, we could conrm 60.73% of the relations extracted. Acknowledgments The authors would like to thank Colin Bannard, the other members of the NTT Machine Translation Research Group, NAIST Matsumoto Laboratory, and researchers in the DELPH-IN community, especially Timothy Baldwin, Dan Flickinger, Stephan Oepen and Melanie Siegel. nal context of the construction, or transparent to number agreement (Fillmore et al., 2002)."]},{"title":"References","paragraphs":["Shigeaki Amano and Tadahisa Kondo. 1999. Nihongo-no Goi-Tokusei (Lexical properties of Japanese). Sanseido.","Geo Barnbrook. 2002. Dening Language | A local grammar of denition sentences. Studies in Corpus Linguistics. John Benjamins.","Francis Bond and Caitlin Vatikiotis-Bateson. 2002. Using an ontology to determine English countability. In 19th International Conference on Computational Linguistics: COLING-2002, volume 1, pages 99{105, Taipei.","Francis Bond, Sanae Fujita, Chikara Hashimoto, Kaname Kasahara, Shigeko Nariyama, Eric Nichols, Akira Ohtani, Takaaki Tanaka, and Shigeaki Amano. 2004. The Hinoki treebank: A treebank for text understanding. In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04). Springer Verlag. (in press).","Ulrich Callmeier. 2002. Preprocessing and encod-ing techniques in PET. In Stephan Oepen, Dan Flickinger, Jun-ichi Tsujii, and Hans Uszkoreit, editors, Collabarative Language Engineering, chapter 6, pages 127{143. CSLI Publications, Stanford.","Ann Copestake, Alex Lascarides, and Dan Flickinger. 2001. An algebra for semantic construction in constraint-based grammars. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL 2001), Toulouse, France.","Ann Copestake. 1990. An approach to building the hierarchical element of a lexical knowledge base from a machine readable dictionary. In Proceedings of the First International Workshop on In-heritance in Natural Language Processing, pages 19{29, Tilburg. (ACQUILEX WP NO. 8.).","William Dolan, Lucy Vanderwende, and Stephen D. Richardson. 1993. Automatically deriving structured knowledge from on-line dictionaries. In Proceedings of the Pacic Association for Computational Linguistics, Vancouver.","Charles J. Fillmore, Collin F. Baker, and Hiroaki Sato. 2002. Seeing arguments through transparent structures. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-2002), pages 787{91, Las Palmas.","Atsushi Fujii and Tetsuya Ishikawa. 2004. Summarizing encyclopedic term descriptions on the web. In 20th International Conference on Computational Linguistics: COLING-2004, Geneva. (this volume).","Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi. 1997. Goi-Taikei | A Japanese Lexicon. Iwanami Shoten, Tokyo. 5 volumes/CDROM.","Kaname Kasahara, Kazumitsu Matsuzawa, and Tsutomu Ishikawa. 1997. A method for judgment of semantic similarity between daily-used words by using machine readable dictionaries. Transac-tions of IPSJ, 38(7):1272{1283. (in Japanese).","Kaname Kasahara, Hiroshi Sato, Francis Bond, Takaaki Tanaka, Sanae Fujita, Tomoko Kanasugi, and Shigeaki Amano. 2004. Construction of a Japanese semantic lexicon: Lexeed. SIG NLC-159, IPSJ, Tokyo. (in Japanese).","Stephan Oepen and John Carroll. 2000. Performance proling for grammar engineering. Natural Language Engineering, 6(1):81{97.","Carl Pollard and Ivan A. Sag. 1994. Head Driven Phrase Structure Grammar. University of Chicago Press, Chicago.","German Rigau, Jordi Atserias, and Eneko Agirre. 1997. Combining unsupervised lexical knowledge methods for word sense disambiguation. In Proceedings of joint EACL/ACL 97, Madrid.","Melanie Siegel and Emily M. Bender. 2002. Ecien t deep processing of Japanese. In Procedings of the 3rd Workshop on Asian Language Resources and International Standardization at the 19th International Conference on Computational Linguistics, Taipei.","Takenobu Tokunaga, Yasuhiro Syotu, Hozumi Tanaka, and Kiyoaki Shirai. 2001. Integration of heterogeneous language resources: A monolingual dictionary and a thesaurus. In Proceedings of the 6th Natural Language Processing Pacic Rim Symposium, NLPRS2001, pages 135{142, Tokyo.","Masatoshi Tsuchiya, Sadao Kurohashi, and Satoshi Sato. 2001. Discovery of denition patterns by compressing dictionary sentences. In Proceedings of the 6th Natural Language Processing Pacic Rim Symposium, NLPRS2001, pages 411{418, Tokyo.","Hiroaki Tsurumaru, Katsunori Takesita, Itami Katsuki, Toshihide Yanagawa, and Sho Yoshida. 1991. An approach to thesaurus construction from Japanese language dictionary. In IPSJ SIG-Notes Natural Language, volume 83-16, pages 121{128. (in Japanese)."]}]}