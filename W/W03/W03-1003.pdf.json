{"sections":[{"title":"Cross-Lingual Lexical Triggers in Statistical Language Modeling  Woosung Kim The Johns Hopkins University 3400 N. Charles St., Baltimore, MD woosung@cs.jhu.edu Sanjeev Khudanpur The Johns Hopkins University 3400 N. Charles St., Baltimore, MD khudanpur@jhu.edu Abstract","paragraphs":["We propose new methods to take advantage of text in resource-rich languages to sharpen statistical language models in resource-deficient languages. We achieve this through an extension of the method of lexical triggers to the cross-language problem, and by developing a likelihood-based adaptation scheme for combining a trigger model with an ","-gram model. We describe the application of such language models for automatic speech recognition. By exploiting a side-corpus of contemporaneous English news articles for adapting a static Chinese language model to transcribe Mandarin news stories, we demonstrate significant reductions in both perplexity and recognition errors. We also compare our cross-lingual adaptation scheme to monolingual language model adaptation, and to an alternate method for exploiting cross-lingual cues, via cross-lingual information retrieval and machine translation, proposed elsewhere."]},{"title":"1 Data Sparseness in Language Modeling","paragraphs":["Statistical techniques have been remarkably successful in automatic speech recognition (ASR) and natural language processing (NLP) over the last two decades. This success, however, depends crucially"," This research was supported by the National Science Foun-","dation (via Grant No","̄ ITR-0225656 and IIS-9982329) and the","Office of Naval Research (via Contract No","̄ N00014-01-1-0685). on the availability of accurate and large amounts of suitably annotated training data and it is difficult to build a usable statistical model in their absence. Most of the success, therefore, has been witnessed in the so called resource-rich languages. More recently, there has been an increasing interest in languages such as Mandarin and Arabic for ASR and NLP, and data resources are being created for them at considerable cost. The data-resource bottleneck, however, is likely to remain for a majority of the world’s languages in the foreseeable future.","Methods have been proposed to bootstrap acoustic models for ASR in resource deficient languages by reusing acoustic models from resource-rich languages (Schultz and Waibel, 1998; Byrne et al., 2000). Morphological analyzers, noun-phrase chunkers, POS taggers, etc., have also been developed for resource deficient languages by exploiting translated or parallel text (Yarowsky et al., 2001). Khudanpur and Kim (2002) recently proposed using cross-lingual information retrieval (CLIR) and machine translation (MT) to improve a statistical language model (LM) in a resource-deficient language by exploiting copious amounts of text available in resource-rich languages. When transcribing a news story in a resource-deficient language, their core idea is to use the first pass output of a rudimentary ASR system as a query for CLIR, identify a contemporaneous English document on that news topic, followed by MT to provide a rough translation which, even if not fluent, is adequate to update estimates of word frequencies and the LM vocabulary. They report up to a 28% reduction in perplexity on Chinese text from the Hong Kong News corpus.","In spite of their considerable success, some shortcomings remain in the method used by Khudanpur and Kim (2002). Specifically, stochastic translation lexicons estimated using the IBM method (Brown et al., 1993) from a fairly large sentence-aligned Chinese-English parallel corpus are used in their approach — a considerable demand for a resource-deficient language. It is suggested that an easier-to-obtain document-aligned comparable corpus may suffice, but no results are reported. Furthermore, for each Mandarin news story, the single best matching English article obtained via CLIR is translated and used for priming the Chinese LM, no matter how good the CLIR similarity, nor are other well-matching English articles considered. This issue clearly deserves further attention. Finally, ASR results are not reported in their work, though their proposed solution is clearly motivated by an ASR task. We address these three issues in this paper.","Section 2 begins, for the sake of completeness, with a review of the cross-lingual story-specific LM proposed by Khudanpur and Kim (2002). A notion of cross-lingual lexical triggers is proposed in Section 3, which overcomes the need for a sentence-aligned parallel corpus for obtaining translation lexicons. After a brief detour to describe topic-dependent LMs in Section 4, a description of the ASR task is provided in Section 5, and ASR results on Mandarin Broadcast News are presented in Section 6. The issue of how many English articles to retrieve and translate into Chinese is resolved by a likelihood-based scheme proposed in Section 6.1."]},{"title":"2 Cross-Lingual Story-Specific LMs","paragraphs":["For the sake of illustration, consider the task of sharpening a Chinese language model for transcribing Mandarin news stories by using a large corpus of contemporaneous English newswire text. Mandarin Chinese is, of course, not resource-deficient for language modeling — 100s of millions of words are available on-line. However, we choose it for our experiments partly because it is sufficiently different from English to pose a real challenge, and because the availability of large text corpora in fact permits us to simulate controlled resource deficiency.","Let","","","denote the text of ","test stories to be transcribed by an ASR system, and let  ","","denote their corresponding or aligned English newswire articles. Correspondence here does not imply that the English document","","needs to be an exact translation of the Mandarin story","","",". It is quite adequate, for instance, if the two stories report the same news event. This approach is expected to be helpful even when the English document is merely on the same general topic as the Mandarin story, although the closer the content of a pair of articles the better the proposed methods are likely to work. Assume for the time being that a sufficiently good Chinese-English story alignment is given.","Assume further that we have at our disposal a stochastic translation dictionary — a probabilistic model of the form","","— which provides the Chinese translation","of each English word ",", where","and","respectively denote our Chinese and English vocabularies.","2.1 Computing a Cross-Lingual Unigram LM","Let","   ","denote the relative frequency of a word","","in the document","","",",",", . It seems","plausible that, ,","     ","","","","   ","","(1)","would be a good unigram model for the","-th Man-","darin story   . We use this cross-lingual unigram","statistic to sharpen a statistical Chinese LM used for","processing the test story","","",". One way to do this is","via linear interpolation","","","","","","  ","","","","","","","(2)","","","","   ","","","   ",""," of the cross-lingual unigram model (1) with a static trigram model for Chinese, where the interpolation weight ","may be chosen off-line to maximize the","likelihood of some held-out Mandarin stories. The","improvement in (2) is expected from the fact that","unlike the static text from which the Chinese trigram","LM is estimated,","","","is semantically close to","","","and","even the adjustment of unigram statistics, based on","a stochastic translation model, may help.","Figure 1 shows the data flow in this cross-lingual","LM adaptation approach, where the output of the","first pass of an ASR system is used by a CLIR sys-","tem to find an English document","","",", an MT system Cross−Language Information Retrieval Cross−Language Unigram Model Contemporaneous English Articles Baseline Chinese Acoustic Model Baseline Chinese Language Model Chinese Dictionary ASR Automatic Transcription","English Article Aligned with Mandarin Story","Machine TranslationStatistical Translation lexicon Mandarin Story Figure 1: Story-Specific Cross-Lingual Adaptation of a Chinese Language Model using English Text. computes the statistic of (1), and the ASR system uses the LM of (2) in a second pass. 2.2 Obtaining Matching English Documents","To illustrate how one may obtain the English doc-","ument","","","to match a Mandarin story","","",", let us","assume that we also have a stochastic reverse-","translation lexicon","",". One obtains from the","first pass ASR output, cf. Figure 1, the relative fre-","quency estimate","","","","","of Chinese words","in","",",","",", and uses the translation lexicon","","to","compute,",",","    "," ","","","","   ","","(3)","an English bag-of-words representation of the Man-","darin story  ","as used in standard vector-based in-","formation retrieval. The document with the highest","TF-IDF weighted cosine-similarity to","","","is selected:   ","","","sim","","","   ","","",""," Readers familiar with information retrieval literature will recognize this to be the standard query-translation approach to CLIR. 2.3 Obtaining Stochastic Translation Lexicons","The translation lexicons ","and","","may","be created out of an available electronic translation","lexicon, with multiple translations of a word being treated as equally likely. Stemming and other morphological analyses may be applied to increase the vocabulary-coverage of the translation lexicons.","Alternately, they may also be obtained automatically from a parallel corpus of translated and sentence-aligned Chinese-English text using statistical machine translation techniques, such as the publicly available GIZA++ tools (Och and Ney, 2000), as done by Khudanpur and Kim (2002). Unlike standard MT systems, however, we apply the translation models to entire articles, one word at a time, to get a bag of translated words — cf. (1) and (3).","Finally, for truly resource deficient languages, one may obtain a translation lexicon via optical character recognition from a printed bilingual dictionary (cf. Doerman et al (2002)). This task is arguably easier than obtaining a large LM training corpus."]},{"title":"3 Cross-Lingual Lexical Triggers","paragraphs":["It seems plausible that most of the information one gets from the cross-lingual unigram LM of (1) is in the form of the altered statistics of topic-specific Chinese words conveyed by the statistics of contentbearing English words in the matching story. The translation lexicon used for obtaining the information, however, is an expensive resource. Yet, if one were only interested in the conditional distribution of Chinese words given some English words, there is no reason to require translation as an intermediate step. In a monolingual setting, the mutual information between lexical pairs co-occurring anywhere within a long “window” of each-other has been used to capture statistical dependencies not covered by ","-gram LMs (Rosenfeld, 1996; Tillmann and Ney, 1997). We use this inspiration to propose the following notion of cross-lingual lexical triggers.","In a monolingual setting, a pair of words","is considered a trigger-pair if, given a word-position in a sentence, the occurrence of","in any of the preceding word-positions significantly alters the (conditional) probability that the following word in the sentence is",":","is said to trigger",". E.g. the occurrence of either significantly increases the probability of or subsequently in the sentence. The set of preceding word-positions is variably defined to include all words from the beginning of the sentence, paragraph or document, or is limited to a fixed number of preceding words, limited of course by the beginning of the sentence, paragraph or document.","In the cross-lingual setting, we consider a pair of words",",","and",", to be a trigger-pair if, given an English-Chinese pair of aligned documents, the occurrence of","in the English document significantly alters the (conditional) probability that the word","appears in the Chinese document:","is said to trigger",". It is plausible that translation-pairs will be natural candidates for trigger-pairs. It is, however, not necessary for a trigger-pair to also be a translation-pair. E.g., the occurrence of Belgrade in the English document may trigger the Chinese transliterations of Serbia and Kosovo, and possibly the translations of China, embassy and bomb! By infering trigger-pairs from a document-aligned corpus of Chinese-English articles, we expect to be able to discover semantically- or topicallyrelated pairs in addition to translation equivalences. 3.1 Identification of Cross-Lingual Triggers","Average mutual information, which measures how","much knowing the value of one random variable","reduces the uncertainty of about another, has been","used to identify trigger-pairs. We compute the av-","erage mutual information for every English-Chinese","word pair","as follows.","Let","","","","","",",",", now be a document-aligned training corpus of English-Chinese article pairs. Let","denote the document frequency, i.e., the number of aligned article-pairs, in which occurs in the English article and","in the Chinese. Let","","denote the number of aligned article-pairs in which","occurs in the English articles but does not occur in the Chinese article. Let  "," ",""," "," ","The quantities","","and","","","are similarly de-","fined. Next let denote the number of English","articles in which occurs, and define  "," and","   ","Similarly define ",",","","via the document fre-","quency"," ","","; define","via the","document frequency",", etc. Finally, let","","    "," ","    ","  ","    ",""," ","","    ","  We propose to select word pairs with high mutual information as cross-lingual lexical triggers.","There are","","","possible English-Chinese word pairs which may be prohibitively large to search for the pairs with the highest mutual information. We filter out infrequent words in each language, say, words appearing less than 5 times, then measure  ","for all possible pairs from the remaining","words, sort them by "," , and select, say, the top 1 million pairs. 3.2 Estimating Trigger LM Probabilities","Once we have chosen a set of trigger-pairs, the next","step is to estimate a probability","","in lieu","of the translation probability","","in (1), and a","probability ","","","","in (3).","Following the maximum likelihood approach pro-","posed by Tillman and Ney (1997), one could choose","the trigger probability","","to be based on the","unigram frequency of","among Chinese word tokens","in that subset of aligned documents","","","which have","","in","","",", namely","  ","   ","       ","   "," ","  ","(4) As an ad hoc alternative to (4), we also use","","","","      "," (5) where we set ","","whenever","is not a","trigger-pair, and find it to be somewhat more effec-","tive (cf. Section 6.2). Thus (5) is used henceforth in","this paper. Analogous to (1), we set","    "," ","","","","","","","","","","(6) and, again, we build the interpolated model","","","","","   ","","","","","","(7)","","","","   ","","","   ","",""]},{"title":"4 Topic-Dependent Language Models","paragraphs":["The linear interpolation of the story-dependent unigram models (1) and (6) with a story-independent","trigram model, as described above, is very reminis-","cent of monolingual topic-dependent language mod-","els (cf. e.g. (Iyer and Ostendorf, 1999)). This moti-","vates us to construct topic-dependent LMs and con-","trast their performance with these models. To this end, we represent each Chinese article in","the training corpus by a bag-of-words vector, and","cluster the vectors using a standard K-means algo-","rithm. We use random initialization to seed the al-","gorithm, and a standard TF-IDF weighted cosine-","similarity as the “metric” for clustering. We per-","form a few iterations of the K-means algorithm, and","deem the resulting clusters as representing differ-","ent topics. We then use a bag-of-words centroid","created from all the articles in a cluster to repre-","sent each topic. Topic-dependent trigram LMs, de-","noted","","","","","","","","",", are also computed for each","topic exclusively from the articles in the","-th cluster,","",". Each Mandarin test story is represented by a bag-","of-words vector","","","","","","generated from the first-","pass ASR output, and the topic-centroid","","having","the highest TF-IDF weighted cosine-similarity to it","is chosen as the topic of","","",". Topic-dependent LMs","are then constructed for each story","","as","","","  ","","","","","(8)","  ","","   ",""," ","","   ",""," and used in a second pass of recognition.","Alternatives to topic-dependent LMs for exploiting long-range dependencies include cache LMs and monolingual lexical triggers; both unlikely to be as effective in the presence of significant ASR errors."]},{"title":"5 ASR Training and Test Corpora","paragraphs":["We investigate the use of the techniques described above for improving ASR performance on Mandarin news broadcasts using English newswire texts. We have chosen the experimental ASR setup created in the 2000 Johns Hopkins Summer Workshop to study Mandarin pronunciation modeling, extensive details about which are available in Fung et al (2000). The acoustic training data (","10 hours) for their ASR system was obtained from the 1997 Mandarin Broadcast News distribution, and contextdependent state-clustered models were estimated using initials and finals as subword units. Two Chinese text corpora and an English corpus are used to estimate LMs in our experiments. A vocabulary","of 51K Chinese words, used in the ASR system, is also used to segment the training text. This vocabulary gives an OOV rate of 5% on the test data.","XINHUA: We use the Xinhua News corpus of about 13 million words to represent the scenario when the amount of available LM training text borders on adequate, and estimate a baseline trigram LM for one set of experiments.","HUB-4NE: We also estimate a trigram model from only the 96K words in the transcriptions used for training acoustic models in our ASR system. This corpus represents the scenario when little or no additional text is available to train LMs.","NAB-TDT: English text contemporaneous with the test data is often easily available. For our test set, described below, we select (from the North American News Text corpus) articles published in 1997 in The Los Angeles Times and The Washington Post, and articles from 1998 in the New York Times and the Associated Press news service (from TDT-2 corpus). This amounts to a collection of roughly 45,000 articles containing about 30-million words of English text; a modest collection by CLIR standards.","Our ASR test set is a subset (Fung et al (2000)) of the NIST 1997 and 1998 HUB-4NE benchmark tests, containing Mandarin news broadcasts from three sources for a total of about 9800 words. We generate two sets of lattices using the baseline acoustic models and bigram LMs estimated from XINHUA and HUB-4NE. All our LMs are evaluated by rescoring","-best lists extracted from these two sets of lattices. The","-best lists from the XINHUA bigram LM are used in all XINHUA experiments, and those from the HUB-4NE bigram LM in all HUB-4NE experiments. We report both word error rates (WER) and character error rates (CER), the latter being independent of any difference in segmenta-tion of the ASR output and reference transcriptions."]},{"title":"6 ASR Performance of Cross-Lingual LMs","paragraphs":["We begin by rescoring the","-best lists from the","bigram lattices with trigram models. For each test","story   , we perform CLIR using the first pass ASR","output to choose the most similar English docu-","ment  ","from NAB-TDT. Then we create the cross-lingual unigram model of (1). We also find the interpolation weight ","which maximizes the likelihood of the 1-best hypotheses of all test utterances from the first ASR pass. Table 1 shows the perplexity and WER for XINHUA and HUB-4NE. Language model Perp WER","-value XINHUA trigram 426 49.9% – CL-interpolated 375 49.5% 0.208 HUB-4NE trigram 1195 60.1% – CL-interpolated 750 59.3%","0.001 Table 1: Word-Perplexity and ASR WER of LMs based on single English document and global  .","All","-values reported in this paper are based on the standard NIST MAPSSWE test (Pallett et al., 1990), and indicate the statistical significance of a WER improvement over the corresponding trigram baseline, unless otherwise specified.","Evidently, the improvement brought by CL-interpolated LM is not statistically significant on XINHUA. On HUB-4NE however, where Chinese text is scarce, the CL-interpolated LM delivers considerable benefits via the large English corpus.","6.1 Likelihood-Based Story-Specific Selection of Interpolation Weights and the Number of English Documents per Mandarin Story The experiments above naı̈vely used the one most similar English document for each Mandarin story, and a global ","in (2), no matter how similar the best matching English document is to a given Mandarin news story. Rather than choosing one most similar English document from NAB-TDT, it stands to reason that choosing more than one English document may be helpful if many have a high similarity score, and perhaps not using even the best matching document may be fruitful if the match is sufficiently poor. It may also help to have a greater interpolation weight  for stories with good matches, and a smaller ","for others. For experiments in this subsection, we select a different ","for each test story, again based on maximizing the likelihood of the","- best output given a CL-Unigram model. The other issue then is the choice and the number of English documents to translate.","","-best documents: One could choose a predetermined number  of the best matching English doc-","uments for each Mandarin story. We experimented","with values of",", ,",",",",","and",", and found","that  ","gave us the best LM performance,","but only marginally better than ","","as described above. Details are omitted, as they are uninteresting.","All documents above a similarity threshold: The argument against always taking a predetermined number of the best matching documents may be that it ignores the goodness of the match. An alternative is to take all English documents whose similarity to a Mandarin story exceeds a certain predetermined threshold. As this threshold is lowered, starting from a high value, the order in which English documents are selected for a particular Mandarin story is the same as the order when choosing the ","-best documents, but the number of documents selected now varies from story to story. It is possible that for some stories, even the best matching English document falls below the threshold at which other stories have found more than one good match. We experimented with various thresholds, and found that while a threshold of","gives us the lowest perplexity on the test set, the reduction is insignificant. This points to the need for a story-specific strategy for choosing the number of English documents, in-stead of a global threshold.","Likelihood-based selection of the number of English documents: Figure 2 shows the perplexity of the reference transcriptions of one typical test story under the LM (2) as a function of the number of English documents chosen for creating (1). For each choice of the number of English documents, the interpolation weight ","in (2) is chosen to maximize the likelihood (also shown) of the first pass output. This suggests that choosing the number of English documents to maximize the likelihood of the first pass ASR output is a good strategy.","For each Mandarin test story, we choose the 1000-best-matching English documents and divide the dynamic range of their similarity scores evenly into 10 intervals. Next, we choose the documents in the top "," -th of the range of similarity scores,","not necessarily the top-","documents, compute","","  ","","","",", determine the ","in (2) that maximizes the likelihood of the first pass output of only the utterances in that story, and record this likelihood. We repeat this with documents in the top ","","-th","of the range of similarity scores, the top"," -th, etc., 0 50 100 150300 400 500 600","# En Doc (dE i ) Perplexity of Reference Reference 0 50 100 150550 560 570 580 − Log Likelihood of 1−Best List 1−Best List Figure 2: Perplexity of the Reference Transcription and the Likelihood of the ASR Output v/s Number of","","for a Typical Test Story. and obtain the likelihood as a function of the similarity threshold. We choose the threshold that maximizes the likelihood of the first pass output. Thus the number of English documents","","","in (1), as well as the interpolation weight ","in (2), are chosen dynamically for each Mandarin story to maximize the likelihood of the ASR output. Table 2 shows ASR results for this likelihood-based story-specific adaptation scheme.","Note that significant WER improvements are obtained from the CL-interpolated LM using likelihood-based story-specific adaptation even for the case of the XINHUA LM. Furthermore, the performance of the CL-interpolated LM is even better than the topic-dependent LM. This is remarkable, since the CL-interpolated LM is based on unigram statistics from English documents, while the topic-trigram LM is based on trigram statistics. We be-lieve that the contemporaneous and story-specific nature of the English document leads to its relatively higher effectiveness. Our conjecture, that the contemporaneous cross-lingual statistics and static topic-trigram statistics are complementary, is supported by the significant further improvement in WER obtained by the interpolation of the two LMs, as shown on the last line for XINHUA.","The significant gain in ASR performance in the resource deficient HUB-4NE case are obvious. The small size of the HUB-4NE corpus makes topic-models ineffective.","6.2 Comparison of Cross-Lingual Triggers with Stochastic Translation Dictionaries","Once we select cross-lingual trigger-pairs as de-","scribed in Section 3,","","","","in (1) is replaced by"," ","of (5), and","","in (3) by","",".","Therefore, given a set of cross-lingual trigger-pairs,","the trigger-based models are free from requiring","a translation lexicon. Furthermore, a document-","aligned comparable corpus is all that is required to","construct the set of trigger-pairs. We otherwise fol-","low the same experimental procedure as above.","As Table 2 shows, the trigger-based model (Trig-interpolated) performs only slightly worse than the CL-interpolated model. One explanation for this degradation is that the CL-interpolated model is trained from the sentence-aligned corpus while the trigger-based model is from the document-aligned corpus. There are two steps which could be affected by this difference, one being CLIR and the other being the translation of the","","","’s into Chinese. Some errors in CLIR may however be masked by our likelihood-based story-specific adaptation scheme, since it finds optimal retrieval settings, dynamically adjusting the number of English documents as well as the interpolation weight, even if CLIR performs somewhat suboptimally. Furthermore, a document-aligned corpus is much easier to build. Thus a much bigger and more reliable comparable corpus may be used, and eventually more accurate trigger-pairs will be acquired.","We note with some satisfaction that even simple trigger-pairs selected on the basis of mutual information are able to achieve perplexity and WER reductions comparable to a stochastic translation lexicon: the smallest","-value at which the difference between the WERs of the CL-interpolated LM and the Trig-interpolated LM in Table 2 would be significant is","for XINHUA and","for HUB-4NE. Triggers (4) vs (5): We compare the alternative ","definitions (4) and (5) for replacing in (1). The resulting CL-interpolated LM (2) yields a perplexity of 370 on the XINHUA test set using (4), compared to 367 using (5). Similarly, on the HUB-4NE test set, using (4) yields 736, while (5) yields 727. Therefore, (5) has been used throughout.","XINHUA HUB-4NE","Perp WER CER -value Language model Perp WER CER","-value","426 49.9% 28.8% – Baseline Trigram 1195 60.1% 44.1% –","381 49.1% 28.4% 0.003 Topic-trigram 1122 60.0% 44.1% 0.660","367 49.1% 28.6% 0.004 Trig-interpolated 727 58.8% 43.3%","0.001","346 48.8% 28.4% 0.001 CL-interpolated 630 58.8% 43.1%","0.001","340 48.7% 28.4% 0.001 Topic + Trig-interpolated 730 59.2% 43.5% 0.002","326 48.5% 28.2% 0.001 Topic + CL-interpolated 631 59.0% 43.3%","0.001","320 48.3% 28.1% 0.001 Topic + Trig- + CL-interp. 627 59.0% 43.3%","0.001","Table 2: Perplexity and ASR Performance with a Likelihood-Based Story-Specific Selection of the Number","of English Documents   ’s and Interpolation Weight  for Each Mandarin Story."]},{"title":"7 Conclusions and Future Work","paragraphs":["We have demonstrated a statistically significant improvement in ASR WER (1.4% absolute) and in perplexity (23%) by exploiting cross-lingual side-information even when nontrivial amount of training data is available, as seen on the XINHUA corpus. Our methods are even more effective when LM training text is hard to come by in the language of interest: 47% reduction in perplexity and 1.3% absolute in WER as seen on the HUB-4NE corpus. Most of these gains come from the optimal choice of adaptation parameters. The ASR test data we used in our experiments is derived from a different source than the corpus on which the translation and trigger models are trained, and the techniques work even when the bilingual corpus is only document-aligned, which is a realistic reflection of the situation in a resource-deficient language.","We are developing maximum entropy models to more effectively combine the multiple information sources we have used in our experiments, and expect to report the results in the near future."]},{"title":"References","paragraphs":["P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):269 – 311.","W. Byrne, P. Beyerlein, J. Huerta, S. Khudanpur, B. Marthi, J. Morgan, N. Peterek, J. Picone, D. Vergyri, and W. Wang. 2000. Towards language independent acoustic modeling. In Proc. ICASSP, volume 2, pages 1029 – 1032.","P. Fung et al. 2000. Pronunciation modeling of mandarin casual speech. 2000 Johns Hopkins Summer Workshop.","D. Doermann et al. 2002. Lexicon acquisition from bilingual dictionaries. In Proc. SPIE Photonic West Article Imaging Conference, pages 37–48, San Jose, CA.","R. Iyer and M. Ostendorf. 1999. Modeling long-distance dependence in language: topic-mixtures vs dynamic cache models. IEEE Transactions on Speech and Audio Processing, 7:30–39.","S. Khudanpur and W. Kim. 2002. Using cross-language cues for story-specific language modeling. In Proc. ICSLP, volume 1, pages 513–516, Denver, CO.","F. J. Och and H. Ney. 2000. Improved statistical alignment models. In ACL00, pages 440–447, Hongkong, China, October.","D. Pallett, W. Fisher, and J. Fiscus. 1990. Tools for the analysis of benchmark speech recognition tests. In Proc. ICASSP, volume 1, pages 97–100, Alburquerque, NM.","R. Rosenfeld. 1996. A maximum entropy approach to adaptive statistical language modeling. Computer, Speech and Language, 10:187–228.","T. Schultz and A. Waibel. 1998. Language independent and language adaptive large vocabulary speech recognition. In Proc. ICSLP, volume 5, pages 1819–1822, Sydney, Australia.","C. Tillmann and H. Ney. 1997. Word trigger and the em algorithm. In Proceedings of the Workshop Computational Natural Language Learning (CoNLL 97), pages 117–124, Madrid, Spain.","D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-ducing multilingual text analysis tools via robust projection across aligned corpora. In Proc. HLT 2001, pages 109 – 116, San Francisco CA, USA."]}]}