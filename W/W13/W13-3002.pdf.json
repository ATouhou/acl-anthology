{"sections":[{"title":"","paragraphs":["Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13), pages 12–20, Sofia, Bulgaria, August 9, 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Order and Optionality: Minimalist Grammars with Adjunction Meaghan Fowlie UCLA Linguistics Los Angeles, California mfowlie@ucla.edu Abstract","paragraphs":["Adjuncts are characteristically optional, but many, such as adverbs and adjectives, are strictly ordered. In Minimalist Grammars (MGs), it is straightforward to account for optionality or ordering, but not both. I present an extension of MGs, MGs with Adjunction, which accounts for optionality and ordering simply by keeping track of two pieces of information at once: the original category of the adjoined-to phrase, and the category of the adjunct most recently adjoined. By imposing a partial order on the categories, the Adjoin operation can require that higher adjuncts precede lower adjuncts, but not vice versa, deriving order."]},{"title":"1 Introduction","paragraphs":["The behaviour of adverbs and adjectives has qualities of both ordinary selection and something else, something unique to that of modifiers. This makes them difficult to model. Modifiers are generally optional and transparent to selection while arguments are required and driven by selection. In languages with relatively strict word order, arguments are strictly ordered, while modifiers may or may not be. In particular, (Cinque, 1999) proposes that adverbs, functional heads, and descriptive adjectives are underlyingly uniformly ordered across languages and models them by ordinary Merge or selection. Such a model captures only the ordering restrictions on these morphemes; it fails to capture their apparent optionality and transparency to selection. I propose a model of these ordered yet optional and transparent morphemes that introduces a function Adjoin which operates on pairs of categories: the original category of the modified phrase together with the category of the most recently adjoined modifier. This allows the derivation to keep track of both the true head of the phrase and the place in the Cinque hierarchy of the modifier, preventing inverted modifier orders in the absence of Move."]},{"title":"2 Minimalist Grammars","paragraphs":["I formulate my model as a variant of Minimalist Grammars (MGs), which are Stabler (1997)’s for-malisation of Chomsky’s (1995) notion of feature-driven derivations using the functions Merge and Move. MGs are mildly context-sensitive, putting them in the right general class for human language grammars. They are also simple and intuitive to work with. Another useful property is that the properties of well-formed derivations are easily separated from the properties of derived structures (Kobele et al., 2007). Minimalist Grammars have been proposed in a number of variants, with the same set of well-formed derivations, such as the string-generating grammar in Keenan & Stabler (2003), the tree-generating grammars in Stabler (1997) and Kobele et al (2007), and the multidominant graph-generating grammar in Fowlie (2011).","At the heart of each of these grammars is a function that takes two derived structures and puts them together, such as string concatenation or tree/graph building. To make this presentation as general as possible, I will simply call these functions Com. I will give derived structures as strings as (2003)’s grammar would generate them,1","but this is just a place-holder for any derived structure the grammar might be defined to generate. Definition 2.1. A Minimalist Grammar is a fivetuple G = ⟨Σ, sel, lic, Lex , M ⟩. Σ is a finite set of symbols called the alphabet. sel∪lic are finite sets of base features. Let F ={+f,-f,=X,X|f∈","1","Keenan & Stabler’s grammar also incorporates an additional element: lexical items are triples of string, features, and lexical status, which allows derivation of Spec-Head-Complement order. I will leave this out for simplicity, as it is not relevant here. 12 lic, X ∈ sel} be the features. For ε the empty string, Lex ⊆ Σ ∪ {ε} × F ∗","is the lexicon, and M is the set of operations Merge and Move. The language LG is the closure of Lex under M . A set C ⊆ F of designated features can be added; these are the types of complete sentences.","Minimalist Grammars are feature-driven, meaning features of lexical items determine which operations can occur and when. There are two disjoint finite sets of features, selectional features sel which drive the operation Merge and licensing features lic which drive Move. Merge puts two derived structures together; Move operates on the already built structure. Each feature has a positive and negative version, and these features with their polarities make the set F from which the feature stacks for Lexical Items are drawn. In the course of the derivation the features will be checked, or deleted, by the operations Merge and Move. Polarity→ Pos Neg for Merge =X X X∈ sel for Move +f -f f∈ lic Table 1: Features","In order for a derivation to succeed, LIs must be in the following form: =A =B +w +v=Y ...X -f -g -h... !\"#$%&'()X *'$+,-'$./ 0-1$23-2%)4$\"#,'$3 5-00)#'-%%$')6&7$ 89$)4-'3#)#9-2%)-#) 3$0$1#3)-3)&4) 1\"#$%&'()Y:))89-3)-3) #9$)1&;<0$;$2#: =\"19)3<$1-4-$')-3)$-#9$')6$'%$.)*=A,=B/)","&')6&7$.)*+w,+v/:)) >2)\")#'\".-#-&2\"0)?@A\"')4'\";$5&'BC)#9$'$)-3)",";\"D-;,;)&2$)3<$1-4-$'C)3&)#9$'$)5&,0.)A$) \"#);&3#)&2$)4$\"#,'$)-2)#9-3)0-3#:)","Figure 1: LI template","For example, ⟨kick, =D=DV⟩ takes a complement of category D, a specifier of categoryD, and is itself a V. ⟨which, =ND-wh⟩ takes an N as complement forming a D phrase, which will move because of feature wh.","Merge and Move are defined over expressions: sequences of pairs ⟨derived structure, feature stack⟩. The first pair in the sequence can be thought of as the “main” structure being built; the remaining are waiting to move. An expression displays feature f just in case that feature is the first feature in the feature stack of the first pair.","An MG essentially works as follows: Merge is a binary operation driven by sel. It takes two expressions and combines them into one just in case the first expression displays =X and the second displays X for some X ∈ sel. Once the second expression is selected, it may still have features remaining; these are always negative licensing features and mean that the second structure is going to move. As such it is stored separately by the derivation. When the matching positive licensing feature comes up later in the derivation, the moving structure is combined again. This is Move.","Move also carries the requirement that for each f∈lic there be at most one structure waiting to move. This is the shortest move constraint (SMC).2 Definition 2.2 (Merge). For α, β sequences of negative lic features, s, t derived structures:3","Merge(⟨s, =Xα⟩ ::moverss, ⟨t, Xβ⟩::moverst) ={ (Com(s, t), α) :: moverss · moverst if β = ε (s, α) :: (t, β) :: moverss · moverst if β ̸= ε Definition 2.3 (Move). For α, β, γ sequences of negative lic features, s, t derived structures, suppose ∃!⟨t, β⟩ ∈ movers such that β = -fγ. Then: Move(⟨s, +fα⟩ ::movers) ={","⟨Com(s, t), α⟩ :: movers − ⟨t, β⟩ if γ = ε ⟨s, α⟩ :: ⟨t, γ⟩ :: movers − ⟨t, β⟩ if γ ̸= ε","In this article I will make use of annotated derivation trees, which are trees describing the derivation. In addition to the name of the function, I (redundantly) include for clarity the derived expressions in the form of strings and features, and sometimes an explanation of why the function applied. For example, Figure 2 shows derivations (unannotated and annotated) of the wolf with feature D. Merge the:=ND wolf:N Merge the wolf:D the:=ND wolf:N Figure 2: Unannotated and annotated derivation trees","2","The SMC is based on economy arguments in the linguistic literature (Chomsky, 1995), but it is also crucial for a type of finiteness: the valid derivation trees of an MG form a regular tree language (Kobele et al., 2007). The number of possible movers must be finite for the automaton to be finite-state. The SMC could also be modified to allow up to a particular (finite) number of movers for eachf∈lic.","3",":: adds an element to a list; · appends two lists; − removes an element from a list. 13"]},{"title":"3 Cartography","paragraphs":["The phenomena this model is designed to account for are modifiers and other apparently optional projections such as the following:","(1) a. The small ancient triangular green Irish pagan","metal artifact was lost.","b. *The metal green small artifact was lost.Adjec-","tives","c. Frankly, John probably once usually arrived","early.","d. *Usually, John early frankly once arrived prob-","ably. Adverbs","e. [DP","[DP zhe this [NumP [NumP yi one [ClP [ClP zhi CL [NP [NP bi]]] pen]]]","‘this pen’ Functional projections","These three phenomena can all display optionality, transparency to selection, and strict ordering. By transparency I mean that despite the intervening modifiers, properties of the selected head are relevant to selection. For example, in a classifier language, the correct classifier selects a noun even if adjectives intervene.","The hypothesis that despite their optionality these projections are strictly ordered is part of syntactic cartography (Rizzi, 2004). Cinque (1999, 2010) in particular proposes a universal hierarchy of functional heads that select adverbs in their specifiers, yielding an order on both the heads and the adverbs. He proposes a parallel hierarchy of adjectives modifying nouns. These hierarchies are very deep. The adverbs and functional heads in-corporate 30 heads and 30 adverbs.","Cinque argues that the surprising universality of adverb order calls for explanation. For example, Italian, English, Norwegian, Bosnian/Serbo-Croatian, Mandarin Chinese, and more show strong preferences for frankly to precede (un)fortunately. These arguments continue for a great deal more adverbs.4","(2) Italian a. Francamente","Frankly ho have purtroppo unfortunately una a pessima bad opinione opinion di of","voi.","you ’Frankly I unfortunately have a very bad opinion of you.’","b. *Purtroppo Unfortuately ho have francamente frankly una a pessima bad opinione opinion di of voi. you","(3) English a. Frankly, I unfortuately have a very bad opin-","ion of you 4 Data from Cinque (1999)","b. ?Unfortunately I frankly have a very bad opinion of you","(4) Norwegian a. Per","Peter forlater leaves [rerlig [honestly talt] spoken] [heldigvis] [fortunately] [nil] [now]","selskapet.","the.party. ‘Frankly, Peter is fortunately leaving the party now.’","b. *Per Peter forlater leaves [heldigvis] [fortunately] [rerlig [honestly talt] spoken] [nil] [now] selskapet. the.party.","(5) Bosnian/Serbo-Croatian a. lskreno,","Frankly, ja I naialost unfortunately imam have jako very lose bad misljenje opinion o of","vama","you. Frankly, I unfortunately have a very bad opinion of you.’","b. *Naialost, unfortunately ja I iskreno frankly imam have jako very lose bad misljenje opinion o of varna. you.","(6) Mandarin Chinese a. laoshi-shuo","Frankly, wo I buxing unfortunately dui to tamen them you have pian-jian. prejudice ’Honestly I unfortunately have prejudice against them.’","b. *buxing unfortunately wo I laoshi-shuo Frankly dui to tamen them you have pian-jian. prejudice","Supposing these hierarchies are indeed universal, the grammar should account for it. Moreover, in addition to strictly ordered adjuncts, ideally a model of adjunction should account for unordered adjuncts as well. For example, English PPs are unordered:","(7) a. The alliance officer shot Kaeli in the cargo","hold with a gun.","b. The alliance officer shot Kaeli with a gun in","the cargo hold.","It is not unusual to see this kind of asymmetry, where right adjuncts are unordered but left adjuncts are ordered."]},{"title":"4 Previous approaches to adjunction","paragraphs":["This section provides a brief overview of four approaches to adjunction. The first two are from a categorial grammar perspective and account for the optionality and, more or less, transparency to selection; however, they are designed to model unordered adjuncts. The other two are MG formal-14 isations of the cartographic approach. Since the cartographic approach takes adjuncts to be regular selectors, unsurprisingly they account for order, but not easily for optionality or transparency to selection. 4.1 Categorial Grammar solutions To account for the optionality and transparency, a common solution is for a modifier to combine with its modified phrase, and give the result the same category as the original phrase. In traditional categorial grammars, a nominal modifier has category N\\N or N/N, meaning it combines with an N and the result is an N.","Similarly, in MGs, an X-modifier has features =XX: it selects an X and the resulting structure has category feature X.","Merge *the bad big wolf:D","the::=ND Merge *bad big wolf:N","bad::=NN Merge big wolf:N big::=NN wolf::N Figure 3: Traditional MG derivation of *the bad big wolf","What this approach cannot account for is ordering. This is because the category of the new phrase is the same regardless of the modifier’s place in the hierarchy. That is, the very thing that accounts for the optionality and the transparency of modifiers (that the category does not change) is what makes strict ordering impossible. Moreover, the modifier is not truly transparent to selection: the modifier in fact becomes the new head; it just happens to share a category with the original head. This can be seen in tree-generating grammars such as Stabler (1997) (Figure 4). Merge ⟨ big, =NN⟩ ⟨wolf, N⟩ < big wolf Figure 4: Derivation tree and derived bare tree. The < points to the head, big. 4.1.1 Frey & Gärtner Frey & Gärtner (2002) propose an improved version of the categorial grammar approach, one which keeps the modified element the head, giv-ing true transparency to selection. They do this by asymmetric feature checking.","To the basic MG formalism a third polarity is added for sel, ≈X. This polarity drives the added function Adjoin. Adjoin behaves just like Merge except that instead of cancelling both ≈X and X, it cancels only ≈X, leaving the original X intact. This allows the phrase to be selected or adjoined to again by anything that selects or adjoins to X. This model accounts for optionality and true transparency: the modified element remains the head (Figure 4.1.1). Merge ⟨big, ≈N⟩ ⟨wolf, N⟩ > big wolf Figure 5: Frey & Gärtner: derivation tree and derived bare tree. The > points to the head, wolf.","Since this grammar is designed to model unordered modifiers, illicit orders are also derivable (Figure 6).","Merge *the bad big wolf:D","the::=ND Merge *bad big wolf:N","bad::≈N Merge big wolf:N big::≈N wolf::N Figure 6: F & G derivation of *the bad big wolf 4.2 Selectional approach A third approach is to treat adjuncts just like any other selector. This is the approach taken by syntactic cartography. Such an approach accounts straightforwardly for order, but not for optionality or transparency; this is unsurprising since the phenomena I am modelling share only ordering restrictions with ordinary selection.","The idea is to take the full hierarchy of modifiers and functional heads, and have each select the one below it; for example, big selects bad but not vice versa, and bad selects wolf. However, here we are left with the question of what to do when bad is not present, and the phrase is just the big wolf. big does not select wolf. 4.2.1 Silent, meaningless heads The first solution is to give each modifier and functional head a silent, meaningless version that serves only to tie the higher modifier to the lower. 15 For example, we add to the lexicon a silent, meaningless “size” modifier that goes where big and small and other LIs of category S go. • ⟨ the, =S D⟩ ⟨ ε, =S D⟩ • ⟨ big, =G S⟩ ⟨ ε, =G S⟩ • ⟨ bad, =N G⟩ ⟨ ε, =N G⟩ • ⟨ wolf, N⟩","This solution doubles substantial portions of the lexicon. Doubling is not computationally significant, but it does indicate a missing generalisa-tion: somehow, it just happens that each of these modifiers has a silent, meaningless doppelganger. Relatedly, the ordering facts are epiphenomenal. There is nothing forcing, say, D’s to always select S’s. There is no universal principle predicting the fairly robust cross-linguistic regularity.","Moreover, normally when something silent is in the derivation, we want to say it is contributing something semantically. Here these morphemes are nothing more than a trick to hold the syntax together. Surely we can do better. 4.2.2 Massive homophony A second solution is for each morpheme in the hierarchy to have versions that select each level below it. For example, the has a version which selects N directly, one that selects “goodness” adjectives like bad, one that selects “size” adjectives like big, and indeed one for each of the ten or so levels of adjectives. • ⟨the, =SD⟩ ⟨the, =GD⟩ ⟨the, =SD⟩ ⟨the, =ND⟩ • ⟨big, =GS⟩ ⟨big, =NatS⟩⟨big, =NS⟩ • ⟨bad, =NatG⟩ ⟨bad, =NG⟩ • ⟨Canadian, =NNat⟩ • ⟨wolf, N⟩ This second solution lacks the strangeness of silent, meaningless elements, but computationally it is far worse. To compute this we simply use Gauss’s formula for adding sequences of numbers, since an LI at level i in a hierarchy has i versions. For example, in the model above, the is at level 4 (counting from 0), and there are 4 versions of the. For a lexicon Lex without these duplicated heads, and a language with k hierarchies of depths li for each 1 ≤ i ≤ k, adding the duplicated heads increases the size of the lexicon. The increase is bounded below by a polynomial function of the depths of the hierarchies as follows:5","|Lex′ | ≥ k ∑ i=1","1/2(l2 i + li) + |Lex|"]},{"title":"5 Proposal","paragraphs":["I propose a solution with three components: sets of categories defined to be adjuncts of particular categories, a partial order on sel, and a new operation Adjoin. The sets of adjuncts I base on Stabler (2013). The partial order models the hierarchies of interest (e.g. the Cinque hierarchy); Adjoin is designed to be sensitive to the order.","Adjoin operates on pairs of selectional features. The first element is the category of the first thing that was adjoined to, for example N. The second element is the category of the most recently adjoined element, for example Adj3. Adjoin is only defined if the new adjunct is higher in the hierarchy than the last adjunct adjoined.","I call these grammars Minimalist Grammars with Adjunction (MGAs). Definition 5.1. A Minimalist Grammar with Adjunction is a six-tuple G = ⟨Σ, ⟨sel, ≥⟩, ad, lic, Lex , M ⟩. Σ is a finite set called the alphabet. sel∪lic are finite sets of base features, and ⟨sel, ≥⟩ is a partial order. Let F ={+f,-f,=X,[X,Y]|f∈ lic, X,Y ∈ sel}. ad : sel → P(sel) maps categories to their adjuncts. Lex ⊆ Σ ∪ {ε} × F ∗",", and M is the set of operations Merge, Move, and Adjoin. The language LG is the closure of Lex under M . A set C ⊆ sel of designated features can be added; {[c, x]|c ∈ C, x ∈ sel, x ≥ c} are the types of complete sentences.6","The differences between MGs defined above and MGAs are: (1) in MGAs sel is partially ordered; (2) in MGs the negative polarity for X ∈ sel is just X; in MGAs it is the pair [X,X]; (3) MGAs add a function: Adjoin; (4) MGAs define some subsets of sel to be adjuncts of certain categories; (5) Merge is redefined for the new feature pair polarity. (Move remains unchanged.)","5","I say “bounded below” because this formula calculates the increase to the lexicon assuming there is exactly one LI at each level in the hierarchy. If there are more, each LI at level i of a hierarchy has i versions as well.","6","I have replaced all negative selectional features X with pairs [X,X]. This is for ease of definingAdjoin and the new Merge. Equivalently, LIs can start with category features X as in a traditional MG, and Adjoin can build pairs. I chose the formulation here because it halves the number of cases for both Merge and Adjoin. 16","For ⟨A, ≥⟩ a partial order, a, b ∈ A are incomparable, written a||b, iff a ̸≥ b and b ̸≥ a.","To shorten the definition of Adjoin, I define a function f adj which determines the output features under Adjoin. If the adjunct belongs to the hierarchy of adjuncts being tracked by the second element of the feature pair, that second element changes. If not, the feature pair is unchanged. Definition 5.2. For W, X, Y, Z ∈ sel, W ∈ ad(Y) : f adj([W, X], [Y, Z]) =    [Y, W] if W ≥ Z [Y, Z] if W||Z undefined otherwise","Notice that if Z and W are incomparable, no record is kept of the feature (W) of the adjunct. This is just like Frey & Gärtner’s asymmetric feature checking, and derives adjuncts that are unordered with respect to each other. In Definition 5.3, I model languages like English in which generally unordered adjuncts, like PPs, appear to the right, while ordered adjuncts, like adjectives, appear to the left. The rules could be easily modified for different orderings. See Section 6 for further discussion. Definition 5.3 (Adjoin). For s, t derived structures, γ, β ∈ {−f|f ∈ lic}∗",", α ∈ {+f, = X|f ∈ lic, X ∈ sel}∗",", W, X, Y, Z ∈ sel, W ∈ ad(Y), C = fadj([W, X], [Y, Z]): Adjoin(⟨s, [W, X]αγ⟩::mvrss, ⟨t, [Y, Z]β⟩ :: mvrst) =   ⟨Com(s, t), αC⟩ :: mvrss · mvrst if γ, β = ε & W ≥ Z ⟨Com(t, s), αC⟩ :: mvrss · mvrst if γ, β = ε & W||Z ⟨s, αC⟩ :: ⟨t, β⟩ :: mvrss · mvrst if γ = ε, β ̸= ε & W ̸< Z ⟨t, αC⟩ :: ⟨s, γ⟩ :: mvrss · mvrst if γ ̸= ε, β = ε & W ̸< Z ⟨ε, αC⟩ :: ⟨s, γ⟩ :: ⟨t, β⟩ :: mvrss · mvrst if γ, β ̸= ε & W ̸< Z","The first case is for ordered adjuncts where neither the adjunct nor the adjoined-to phrase will move (encoded in empty γ, β). The second is the same but for unordered adjuncts, which will appear on the right. The last three cases are for moving adjunct, moving adjoined-to phrase, and both moving, respectively. α is a sequence of positive licensing features, which allows adjuncts to take specifiers.","Merge needs a slight modification, to incorporate the paired categories. Notice that Merge is interested only in the first element of the pair, the “real” category. Definition 5.4 (Merge). For α, β ∈ F ∗",", s, t derived structures, X, Y ∈ sel: Merge(⟨s,=Xα⟩ ::mvrss, ⟨t, [X, Y]β⟩::mvrst) ={","(Com(s, t), α) :: mvrss · mvrst if β = ε (s, α) :: (t, β) :: mvrss · mvrst if β ̸= ε Move remains as in definition 2.3 above. 5.1 Examples MGAs are most easily understood by example. This first example demonstrates straightforward applications of Adjoin that derive strictly-ordered prenominal adjectives. The big bad wolf is derivable because the derivation remembers that an N-adjunct at level G in the hierarchy, ⟨bad, [G,G]⟩, adjoined to the noun. It encodes this fact in the second element of the pair [N,G]. Big is then able to adjoin because it too is an N-adjunct and it is higher in the hierarchy than bad (S>G). Finally, the can be defined to selectwolf directly.","Let sel = {D, G, M, N, P, C, T, V} and the partial order ≥ on sel be such that D ≥ S ≥ G ≥ M ≥ N and C ≥ T ≥ V","adjuncts = {⟨N, {S, G, M, P, C}⟩} Lex = {⟨bad, [G,G]⟩, ⟨big, [S,S]⟩, ⟨the, =N[D,D]⟩, ⟨wolf, [N,N]⟩, ⟨woods, [N,N]⟩, ⟨in, =D[P,P]⟩}","Merge (the big bad wolf, [D,D])","(the, =N[D,D]) Adjoin (big bad wolf, [N,S]) (since S≥G and S∈ad(N))","(big,[S,S]) Adjoin","(bad wolf, [N,G]) (since G≥N and G∈ad(N)) (bad,[G,G]) (wolf,[N,N]) Figure 7: Valid derivation of the big bad wolf","*Bad big wolf, on the other hand, is not derivable without movement since the derivation remembers that big, which is at level S in the hierarchy, has already been adjoined. bad, being lower in the hierarchy, cannot adjoin. 17","Adjoin *bad big wolf (since G < S)","(bad, [G,G]) Adjoin","(big wolf, [N,S]) (since S≥N and S∈ad(N)) (big, [S,S]) (wolf, [N,N]) Figure 8: Invalid derivation of *bad big wolf","This next example shows a right adjunct, a PP, being adjoined to an NP. Since P||N – that is, no hierarchical order is defined between N and P – the PP adjoins to the right, but does not alter the category of the noun.","Adjoin ⟨wolf in the woods, [N, N]⟩ since P ∈ad(N) and P||N","Merge ⟨in the woods, [P, P]⟩","⟨in, = D[P, P]⟩ Merge ⟨the woods, [D, D]⟩ ⟨the, =N[D, D]⟩ ⟨woods, [N, N]⟩ ⟨wolf, [N, N]⟩ Figure 9: Right adjunction"]},{"title":"6 Discussion and extensions","paragraphs":["This model captures both the strict ordering of the merge-only models and the optionality and transparency to selection of the categorial approaches. Cinque’s observation that there is a hierarchy of functional heads and adverbs is modelled directly by defining a hierarchy in the grammar itself. The strict linear order falls out of the order imposed on the selectional features and the definition of Adjoin: adjunction is only defined when the hierarchy is respected. Optionality is the result of the transitivity of orders: intervening adjuncts are not necessary for a higher one to be adjoined. Transparency to selection is modelled by the pairing of the selectional features: the original category of the modified element is preserved, andMerge can see only that feature. The adjuncts are literally ignored.","The cross-linguistic consistency of the orders is accounted for by the claim that all human languages have the same partial order on sel. As such, it does not have to be learned, but rather comes with the grammar.","Computationally, this approach has an advantage over the merge-only model with homophony as the latter increases the size of the lexicon by a polynomial function in the depths of the hierarchies of adjuncts, but the former does not. 6.1 Left and right adjuncts As mentioned, I defined Adjoin to derive the asymmetry observed between left and right adjuncts in many languages: left adjuncts such as adverbs and descriptive adjectives are strictly ordered, while right adjuncts such as PPs and clauses are not. This fact is derived by letting the presence or absence of an ordering relation between the adjunct and modified category determine which case of Adjoin applies. If there is an order, the usual linear order will be calculated by Com, and the place in the hierarchy is tracked. Otherwise, the linear order is switched, and there is asymmetric feature checking.","If this is not the effect desired, there are alternatives. The simplest is to make the domain of the function ad sel × {right, left}, specifying the sets of right and left adjuncts. This allows for much more flexibility, for good or ill. It does not derive the asymmetry, but does allow ordered and unordered adjuncts to appear on the same side of the head, if such a pattern is desired. This is an empirical question. 6.2 Selection and adjuncts This model allows LIs that are in the set of adjuncts to be selected normally as arguments, since adjuncts have categories of their own. For example, Red Ridinghood was small is derivable by allowing was to select ⟨small, [S,S]⟩: ⟨was, =S[V,V]⟩. This is an improvement over models that do not give adjuncts categories of their own, such as Frey & Gärtner’s, but it is still lacking. In this model, there will have to be massive duplication in the lexicon so that was can select every adjective: ⟨was, =S[V,V]⟩, ⟨was, =G[V,V]⟩etc.","To solve this problem, we can take advantage of the function ad, and define was to select anything from a particular image under ad. Such a model expands the definition of Merge to operate not only on categories, but also on sets of categories. The model would look something like this:","Merge(⟨was, =ad(N)[V,V]⟩, ⟨small, [S,S]⟩) is defined iffS∈ ad(N)","Because the set of features F is finite, allowing Merge to be defined over subsets of F does not change the finite properties of MGs. Merge could in fact be allowed to be defined over any subset 18 of F . I suggest this model because it is restricted: only sets that exist for other reasons already can be quantified over.","MGAs also allow adjuncts to select arguments and license Move. For example, a preposition can select a complement before becoming an adjunct PP. Moreover, a functional projection such as Focus can Move a focused phrase into its specifier from the main tree, or Topic can Merge a specifier. The latter is a result of allowing positive polarity features to follow the category pair. Recall that in traditional MGs, an LI must be of the following form for the derivation to succeed, where each pi is a positive polarity feature, X, Y ∈ sel and each fi ∈ lic: (= Y(p1p2...pn))X(-f1-f2...-fm)","However, in MGAs, LIs of the following form are possible if the LI will Adjoin, the crucial difference being the presence of pn+1...pk: (= Y(p1p2...pn))[X, Y](pn+1...pk)(-f1-f2...-fm)","Figure 10 shows the end of a derivation in which the mover briefly is an adjunct, and so the licensor, the null Foc head. Its positive licensing feature +foc moves to the front of the stack of the derived structure’s features. Suppose Foc ∈ ad(T) and Foc ≥ T.","Move ⟨briefly she spoke, [T,Foc]⟩","Adjoin ⟨she spoke, +foc[T,Foc]⟩, ⟨briefly, -foc⟩","⟨ε, [Foc,Foc]+foc⟩ Merge ⟨she spoke, [T,T]⟩, ⟨briefly, -foc⟩ Figure 10: Adjunct FocP with moved specifier. 6.3 Adjuncts of adjuncts In natural language, adjuncts can also be adjoined to, for example as in the very bad wolf. The function ad maps single categories to their adjuncts, but it is not generally the case that, say, an adverb, can only adjoin to certain adjectives. In order to capture this fact without duplication in the lexicon, Adjoin, like Merge, can be extended to allow subsets of F . Similarly to the Merge case, we can restrict these subsets by requiring that they be the image of a category under ad. For example: ⟨frankly, [Fr,Fr]⟩, ⟨unfortunately, [Fo,Fo]⟩, ⟨allegedly, [Al,Al]⟩, ⟨bad, [G,G]⟩, ⟨wolf, [N,N]⟩∈ Lex Fr ≥ Fo ≥ Al ≥ V, S ≥ G ≥ N, P ad(N) = {S,G,P} ad(V) = ad(S) = ad(G)= {Fr,Fo,Al}","Adjoin","⟨unfortunately bad, [G,G]⟩","(since Fo||G and Fo∈ad(G)) ⟨unfortunately, [Fo,Fo]⟩ ⟨bad, [G,G]⟩ Figure 11: Adjoining to an adjunct","Notice however that we are still missing a generalisation: S,G, and indeed all adjectives have the same adjuncts. Now, this can be modelled by calling this set ad(ad(N)). However, such a solution assumes a special status for N over many other categories such as G: why ad(ad(N)) rather than ad(ad(G))? I would argue that such a status would reflect the reality of natural language. We can see N and V behaving in special ways: both are at the bottom of hierarchies, for example. However, as far as I am aware, no such status exists in any MGs. Formalising these observations is a matter for further research. 6.4 Islandhood Adjuncts have another classic property: islandhood. Movement is not possible out of certain types of adjuncts.","(8) a. You left [because your ex showed up]Adj b. *Who did you leave [because showed","up]Adj?","Any approach that keeps Adjoin separate from Merge introduces the option of stipulating the Adjunct Island Constraint (AIC), either as a separate constraint on Adjoin, as Frey & Gärtner do, or by simply not including moverss in the definition of Adjoin, making the function undefined when the adjunct carries movers. This is not very satisfy-ing, though: better perhaps would be to derive it, as Graf (2013) does. On the other hand, perhaps not all adjuncts are islands. If beside is an adjunct in (9), it is not an adjunct island. (9) Who are you sitting [beside ]Adjunct? As always, islands must remain a matter for further research."]},{"title":"7 Conclusion","paragraphs":["I have presented a model of adjunction that accounts for both the optionality and the strict or-19 dering of many adjuncts. MGAs accomplish this by the simple expedience of keeping track of two pieces of information at once: the original category of the projecting phrase, and the category of the most recent adjunct to adjoin. This allows Adjoin to be defined to only apply when the next adjunct is not lower in a hierarchy than the last. At the same time, Merge can see the original category, and ignores the adjunct’s category.","I have also suggested some extensions of MGAs to more efficiently account for adjuncts as the second argument of Merge and Adjoin. These involved quantification over categories, with the added suggestion that the sets of categories in question be restricted by the sets of adjuncts already defined.","Future directions for this research include not only matters internal to the model, such as how best to model adjuncts of adjuncts, but also larger questions of the mathematical properties of MGAs. MGAs are weakly equivalent to MGs, since MGAs merely take existing ways to derive certain strings and seek more efficient ways, which capture more generalisations. If every adjunct in the lexicon is replaced with the right set of selectors, Adjoin does not need to be used. For example, the adjectives in the MGA lexicon used in the examples in Section 5.1 can be replaced by the adjectives in either grammar from the selectional approaches in Section 4.2, and the same string set can be generated.","Clearly MGs and MGAs are not strongly equivalent: the derivation trees differ in that MGAs have a function that is not present in MGs.","Because the possible configurations of features remains finite, the derivation tree languages of MGAs should prove to be regular, following Kobele et al (2007)’s presentation: transition rules for Adjoin need merely be added.","Also of interest are the subregular properties of the derivation tree language. Although to my knowledge such notions as tierwise strictly local (Heinz et al., 2011) have not yet been formally defined for tree languages, I conjecture that in MGAs, Merge is tierwise strictly k-local, and Adjoin is strictly k-local."]},{"title":"References","paragraphs":["Noam Chomsky. 1995. The Minimalist Program. MIT Press, Cambridge, MA.","Gugliemo Cinque. 1999. Adverbs and functional heads: a cross-linguistic perspective. Oxford studies in comparative syntax. Oxford University Press, Oxford.","Gugliemo Cinque. 2010. The syntax of adjectives: a comparative study. Linguistic Inquiry monographs. MIT Press, Cambridge, MA.","Meaghan Fowlie. 2011. Multidominant minimalist grammars. Master’s thesis, University of California, Los Angeles.","Werner Frey and Hans-Martin Gärtner. 2002. On the treatment of scrambling and adjunction in minimalist grammars. In Proceedings of the Conference on Formal Grammar (FGTrento), pages 41–52, Trento.","Thomas Graf. 2013. The price of freedom: Why adjuncts are islands. Slides of a talk given at the Deutsche Gesellschaft für Sprachwissenschaft 2013, March 12–15, University of Potsdam, Potsdam, Ger-many.","Jeffrey Heinz, Chetan Rawal, and Herbert Tanner. 2011. Tier-based strictly local constraints for phonology. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Portland, Oregon, USA, June. Association for Computational Linguistics.","Edward L. Keenan and Edward P. Stabler. 2003. Bare Grammar. CSLI Publications, Stanford.","Gregory M. Kobele, Christian Retoré, and Sylvain Salvati. 2007. An automata-theoretic approach to minimalism. In J. Rogers and S. Kepser, editors, Model Theoretic Syntax at ESSLLI ’07. ESSLLI.","Luigi Rizzi. 2004. Locality and left periphery. In Adriana Belletti, editor, Structures and Beyond: The Cartography of Syntactic Structures, volume 3, pages 223–251. Oxford University Press, Oxford.","Edward Stabler. 1997. Derivational minimalism. Logical Aspects of Computational Linguistics, pages 68–95.","Edward Stabler. 2013. Bracketing paradoxes and opacity: Parsing late adjunction in copy constructions. Talk given at UCLA Mathematical Linguistics Circle, April. 20"]}]}