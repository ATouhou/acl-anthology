{"sections":[{"title":"","paragraphs":["Proceedings of the 11th International Conference on Finite State Methods and Natural Language Processing, pages 30–34, St Andrews–Sctotland, July 15–17, 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Processing Structured Input with Skipping Nested Automata Dominika Pawlik University of Warsaw Institute of Mathematics Aleksander Zabłocki University of Warsaw Institute of Informatics {dominika, olekz}@mimuw.edu.pl, b.zaborowski@ipipan.waw.pl Bartosz Zaborowski Polish Academy of Sciences Institute of Computer Science Abstract","paragraphs":["We propose a new kind of finite-state automata, suitable for structured input characters corresponding to unranked trees of small depth. As a motivating applica-tion, we regard executing morphosyntactic queries on a richly annotated text corpus."]},{"title":"1 Introduction","paragraphs":["Efficient lookup in natural language corpora becomes increasingly important, correspondingly to the growth of their size. We focus on complex queries, involving regular expressions over segments and specifying their syntactic attributes (e.g. “find all sequences of five nouns or gerunds in a row”). For such queries, indexing the corpus is in general not sufficient; finite-state devices come then as the natural tool to use.","The linguistic annotation of the text seems to be getting still more complex. To illustrate that, German articles in the IMS Workbench are annotated with sets of readings, i.e. possible tuples of the grammatical case, number and gender (an example is shown in Fig. 1a). Several other big corpora are stored in XML files, making it easy to extend their annotation in the future if so desired.","Hence, we consider a general setting where the segments are tree-shaped feature structures of fixed type, with list-valued attributes allowed (see Fig. 1a). A corpus query in this model should be a regular expression over segment specifications, being in turn Boolean combinations of attribute specifications, with quantifiers used in the case of list-valued attributes. We may also wish to allow specifying string-valued attributes by regular expressions. For instance, der Tisch /the tablemasculine/ is a match for the expression1 1","This example query is rather useless by itself; however, it compactly demonstrates several features which (variously combined) have been found needed in NLP applications. [ (POS ! = N ∨ WORD = \".*sch\") ∧ ∃i∈READ (i.GEND = m ∧ i.NUMB = sg) ]∗ describing sequences of segments having a masculine-singular reading, in which all nouns end with sch.","In this paper, we propose an adjustment of existing finite-state solutions suited for queries in such model. Our crucial assumption is that the input, although unranked, has a reasonably bounded depth, e.g. by 10. This is the case in morphosyntactic analysis (but often not in syntactic parsing)."]},{"title":"2 Related Work","paragraphs":["There are two existing approaches which seem promising for regex matching over structured alphabets. As we will see, each has an advantage over the other.","FSAP model. The first model relies on finite-state automata with predicates assigned to their edges (FSAP, (van Noord and Gerdemann, 2001)). (A FSAP runs as follows: in a single step, it tests which of the edges leaving the current states are labeled with a predicate satisfied by the current input symbol, and non-deterministically follows these edges). In our case, pattern matching can be realized by a FSAP over the infinite alphabet ofsegments: one segment becomes one input symbol, and segment specifications become predicates.","As showed by van Noord and Gerdemann, FSAPs are potentially efficient as they admit determinization. However, this involves some Boolean operations on the predicates used; as a result, testing predicates for segments might become involved. For example, a non-optimized (purely syntax-driven) evaluation of ∃x∈READ x.CASE = N ∧ ∃y∈READ y.CASE = G (1) would consist of two iterations over all the readings (one looking for N and another for G), although in fact one iteration is clearly sufficient. As 30 (a) se gment 2 6 6 6 6 6 6 6 6 6 4 WORD ‘der’ = list n d, e, r o POS D READ list 8 >>< >>: r eading 2 6 4 GEND m CASE N NUMB sg 3 7 5, r eading 2 6 4 GEND f CASE G NUMB sg 3 7 5 9 >>= >>; 3 7 7 7 7 7 7 7 7 7 5","(b)  ̨ ̨̨ ̨","  ̨ ̨̨ ̨"," ̨ D̨ ̨ ̨ ̨ ̨̨ ̨"," ̨ ̨̨ ̨ ̨ d̨ ̨ ̨ ̨ ę ̨ ̨ ̨ r̨ ̨ ̨ ̨ ̨̨ ̨ ̨ ̨̨ ̨  ̨ ̨̨ ̨"," ̨ ̨̨ ̨ ̨ m̨ ̨ ̨̨ N̨ ̨ ̨̨ s̨g ̨ ̨̨","̨̨","̨ ̨ f̨ ̨ ̨ ̨ G̨ ̨ ̨̨ s̨g ̨ ̨̨ ̨̨","̨","(c) 0 1 2 3   d e r D  m Nsg  f Gsg  ","# (d) 0 1 2 3 # D d e r m Nsg f Gsg Figure 1: A sample segment for the German ambiguous article der, which can be masculine nominative as well as feminine genitive (for brevity, other its readings are ignored), presented as a typed feature structure (a) and as an unranked tree (b). Note that strings are treated as lists, which ensures finiteness of the alphabet. We adjust the tree representation by labeling every non-leaf with and appending a new leaf labeled with to its children. Parts (c) and (d) show respectively the prefix-order and breadth-first linearizations of the tree. For legibility, we display them stratified wrt. the original depth. we will see, the other approach is free of this problem.","VPA model. Instead of treating segments as single symbols, we might treat our input as a bounded-depth ordered unranked tree over a finite alphabet (see Fig. 1b), which is a common perspective in the theory of XML processing and tree automata. Recently, several flavours of determinizable tree automata for unranked trees have been proposed, see (Comon et al., 2007), (Murata, 2001) and (Gauwin et al., 2008). Under our assumptions, all these models are practically covered by the elegant notion of visibly pushdown automata (VPA; see (Alur and Madhusudan, 2004)). As explained in (Alur and Madhusudan, 2009), executing a VPA on a given tree may be roughly understood as processing its prefix-order linearization (see Fig. 1b–c) with a suitably enhanced classical FSA. We omit the details as they are not important for the scope of this paper.","Discussion. FSAPs and VPAs both have potential advantages over each other. For the example rule (1), a naive FSAP will scan the input two times while a deterministic VPA will do it only once. On the other hand, the VPA will read all input symbols, including the irrelevant values of POS, GEND and NUMB, while a FSAP will simply skip over them.","We would like to combine these two advantages, that is, design a flavour of tree automata allowing both determinization and skipping in the above sense (see Fig. 2b for an example). Al-though this might be seen as a minor adjustment of the FSAP model (or one of the tree-theoretic models cited above), it looks to us that it has not been mentioned so far in the literature.2","Finally, we mention concepts which are only seemingly related. Some authors consider jumping or skipping for automata in different meanings, e.g. simply moving from a state to another, or compressing the input to the list of gap lengths between consecutive occurrences of a given symbol (Wang, 2012), which is somehow related but far less general. In some important finite-state frameworks, like XFST (Beesley and Karttunen, 2003) and NooJ, certain substrings (like +Verb) can be logically treated as single input symbols. However, what we need is nesting such clusters, combined with a choice for an automaton whether to inspect the contents of a cluster or to skip it over."]},{"title":"3 Skipping nested automata","paragraphs":["Let Σ be a finite alphabet, augmented with additional symbols , , # (see Fig. 1). We follow the definitions and notation for unranked Σ- trees from (Comon et al., 2007, Sec. 8), in particular, we identify a Σ-tree t with its labeling function t : N∗","⊇ P os(t) → Σ. For p ∈ P os(t), we denote its depth (i.e. its length as a word) by d(p).","Let p ∈ P os(t), d ≤ d(p) + 1 and s > 0. We define the (d, s)-successor of p, denoted p[d, s],","2","A sort of skipping is allowed in tree walking automata (Aho and Ullman, 1971), which can be roughly described as Turing machines for trees. However, they do not allow skipping over several siblings at once. Also, as shown in (Bojańczyk and Colcombet, 2006), they may be not determinizable. 31 to be the s-th vertex at depth d following p in the prefix order3",", and leave it undefined if this vertex does not exist. We also set p[d(p), 0] = p.","A skipping nested automaton (SNA) over Σ is a tuple A = (Q, QI , QF , δ, d), where Q (resp. QI , QF ) is the set of all (resp. initial, final) states, d : Q → N is the depth function and δ ⊆ Q × Σ × Q × N+ is a finite set of transitions, such that d(q) = 0 for q ∈ QI ,","d(q′ ) ≤ d(q) + 1 for (q, σ, q′",", s) ∈ δ. (The intuitive meaning of d(q) is the depth of the next symbol to be read when q is the current state, which leads to some kind of skipping. Introduc-ing s will allow performing more general skips).","A run of A on a Σ-tree t is a sequence ρ =( (pi, qi))n","i=0 ⊆ P os(t) × Q such that p0 = t(ε), q0 ∈ QI and for every i < n there is s ∈ N such that (qi, t(pi), qi+1, s) ∈ δ and pi+1 = pi[d(qi+1), s]. We say that ρ reads pi and skips over all positions between pi and pi+1 in the prefix order. We say thatρ is accepting if qn ∈ QF . A tree is accepted by A if there is an accepting run on it. An example is shown in Fig. 2.","A run ρ = (","(pi, qi))n","i=0 is crashing if there is (qn, t(pn), qn+1, s) ∈ δ such that pn[d(qn+1), s] is undefined. (Intuitively, this means jumping to a non-existent node). We say that A processes t safely if all its runs on t are not crashing. This property turns out to be important for determinization (see Section 4). A tree t is accepted safely if it is processed safely and accepted.","In practice, safe processing of trees coming from typed feature structures (as in Fig. 1) can be ensured with the aid of analyzing the types. For example, the SNA shown in Fig. 2 can assume state q2 only at (the start of) a reading, which must have four children; hence the skipping transition from q2 to q3 is safe. On the other hand, we cannot use e.g. a transition from q1 to q2 with s = 3 because a list (here, of readings) may turn out to have only one child. We omit a general formal treatment of this issue since it trivialises in our in-tended applications. 3 This is the s-th child of p if d = d(p) + 1, and the s-","th right sibling of the ` d(p) − d ́","-fold parent of p otherwise.","(Note that in the second case d(p) − d must be non-negative;","for d(p) − d = 0, the “ 0-fold parent” of p means simply p)."]},{"title":"4 (Quasi-)determinization","paragraphs":["A SNA A = (Q, QI , QF , δ, d) is deterministic if, for every q and σ, there is at most one (q, σ, q′",", s) ∈ δ. By quasi-determinization we mean building a deterministic SNA A = (Q, QI , QF , δ, d) which accepts safely the same trees which A does.","Let S denote the highest value of s appearing in A. We say that (q, r) ∈ Q × [0, S] is an option for A at p wrt. p0 if there is a run ρ of A on t which ends in (p0[d(q), r], q) such that p either is the final position of ρ or is skipped over by ρ in its last step. A state of A will be a set of possible options for A at a given position wrt. itself.","We define: Q = 2Q×[0,S]",", QI = { {(q, 0)} ∣ ∣ q ∈ QI } , QF = { X ∈ Q ∣ ∣ X ∩ (QF × {0}) ̸= ∅} .","d(X) = max (q,r)∈X d(q) for X ∈ Q. It remains to defineδ. For each X ∈ Q, σ ∈ Σ, it shall contain a tuple (","X, σ, X′′ , s)",", where X′′",", s","are computed by setting d = d(X), computing","X′ = { (q, r) ∈ X : d(q) < d ∨ r > 0 }","∪","{(q′",", r′",") : (q, σ, q′",", r′",") ∈ δ, (q, 0) ∈ X, d(q) = d},","(intuitively, this is the set of options for A at","p′ = p[d(p), 1] wrt. p, provided that p′","exists),","then setting d′","= d(X′",") and finally s = min { r : (q, r) ∈ X′",", d(q) = d′} ,","X′′","= {","(q, r) ∈ X′",": d(q) < d′} ∪ {","(q, r − s) : (q, r) ∈ X′ , d(q) = d′} .","(Explanation: p′′","= p[d′",", s] is the nearest (wrt. the","prefix order) ending position of any of the runs","corresponding to the options from X′","; hence A","may jump directly to p′′","; the options at p′′","wrt. p","are the same as at p′",", i.e. X′","; hence, the target X′′","is obtained from X′","by “re-basing” from p to p′′",".) While the trees accepted safely by A and A","coincide, this is not true for simply accepted trees.","For example, the tree t corresponding (in the","prefix order) toa# is accepted by A defined as q00","q11 q21 a (2)","q30 a (there is a run ending in q3) but not by A because for X = {(q1, 0)} and σ = a we obtain d(X′′",") = d(X′",") = 1 and s = 2, leading to a crash in the only run of A on t. 32 (a) q00 q11  (3) q22  q33  (2) Σ \\ {, G} q40 G q50 # (b) 0 1 2 3 q 0   d e r Dq 1 q 2 ","mq 3 N sg q 2  fq 3 G sg   q 4 #q","5 Figure 2: A SNA accepting a segment followed by # (end of input) and having a genitive reading (a), and its run on the segment from the previous figure (b). In part (a), numbers above states are their depths; numbers above dotted arcs are the values of s (not shown when s = 1). In part (b), the black symbols are read while the gray symbols are skipped over; this corresponds to the continuous and dotted arcs."]},{"title":"5 Practical use","paragraphs":["In order to make SNA applicable, we should explain how to build SNAs corresponding to typical corpus queries, and also how skipping should be efficiently performed in practice.","It is straightforward to build a non-skipping SNA for a regular expression e over Σ provided that e does not contain or inside ?, ∗","or +",", and all their occurrences are well-matched inside every branch of |. Under our assumption of bounded input depth, every regular expression can be transformed to an equivalent one of that form.","Skipping SNAs in our applications are defined by an additional regex construct _, matching any single sub-tree of the input. This is compiled into","s uΣ","(with d ≡ 0), which makes a skip if the input starts with . To enhance even longer skips, patterns of the form _{n} and e_∗","are suitably optimized. For example, the SNA of Fig. 2 recognizes _ __∗","_G_∗","_∗","_∗","#.","Proceeding to skipping in practice, we assume that, as a result of pre-processing, we are given the breadth-first linearization t̃ ∈ Σ∗","of the input (see Fig. 1d), stored physically as an array (for a given i, accessing t̃[i] takes a constant time), and that any occurrence of at position i is equipped with the pointer L(i) to its left-most child.4","More-over, we equip a deterministic SNA A with an array S such that, when A stays at p of depth d, S[i] should point to the (i, 1)-successor of p for all i < d.5","In this setting, the (d, s)-successor of the current position has index S[d] + (s − 1), which is computable in constant time. Hence, we are able to run A efficiently (Fig. 3 shows an example). In particular, the running time is independent of the number of input symbols skipped over. 4 Note that this is the way in which the original structure","would be stored in memory by a standard C implementation. 5 Upkeeping this requires only one memory access for ev-","ery processed; cf. (Alur and Madhusudan, 2004). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 3 4 # 5 7 D 1 2 11  d e r 2 2 6 14 2 2 6 18  m 3 2 6 12 N sg f 3 2 6 13 G sg Figure 3: A run of the SNA from Fig. 2 on the input from Fig. 1d. The numbers above are pointers to their left-most children. The bottom number in each frame indicates the current state; the remaining ones show the stack S (S[i] appears at depth i)."]},{"title":"6 Evaluation and conclusion","paragraphs":["A preliminary version of our method has been used for finding the matches of relatively complex hand-written patterns aimed at shallow pars-ing and correcting errors in the IPI Corpus of Polish (Przepiórkowski, 2004). As a result, although the input size grew by about 30% due to introduc-ing and nodes, over 75% of the obtained input was skipped, leading to an overall speed-up by about 50%. Clearly, empirical results may depend heavily on the particular input and queries. Hence, our solution may turn out to be narrowly scoped as well as to be useful in various aspects of XML processing. Note that, although the expressive power of SNAs as presented is rather weak, it seems to be easily extendable by integrating our main idea with the general VPA model.6"]},{"title":"References","paragraphs":["Alfred V. Aho and Jeffrey D. Ullman. 1971. Trans-","lations on a context-free grammar. Information and","6","This would require some technical adjustments, incl. replacing absolute depths of states with relative jump heights of transitions, and bounding these by 1. We skip the details due to space limitations. For very shallow inputs (including the Spejd’s case), these modifications would be rather disadvantageous. 33 Control, 19(5):439–475.","Rajeev Alur and P. Madhusudan. 2004. Visibly pushdown languages. In Proceedings of the thirty-sixth annual ACM symposium on Theory of computing, pages 202–211, New York, NY, USA. ACM.","Rajeev Alur and P. Madhusudan. 2009. Adding nesting structure to words. J. ACM, 56(3):16:1–16:43.","Kenneth R. Beesley and Lauri Karttunen. 2003. Finite State Morphology. CSLI Studies in Computational Linguistics. CSLI Publications.","Mikołaj Bojańczyk and Thomas Colcombet. 2006. Tree-walking automata cannot be determinized. Theor. Comput. Sci., 350(2-3):164–173.","H. Comon, M. Dauchet, R. Gilleron, C. Löding, F. Jacquemard, D. Lugiez, S. Tison, and M. Tommasi. 2007. Tree automata techniques and applications. http://www.grappa.univ-lille3. fr/tata. release October, 12th 2007.","Olivier Gauwin, Joachim Niehren, and Yves Roos. 2008. Streaming tree automata. Inf. Process. Lett., 109(1):13–17.","Makoto Murata. 2001. Extended path expressions for XML. In Peter Buneman, editor, PODS. ACM.","Gertjan van Noord and Dale Gerdemann. 2001. Finite state transducers with predicates and identities. Grammars, 4(3):263–286.","Adam Przepiórkowski. 2004. Korpus IPI PAN. Wersja wstępna. Institute of Computer Science, Polish Academy of Sciences, Warsaw.","Xiaofei Wang. 2012. High Performance Stride-based Network Payload Inspection. Dissertation, Dublin City University. 34"]}]}