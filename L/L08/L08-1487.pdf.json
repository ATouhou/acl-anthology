{"sections":[{"title":"Communicating Unknown Words in Machine Translation Matthias Eck, Stephan Vogel, Alex Waibel","paragraphs":["interACT Research Carnegie Mellon University, Pittsburgh, PA, USA","matteck@cs.cmu.edu, stephan.vogel@cs.cmu.edu, waibel@cs.cmu.edu Abstract A new approach to handle unknown words in machine translation is presented. The basic idea is to find definitions for the unknown words on the source language side and translate those definitions instead. Only monolingual resources are required, which generally offer a broader coverage than bilingual resources and are available for a large number of languages. In order to use this in a machine translation system definitions are extracted automatically from online dictionaries and encyclopedias. The translated definition is then inserted and clearly marked in the original hypothesis. This is shown to lead to significant improvements in (subjective) translation quality.",""]},{"title":"1 Introduction","paragraphs":["Every automatic machine translation system faces the problem of unknown words. Currently available corpora, especially for lower resource languages do not cover all possible words in a given language and new words are frequently added. It is for example estimated that the English language has a vocabulary of about 500,000 to 600,000 words with about 25,000 new words introduced each year (Kister, 1992).  The unknown word problem is especially severe for small portable translation systems, as here the vocabulary has to be limited to be able to put the translation system on the portable device."]},{"title":"2 Motivation","paragraphs":["At first an apparently small domain like tourism seems to be covered reasonably well by available corpora, e.g. the BTEC corpus (Takezawa et al., 2002) as evaluations do show (e.g. Fordyce, 2007), but this is not a real situation. Every potential user of such a translation system in the tourism domain will have a variety of interests, hobbies, and needs with potentially thousands of technical terms, that are not covered. Even worse is the situation in other domains like the medical domain, as here specialized technical terms are very common.  The following are two example translations from a medical baseline system translating Spanish → English, where one word each is unknown.  Baseline: revelan you have diabetes. Reference: they reveal that you have diabetes. Baseline: i am sure you will be getting a great mejoría in 4","or 5 weeks Reference: i am sure you will feel a great improvement in 4","to 5 weeks","Table 1: Example translations with references"," In both cases the rest of the sentence is translated very well, but especially in the second sentence the unknown word contains a lot of information as the patient will not know what he has to expect in 4 or 5 weeks. It is not even clear if it will be a positive or a negative event. The first sentence is relatively understandable, but there is the possibility that the unknown word might negate the actual sentence. A background lexicon can ameliorate this situation, but it will not be possible to have a lexicon covering all words.  Our approach is based on how a non-native speaker would handle the situation if he does not know the translation of a certain word he intends to communicate. The natural reaction will be to use a known synonym or generally describe the unknown word in other words. For example the translation of the word “biweekly” might not be known, but the explanations “twice a week” or “two times a week” contain more common words and should be easier to translate for a non-native speaker. In order to do this in a machine translation system the first goal is to automatically produce these explanations. Monolingual resources like dictionaries and encyclopedias contain this information and online versions are available. Wikipedia (www.wikipedia.org) specifically is an online encyclopedia in a variety of languages but other websites offer similar information and online dictionaries exist for a number of languages. The advantages of the monolingual sources are mainly an improved coverage. Monolingual resources contain far more vocabulary than any bilingual resource and their actual intention is to cover every word in a language. The most recent Oxford English Dictionary for example contains 616,500 word forms (Simpson and Weiner, 1989). Broad monolingual resources are also available in languages where parallel bilingual data might be very scarce. For all translation experiments a standard statistical machine translation system was used but this does not limit the applicability of the proposed approach. Any machine translation system is theoretically able to benefit from the approach."]},{"title":"3 Related Work","paragraphs":["Various other approaches to translate or deal with unknown words have been introduced before. One idea relies on morphological similarities to map the unknown words to actually known words as for example used in Mermer et al. (2007). This can give very good"]},{"title":"1542","paragraphs":["r lo a o in T in o to ( O f T i o w b c S h p la d G c e c la C p ( g f m p A v p c tr I r a a a s r o tr n c F A u h d h  results, especia ogically richer arise if the infle of speech. The n an incorrect p This approach i n Lepage and of Analogical L o the translatio 2007). Other groups in for unknown w Takaaki and Ma s used to be ab of the bilingua which an unkn both languages candidate. Some other ap here often spec primarily releva anguages are described in H Generally trans character and c examples and c can be benefici arge vocabular Closer related paraphrasing m 2006) and Co generate parap from bilingual meaning but c potentially mor Additional bilin vary in their paraphrases ca corpus and can ranslation task t should be po related to thes additional step after these app approaches ba shown very go reasonably clos other approach ransliteration a named entities comparable cor"]},{"title":"4","paragraphs":["Figure 1 show After a regular t unknown word have to be extra definitions are hypothesis. ally if the so r than the targe ectional differe approach will part of speech is comparable t Denoual (2005 Learning that w on of unknown nvestigated com word translation atsuo, 1999). I ble to compare al comparable own word pair s the pair is a proaches main cial transliterati ant if the chara different. Te Huang (2005) sliteration mod character group can produce a t ial to spell-che ry to correct sm to the approa methods describ ohn and Lapat hrases for unk texts. These p can be transla re common, w ngual corpora second langu an be extracted n later be applie k. ointed out that e approaches, to handle the proaches have ased on morph ood results, bu se words are in hes also have in approaches are or need addi rpora."]},{"title":"4 Propose","paragraphs":["ws an overview translation run ds. For these u acted and trans e introduced i ource language et language. A nce indicates a then produce t in the target la to the proportio 5). They used was later also di words in Lang mparable corpo ns (e.g. Fung an In these cases a e contexts in bo corpora. If th r occurs are of assumed to be nly target nam ion rules are ap acter sets of sou chniques are and Zhao e dels are introdu p transliteratio transliteration eck this hypoth mall transliterat ach presented bed in Callison ta (2007). The known words paraphrases ret ated as they c words as the or are necessary, uage. That m d from an En ed to an Englis t the presented but should b remaining un e been applie hological sim ut they can on n the translation nherent limitat e only applica itional bilingu"]},{"title":"ed Process","paragraphs":["w of the prop n the hypothesis unknown word slated. Finally in the origina e is morpho-A problem can a different part the translation anguage. onal analogies the technique irectly applied glais and Patry ora as a source nd Yee, 1998; a seed lexicon oth languages he contexts in ften similar in a translation med entities as pplied. This is urce and target for example et al. (2007). uced that learn on from given hypothesis. It hesis against a tion errors. here are the n-Burch et al. eir idea is to and n-grams tain the same contain other, riginal phrase. , but they can means English nglish-German sh → Spanish d approach is be seen as an known words ed. Especially milarities have nly be used if n lexicon. The tions, e.g. the able to certain al or at least osed process. s still contains ds definitions the translated al translation"]},{"title":"4.1 Ex","paragraphs":["Given an definition definition short and should al translatio translate t  Concerni two main (Example  Regular c","e.g.  Named en","e.g.  For regu standard short exp For our e (http://ww results fro coverage (http://ww Both dic necessary help to fi shown th common Figure 2 search ter Figure 1"]},{"title":"xtract Defini","paragraphs":["n unknown w n for this word n of an unknow d as easy to un lso not use any on system, as i the definition. ng the source n cases, depend es from the late content words ( Workforce, thr ntities: Cairo, Pennsy lar content wo online diction planations. experiments in ww.dictionary.c om various dic . For Spanis ww.wordrefere ctionaries list y a word sense find the best fi hat rare words words (Twilley shows the res rm “biweekly” : Process Over"]},{"title":"ition for Unk","paragraphs":["ord the first d in the source wn word shoul nderstand as th y words that a it would again for the defini ding on the typ er experiments (that are not na rice, ascertain, ylvania, McDon ords that are aries usually p n English we u com). Dictio ctionaries and s sh we used ence.com) (Kel multiple mean disambiguatio itting one at th are usually le y, 1994). sults from dict ”. rview"]},{"title":"known Word","paragraphs":["step is to find language. A u ld be unambig he original wo are unknown t n not be possib itions we iden pe of unknown ) amed entities): , biweekly, anc nalds, BMW not named en provide concis used dictionary onary.com m showed a very wordreference llogg, 1999). nings per wor on component his stage but it ess ambiguous tionary.com fo"]},{"title":"d","paragraphs":["d the useful guous, ord. It to the ble to ntified word cestry ntities e and y.com merges good e.com rd. If could t was s than or the"]},{"title":"1543 ","paragraphs":["Figure 2: Dictionary.com results for the search term \"biweekly\"  Named entities are a special case as regular dictionaries do not contain many actual named entities or specific brand names. An encyclopedia offers a better coverage here. For our experiments we used automatic extraction from Wikipedia articles. A problem is that Wikipedia articles can be extremely long and it is not useful to translate a long article just to communicate a single unknown word. However we found empirically that the first sentence of the Wikipedia article usually gives a good definition of the term if the term can be clearly defined."]},{"title":"4.2 Translation","paragraphs":["The next step is the actual translation of the extracted definition. Major issues here are potentially unknown words occurring in the definition. Especially named entity explanations tend to use further named entities that might also not be known to the translation system. For other content words the general impression is that the explanations tries to use more common words, which generally helps the translation system. Some dictionaries are specifically designed with this goal in mind, e.g. the Oxford 3000 is a list of 3000 common words that are used in the definitions in the Oxford Advanced Learners Dictionary (with few exceptions) (Wehmeier, 2007). On rare occasions a word is explained by using it again in a sentence. Another problem is that the style of the definitions can be very different from the domain of the actual translation system. In our example the translation system was trained on dialogs, a completely different style than the short and concise definitions. It could be valuable to further optimize or specifically design a translation system dedicated to translating this type of data."]},{"title":"4.3 Insert translated definition","paragraphs":["To finally produce the improved translation we have to introduce the translated definition into the baseline translation. Just replacing the unknown word with the definition is questionable as this might make the sentence unclear and confusing in the target language. For that reason we propose to clearly mark the definition as such and leave the decision if that definition clearly defines a word or a short phrase to the speaker of the target language. This way we avoid affecting the coherence of the rest of the sentence. Table 2 shows the two previous example sentences with translated and inserted definitions. Both sentences are clearly improved and are can be easily understood.  Improved hypothesis: (UNK: revelan # undiscovered it secret) you have diabetes Spanish definition: revelan: descrubrir lo secreto Baseline: revelan you have diabetes. Reference: they reveal that you have diabetes. Improved: i am sure you will be getting a great (UNK:","mejoría # getting better) in 4 or 5 weeks Spanish definition: mejoria: mejora","Baseline: i am sure you will be getting a great mejoría in 4","or 5 weeks","Reference: i am sure you will feel a great improvement in 4","to 5 weeks","Table 2: Sentences with inserted and translated definitions","compared to baseline and reference"]},{"title":"5 Experimental Results 5.1 Monolingual Experiments","paragraphs":["In our first experiment we wanted to see for how many monolingual English words we could extract a meaningful definition that would nicely explain the unknown word. For this experiment we chose the 16 reference translations of the IWSLT 2004 test set (Akiba et al., 2004) and determined all unknown words in those references compared to the English Full BTEC corpus (Takezawa et al., 2002). Overall 236 words out of the references are unseen and definitions for those were extracted automatically from dictionary.com. For this experiment the first definition was always chosen. One human subject (native English speaker) judged the adequacy of the extracted definitions on a scale of 1(worst) to 5(best) (compare Fordyce, 2007). The subject was asked to judge the adequacy as if the definitions were translations. The subject was also asked to assume the most common meaning for each word. Figure 3 shows the distribution of the different adequacy scores. For 46 words no definition could be extracted and the lowest score of 1 was assigned. These words include typographical errors, exclamations (“Yum”) and certain slang terms. 9 other words also received the lowest score, mainly due to definitions for unusual word meanings. 88 words overall received a score of 2 or 3. This was mainly due to incorrect conjugations or referring to an incorrect part of speech e.g.:  • summoning: To call together; to convene • locations: The act or process of locating  Most online dictionaries automatically project inflected word forms to the base form, which leads to these issues, but we expect these problems to be less severe than a score of 2 or 3 might suggest. 8 definitions received an"]},{"title":"1544","paragraphs":["adequacy score of 4, and 85 times the best score of 5 was assigned.  ","Figure 3: Monolingual adequacy score overview"," These results also indicate that the potentially different meanings are not a very significant problem as only 9 times a definition was judged incorrect because of an unusual meaning. The overall average score was 3.12."]},{"title":"5.2 Bilingual Experiments","paragraphs":["The actual question is however if it is possible to extract these definitions in a source language and translate the definitions to a target language while conserving the complete meaning of the extracted definition. This was investigated in this bilingual experiment.  Experimental Setup For training data we used the English-Spanish BTEC corpus. As mentioned the BTEC corpus contains dialog style tourism phrases. Overall 123,416 lines of bilingual data were available. A 500 line test set consisting of medical dialogs was used to test the approach translating from Spanish to English. The translation system used for the baseline translations and also the translation of the extracted definitions is a standard statistical machine translation system using an online phrase extraction method and a 6-gram language model trained on the English part of the bilingual training corpus (Vogel, 2003; Vogel, 2005; Eck et al., 2006).  Extracting definitions This test sets contains 289 unknown words in Spanish for which we tried to extract Spanish definitions from wordreference.com. For the first experiment the first definition was chosen as it is most likely the most common meaning. In a second experiment the definition with the lowest number of unknown words was chosen. The argument for this is simply as pointed out in section 4.2 that the definition has to be translated. For 86 words no definition could be extracted. As in the previous experiment these words are mainly typos, named entities and brand names that are not available in wordreference.com. For the remaining 203 words definitions were extracted. Those definitions contained on average 2.50 unknown words if the first definition was extracted and 1.71 unknown words if the definition with the lowest number of unknown words was chosen. Table 3 compares how often definitions with 0 to 2 unknown words could be extracted in both approaches.  # Unknown words First definition Lowest number of","unknown words 0 33x 57x 1 46x 61x 2 49x 46x >2 75x 39x Average/definition 2.50 1.71","Table 3: Unknown words in extracted definitions  The definitions were again subjectively judged for adequacy according to the scale in Table 4. Here the translations were inserted in the respective hypothesis sentences as described in section 4.3.  1 Worse than unknown word, misleading 2 No change compared to unknown word 3 Clear improvement 4 Good translation 5 Perfect translation","Table 4: Adequacy judgments for","bilingual experiments  A score of 1 was assigned if the translation became actually misleading and was clearly worse than the unknown word. This means the sentence had to make reasonable sense, but was also misleading. A score of 2 was assigned if the inserted definition did not give any benefit over the unknown word. This also means that the baseline score with all unknown words would be a score of 2. Scores 3 to 5 were assigned for improvements over the unknown word. Figure 4 illustrates the adequacy results.   Figure 4: Bilingual Adequacy score overview  Generally if more than 2 unknown words are in the definition the translations were useless and received a score of 2, which leaves 128 first definitions and 164 definitions with the fewest number of unknown words. The average adequacy score for those definitions is 2.55 for the first definitions and 2.51 for the definitions with the fewest number of unknown words, which is only 020406080100 12345 number  of  word s  Adequacy score 0 50 100 12345 nu mb er  of  wo rd s Adequacy score First definition Fewest unknown words"]},{"title":"1545","paragraphs":["slightly lower than the score for the first definition but it produced definitions for more words. A score of 1 was only assigned two times and three times respectively while a score of 5 (perfect translation) was never assigned. If only the definitions with 0 unknown words are considered the averages are 2.96 for the first definition (33 instances) and 2.67 (57 instances) for the definition with the fewest unknown words."]},{"title":"5.3 Translation Examples","paragraphs":["Table 5 shows some examples for translated definitions with 0 unknown words in the first definition (so it was also the definition with the fewest unknown words). Most examples show clear improvements.  Spanish word: innecesario Translated definition: is not it necessary Reference: unnecessary Spanish word: repetitivos Translated definition: to repeat Reference: repeat Spanish word: acidos Translated definition: you have taste sour Reference: acidic Spanish word: energías Translated definition: power be able Reference: energy Spanish word: intranquilas Translated definition: eager nervous Reference: stressful Table 5: Example translations with 0 unknown","words in the definitions  Table 6 compares the translations of the first definition with the translations of the definition with the fewest unknown words.  Spanish word: brota First definition: quite UNK the floor the UNK Fewest unknown: get out to the surface disease Reference: outbreak (disease) Spanish word: dolían First definition: quite UNK pain in a part of the","body Fewest unknown: causing consumers' pain Reference: sore Spanish word: asquerosa First definition: 4x UNK Fewest unknown: disgusting to have UNK Reference: disgusting Spanish word: radiante First definition: UNK bright Fewest unknown: very happy, or satisfied for","something Reference: radiating (pain)","Table 6: Comparison - Translations of the first definition and the definition with the fewest unknown words  This clearly illustrates the correlation between the number of unknown words and the quality of the translation. The last example shows one of the instances where the translated definition was judged worse than the unknown word. “radiante” is translated correctly but in this context describing “radiating pain” the incorrect and misleading meaning was chosen."]},{"title":"5.4 Extracting definitions from Wikipedia","paragraphs":["To extract definitions for named entities we used Wikipedia in preliminary experiments. Bilingual experiments were not done yet. However it is reasonable to assume that similar results as before can be achieved if concise definitions for the unknown words are available. This is also the main issue in Wikipedia as articles tend to be very long and not concise at all. As mentioned before we found empirically that the first sentence of an article tends to give a good definition if a concise definition is possible. Table 7 shows some examples. It is clear that the dialog partner has to have additional world knowledge to understand what is being defined to get to the actual term. However there could also be situations where the more general term e.g. “city” or “city in Egypt” for “Cairo” could be better than not having any translations. The last example shows an instance where the definition is not unambiguous (Bolivia is not the only landlocked country in South America).  Unknown word First Wikipedia sentence Cairo is the capital city of Egypt. Kilimanjaro is an inactive stratovolcano in","north-eastern Tanzania. Tempura  is a classic Japanese dish of deep fried lightly-battered vegetables or seafood. Nile  is a major north-flowing river in Africa, generally regarded as the longest river in the world.","Bolivia is a landlocked country in South America.","Table 7: Example definitions extracted from Wikipedia"]},{"title":"6 Conclusions & Future Work","paragraphs":["The experiments show that the proposed approach can give considerable improvements in communicating unknown words. The main limiting issues are remaining unknown words in the extracted definitions and the projection of inflected words to a base form, which can lead to differences concerning the part of speech. It could be shown that selecting a the definition with the lowest number of unknown words can improve this situation while the translation quality still improves. It might be valuable as noted before to develop specialized translation systems to translate the definitions as the domain mismatch in the experiments clearly influenced the translations. Further experiments with definitions for named entities extracted from Wikipedia articles will be necessary. It might also be valuable to"]},{"title":"1546","paragraphs":["investigate summarization approaches to improve the extraction of concise and unambiguous definitions from the long articles. The question how this can be included in a complete speech to speech translation system remains as well. It will most likely be necessary to type the unknown word in as it cannot be assumed that it is part of the speech recognition vocabulary. At that point the user could also be asked to select the most fitting definition from a number of presented options."]},{"title":"7 Acknowledgements","paragraphs":["This work is in part supported by grants from the US DARPA (TransTac project) and the National Science Foundation (STR-DUST project)."]},{"title":"8 References","paragraphs":["Yasuhiro Akiba, Marcello Federico, Noriko Kando, Hiromi Nakaiwa, Michael Paul, and Junichi Tsujii (2004). Overview of the IWSLT 2004 Evaluation Campaign. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT 2004), Kyoto, Japan.","Chris Callison-Burch, Philipp Koehn, and Miles Osborne (2006). Improved statistical machine translation using paraphrases. In Proceedings of the Human Language Technology Conference and the Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2006), New York City, NY, USA.","Trevor Cohn and Mirella Lapata (2007). Machine Translation by Triangulation: Making Effective Use of Multi-Parallel Corpora. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2007), Prague, Czech Republic.","Matthias Eck, Ian Lane, Nguyen Bach, Sanjika Hewavitharana, Muntsin Kolss, Bing Zhao, Almut Silja Hildebrand, Stephan Vogel, and Alex Waibel (2006). The UKA/CMU Statistical Machine Translation System for IWSLT 2006. In Proceedings of International Workshop on Spoken Language Translation (IWSLT 2006), Kyoto, Japan.","Cameron Shaw Fordyce (2007), Overview of the IWSLT 2007 Evaluation Campaign. In Proceedings of International Workshop on Spoken Language Translation (IWSLT 2007), Trento, Italy.","Pascale Fung and Lo Yuen Yee (1998). An IR approach for translating new words from non parallel, comparable texts. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 1998), San Francisco, CA, USA.","Fei Huang. Cluster-specific Name Transliteration (2005). In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT-EMNLP 2005), Vancouver, BC, Canada.","Michael Kellogg (1999), Wordreference.com, http://www.wordreference.com ","Ken Kister. Dictionaries defined. Library Journal, 6/15/92, Vol. 117 Issue 11, p43, 4p, 2bw","Philippe Langlais and Alexandre Patry (2007). Translating Unknown Words by Analogical Learning. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), Prague, Czech Republic.","Yves Lepage and Etienne Denoual (2005). ALEPH: an EBMT system based on the preservation of proportional analogies between sentences across languages. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT 2005), Pittsburgh, PA, USA.","Lexico Publishing Group, LLC, Dictionary.com, http://dictionary.reference.com.","Coskun Mermer, Hamza Kaya, and Mehmet Ugur Dogan (2007). The TÜBITAK-UEKAE Statistical Machine Translation System for IWSLT 2007. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT 2007), Trento, Italy.","John Simpson and Edmund Weiner (Editors) (1989) Oxford English Dictionary. second edition, Clarendon Press, 1989, twenty volumes, hardcover, ISBN 0-19-861186-2.","Tanaka Takaaki and Yoshihiro Matsuo. Extraction of translation equivalents from non-parallel corpora. In Proceedings of the International Conference on Theoretical and Methodological Issues in Machine Translation (TMI 1999), Chester, England.","Toshiyuki Takezawa, Eiichiro Sumita, Fumiaki Sugaya, Hirofumi Yamamoto, and Seiichi Yamamoto. Toward a Broad-coverage Bilingual Corpus for Speech Translation of Travel Conversations in the Real World. In Proceedings of the International Conference on Language Resources and Evaluation (LREC 2002), Las Palmas, Spain.","Leslie C. Twilley, Peter Dixon, Dean Taylor, and Karen Clark (1994). University of Alberta norms of relative meaning frequency for 566 homographs. Memory&Cognition, 22(1):111-126.","Stephan Vogel (2003). SMT Decoder Dissected: Word Reordering. In Proceedings of the International Conference on Natural Language Processing and Knowledge Engineering (NLP-KE 2003), Beijing, China.","Stephan Vogel (2005). PESA: Phrase Pair Extraction as Sentence Splitting. In Proceedings of MTSummit X, Phuket, Thailand.","Sally Wehmeier (editor) (2007). Oxford Advanced Learners Dictionary. Oxford University Press, 7th edition.","Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vogel (2007). A Log-linear Block Transliteration Model based on Bi-Stream HMMs. In Proceedings of the Human Language Technology Conference and the Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2007), Rochester, NY, USA."]},{"title":"1547","paragraphs":[]}]}