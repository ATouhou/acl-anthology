{"sections":[{"title":"Causal Relation Extraction Eduardo Blanco, Nuria Castell, Dan Moldovan","paragraphs":["Human Language Technology Research Institute, TALP Research Centre - LSI, Lymba Corporation The University of Texas at Dallas, Universitat Politècnica de Catalunya, Richardson - TX","eduardo@hlt.utdallas.edu, castell@lsi.upc.edu, moldovan@lymba.com","Abstract This paper presents a supervised method for the detection and extraction of Causal Relations from open domain text. First we give a brief outline of the definition of causation and how it relates to other Semantic Relations, as well as a characterization of their encoding. In this work, we only consider marked and explicit causations. Our approach first identifies the syntactic patterns that may encode a causation, then we use Machine Learning techniques to decide whether or not a pattern instance encodes a causation. We focus on the most productive pattern, a verb phrase followed by a relator and a clause, and its reverse version, a relator followed by a clause and a verb phrase. As relators we consider the words as, after, because and since. We present a set of lexical, syntactic and semantic features for the classification task, their rationale and some examples. The results obtained are discussed and the errors analyzed."]},{"title":"1. Introduction","paragraphs":["The automatic detection and extraction of Semantic Relations is a crucial step to improve the performance of several Natural Language Processing applications. For example, a Question Answering system will identify (1b) as the answer to (1a) only if it detects the causation encoded in (1b). 1. (a) Why do babies cry?","(b) Hunger is the most common cause of crying in a young baby. This work is focused on the detection and extraction of Causal Relations from open domain text. A discussion of what can be considered a causation and a formal definition can be found in (Hobbs, 2005). Broadly speaking, causation is a relation between two events: cause and effect. Cause is the producer of the effect, and effect the result of the cause. The rest of the paper is organized as follows. Section 2. provides insights on causation. Section 3. briefly describes previous approaches to extract causal knowledge. Section 4. presents the method proposed and the results obtained. Section 5. draws some conclusions and defines future lines of research."]},{"title":"2. Causal Relations","paragraphs":["Causal relations have been studied in several fields. (White, 1990) provides an overview of theories within the fields of Philosophy and Psychology. In Cognitive Linguistics, one of the most important theories is Force Dynamics (Talmy, 2000). 2.1. Causal Relations and other Semantic Relations Researchers have proposed different sets of Semantic Relations, ranging from a few to dozens. In this section, we relate CAUSATION to other relations. The closest semantic relation to CAUSATION is INFLU-ENCE. The distinction is a matter of degree: an INFLU-ENCE holds between event1 and event2 if event1 affects the manner or intensity of event2, but does not affect the occurrence (e.g. “Targeting skin cancer relatives improves screening.” ). CONDITION, CONSEQUENCE and REASON are subtypes of CAUSATION1",". CONDITION holds if the cause is hypothetical (e.g. “If he were handsome, he would be married.” ). CONSEQUENCE holds if the effect is indirect or unintended (e.g. “His resignation caused regret among all classes.” ). REASON holds if it is a causation of decision, belief, feeling or acting (e.g. “I went because I though it would be interesting.” ). A clear overlap exists between CAUSAL and TEMPORAL relations. By definition, the cause should always occur before the effect, i.e., if event1 causes event2, event1 should occur before than event2. 2.2. Encoding of Causation From the point of view of detecting Causal Relations, the following distinctions may be useful:","• Marked or unmarked: a causation is marked if there is a specific linguistic unit that signals the relation; un-marked otherwise. “I bought it because I read a good review” is marked; “Be careful. It’s unstable” isn’t.","• Ambiguity: if the mark signals always a causation, it is unambiguous (e.g. “because”). If it signals sometimes a causation, it is ambiguous (e.g. “since” ).","• Explicit or implicit: a causation is explicit if both arguments are present; implicit if one or both are miss-ing. “She was thrown out of the hotel after she had run naked through its halls.” is explicit; “John killed Bob.” is implicit, since the effect, Bob’s death, is not explictily stated. We focus on marked and explicit causations."]},{"title":"3. Previous Work","paragraphs":["Several attempts have been made in order to extract causal knowledge from text. The older approaches used handcoded and domain-specific knowledge bases (Kaplan and Berry-Rogghe, 1991). 1 In this work we consider all of them as CAUSATION."]},{"title":"310 no. Pattern Productivity Example","paragraphs":["1 [VP rel C], [rel C, VP] 63.75 % We didn’t go because it was raining. 2 [NP VP NP] 13.75 % The speech sparked a controversy. 3 [VP rel NP], [rel NP, VP] 8.12 % He died of cancer. 4 other 14.38 % The lighting caused the workers to fall. Table 1: Syntactic patterns expressing causation, their productivity and examples.","Example","relator encoding causation not encoding causation","after Marty stood with his mouth hanging open","foolishly after it had happened. The executions took place a few hours after the radio announced their conviction.","as There was no debate as the Senate passed the bill on to the House. It has a fixed time, as collectors well know.","because He had to leave early because he was feeling bad. —","since He had to depend on himself, since he was miles away from others. It was the first time any of us had laughed since the morning began. Table 2: Examples of instances encoding and not encoding causation. (Khoo et al., 2000) focused on the medical domain; (Garcia, 1997) developed a system based on Force Dynamics. (Girju and Moldovan, 2002) defined a set of semantic constraints to rank possible causations. Newer approaches use Machine Learning (ML) techniques (Girju, 2003; Chang and Choi, 2006). Those systems are more robust and yield higher performance, with F-measures around 0.8."]},{"title":"4. The Method","paragraphs":["Our method for the detection and extraction of causations is based on the use of syntactic patterns that may encode causation. We then redefine the problem as a classification between two classes: encoding or not encoding causation (cause or ¬cause). 4.1. Syntactic patterns that encode causation We manually classified 1270 sentences from the TREC5 corpus into encoding or not encoding causation; 170 in-trasentencial causations were found. The sentences encoding causation were manually clustered into the syntactic patterns shown in table 1. rel stands for relator, which can be either a preposition or conjunction. The manual clustering allowed us to realize that the four most common relators encoding causation are after, as, because and since. Because pattern 1 comprises more than half of the causations found, we focused only on pattern 1 and these four relators. From now on, instance means an instance of pattern 1 signaled by one of relators considered. Note that an instance not always encodes a causation. Some examples can be found in table 2. 4.2. Pattern Matching We performed our experiments using the semantically an-notated SemCor 2.1 corpus. 1068 instances were found.","Relator Occurrences encoding causation Causations signaled after 15.35 % 6.85 % as 11.21 % 7.34 % because 98.43 % 73.39 % since 49.61 % 12.52 % Table 3: Statistics of the causations found. They were manually classified2","into cause and ¬cause; 517 causation were detected3",". Table 3 shows statistics of the instances depending on the relator. All the instances considered encode the cause in the VP contained in C (V PC) and the effect in the first V P , e.g., “He, too, [was subjected]V P to anonymous calls [after]rel [he [scheduled]V PC the election]C”. The extraction of cause and effect is done at the same time than the pattern matching. 4.3. Feature Selection The features considered in our experiments are depicted in table 4. The set came up during the manual classification. It was a slow task, but it allowed us to get a better understand-ing of the nature of causation. By semantic class we mean the most common subsumer in WordNet 2.1. A verb sense is potencially causal if its gloss or any of its subsumers’ glosses contains the words cause to or change. Out of all the features considered, only the following are useful for discriminating between cause and ¬cause: relator, relator left and right modifiers, semantic class cause verb, cause verb is potentially causal, cause verb is past 2 Only one annotator fulfill the task, so we cannot report inter-","annotator agreement. 3 This means the baseline for the classification task is 0.516."]},{"title":"311 Feature Rationale Examples Relator","paragraphs":["A relator can encode a causation always or sometimes - [cause] “Leadership is lacking in our society because it has no legitimate place to develop.” - [¬cause] “We had met two years after she had arrived.” - [cause] “Marty stood for several moments with his mouth hanging open foolishly after it had happened.” Relator left and right Modifiers causations can hardly be signaled by a relator modified by some POS tags - adverb + after almost always signals a temporal relation, not a causation: “This was long after Morse had left the house.” - as + preposition can hardly signal a causation: “. . . he felt he was noting it, as if it were . . . ” Semantic Class Cause Verb only certain verb senses can express a cause - if the relator is after and the cause verb semantic class is be-v-3, then it is a temporal relation, not a causation: “We heard him yelling after he was out of sight.” Cause Verb is Potentially Causal if a verb sense is potencially causal, then is more likely to express a cause - ring-v-1 is subsumed by sound-v-2, which gloss is “cause to sound ” Semantic Class Effect Verb only certain verbs can express an effect - If the relator is after and the effect verb semantic class is express-v-2, then is not a causation: “My name’s Gisele”, the blonde said after she ordered a Scotch”. Effect Verb is Potentially Causal if a verb sense is potencially causal, then is more likely to express an effect - walk-v-3 is subsumed by travel-v-1, which gloss is “change location” Verb Tense Cause and Effect Verb depending on the relator, some verb tenses are not likely to express causation - If the relator is as or after, the cause verb is present and it is not a copula, then is not a causation: [¬cause]: “Henrietta was discovering, as the born writer does, not merely . . . ” ; [¬cause]: “To play the guitar as he aspires will devour his . . . ” - If the relator is as and the effect verb is conditional, then is not a causation: “She wouldn’t go as Maude suggested.” - If the effect verb is progressive, then is not a causation: “The burden of his secret was pressing down on him, as it was on them.” - If the effect verb es passive, then it is more likely to express a causation: “. . . and then Richard was shocked as, all at once, flames shot out from the sharp features of . . . ” Table 4: Features considered for the Machine Learning approach. and effect verb is perfective. Note that the semantic features for the effect verb aren’t in this set. We added a new feature, lexical clue, which allows as to discard some missmatches. lexical clue is true if between the relator and VPC there is a ‘,’, ‘and’ (e.g., “He went as a tourist and ended up living there.” ) or another relator (e.g., “City planners do not always use this boundary as effectively as they might” ). 4.4. Machine Learning algorithm Class Precision Recall F-Measure cause 0.969 0.839 0.899 ¬cause 0.865 0.975 0.917 Table 5: Results obtained during training. The 1068 instances were divided into training (75%) and test (25%). As a learning algorithm, we used an implementation of Bagging with C4.5 decision trees (Witten and Frank, 2005). Table 5 and 6 show the results obtained with the training and test instances respectively. The F-measures Class Precision Recall F-Measure cause 0.955 0.842 0.895 ¬cause 0.869 0.964 0.914 Table 6: Results obtained during testing. obtained during training are very close to the ones obtained during test, meaning that the model was able to generalize the training examples. Analyzing table 3 we can easily conclude that most of the causations are encoded by the relators because and since. The model learned is only able to classify correctly the causations signaled by these two relators. When the relator is because, it always classifies the instance as cause; when it is as or after, as ¬cause; when it is since the model decides between the two classes based on the values of the features. The results obtained when the relator is since are shown in table 7. Again, the results are good. The results obtained are difficult to compare with other works, since we focus on a different pattern. (Girju, 2003; Chang and Choi, 2006) obtained a F-measure of 0.80 and"]},{"title":"312 Class Precision Recall F-Measure","paragraphs":["cause 0.957 0.846 0.898 ¬cause 0.878 0.966 0.920 Table 7: Results obtained with the examples signaled by since during testing Class Precision Recall F-Measure cause 0.541 0.713 0.615 ¬cause 0.628 0.445 0.521 Table 8: Restults obtained using only the semantic features. 0.81 respectively. 4.5. Error Analysis Most of the error is due to the inability to dicriminate between cause and ¬cause when the causation is signaled by as or after. More training data and another set of features may improve the results. We can find examples in the training corpus belonging to different classes and with exactly the same values for the features, e.g., sentence (1) and sentence (2) have the same values for all the features except for the semantic ones.","1. [cause]They [arrested]V P him [after]rel [he [assaulted]V PC them]C. 2. [¬cause]He [left]V P [after]rel [she [had]V PC left]C. A common way to solve the problem would be to para-phrase sentence (2). However, if we change the relator for because, the sentence encodes a causation: “He left because she had left”. Paraphrasing does not seem to be a possible solution. One of the best rules learned states that when the relator is since and the effect verb is perfective tense, it doesn’t encode a causation. However, the rule does not always work, e.g., [cause]: “Less than half the sum [has been spent]V PC , [since]rel [the board [pinched]V PC pennies during that negotiation]C.” Examining the trees learned we can conclude that most of the possible semantic classes are not covered. The semantic features are only useful when the rest are not enough to discriminate, and when this occurs the number of instances left to classify is low, so most of the possible semantic classes are not covered. We believe more data may improve the results. The results obtained when only using the semantic features (semantic classes cause and effect verb, cause and effect verb are potencially causal) are the shown in table 8."]},{"title":"5. Conclusions and Further Work","paragraphs":["We have proposed a system for the detection of marked and explicit causations between a verb phrase and a subordinate clause which yields a high performance. The system is relatively simple and is able to detect causations from open domain text. So far research has focused on causations expressed with noun phrases, e.g. “The [incident]NP1 provoked [widespread protest]NP2’. A key element to really see the potential of the method would be to integrate it with a system that extracts other semantic relations. We could experiment with inference rules that combine CAUSATION and other semantic relations. For example, if event1 causes event2 and event3 is subsumed by event1, then event3 causes event2; if event1 causes event2 and event2 entails event3, then event1 causes event3. Another possible inference rule would express the transivity property of causations. To address implicit causations another system is needed. We hypothesize that working with verbs that encode part of the effect (e.g. kill, melt, drop, anger) may help. Another possible extension would be to deal with causal chains, e.g. (1), and intricate causal relations, e.g. (2). A causal chain can be defined as a sequence of events that lead up to some final effect.","1. Artworks become art when they transcend the simple facts of their existence, and they can do that only when they blend with the viewer.","2. It is lined primarily by industrial developments because the constant traffic do not make it an attractive neighborhood."]},{"title":"6. References","paragraphs":["Chang, D.-S. and Choi, K.-S. (2006). Incremental cue phrase learning and bootstrapping method for causality extraction using cue phrase and word pair probabilities. Information Processing and Management: an International Journal, 42(3):662–678.","Garcia, D. (1997). Coatis, an nlp system to locate expressions of actions connected by causality links. In EKAW ’97: Proceedings of the 10th European Workshop on Knowledge Acquisition, Modeling and Management, pages 347–352.","Girju, R. (2003). Automatic detection of causal relations for question answering. In Proceedings of the 41st ACL, Workshop on Multilingual Summarization and Question Answering.","Girju, R. and Moldovan, D. (2002). Mining answers for causation questions. In Proceedings of the American Association for Artificial Intelligence (AAAI) - Spring Symposium.","Hobbs, J. R. (2005). Toward a useful concept of causality for lexical semantics. Journal of Semantics, 22(2):181– 209.","Kaplan, R. M. and Berry-Rogghe, G. (1991). Knowledge-based acquisition of causal relationships in text. Knowl. Acquis., 3(3):317–337.","Khoo, C. S. G., Chan, S., and Niu, Y. (2000). Extracting causal knowledge from a medical database using graphical patterns. In ACL ’00: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, pages 336–343, Morristown, NJ, USA.","Talmy, L. (2000). Toward a Cognitive Semantics. MIT Press.","White, P. (1990). Ideas about causation in philosophy and psychology. Psychological Bulletin, 108(1):3–18.","Witten, I. and Frank, E. (2005). Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann."]},{"title":"313","paragraphs":[]}]}