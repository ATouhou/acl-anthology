{"sections":[{"title":"Sign Language Corpus Annotation: Toward A New Methodology Emilie Chételat-Pelé and Annelies Braffort","paragraphs":["LIMSI/CNRS, Orsay, France","Provence University, Aix-en-Provence, France","Emilie.chetelat@limsi.fr, annelies.braffort@limsi.fr","  Abstract  This paper deals with non manual gestures annotation involved in Sign Language within the context of automatic generation of Sign Language. We will tackle linguistic researches in sign language, present descriptions of non manual gestures and problems lead to movement description. Then, we will propose a new annotation methodology, which allows non manual gestures description. This methodology can describe all Non Manual Gestures with precision, economy and simplicity. It is based on four points: Movement description (instead of position description); Movement decomposition (the diagonal movement is described with horizontal movement and vertical movement separately); Element decomposition (we separate higher eyelid and lower eyelid); The use of a set of symbols rather than words. One symbol can describe many phenomena (with use of colours, height...). First analysis results allow us to define precisely the structure of eye blinking and give the very first ideas for the rules to be designed. All the results must be refined and confirmed by extending the study on the whole corpus. In a second step, our annotation will be used to produce analyses in order to define rules and structure definition of Non Manual Gestures that will be evaluate in LIMSI’s automatic French Sign Language generation system."]},{"title":"1. Introduction","paragraphs":["The French Sign Language (LSF) is the visuo-gestural language practised by the French deaf community. Research on the LSF, as for all the Sign Languages (SL), requires to built and analyse video corpora. This paper tackles non manual gestures annotation within the context of SL research. Non manual gestures (NMGs) annotation, like co verbal annotation, lead to description problems: how to describe a movement? This communication presents an annotation methodology, which allows non manual gestures description involved in SL. The first part presents actual descriptions of NMGs and problems lead to movement description. In the second part, we propose a new methodology, which allows us precise NMGs description. The third part, finally, presents an application of this methodology and our firsts results."]},{"title":"2. Non Manual Gestures Description","paragraphs":["Sign languages are made up of manual signs and non manual signs (movement of the eyes, eyebrows, mouth, cheeks and head), that is defined as non manual gestures (McCalve, 2002) or NMGs. Many researches in SL emphasize the importance of NMGs at different language levels (lexical, syntactical, pragmatic...) (Liddell, 1980; Coerts, 1992; Vermeerbergen, 1998). Plus, these researches recognize that NMGs are essentials for the message comprehension. More particularly, studies on LSF can show the main functions of NMGs like the modality expression, the adjective production... (Cuxac, 2000; Vergé, 2001). For example, at the lexical level, figures 1 and 2 (Moody"]},{"title":"1986)","paragraphs":["show that the difference between ‘happy’ and ‘I feel sick’ in LSF is only the face’s expression. "," Figure 1: ‘Happy’ in LSF. Figure 2: ‘I feel sick’ in LSF. However these linguistic researches can’t yet explain and define the way that NMGs operate to assume these functions. Therefore, systems of LSF automatic generation do not deal with NMGs. That implies comprehension problems for deaf people. A specific NMGs study could allow us to know when and how NMGs are involved in meaning transmission and information comprehension, in order to design a formal description usable by automatic generation system. This study involves precise description of NMGs. At present, descriptions are symbolical and need instantiation for the animation software (for example “sad expression” is not understandable by the animation software and need formals definitions) (Chételat-Pelé, Braffort, Véronis, 2007). Transcription systems, like HamNoSys (Prillwitz and Zienert, 1989), figure 3, are closer to this instantiation but describe only NMGs position (for example \"eyebrows high\", at the right on the figure).   Figure 3: ‘What’ with HamNoSys system. This type of description relates to a given instant and does not allow us to deal with and to observe the movement intensity and dynamics. For example, for a description such as “Eyebrows high”, we would like to know the movement intensity and the rising duration. Thus, these systems are not accurate enough to study the importance of these elements in the meaning transmission.   "]},{"title":"668 3. Toward a new methodology","paragraphs":["Our purpose is to have an objective and precise description of all NMGs involved in LSF within the context of automatic processing of LSF. Then, we propose a new annotation methodology, which is presented in this section. This methodology can describe all NMGs with precision, economy and simplicity. It is based on the use of a set of symbols rather than words. Moreover, one symbol can describe many phenomena (with use of colors, height...). For example, we use one symbol for the rising and the color of this symbol changes according to intensity (Figure 4). Thus, the number of symbols is very small (Figure 5).   Figure 4: Different degrees of intensity.   Figure 5: Symbols used. This description is based on three points:","- elements decomposition: for example we separate the higher eyelid and the lower eyelid;","- movement decomposition: for example, the diagonal movement of shoulders is described with an horizontal movement and a vertical movement separately;","- movement description (instead of position description): for example: \"eyelid lowering\" instead of \"low eyelid\". The definition of each movement depends on the previous movement The decomposition of elements allows us to acquire points, which move only on simple lines (Frontal line, vertical line and lateral line). Thus the description is easier and precise. Finally, annotating a movement rather a position allows us to describe all observed phenomena, even those, which could seem less central. Then it is possible to annotate first and choose secondly the pertinent phenomena. Moreover, this methodology gives us the possibility to study all phases of the movement. In fact, a movement is made up of three phases: transition between the first position and the second position; stop on the second position and transition between the second position and the first or another position (Figure 6).   ","  Figure 6: Phases of movement. The duration of these phases can vary according to the context. For example, an eye blinking lasts, on average, 0,2 seconds (Chetelat-Pelé, Braffort, Véronis, 2007). But the closure of the eyelid can vary between 0,04 and 0,12 seconds (figure 7) according to the context leading to a different meaning. Figure 7: Closure duration of higher eyelid in a blinking. Thus, if each movement is annotated by specifying these three phases, it is possible to study the importance of each phase in the comprehension process."]},{"title":"4. Application of the methodology","paragraphs":["This methodology was applied on the LS-COLIN corpus (Braffort et al, 2001; Segouat, Braffort, Martin, 2006). The LS-Colin corpus was build with the double aim to provide data for linguists who want to highlight the iconicity of the LSF, and to provide good quality pictures for computer scientists working on image processing (Segouat, Braffort, Martin, 2006). This corpus was recorded with three cameras, providing three shots: close-up, frontal and upper. With such a kind of corpora, linguists and computer scientists can work together on the same video in order to perform complementary analysis. For our part, we used the close-up shot (figure 8) and annotated movement of the eyes, eyebrows, mouth, cheeks, shoulders and head.             Figure 8: LS-Colin corpus, close-up view. One second of LS-COLIN corpus comprises 25 frames. Annotation was made frame by frame on 3 persons (for a total of 8 minutes). We used Anvil software (Kipp, 2004) because it allows us to describe and play the video in the same time (Figure 9) and offers the possibility to use personal icons, which is of primarily importance for us, and colour, which is very useful to capture global organisations in the annotation (Figure 10). The figure 9 shows the four windows of Anvil: The top left (a), is the edit window (for selecting and playing the video frame by frame...); the middle (b) is the"]},{"title":"669","paragraphs":["video window; to the right (c) there is the attribute window (for annotate) and at the bottom (e) is the annotation window.   Figure 9: Anvil Software. Annotation (Figure 10) is made up of two parts: at the left are the elements to annotate and at the right is the annotation with time axis from left to right. The first line shows the eyebrows movements: The first symbol is a slightly rising (first degree); the second symbol is the position keeping and the third symbol is a new slightly rising. Thus, one first degree rising plus one first degree rising result in a new position higher (second degree: the arrow colour changes) (symbol number 4). Second line shows the higher eyelid movement: we have two eye blinks (in green) with two phases (closure and opening). Then in blue, we see a rising eyelid (second degree). The third line represents lower eyelid movement. The blue color shows a rising and the yellow color represents a wrinkled eyes. Colors are very precious for analysis. For example, we can study the influence of the local phenomena on the utterance level: here, in figure 10, the blue part on the three lines corresponds to the expression of surprise (eyebrows high, eyes very open...) and the yellow part corresponds to a sign which needs wrinkled eyes. Thus, it is possible to study the duration and the importance of each element. For the blinking of the eyes, the annotation shows that their positions are accurate and probably constrained. Indeed, frequency of eye blink varies between three eye blinks in 0.01 second and only one in 18.5 seconds. Moreover, these eye blinks are present between two signs in 70% of cases. The staying 30% are the signs repetition and the specific signs like ‘explosion’, which need a blink. This first annotation showed that this methodology is an answer to our purpose: all NMGs can be described, with few symbols. Moreover, the dynamics of the movement can be analysed, and each phase of it separately. Finally, first analysis results allow us to define precisely the structure of eye blinking and eyebrows and give the very first ideas for the rules to be designed. This methodology must be evaluate and each symbol must have a numerical instantiation (Chételat-Pelé, Braffort, Véronis, 2008)."]},{"title":"5. Conclusion","paragraphs":["Our study tackles NMGs annotation within the context of SL research. Annotation system needs precisions for their instantiation in the animation software. We have presented in this paper a new annotation methodology based on the use of a set of simple symbols, the corporal element decomposition, the movement decomposition and the movement description. In a small subset of a LSF corpus, this methodology allows us to describe all NMGs with precision, each movement phase separately. All the results must be refined and confirmed by extending the study on the whole corpus. In a second step, our annotation will be used to produce analyses in order to define rules and structure definition of NGM that will be evaluate in LIMSI’s automatic LSF generation system.                   Figure 10: Annotation Extract.      "]},{"title":"670 6. Références","paragraphs":["Braffort, A. ; Choisier, A. ; Collet, C. ; Cuxac, C. ; Dalle, P. ; Fusellier, I. ; Gherbi, R. ; Jausions, G. ; Jirou, G. ; Lejeune, F. ; Lenseigne, B. ; Monteillard, N. ; Risler, A. ; Sallandre, M.-A. (2001). Projet LS-COLIN. Quel outil de notation pour quelle analyse de la LS ?. In Journées Recherches sur la langue des signes. UTM, Le Mirail, Toulouse.","Chetelat-Pele, E.; Braffort, A. ; Véronis, J. (2007). Mise en place d'une méthodologie pour l'annotation des gestes non manuels. In TALS 2007. Traitement Automatique des Langues des Signes 2007 : atelier de Traitement Automatique des Langues Naturelles 2007. Toulouse, France.","Chetelat-Pele, E.; Braffort, A. ; Véronis, J. (2008). Sign Language Corpus Annotation: Toward a New Methodology. In LREC 2008. Conference on Language Resources and Evaluation : Workshop Construction and Exploitation of Sign Language Corpora 2008 . Marrakesh. (To appear).","Coerts J. (1992). Nonmanual grammatical markers. An analysis of interrogatives, negations, and topicalisations in sign language of the Netherlands. Dissertation, Amsterdam University.","Cuxac C. (2000). La Langue des Signes Française: Les voies de l’iconicité. Faits de Langues. Paris : Ophrys.","Kipp M. (2004). Gesture Generation by Imitation - From Human Behavior to Computer Character Animation\", Boca Raton, Florida: Dissertation.com.","Liddell S. (1980). American Sign Language Syntax. The Hague : Mouton Publishers.","Mcclave E. (2002). Non-manual Gestures in American Sign Language. In Gesture: the living Medium, Austin, TX, June 5-8. 2002 Manuscript.","Moody B. (1986). La langue des signes - Tome 2: dictionnaire bilingue élémentaire. International Visual Theatre (I.V.T.). Editions Ellipses. Paris","Prillwitz S. & Zienert H. (1989). Hamburg Notation System for Sign Language: Development of a sign writing with computer application. Allemagne : S. Prillwitz & T. Vollhaber (Eds.): Current trends in European Sign Language Research, Signum.","Segouat, J.; Braffort, A.; Martin, E. (2006). Sign language corpus analysis: synchronisation of linguistic annotation and numerical data. LREC 2006. Fifth International Conference on Language Resources and Evaluation, Genoa, Italy : 2006","Verge F. (2001). Le regard en Langue des signes française. Thèse de doctorat de Sciences du Langage, Université de Toulouse.","Vermeerbergen M. (1998). More than Hands Can Say : The use of Nonmanual Linguistic Features in Flemish Sign Language. In: Santi, Serge et al (eds): Oralité et gestualité. Communication multimodale, interaction. Actes du colloque Orange 98. Paris : L'Harmattan (1998) - pp. 119-124 "]},{"title":"671","paragraphs":[]}]}