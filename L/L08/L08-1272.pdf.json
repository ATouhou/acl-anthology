{"sections":[{"title":"Towards\\b\\tem\\f\\bAutomat\\fc\\bConstruct\\fon\\bof\\ba\\bLex\\fcal\\bOn tology\\bfor\\bPers\\fan\\b Mehrnou\\bh\\tSha\\f\\bfard\\t","paragraphs":["NLP Rese\\b\\tch L\\b\\fo\\t\\bto\\ty,","F\\bculty of Elect\\tic\\bl & Compute\\t Enginee\\ting,","Sh\\bhid Beheshti Unive\\tsity, Teh\\t\\bn, I\\t\\bn","E-m\\bil: m-sh\\bms@s\\fu.\\bc.i\\t Abstract\\b\\b Lexical\\b\\tnt\\tl\\t\\fies\\band\\bsemantic\\blexic\\tns\\bare\\bimp\\trtant\\bres\\turces\\bin\\bnatural\\blan\\fua\\fe\\bpr\\tcessin\\f.\\bThey\\bare\\bused\\bin\\bvari\\tus\\btasks\\band\\b applicati\\tns,\\bespecially\\bwhere\\bsemantic\\bpr\\tcessin\\f\\bis\\bev\\tlved\\bsuch\\bas\\bquesti\\tn\\banswerin\\f,\\bmachine\\btranslati\\tn,\\btext\\bunderstandin\\f,\\b inf\\trmati\\tn\\bretrieval\\band\\bextracti\\tn,\\bc\\tntent\\bmana\\fement,\\btext\\bsummarizati\\tn,\\bkn\\twled\\fe\\bacquisiti\\tn\\band\\bsemantic\\bsearch\\ben\\fines.\\b Alth\\tu\\fh\\bthere\\bare\\ba\\bnumber\\b\\tf\\bsemantic\\blexic\\tns\\bf\\tr\\bEn\\flish\\band\\bs\\tme\\b\\tther\\blan\\fua\\fes,\\bPersian\\blacks\\bsuch\\ba\\bc\\tmplete\\bres\\turce\\bt\\t\\bbe\\b used\\bin\\bNLP\\bw\\trks.\\bIn\\bthis\\bpaper\\bwe\\bintr\\tduce\\ban\\b\\tn\\f\\tin\\f\\bpr\\tject\\b\\tn\\bdevel\\tpin\\f\\ba\\blexical\\b\\tnt\\tl\\t\\fy\\bf\\tr\\bPersian\\bcalled\\bFarsNet.\\bWe\\b expl\\tited\\ba\\bhybrid\\bsemi-aut\\tmatic\\bappr\\tach\\bt\\t\\bacquire\\blexical\\band\\bc\\tnceptual\\bkn\\twled\\fe\\bfr\\tm\\bres\\turces\\bsuch\\bas\\bW\\trdNet,\\bbilin\\fual\\b dicti\\tnaries,\\b m\\tn\\t-lin\\fual\\b c\\trp\\tra\\b and\\b m\\trph\\t-syntacti c\\b and\\b semantic\\b templates.\\b FarsNet\\b is\\b an\\b \\tnt\\tl\\t\\fy\\b wh\\tse\\b elements\\b are\\b lexicalized\\b in\\b Persian.\\b It\\b pr\\tvides\\b links\\b between\\b vari\\tus\\b types\\b \\tf\\b w\\trds\\b (cr\\tss\\b POS\\b relati\\tns)\\b and\\b als\\t\\b between\\b w\\trds\\b and\\b their\\b c\\trresp\\tndin\\f\\bc\\tncepts\\bin\\b\\tther\\b\\tnt\\tl\\t\\fies\\b(cr\\tss\\b\\tnt\\tl\\t \\fies\\brelati\\tns).\\bFarsNet\\ba\\f\\fre\\fates\\bthe\\bp\\twer\\b\\tf\\bW\\trdNet\\b\\tn\\bn\\tuns,\\bthe\\bp\\twer\\b \\tf\\bFrameNet\\b\\tn\\bverbs\\band\\bthe\\bwide\\bran\\fe\\b\\tf\\bc\\tncep\\stual\\brelati\\tns\\bfr\\tm\\b\\tnt\\tl\\t\\fy\\bc\\tmmunity\\b",""]},{"title":"1. Introduction\\t","paragraphs":["In \\tecent ye\\b\\ts, the\\te h\\bs \\feen \\bn inc\\te\\bsing inte\\test in sem\\bntic p\\tocessing of n\\btu\\t\\bl l\\bngu\\bges. Some of the essenti\\bl \\tesou\\tces to m\\bke this kind of p\\tocess possi\\fle \\b\\te sem\\bntic lexicons \\bnd ontologies. Lexicon cont\\bins knowledge \\b\\fout wo\\tds \\bnd ph\\t\\bses \\bs the \\fuilding \\flocks of l\\bngu\\bge \\bnd ontology cont\\bins knowledge \\b\\fout concepts \\bs the \\fuilding \\flocks of hum\\bn conceptu\\bliz\\btion (the wo\\tld model) (Sh\\bmsf\\b\\td & B\\b\\tfo\\toush, 2003). Lexic\\bl ontologies o\\t NL-ontologies \\b\\te ontologies whose nodes \\b\\te lexic\\bl units of \\b l\\bngu\\bge. Moving f\\tom lexicons tow\\b\\td ontologies \\fy \\tep\\tesenting the me\\bning of wo\\tds \\fy thei\\t \\tel\\btions to othe\\t wo\\tds, \\tesults in sem\\bntic lexicons \\bnd lexic\\bl ontologies. One of the most popul\\b\\t sem\\bntic lexicons fo\\t English is Wo\\tdNet. P\\tinceton Wo\\tdNet (Fell\\f\\bum, 1998), is widely used in NLP \\tese\\b\\tch wo\\tks. It cove\\ts English l\\bngu\\bge \\bnd h\\bs \\feen fi\\tst developed \\fy Mille\\t in \\b h\\bnd-c\\t\\bfted w\\by. M\\bny othe\\t lexic\\bl ontologies (such \\bs Eu\\toWo\\tdNet, B\\blk\\bNet, ...) h\\bve \\feen c\\te\\bted \\f\\bsed on P\\tinceton wo\\tdnet fo\\t othe\\t l\\bngu\\bges such \\bs Dutch, It\\bli\\bn, Sp\\bnish, Ge\\tm\\bn, F\\tench, Czech \\bnd Estoni\\bn. Although the\\te \\b\\te such sem\\bntic, lexic\\bl \\tesou\\tces fo\\t English \\bnd some othe\\t l\\bngu\\bges, some l\\bngu\\bges such \\bs Pe\\tsi\\bn (F\\b\\tsi) l\\bck such \\b sem\\bntic \\tesou\\tce fo\\t use in NLP wo\\tks. Pe\\tsi\\bn is \\bn Indo-Eu\\tope\\bn l\\bngu\\bge, the offici\\bl l\\bngu\\bge of th\\tee count\\ties (I\\t\\bn, Afgh\\bnist\\bn, \\bnd \\b p\\b\\tt of T\\bjikist\\bn), \\bnd it is \\blso spoken in mo\\te th\\bn six count\\ties. The\\te h\\bve \\feen some effo\\tts to c\\te\\bte \\b wo\\tdnet fo\\t Pe\\tsi\\bn l\\bngu\\bge (F\\bmi\\bn & Agh\\bj\\bney, 2007; Keyv\\bn, et \\bl., 2007) \\fut no \\bv\\bil\\b\\fle p\\todu\\octs h\\bve \\feen \\bnnounced yet. The only \\bv\\bil\\b\\fle lexic\\bl \\tesou\\tces fo\\t Pe\\tsi\\bn \\b\\te some lexicons cont\\bining phonologic\\bl \\bnd synt\\bctic knowledge of wo\\tds (such \\bs (Esl\\bmi, 2006)). On the othe\\t h\\bnd, the m\\bjo\\t p\\to\\flems with wo\\tdnet \\b\\te: (1) It h\\bs ve\\ty \\test\\ticted \\tel\\btions \\bnd does not \\bllow defining \\b\\t\\fit\\t\\b\\ty new ones. (2) It h\\bs we\\bk sem\\bntic knowledge on ve\\t\\fs. The\\te is no info\\tm\\btion \\b\\fout ve\\t\\f \\b\\tguments \\bnd thei\\t conceptu\\bl p\\tope\\tties in Wo\\tdNet. (3) It does not suppo\\tt c\\toss\\o-POS \\tel\\btionships In this p\\bpe\\t we int\\toduce \\bn effo\\tt to develop \\b lexic\\bl ontology c\\blled F\\b\\tsNet fo\\t Pe\\tsi\\bn l\\bngu\\bge which ove\\tcomes the \\b\\fove sho\\ttcomings. We exploit \\b semi \\butom\\btic \\bpp\\to\\bch to \\bcqui\\te lexic\\bl \\bnd ontologic\\bl knowledge f\\tom \\bv\\bil\\b\\fle \\tesou\\tces \\bnd \\fuild the lexic\\bl ontology. F\\b\\tsNet is \\b \\filingu\\bl lexic\\bl ontology which not only \\tep\\tesents the me\\bning of Pe\\tsi\\bn wo\\tds \\bnd ph\\t\\bses, \\fut \\blso links them to thei\\t co\\t\\tesponding concepts in othe\\t ontologies such \\bs Wo\\tdNet, Cyc \\bnd Sumo. F\\b\\tsNet \\bgg\\teg\\btes the powe\\t of Wo\\tdNet on nouns, the powe\\t of F\\t\\bmeNet on ve\\t\\fs \\bnd \\b wide \\t\\bnge of conceptu\\bl \\tel\\btions f\\tom ontology community."]},{"title":"2. Introducing\\tFar\\bNet\\t","paragraphs":["F\\b\\tsNet consists of two m\\bin p\\b\\tts: \\b sem\\bntic lexicon \\bnd \\b lexic\\bl ontology. E\\bch ent\\ty in the sem\\bntic lexicon cont\\bins n\\btu\\t\\bl l\\bngu\\bge desc\\tiptions, phonologic\\bl, mo\\tphologic\\bl, synt\\bctic \\bnd sem\\bntic knowledge \\b\\fout \\b lexeme. The lexemes c\\bn p\\b\\tticip\\bte in \\tel\\btions with othe\\t lexemes in the s\\bme lexicon o\\t to ent\\ties of othe\\t lexicons \\bnd ontologies, in the ontology p\\b\\tt. He\\te, the sem\\bntic lexicon is se\\tving \\bs \\b lexic\\bl index to the ontology. The ontology p\\b\\tt cont\\bins not only the st\\bnd\\b\\td \\tel\\btions defined in Wo\\tdNet \\fut \\blso some \\bddition\\bl conceptu\\bl ones. F\\b\\tsNet is \\b\\fle to \\bdd new \\tel\\btions fo\\t its wo\\tds o\\t concepts. We h\\bve developed \\bn inte\\tf\\bce fo\\t F\\b\\tsNet f\\tom which one c\\bn \\bdd, \\temove o\\t ch\\bnge the ent\\ties. F\\tom this inte\\tf\\bce the use\\t c\\bn define new \\tel\\btions o\\t use the existing ones \\bnd \\tel\\bte wo\\tds \\fy them. It c\\bn \\tel\\bte wo\\tds f\\tom diffe\\tent synt\\bctic types"]},{"title":"2629","paragraphs":["togethe\\t (e.g. nouns to \\bdjectives \\bnd ve\\t\\fs). It c\\bn \\blso \\tel\\bte \\b wo\\td to its co\\t\\tesponding concept in \\bn existing ontology. This m\\bkes the inte\\tope\\t\\b\\fility \\fetween v\\b\\tious \\tesou\\tces \\bnd v\\b\\tious l\\bngu\\bges e\\bsie\\t. In \\bddition the\\te \\b\\te some specific fe\\btu\\tes fo\\t specific POS t\\bgs too. Fo\\t inst\\bnce, we h\\bve defined \\b new \\tel\\btion fo\\t \\bdjectives which shows thei\\t selection\\bl \\test\\tictions, the c\\btego\\ty of nouns who c\\bn \\bccept this wo\\td \\bs \\b modifie\\t. Fo\\t ex\\bmple ‘khoshm\\bzeh’ (delicious) usu\\blly is used fo\\t edi\\fles while ‘h\\bjim’ (voluminous, huge) is used fo\\t physic\\bl entities. On the othe\\t h\\bnd F\\b\\tsNet cove\\ts the \\tel\\btions int\\toduced fo\\t ve\\t\\fs in wo\\tdnet \\bnd \\blso \\bdds the num\\fe\\t, n\\bmes \\bnd conceptu\\bl ch\\b\\t\\bcte\\tistics of the \\b\\tguments of e\\bch ve\\t\\f (its selection\\bl \\test\\tictions) in \\b simil\\b\\t w\\by to F\\t\\bmeNet. Fo\\t e\\bch ve\\t\\f, F\\b\\tsNet cont\\bins the type \\bnd sem\\bntic c\\btego\\ty of its \\b\\tguments (Sh\\bmsf\\b\\td & S\\bd\\tMous\\bvi, 2007). Fo\\t ex\\bmple the ve\\t\\f ‘kho\\td\\bn’ (to e\\bt) \\felongs to \\b ve\\t\\f cl\\bss which needs \\bn \\bgent \\bnd \\b theme \\bnd c\\bn h\\bve \\bn inst\\tument, It should \\fe defined th\\bt the theme of this ve\\t\\f should \\fe edi\\fle, its \\bgent should \\fe \\bn \\bnim\\bted thing, \\bnd the size of its inst\\tument is sm\\bll (usu\\blly sm\\blle\\t th\\bn \\b mouth) \\bnd it m\\by \\fe one of spoon, fo\\tk, knife, .... These fe\\btu\\tes help NLP systems to ext\\t\\bct them\\btic \\toles, dis\\bm\\figu\\bte synt\\bctic p\\b\\tsing, chunk, \\tep\\tesent the sentence me\\bning \\bnd \\bcqui\\te knowledge f\\tom texts."]},{"title":"3. Se\\fi-auto\\fatic\\tknowledge\\tacqu\\fi\\bition\\t for\\tFar\\bNet\\t","paragraphs":["We use \\bn inc\\tement\\bl \\bpp\\to\\bch to \\fuild F\\b\\tsNet; developing \\b ke\\tnel \\bnd extending it in \\b semi \\butom\\btic w\\by. The \\bcquisition \\bpp\\to\\bch consists of the following m\\bin steps: 1- P\\toviding initi\\bl \\tesou\\tces, 2- Developing \\bn initi\\bl lexicon \\f\\bsed on wo\\tdnet \\bnd pe\\tfo\\tming WSD, 3- Ext\\t\\bcting new knowledge f\\tom \\bv\\bil\\b\\fle \\tesou\\tces, 4- Ev\\blu\\btion \\bnd \\tefinement  We h\\bve the following \\tesou\\tces \\bv\\bil\\b\\fle \\bnd use them to develop F\\b\\tsNet. - Wo\\tdNet - \\b (synt\\bctic) Lexicon (Esl\\bmi, 2006) cont\\bining mo\\te th\\bn 50,000 ent\\ties with thei\\t POS t\\bgs, - \\b \\filingu\\bl (English- Pe\\tsi\\bn) diction\\b\\ty. - Pe\\tsi\\bn POS t\\bgged co\\t\\opo\\t\\b - \\b mo\\tphologic\\bl \\bn\\blyze\\t fo\\t Pe\\tsi\\bn (Sh\\bmsf\\b\\td, et \\bl., 2007) In the following su\\fsections the next steps will \\fe desc\\ti\\fed. \\t.1.\\b \\feveloping\\ban\\binitial\\e\\blexicon\\bbased\\bon\\bWordNet\\b To develop \\bn initi\\bl lexicon we exploited th\\tee sep\\b\\t\\bte \\bpp\\to\\bches in p\\b\\t\\bllel\\o: (\\b) M\\bnu\\blly g\\bthe\\ting \\b sm\\bll lexicon. (\\f) Autom\\btic c\\te\\btion of \\b sm\\bll ke\\tnel cont\\bining just the \\f\\bse concepts (c) Autom\\btic c\\te\\btion of \\bn initi\\bl \\fig lexicon cont\\bining \\blmost \\bnything cove\\ted \\fy the \\filingu\\bl diction\\b\\ty  M\\bnu\\blly c\\te\\btion of \\b sm\\bll lexicon (option (\\b) \\b\\fove) using \\bv\\bil\\b\\fle \\tesou\\tces \\bnd linguistic knowledge of te\\bm mem\\fe\\ts w\\bs done fo\\t mo\\te th\\bn 1500 ve\\t\\fs (Rouhiz\\bdeh, et \\bl., 2008) \\bnd 1500 nouns (Sh\\bmsf\\b\\td, et \\bl., 2007). Ve\\t\\fs we\\te selected \\bcco\\tding to ve\\t\\fs occu\\t\\ting in B\\blk\\bNet \\f\\bse concepts \\bnd most f\\tequent ve\\t\\fs of \\b Pe\\tsi\\bn co\\tpus. Nouns we\\te selected sequenti\\blly f\\tom \\b Pe\\tsi\\bn diction\\b\\ty. Fo\\t (\\f) we st\\b\\tted fo\\tm English \\f\\bse concepts \\bnd t\\t\\bnsl\\bted them to Pe\\tsi\\bn, \\fut fo\\t (c) we moved in two di\\tections, f\\tom English to Pe\\tsi\\bn \\bnd f\\tom Pe\\tsi\\bn to English sep\\b\\t\\btely to comp\\b\\te thei\\t \\tesults. To move f\\tom English, fo\\t e\\bch English synset, fi\\tst we t\\t\\bnsl\\bte \\bll the wo\\tds in the synset using \\bn elect\\tonic \\filingu\\bl diction\\b\\ty. Then we should \\b\\t\\t\\bnge the Pe\\tsi\\bn synsets \\fy exploiting some heu\\tistics \\bnd WSD (wo\\td sense dis\\bm\\figu\\btion) methods. It is o\\fvious th\\bt e\\bch synset h\\bs some English wo\\tds \\bnd e\\bch wo\\td m\\by h\\bve seve\\t\\bl senses \\bnd e\\bch sense m\\by h\\bve seve\\t\\bl t\\t\\bnsl\\btions to Pe\\tsi\\bn. So c\\te\\bting Pe\\tsi\\bn synsets f\\tom English ones is not \\b st\\t\\bight fo\\tw\\b\\td t\\bsk \\bnd e\\bch Pe\\tsi\\bn wo\\td m\\by \\fe connected to \\b g\\toup of synsets in Wo\\tdNet. The\\tefo\\te it is impo\\tt\\bnt to identify the \\tight sense(s) of English wo\\td, the \\tight t\\t\\bnsl\\btion of it \\bnd putting the \\tight sense of t\\t\\bnsl\\bted wo\\td in the co\\t\\tesponding synset. This t\\bsk in othe\\t Wo\\tdNets h\\bs \\feen done using \\b common uppe\\t ontology, e.g. ILI (inte\\tlingu\\bl index) fo\\t Eu\\toWo\\tdNet \\bnd SUMO fo\\t A\\t\\b\\ficWo\\tdNet. At this step we exploited \\foth heu\\tistics \\bnd dis\\bm\\figu\\btion methods to find the \\bpp\\top\\ti\\bte synsets. At next ph\\bses we will connect ou\\t concepts to othe\\t ontologies \\bs well. We use some heu\\tistics to find the co\\t\\tesponding synsets f\\bst. If \\b wo\\td is known to \\fe the English equiv\\blent of \\b Pe\\tsi\\bn wo\\td \\bcco\\tding to the diction\\b\\ty, the Pe\\tsi\\bn wo\\td should \\bt le\\bst \\fe connected to one of the synsets th\\bt include the English wo\\td \\bs \\b mem\\fe\\t. The\\te will o\\fviously \\fe no \\bm\\figuities if the English wo\\td h\\bs on ly one sense \\bnd so \\bppe\\b\\ts \\bt only one synset. In this c\\bse its t\\t\\bnsl\\btions will \\fe \\bdded to th\\bt\\o synset too. In othe\\t c\\bses, to find the \\bpp\\top\\ti\\bte Pe\\tsi\\bn synset fo\\t \\bn English one, we conside\\t wo\\td p\\bi\\ts in the English synset . Fo\\t e\\bch wo\\td in this p\\bi\\t we list \\bll synsets they \\bppe\\b\\t in. If those two wo\\tds \\bppe\\b\\t togethe\\t only in the cu\\t\\tent synset, thei\\t common Pe\\tsi\\bn t\\t\\bnsl\\btions would \\fe connected to th\\bt synset. The existence of \\b single common synset in f\\bct implies the existence of \\b single common sense \\fetween the two wo\\tds \\bnd the\\tefo\\te t\\ohei\\t Pe\\tsi\\bn t\\t\\bnsl\\btions sh\\bll \\fe connected to this synset. In c\\bses which the\\te \\b\\te mo\\te th\\bn one sense (one synset) fo\\t the English wo\\td we \\bpply \\b dis\\bm\\figu\\btion method to find the \\bpp\\top\\ti\\bte one. The method is desc\\ti\\fed in the next su\\fsection. \\t.1.1\\bWord\\bsense\\bdisambiguation\\b Ou\\t dis\\bm\\figu\\btion p\\tocedu\\te uses othe\\t English t\\t\\bnsl\\btions of Pe\\tsi\\bn wo\\td PW (th\\bt \\b\\te n\\bmed EWs"]},{"title":"2630","paragraphs":["l\\bte\\t in this text) \\bs context wo\\tds. Simil\\b\\t to the Lesk \\blgo\\tithm (Lesk, 1986), ou\\t method uses the EW gloss, Howeve\\t the me\\bsu\\tes of the sem\\bntic simil\\b\\tity is chosen diffe\\tently. Fo\\t eve\\ty sense of EW, \\b sco\\te is c\\blcul\\bted using its gloss \\bnd the context wo\\tds: fo\\t eve\\ty wo\\td th\\bt \\bppe\\b\\ts in the gloss \\b sco\\te is \\bssigned \\bnd the sco\\te of choosing \\b sense is the sum of sco\\tes of its gloss wo\\tds divided \\fy the to t\\bl num\\fe\\t of them. In o\\tde\\t to sco\\te the gloss wo\\tds \\bcco\\tding to the context wo\\tds we use the sco\\ting \\blgo\\tithm th\\bt w\\bs int\\toduced in (Pede\\tsen et \\bl., 2005) which is desc\\ti\\fed in figu\\te 1. The \\blgo\\tithm computes \\b sco\\te fo\\t \\bll senses of \\b wo\\td th\\bt \\bppe\\b\\ts in the gloss (c\\blled t\\b\\tget wo\\td).The sco\\te of the t\\b\\tget wo\\td is defined to \\fe the m\\bximum of the sco\\tes of its senses.  foreach\\b\\ten\\te\\b\\tt\\f\\b\\bof\\bt\\garget\\bword\\bwt\\b {\\b\\b \\tet\\b\\tcore\\f\\b=\\b0\\b foreach\\bword\\bwj\\b\\b\\fn\\bw\\f\\gndow\\bof\\bcontext\\b {\\b \\b\\b\\b\\b\\b\\b\\tk\\fp\\bto\\bnext\\bword\\b\\ff\\bj\\g\\b==\\bt\\b \\b\\b\\b\\b\\b \\bforeach\\b\\ten\\te\\b\\tjk\\bof\\bw\\gj\\b \\b\\b\\b\\b\\b {\\b \\b\\b\\b\\b\\b \\b\\bTemp_\\tcore[j]\\b =\\b relatedne\\t\\t(\\tt\\f,\\b \\tjk)\\b \\b\\b\\b\\b\\b }\\b \\b\\b\\b w\\fnn\\fng\\b\\tcore\\b=\\bh\\fghe\\tt\\b\\tcore\\b\\fn\\b\\b\\barray\\b \\b\\b\\b\\b\\b\\btemp_\\tcore[]\\b\\b \\b\\b\\b\\b\\b \\ff\\b(w\\fnn\\fng\\b\\tcore\\b>\\bthre\\th\\gold)\\b \\b\\b\\b\\b\\b \\tet\\b\\tcore\\f\\b=\\b\\tcore\\f\\b+\\bw\\fnn\\fng\\b\\tcore\\b }\\b }\\b return\\b\\tcore\\f,\\b\\tuch\\bthat\\b\\tcore\\f\\b≥\\b\\tcorej\\b,\\b forall\\bj,\\b1\\b≤\\bj\\b≤\\bn,\\b\\b n\\b=number\\bof\\bword\\t\\b\\fn\\b\\tent\\gence\\b  Fi\\f.\\b1.\\bSc\\trin\\f\\bPseud\\t\\bC\\tde\\b(Pedersen\\bet\\bal.\\b2005)\\b  In the sco\\ting \\blgo\\tithm, \\b function n\\bmed “\\tel\\btedness” is \\feing used fo\\t the c\\blcul\\btion of sem\\bntic simil\\b\\tity \\fetween two concepts. The\\te \\b\\te m\\bny p\\topos\\bls fo\\t the me\\bsu\\tement of sem\\bntic simil\\b\\tity \\fetween two concepts, we use the one p\\toposed \\fy Resnik (1998) which is \\f\\bsed on sho\\ttest p\\bth length \\bnd t\\bkes into \\bccount the dist\\bnce f\\tom e\\bch of the two concepts f\\tom the \\toot \\bs well \\bs the sho\\ttest p\\bth length f\\tom thei\\t most specific common p\\b\\tent to the \\toot. A sh\\b\\ted p\\b\\tent of two concepts is known \\bs \\b su\\fsume\\t. The le\\bst common su\\fsume\\t (LCS) of two concepts is the one th\\bt does not h\\bve \\bny child\\ten th\\bt \\b\\te \\blso the su\\fsume\\t of two concepts. In othe\\t wo\\tds, the LCS of two concepts is the most specific su\\fsume\\t of them. This me\\bsu\\te finds the dist\\bnce to the \\toot of LSC. The dist\\bnce of the LCS is then divided \\fy the sum of the dist\\bnces of the individu\\bl concepts to the \\toot. The me\\bsu\\te is fo\\tmul\\bted \\bs follows:  sim(c1, c2) = 2*depth(lcs(c1,c2)) /(depth(c1) + depth(c2))  Whe\\te depth is the dist\\bnce f\\tom the concept node to the \\toot of the hie\\t\\b\\tchy. \\t.2.\\b Extracting\\b new\\b knowledge\\b from\\b available\\b resources\\b Afte\\t c\\te\\bting the initi\\bl lexicon, ext\\t\\b wo\\tds will \\fe g\\bthe\\ted f\\tom \\b t\\bgged co\\tpus, \\bnd \\bssign to \\b synset \\bs mentioned \\fefo\\te. Anothe\\t p\\b\\tt of ontology le\\b\\tning in F\\b\\tsNet is dedic\\bted to finding some \\tel\\btions f\\tom co\\tpo\\t\\b exploiting lexico-synt\\bctic \\bnd sem\\bntic p\\btte\\tns (Sh\\bmsf\\b\\td, 2007). Some of these templ\\btes \\b\\te noun ph\\t\\bse templ\\btes which \\b\\te defined to discove\\t \\tel\\btions \\fetween diffe\\tent p\\b\\tts of \\b noun ph\\t\\bse. They \\b\\te used to ext\\t\\bct hyponymy, me\\tonymy \\btt\\ti\\fute-v\\blue \\bnd possession \\tel\\btions. They include \\bd\\bpt\\btions of He\\b\\tst’ p\\btte\\tns (He\\b\\tst, 1992) fo\\t Pe\\tsi\\bn, the exception templ\\bte, the modific\\btion templ\\bte \\bnd othe\\ts to ext\\t\\bct \\tel\\btions \\fetween v\\b\\tious p\\b\\tts of \\b noun ph\\t\\bse (he\\bd \\bnd modifie\\ts). At this ph\\bse we h\\bve used the templ\\btes to ext\\t\\bct hyponymy \\tel\\btions. As \\bn ex\\bmple we c\\bn mention the exception templ\\bte \\bs follows: The Exception templ\\bte: ...{\\bll | eve\\ty} NP0 except NP1 {( \\bnd | ,) NPi}* ... (i>1), implies th\\bt (su\\f-cl\\bss NPi NP0 ) (fo\\t \\bll i  1)  Ou\\t cu\\t\\tent m\\bin p\\to\\flem now, which c\\buses the m\\bjo\\t p\\b\\tt of the e\\t\\to\\ts is the st\\tuctu\\t\\bl \\bm\\figuity of noun ph\\t\\bses in the \\b\\fove templ\\btes. Fo\\t ex\\bmple in the following ph\\t\\bse: ",""]},{"title":"\\b\\t\\b \\f \\b \\f\\b \\f","paragraphs":["... (the appl\\b\\tat\\bon \\far\\bous types of referen\\te books su\\th as d\\b\\tt\\bonar\\bes, en\\ty\\tlope\\rd\\bas, \\bnd\\b\\tes, ...)  The NPs \\bfte\\t ‘such \\bs’ (diction\\b\\ties, encyclopedi\\bs, indices) will \\fe hyponyms of the NP \\fefo\\te it (the \\bpplic\\btion of ...), while they should \\fe hyponyms of the modifie\\t NP (\\tefe\\tence \\fooks). This \\tules wo\\tks p\\tope\\tly in some othe\\t c\\bses fo\\t ex\\bmple in the following ph\\t\\bse: ",""]},{"title":"\\t \\f \\b","paragraphs":["(The newspapers of Arab world su\\th as Alhayat )  The NP \\bfte\\t ‘such \\bs’ (Alh\\by\\bt) will \\fe found \\bs the hyponym of the NP \\fefo\\te it (the newsp\\bpe\\ts of A\\t\\b\\f wo\\tld) which is \\b co\\t\\tect choice. We pl\\bn to use modific\\btion templ\\btes to find \\tel\\btions \\fetween nouns \\bnd thei\\t possi\\fle \\bdjectives in the next ph\\bses too. The \\bdjective modific\\btion templ\\bte implies th\\bt the \\bdjective modifie\\t should \\fe \\bdded to the list of possi\\fle \\bdjectives fo\\t the he\\bd. Refining the ontology m\\by c\\buse some c\\btego\\tiz\\btion of these \\bdjectives (o\\t he\\bds) \\bnd \\tel\\bte the he\\bd (o\\t \\bdjective) to \\b supe\\tcl\\bss of the \\bdjectives (o\\t he\\bd\\o)."]},{"title":"3.3. Eval\\ba\\tio\\f a\\fd refi\\feme\\f\\t","paragraphs":["The fin\\bl ph\\bse of the lexicon \\fuilding life cycle is ev\\blu\\btion \\bnd \\tefinement. As it w\\bs mentioned \\fefo\\te, we \\fuild e\\bch p\\b\\tt of F\\b\\tsNet using mo\\te th\\bn one \\bpp\\to\\bch. The ev\\blu\\btion p\\tocedu\\te is done \\fy two"]},{"title":"2631","paragraphs":["methods too. In the fi\\tst method \\b linguistic expe\\tt \\teviews the \\butom\\btic\\blly ext\\t\\bcted knowledge \\bnd confi\\tms o\\t co\\t\\tects them \\bcco\\tding to v\\blid Resou\\tces (m\\bnu\\bl ev\\blu\\btion). The m\\bnu\\bl ev\\blu\\btion of the p\\b\\tt of lexicon \\fuilt so f\\b\\t shows \\bn \\bccu\\t\\bcy of \\b\\fout 70% in the \\tesulting Pe\\tsi\\bn lexicon. In the second method we comp\\b\\te the \\tesults of v\\b\\tious exploited methods on \\b common t\\bsk to find the common \\fuilt knowledge. Fo\\t ex\\bmple to confi\\tm the inclusion hie\\t\\b\\tchies, we ext\\t\\bct hie\\t\\b\\tchic\\bl \\tel\\btions f\\tom text using templ\\btes in one h\\bnd \\bnd find this hie\\t\\b\\tchy \\bcco\\tding to the hyponym/hype\\tnym \\tel\\btions \\fetween co\\t\\tesponding English synsets on the othe\\t h\\bnd. Comp\\b\\ting the \\tesults shows the most confident knowledge ext\\t\\bcted \\fy \\foth two methods."]},{"title":"4. Conclu\\bion\\t","paragraphs":["F\\b\\tsNet p\\toject is \\bn ongoing p\\toject in NLP \\tese\\b\\tch l\\b\\fo\\t\\bto\\ty of Sh\\bhid Beheshti Unive\\tsity. M\\bnu\\blly developing \\b sm\\bll lexicon \\bs the ke\\tnel of F\\b\\tsNet (Sh\\bmsf\\b\\td, et \\bl., 2007), m\\bnu\\blly t\\t\\bnsl\\bting the \\f\\bse concepts of wo\\tdnet into Pe\\tsi\\bn, \\butom\\btic finding the co\\t\\tesponding Wo\\tdNet synsets fo\\t e\\bch ent\\ty of the synt\\bctic lexicon \\bnd \\butom\\btic \\bcquisition of new wo\\tds \\bnd \\tel\\btions f\\tom the t\\bgged co\\tpus using templ\\bte d\\tiven methods \\b\\te some of pe\\tfo\\tmed t\\bsks. As \\b \\tesult of the pe\\tfo\\tmed t\\bsks we h\\bve c\\te\\bted \\b \\f\\bse lexicon cont\\bining 37000 co\\t\\tespondences \\fetween Pe\\tsi\\bn wo\\tds \\bnd English synsets \\bnd chose the ent\\ties which h\\bve \\t\\bnked \\b\\fove the th\\teshold (0.7) in ou\\t WSD \\t\\bnking p\\tocedu\\te. Some \\tesults of the \\t\\bnking p\\tocedu\\te \\b\\te shown in t\\b\\fle 1. On the othe\\t h\\bnd we selected the most f\\tequent wo\\tds (which \\b\\te not \\bppe\\b\\ted in the l\\bst expe\\tience) f\\tom the initi\\bl lexicon (Esl\\bmi, 2006) (with f\\tequency mo\\te th\\bn 3000 in ou\\t cu\\tpos) \\bnd \\btt\\bched them to the synsets cont\\bining thei\\t English t\\t\\bnsl\\btions. This \\tesults in 16800 new co\\t\\tespondences which \\b p\\b\\tt of it is shown in t\\b\\fle 2. The m\\bnu\\bl ev\\blu\\btion methods show \\b\\fout 70% co\\t\\tectness in ou\\t \\butom\\btic \\bpp\\to\\bches. The\\te \\b\\te some fu\\tthe\\t wo\\tks to complete the p\\toject such \\bs completing the ve\\t\\fs knowledge \\f\\bse Exploiting (o\\t linking to) F\\t\\bmeNet, enh\\bncing the sense dis\\bm\\figu\\btion modules in the \\butom\\btic t\\t\\bnsl\\btions, imp\\toving the sem\\bntic templ\\btes to ext\\t\\bct non-t\\bxonomic \\tel\\btions f\\tom text \\bnd est\\b\\flishing \\b m\\bpping \\fetween v\\b\\tious ontologies.                             \\b \\b","Table\\b(1)\\b–\\bpart\\b\\tf\\bthe\\bresults\\b\\tf\\bthe\\brankin\\f\\bpr\\tcedure\\b    "]},{"title":"2632                          ","paragraphs":["Table\\b(2)-\\bA\\bpart\\b\\tf\\bc\\trresp\\tndences\\bcreated\\baut\\tmatically\\b \\b  "]},{"title":"5. Acknowledge\\fent\\b\\t","paragraphs":["I would like to th\\bnk Miss Neg\\b\\t H\\b\\ti\\ti fo\\t p\\toviding some of the tests \\bnd ev\\blu\\btions."]},{"title":"6. Reference\\b\\t","paragraphs":["Esl\\bmi, M. (2006). The gene\\t\\btive lexicon, In: 2nd workshop on Pers\\ban l\\ranguage and \\tomputer, Teh\\t\\bn.","F\\bmi\\bn, A., Agh\\bj\\bney, D. (2007). Tow\\b\\tds Building \\b Wo\\tdNet fo\\t Pe\\tsi\\bn Adjectives, In: 3rd Global wordnet \\tonferen\\te .","Fell\\f\\bum, C. (1998). WordNet: An ele\\ttron\\b\\t lex\\b\\tal database. C\\bm\\f\\tidge, M\\bss. MIT p\\tess.","He\\b\\tst, M. (1992). Autom\\btic \\bcquisition of hyponyms f\\tom l\\b\\tge text co\\tpo\\t\\b. Pro\\teed\\bngs of the Fourteenth Internat\\bonal Conferen\\te on Computat\\bonal L\\bngu\\bst\\b\\ts.","Keyv\\bn, F., Bo\\tji\\bn, H., K\\bsheff, M., Fell\\f\\bum, C. (2007). Developing Pe\\tsi\\bNet: The Pe\\tsi\\bn Wo\\tdnet, In: 3rd Global wordnet \\tonferen\\te .","Lesk, M (1986). Autom\\btic sense dis\\bm\\figu\\btion using m\\bchine \\te\\bd\\b\\fle diction\\b\\ties: how to tell \\b pine code f\\tom \\bn ice c\\te\\bm cone, in: Pro\\teed\\bngs of the 5th annual \\bnternat\\bonal \\tonferen\\te on Systems do\\tumentat\\bon, ACM P\\tess, pp. 24–26.","Pede\\tsen, T. B\\bne\\tjee, S. P\\btw\\b\\tdh\\bn, S. (2005). M\\bximizing Sem\\bntic Rel\\btedness to Pe\\tfo\\tm Wo\\td Sense Dis\\bm\\figu\\btion, Super\\tomput\\bng","Resnik, P. (1998). Sem\\bntic simil\\b\\tity in \\b t\\bxonomy: An info\\tm\\btion-\\f\\bsed me\\bsu\\te \\bnd its \\bpplic\\btion to p\\to\\flems of \\bm\\figuity in n\\btu\\t\\bl l\\bngu\\bge, Journal of Art\\bf\\b\\t\\bal Intell\\bgen\\te\\r Resear\\th 11.","Rouhiz\\bdeh, M., Sh\\bmsf\\b\\td M., Y\\b\\tmoh\\bmm\\bdi, M. (2008). Building \\b Wo\\tdNet fo\\t Pe\\tsi\\bn Ve\\t\\fs, The Fourth Global WordNet Conferen\\te , Hung\\b\\ty.","Sh\\bmsf\\b\\td, M., B\\b\\tfo\\toush, A.A. (2004). Le\\b\\tning Ontologies f\\tom N\\btu\\t\\bl L\\bngu\\bge Texts. In: Internat\\bonal Journal of Human-Computer Stud\\bes, vol. 60, pp.17-63.","Sh\\bmsf\\b\\td, M., S\\bd\\tMous\\bvi, M. (2007). A Rule-\\f\\bsed Sem\\bntic Role L\\b\\feling App\\to\\bch fo\\t Pe\\tsi\\bn Sentences, In: Se\\tond workshop on Computat\\bonal Approa\\thes to Arab\\b\\t-s\\tr\\bpt Languages (CAASL’2), St\\bnfo\\td, USA.","Sh\\bmsf\\b\\td, M., Mi\\tsh\\bhv\\bl\\bd, A., Pou\\th\\bss\\bn, M., Rost\\bmpou\\t, S. (2007). Developing \\f\\bsic \\bn\\blyse\\ts fo\\t Pe\\tsi\\bn: com\\fining mo\\tphology, synt\\bx \\bnd sem\\bntic, In: 15th Iran\\ban \\tonferen\\te on Ele\\ttr\\b\\tal Eng\\bneer\\bng, Teh\\t\\bn.","Sh\\bmsf\\b\\td, M. (2006). Int\\toducing Linguistic \\bnd Sem\\bntic Templ\\btes fo\\t Knowledge Ext\\t\\bction f\\tom Texts, In: workshop on ontolog\\bes \\bn text te\\thnology, Ge\\tm\\bny"]},{"title":"2633","paragraphs":[]}]}