{"sections":[{"title":"Automatic Acquisition of Sense Examples using ExRetriever Juan Fern ández , Mauro Castillo , German Rigau","paragraphs":["y"]},{"title":", Jordi Atserias , Jordi Turmo ","paragraphs":["TALP Research Center. UPC","f","juanf,castillo,batalla,turmog","@lsi.upc.es y IXA Research Group. UPV/EHU","rigau@si.ehu.es","Abstract A current research line for word sense disambiguation (WSD) focuses on the use of supervised machine learning techniques. One of the drawbacks of using such techniques is that previously sense annotated data is required. This paper presents ExRetriever, a new software tool for automatically acquiring large sets of sense tagged examples from large collections of text and the Web. ExRetriever exploits the knowledge contained in large-scale knowledge bases (e.g., WordNet) to build complex queries, each of them characterising particular senses of a word. These examples can be used as training instances for supervised WSD algorithms."]},{"title":"1. Introduction","paragraphs":["A promising current line of research of WSD uses semantically annotated corpora to train Machine Learning algorithms to decide which word sense to choose in which contexts. These approaches are termed ”supervised” be-cause they learn from previously sense annotated data.","Supervised Machine Learning algorithms use semantically annotated corpora to induce classification models for deciding which is the appropriate word sense for each particular context. The compilation of corpora for training and testing such systems require a large human effort since all the words in these annotated corpora have to be manually tagged by lexicographers with semantic classes taken from a particular lexical semantic resource, most commonly WordNet. Supervised methods suffer from the lack of widely available semantically tagged corpora, from which to construct really broad coverage systems. This extremely high overhead for supervision (all words, all languages) explain why supervised methods have been seriously questioned.","As a possible solution, some recent work is focusing on reducing the acquisition cost and the need for supervision in corpus-based methods for WSD. (Leacock et al., 1998), (Mihalcea and Moldovan, 1999) and (Agirre and Martinez, 2000) automatically generate arbitrarily large corpora for unsupervised WSD training, using the knowledge contained in WordNet to formulate search engine queries over large text collections or the Web."]},{"title":"2. Automatic Acquisition of Examples for WSD","paragraphs":["(Leacock et al., 1998) using AutoTrain collected monosemous relatives. The sampling process retrieves the ”closest” relatives first. The quality of the acquired data was evaluated indirectly comparing the results of a WSD system for 14 nouns when trained on monosemous relatives and on manually tagged training materials. The result of this experiment was that some words could be automatically tagged with nearly human taxes of success, but there were other words for which automatic tagging was not worth.","The work of (Mihalcea and Moldovan, 1999) tries to overcome these limitations (1) by using the word definitions provided by glosses and (2) by using the Web as a very large corpora. In this case, they use Altavista as a search engine to create complex search queries using boolean operators for increasing the quality of the information retrieved.","Their approach was tested on 20 polysemous words leading an accuracy of 91%. Using this method for these words, they obtained thirty times more examples than appearing in SemCor.","(Agirre and Martinez, 2000) implemented the previously described method of Mihalcea and Moldovan to obtain training data for 13 words, and tested on examples from SemCor. Only a few words get better results than random and for a particular word the error rate reached 100%.","Agirre and Martı́nez suggest that one possible explanation of this apparent disagreement could be that the acquired examples, being correct on themselves, provide systematically misleading features (for instance, as suggested by (Leacock et al., 1998) when using a large set of local closed-class and part-of-speech features). Besides, all words were trained with equal number of examples.","In order to test the feasibility of this approach, the MEANING project1","has developed and released a new tool: the first version of ExRetriever, a flexible system to perform sense queries on large corpora. ExRetriever characterize automatically each synset of a word as a query (using mainly, synonyms, hyponyms and the words of the definitions); and then, using these queries to obtain sense examples (sentences) automatically from a large text collection. The current implementation of ExRetriever access directly the content of the MCR (Atserias et al., 2004). The system is using also SWISH-E to index large collections of text such as SemCor or BNC. ExRetriever has been designed to be easily ported to other lexical knowledge bases and corpora, including the possibility to query search engines such as Google. 1 http://www.lsi.upc.es/ñlp/meaning 25"]},{"title":"3. ExRetriever: A new Approach","paragraphs":["Although, this approach seems to be very promising, it remains unclear which is the best strategy for building sense queries from a large-scale knowledge base like WordNet. ExrRetriever will explore the trade-off between coverage (collecting large quantities of sense examples) and accuracy (making queries more precise and restrictive, and obviously less productive).","First experiments have been performed using large scale corpora stored locally. This allowed to perform controlled tests and comparisons between different query buiding strategies very fast. Later, when having a more clear view of the knowledge to be used (e.g. regarding PoS, monosemous relatives only, synonyms, direct hypernyms, direct hyponyms, INVOLVED relations, etc.) the query construction (e.g. including or not AND-NOTs with characterizations of the other sense queries), the complete query process (e.g. union set of queries, incremental construction, etc.), the post processing (e.g. using PoS, syntactic or domain filtering), the other languages involved in the project (using the MCR) and corpus.","This tool characterises each sense of a word as a specific query. This is automatically done by using a particular query construction strategy, which is defined a priory by an expert. Each different strategy can take into account the information related to words and available into a lexical knowledge base in order to automatically generate the set of queries.","The current version of ExRetriever is able to use different lexical databases through the MCR of MEANING (Atserias et al., 2004) and different corpora (SemCor, BNC, the Web, etc.) through a common API.","In order to easily implement different query construction strategies, ExRetriever has been powered with a declarative language. This language allows the manual definition of complex query construction strategies and it is briefly described in the fowolling section."]},{"title":"4. The Query Language","paragraphs":["ExRetriever query language consist on the following three component types: logical operators, functions and constants."," Operators are the usual boolean operators AND, OR and NOT."," Functions Currently, – Glos used to obtain the words appearing in the gloss. –relused to obtain the different relations in the lexical knowledge base –nrelsimilar to rel, but stablishing the maximum polysemy of the returned senses."," Constants can be divided in: – noempty a parameter for the Glos function, used","to remove all stopwords from a gloss. – senses particular senses (e.g church#n#2) – relations particular MCR relationships used as","parameters to ”rel” and ”nrel” (e.g. hypo). 4.1. Example for chair","In this section we explain, using an example, the construction of a query accordingly to a particular query construction strategy. We apply the query strategy Meaning1SemCor to the third sense of the word chair. Table 1 provides a brief description of word chair in WN1.6.","Meaning1Semcor: Glos(or,and,noempty) OR or(nrel(1,syns)) OR or(nrel(1,hypo))","The first function Glos(or,and,noempty) returns a logical formula which is the target word (i.e. chair and the union set with or of the non noempty words of the gloss of chair#n#3: (chair AND ( officer OR presides OR meetings OR organization)).","The second function, or(nrel(1,syns)) returns the union set with or of the monosemous synonyms of chair#n#3: (chairman OR chairwoman OR chairperson)","Finally, or(nrel(1,hypo) returns the union set of the monosemous hyponyms chair#n#3: (OR (vice chairman).","Table 2 shows the resulting queries for all the sense of the word chair (noun).","sense gloss hypo syn","n#1 a seat for one per-","son , with a sup-","port for the back armchair (2) barber chair ...","n#2 the position of professor professorship","n#3 the officer who presides at the meetings of an organization","vice chairman president (6) chairman chairwoman chairperson","n#4 an instrument of death by electrocution that resembles a chair lectric chair death chair hot seat Table 1: Sense of chair noun in wordNet 1.6 4.2. Examples obtained from SemCor Once the query is applied to a particular word, we can use these queries in a search engine to retrieve examples for the selected sense. The examples retrieved are structured using XML and include information about their source, the target word and the base sense from which the query is build. ","Example Sentences=”1” src=”brown2/tagfiles/brl15#104577”","It contained a desk, files, a typewriter on a stand, and two big leather","MEANING origPOS=”n” rel=”hypo” synsetSense=”1” synsetLema=”armchair” synset-POS=”n” baseSense=”1” baseLema=”chair” basePOS=”n” origSense=”1”","armchairs","/MEANING",".","/Example"]},{"title":"5. Experiments","paragraphs":["Within the framework of the MEANING project we designed a preliminar set of tests to validate ExRetriever. Both direct and indirect evaluation experiments of the ExRetriever performance have been designed. However, in this paper we present the results of the direct evaluation on SemCor. 26","chair#n#1:","(chair AND (seat OR person OR support OR back))","OR","(armchair OR barber chair OR chaise longue OR","folding chair OR highchair OR feeding chair OR","ladder-back chair OR lawn chair OR garden chair OR","rocking chair OR straight chair OR side chair OR","swivel chair OR tablet-armed chair OR wheelchair)","char#n#2:","(chair AND (position OR professor))","OR (professorship)","chair#n#3: (chair AND","( officer OR presides OR meetings OR organization))","OR","(chairman OR chairwoman OR chairperson)","OR (vice chairman)","chair#n#4: ( chair AND","( instrument OR death OR electrocution OR resembles))","OR","(electric chair OR death chair OR hot seat) Table 2: Queries for chair noun usin Meaning1SemCor","Using ExRetriver on SemCor we can perform detailed micro-analisys on the data available. That is, we can easily perform many adjustements for building queries and filter-ing appropriately those unwanted examples, balancing the trade-off between coverage (we want to obtain all the examples of a particular sense occurring in a corpus) and precision (we want only those corresponding to the particular sense).","Each one of such experiments consists in applying a particular query construction strategy to a set of 73 English words from Senseval-2 lexical sample task. The resulting specific queries (one for each sense word) automatically generated by applying each strategy have been tested against Semcor. Due to the small size of Semcor (around 250 thousand words), specific queries are likely to produce poor recall. However, Semcor is the unique sense tagged resource providing large quantities of examples for all-words.","Six different query construction strategies have been tested, some of them inspired in those used by other authors. They are briefly described as follows:","1. Lea1Semcor: or(nrel(1,syns)) OR or(nrel(1,hypo)) OR or(nrel(1,hype)) Inspired in the work presented in (Leacock et al., 1998), this strategy generates a specific query for each word sense by collecting only monosemous relatives (i.e., synonyms, immediate hyponyms and inmediate hypernyms of the sense). 2. Moldo1Semcor: or(nrel(1,syns)) Used as in (Mihalcea and Moldovan, 1999), this strategy builds each specific query as the set of monosemous synonyms of the particular word sense. In fact, this is a particular case of the previous strategy. 3. Moldo2Semcor: or(rel(glos)) This method builds a query corresponding exactly to the gloss of the synset. 4. Moldo3Semcor: Glos(or,and,noempty) This strategy is a simplified version of the fourth method described in (Mihalcea and Moldovan, 1999). As we do not parse the glosses, we can not use their head phrases. Instead we only remove the stopwords. 5. Meaning1Semcor: Glos(or,and,noempty) OR or(nrel(1,syns)) OR or(nrel(1,hypo)) In order to increase the coverage of the previous strategies, we added to the previous method, the posibility to query also for their monosemous relatives (synonyms and hyponyms). 6. Meaning2Semcor: Glos(or,and,noempty) OR Glos(or,and,or,rel(hypo),noempty) The second function of this method builds the query using all the hyponym glosses (removing the stopwords) and their defining senses."]},{"title":"6. Results Moldo2Semcor","paragraphs":["strategy do not provide results in SemCor, as this method is looking for the synset gloss. Obviously, in a small corpus such as Semcor this is hightly improvable.","Table 3 presents the results of strategy Meaning1SemCor when applied on the noun chair. Ok stands for correctly detected examples of the respective senses of the word. Those incorrectly assigned senses are labeled with Ko. NoTag corresponds to non sense annotated word occurrences occurring in Semcor (those comming from bronv files). #Sense stands for the total number of sense occurrences occurring in Semcor (i.e. the total coverage). As each query asks for different relatives, they also obtain different number of possible sense occurrences. Finally, P, R and F1, correspond to precision, recall and F– measure, respectivelly.","For this word, ExRetriever obtained 26 examples for the first sense (23 correct), 2 examples for the sense two (only one correct), 7 examples for the third sense (all of them correct) and finally, for the fourth sense, 2 examples (only one correct). Meaning1Semcor obtains 86% precision (achiev-ing 100% precision for sense three). However, the method only obtains 53% recall (70% recall for the sense three). 27 Sense Ok Ko NoTag #Sense P R F1 n#1 23 3 4 41 88 52 65 n#2 1 1 0 3 50 25 63 n#3 7 0 34 10 100 70 82 n#4 1 1 0 1 50 50 50 Totals 32 5 38 55 86 53 66 Table 3: Results of chair#n applying Meaning1SemCor Query P R F1 Lea1 94 27 42 Mol1 100 19 32 Mol3 81 42 55 Mea1 86 53 66 Mea2 73 35 47 Table 4: chair#n Totals in different construction strategies","Table 4 shows precision, recall and F1 figures using different queries for the word chair. The best precision if obtained for strategy Moldovan1SemCor reaching 100%. However, this method only obtains 19% recall. Overall, for this word, the best result is obtained for Meaning1Semcor obtaining an F1–measure of 66%. Q Ok Ko NoTag #Sense P R F1 Lea1 1551 1569 2037 12744 50 11 18 Mol1 257 209 436 5129 55 5 9 Mol3 2195 26734 2962 6122 8 7 7 Mea1 2978 27882 4318 10390 10 8 9 Mea2 6227 56038 9884 14595 10 9 9 Table 5: Overall figures","Table 5 shows the overall figures for each query when applied to the total 73 words of the test set. When applying sistematically the same method to all the words, Moldo1Semcor and Lea1Semcor strategies obtain the best precision (55% and 50% respectivelly). However, Lea1SemCor method obtains much better recall than Modo1Semcor (11% vs. 5%)."]},{"title":"7. Conclusions and future work","paragraphs":["In this paper, ExRetriever, a query-based system to extract sense examples from corpus has been described. Some preliminar experiments have been presented. They have been used to evaluate the performance of different types of query construction strategies. Using ExRetriever, new strategies can be easily defined, executed and evaluated.","We plan to experiment other strategies. For instance, performing full parsing on the glosses could help discard-ing irrelevant words from glosses. In addition, using the knowledge already contained into the Multilingual Central Repository (e.g., selectional preferences acquired from the BNC, eXtended WordNet, domain information, the Topic Signatures acquired from the Web, etc.) could be use-ful knowledge to better model sense words as queries. Moreover, we plan to use alternative schemata for building queries, such as the incremental process performed by (Leacock et al., 1998).","Another very promising line of research will follow (Widdows, 2003). This work presents a theoretically motivated method for removing unwanted meanings directly from the original query in vector models. Irrelevance in vector spaces is modelled using orthogonality. Using this approach, query vector negation removes not only unwanted strings but unwanted meanings. This method is applied to standard IR systems, processing queries such as “play NOT game”. This work presents an algebra to operate with word vectors rather than words. It seems, following this approach, that most of the errors produced be-cause of the substitutionof the target word for their relatives can be avoided. Furthermore, using this approach, we can also use other sense tagged corpora for direct comparisons of ExRetriever. Although DSO only provides sense tagged data 141 words (nouns and verbs), the are examples in large quantities (around thousands). In this case, queries can not include substitutive relatives, only query restrictions over the polysemous target word.","We also plan to perform indirect evaluations using supervised WSD systems on the acquired sense examples. Once acquired a sense tagged corpus using ExRetriever, we will use several Machine Learning algorithms to perform several cross-comparisons with respect to other sense tagged resources (SemCor, DSO and those resources provided by Senseval)."]},{"title":"8. Acknowlegments","paragraphs":["This work is suported by the European Comision (MEANING IST-2001-34460). Our research group, TALP Research Center, is recognized as a Quality Research Group (2001 SGR 00254) by DURSI, the Research Department of the Catalan Government."]},{"title":"9. References","paragraphs":["Agirre, E. and D. Martinez, 2000. Exploring automatic word sense disambiguation with decision lists and the web. In Proceedings of the COLING workshop on Semantic Annotation and Intelligent Annotation. Luxembourg.","Atserias, Jordi, Luı́s Villarejo, German Rigau, Eneko Agirre, John Carroll, Bernardo Magnini, and Piek Vossen, 2004. The meaning multilingual central repository. In Second International WordNet Conference-GWC 2004. Brno, Czech Republic. ISBN 80-210-3302-9.","Leacock, C., M. Chodorow, and G. Miller, 1998. Using Corpus Statistics and WordNet Relations for Sense Identification. Computational Linguistics, 24(1):147–166.","Mihalcea, R. and I. Moldovan, 1999. An Automatic Method for Generating Sense Tagged Corpora. In Proceedings of the 16th National Conference on Artificial Intelligence. AAAI Press.","Widdows, D., 2003. Orthogonal negation in vector spaces for modelling word-meanings and document retrieval. In Proceedings of 41th annual meeting of the Associa-tion for Computational Linguistics (ACL’2003). Saporo, Japan. 28"]}]}