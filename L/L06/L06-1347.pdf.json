{"sections":[{"title":"Sign Lang\\bag\\t co\\fp\\bs analysis: Synch\\fonisation of ling\\bistic annotation and n\\bm\\t\\fical data Jé\\fémi\\t S\\tgo\\bat, Ann\\tli\\ts B\\faffo\\ft and Emili\\t Ma\\ftin","paragraphs":["LIMSI/CN\\bS\\t O\\fsay\\t F\\fance","Campus d’O\\fsay\\t Bat. 508\\t BP133\\t F-91403 O\\fsay cedex annelies.b\\faffo\\ft@limsi.f\\f","Abst\\fact This pape\\f p\\fesents a study on synch\\fonization of linguistic annotation and nume\\fical data on a video co\\fpus of F\\fench Sign Language. We detail the methodology and sketches out the potential obse\\fvations that can be p\\fovided by such a kind of mixed annotation. The co\\fpus is composed of th\\fee views: close-up\\t f\\fontal and top. Some image p\\focessing has been pe\\ffo\\fmed on each video in o\\fde\\f to p\\fovide global info\\fmation on the movement of the signe\\fs. That consists of the size and position of a bounding box su\\f\\founding the signe\\f. Linguists have studied this co\\fpus and have p\\fovided annotations on iconic st\\fuctu\\fes\\t such as “pe\\fsonal t\\fansfe\\fs” (\\fole shifts). We used an annotation softwa\\fe\\t ANVIL\\t to synch\\fonize linguistic annotation and nume\\fical data. This new app\\foach of annotation seems p\\fomising fo\\f automatic detection of linguistic phenomena\\t such as classification of the signs acco\\fding to thei\\f size in the signing space\\t and detection of some iconic st\\fuctu\\fes. Ou\\f fi\\fst \\fesults must be consolidated and extended on the whole co\\fpus. The next step will consist of designing automatic p\\focesses in o\\fde\\f to assist SL annotation.  "]},{"title":"1. Int\\fod\\bction","paragraphs":["F\\fench Sign Language (FSL) is the visuo-gestu\\fal language used by the F\\fench deaf community. \\besea\\fch on the FSL\\t as fo\\f all Sign Languages (SL)\\t \\fequi\\fes building and analyzing video co\\fpo\\fa.","Two multimedia annotation pieces of softwa\\fe a\\fe dedicated to SL co\\fpo\\fa analysis: ILex (Hanke\\t 2002) is a tool fo\\f SL lexicog\\faphy and co\\fpus analysis allowing di\\fect access to a lexicon sto\\fed in a database. SignSt\\feam (Neidle\\t 2002) allows multiple utte\\fances to be open at the same time\\t pe\\fmitting side-by-side compa\\fison of data.","Two othe\\f multimedia annotation softwa\\fe a\\fe dedicated to video co\\fpo\\fa analysis\\t but not especially fo\\f sign languages. Elan (Wittenbu\\fg\\t 2002) is not dedicated to SL\\t but the associated metadata tool p\\fovides a SL p\\fofile. Anvil (Kipp\\t 2001) is not dedicated to SL\\t but allows seve\\fal speech tie\\fs to be activated.","One of ou\\f aims is to pa\\fticipate in the development of such tools\\t which should include fo\\f example image p\\focessing tools\\t nume\\fical analysis and \\fecognition tools (B\\faffo\\ft\\t 2004). That includes studying which kind of automatic analysis applied to the video would enable us to ext\\fact info\\fmation on the st\\fuctu\\fe of utte\\fances in FSL.","Thus\\t to identify the \\felevant t\\featments\\t we have sta\\fted a study that consists in co\\f\\felating linguistic annotation with nume\\fical data\\t p\\fovided by a p\\fe-p\\focess of the video. The idea is to use the speech tie\\fs to visualize nume\\fical data.","This pape\\f desc\\fibes the methodology and sketches out the potential obse\\fvations that can be p\\fovided by this kind of mixed annotation."]},{"title":"2. M\\tthodology","paragraphs":["Seve\\fal national multi-disciplina\\fy p\\fojects dedicated to FSL have been initiated in F\\fance since 2000\\t whe\\fe both linguists and compute\\f scientists we\\fe involved. Du\\fing one of these p\\fojects\\t named LS-COLIN1","\\t a video database of FSL was built\\t with the double aim to 1 http://www.i\\fit.f\\f/LS-COLIN p\\fovide data fo\\f linguists who want to highlight the iconicity of the FSL\\t and to p\\fovide good quality videos fo\\f automatic analysis (Cuxac 2001).","This co\\fpus is composed of seve\\fal kinds of discou\\fse on diffe\\fent topics: na\\f\\fative (two diffe\\fent sto\\fies)\\t explicative (cooking)\\t a\\fgumentative (on impo\\ftant events)\\t explicative meta-linguistic (on linguistic cou\\fses). Thi\\fteen signe\\fs we\\fe \\feco\\fded on each topic\\t and one of the sto\\fy was pe\\ffo\\fmed twice by each signe\\f\\t in o\\fde\\f to study both inte\\f and int\\fa va\\fiations (Cuxac 2001).","This co\\fpus was \\feco\\fded with th\\fee came\\fas\\t p\\foviding th\\fee views: close-up\\t f\\fontal and top (Figu\\fe 1). It was \\feco\\fded at the INJS2","Institute in Pa\\fis\\t with blue backg\\found\\t da\\fk clothes\\t and high quality lighting\\t in o\\fde\\f to allow \\fesea\\fche\\fs to pe\\ffo\\fm image p\\focessing on the videos (B\\faffo\\ft\\t 2001)\\t (Me\\fcie\\f\\t 2005).  Figu\\fe 1: The th\\fee views of LS-COLIN co\\fpus  With such a kind of co\\fpus\\t linguists and compute\\f scientists can study the same video togethe\\f\\t with the aim to pe\\ffo\\fm complementa\\fy analysis. 2 INJS: Institut National des Jeunes Sou\\fds"]},{"title":"1996 2.1. Ling\\bistic annotation","paragraphs":["The pu\\fpose of one of the linguistic analyses pe\\ffo\\fmed on LS-COLIN co\\fpus\\t was to \\fefine the catego\\fization of the discou\\fse units established by Cuxac (Cuxac\\t 2000). Mo\\fe p\\fecisely\\t the goal was to study in details the linguistic p\\focesses ca\\f\\fied out when the aim of the signe\\f is “to show what he is saying”. That is what Cuxac named “illust\\fative aim”. He has distinguished th\\fee kinds of linguistic st\\fuctu\\fes that he called transfers: The s\\b\\te and s\\fape transfer (TTF)\\t which is used to desc\\fibe the shape of a pe\\fson\\t an object o\\f a place (Figu\\fe 2a)\\t the s\\btuat\\bonal transfer (TS)\\t which is used to show the displacement of a pe\\fson o\\f an object \\felatively to a stable locative \\fefe\\fence (Figu\\fe 2b)\\t and the pe\\fsonal t\\fansfe\\f (TP)\\t whe\\fe the signe\\f “becomes” one of the pe\\fson o\\f object of the discou\\fse (Figu\\fe 2c). TS and TP can be combined in double t\\fansfe\\fs (DT)\\t such as in Figu\\fe 2d. Sometimes\\t some pa\\fts of lexical signs can appea\\f in DT (Figu\\fe 2e)","Salland\\fe ca\\f\\fied out this wo\\fk du\\fing he\\f PhD (Salland\\fe\\t 2003). She en\\fiched the classification by adding sub-catego\\fies in TP and DT. The\\fefo\\fe\\t she has annotated an impo\\ftant pa\\ft of the LS-COLIN co\\fpus\\t with the desc\\fiption of the iconic st\\fuctu\\fes encounte\\fed. We have used he\\f annotation in this study. ","Figu\\fe 2: Examples of t\\fansfe\\fs a: A TTF\\t “sp\\fead past\\fy” in a \\fecipe\\t","b: A TS\\t “a bi\\fd on a fence” in the ho\\fse sto\\fy (HS) c: A TP\\t “a ho\\fse galloping” in the HS d: A DT\\t “a \\fuminating cow” in the HS","e: A DT with lexicon sign\\t “the cow (p\\fofo\\fm with the","dominated hand) is waiting (dominant hand)” in the HS"]},{"title":"2.2. N\\bm\\t\\fical annotation","paragraphs":["An analysis of the video by image p\\focessing was also ca\\f\\fied out on the same co\\fpus by Cassel du\\fing his PhD (Cassel\\t 2005). He applied human detection and t\\facking in a video\\t designed in the context of ac\\fobatic movements. This p\\focess p\\fovides fou\\f tempo\\fal data: Position (X\\t Y) and size (L\\t H) of the bounding box which su\\f\\founds the signe\\f\\t as shown in Figu\\fe 3. The softwa\\fe p\\fovides a set of cu\\fves fo\\f each video file\\t that we can use fo\\f analysis (Figu\\fe 4).  Figu\\fe 3: The bounding box and the 4 co\\f\\felated values.","","Fo\\f example\\t in the f\\fontal view\\t the bounding box t\\facks the signe\\f’s body\\t head and a\\fms: The width \\fep\\fesents the distance between the hands o\\f the shoulde\\fs\\t depending on the position of the hands\\t and the height \\fep\\fesents the distance between the legs and the head\\t o\\f the hands if they a\\fe above the head. ","Figu\\fe 4: Example of a set of cu\\fves fo\\f the top view","","The study has consisted in integ\\fating these two types of annotation into an annotation softwa\\fe and to analyze the possible co\\f\\felations between linguistic phenomena and nume\\fical data. Fo\\f the moment\\t only one FSL sto\\fy\\t signed by two diffe\\fent pe\\fsons\\t was annotated (that is two videos). The co\\f\\felations obse\\fved we\\fe listed manually. The annotation tool used was ANVIL (Kipp\\t 2001) because at this moment this is the only tool that enables us to impo\\ft the data \\fesulting f\\fom the image p\\focessing\\t to display them as cu\\fves and to synch\\fonize them with the linguistic annotation (Figu\\fe 5)."]},{"title":"L H X Y a b c d e 1997 ","paragraphs":["Figu\\fe 5: Example of annotation with linguistic and nume\\fical data. "]},{"title":"3. Fi\\fst obs\\t\\fvations","paragraphs":["Ou\\f obse\\fvations a\\fe pa\\ftly qualitative\\t and pa\\ftly quantitative.","A fi\\fst obse\\fvation is that the cu\\fves \\fep\\fesenting the width and the height of the bounding box can be used to measu\\fe the occupation of the signing space\\t by looking at the va\\fiations in the th\\fee views. This global info\\fmation allows us to classify the signs acco\\fding to the amplitude (in width and length) in the diffe\\fent views.","Fo\\f instance\\t the H va\\fiable in the f\\font view can be used to detect the signs fo\\f which the hands a\\fe above the head: The peeks in the \\fead ci\\fcle in the Figu\\fe 6 co\\f\\fespond to the sign shown in the Figu\\fe 7.","Fo\\f the L va\\fiable in the same view\\t the low values (unde\\f the mean value) in the g\\feen ci\\fcle in Figu\\fe 6 co\\f\\fespond to the moments whe\\fe the elbows a\\fe o\\fiented towa\\fd the cente\\f of the body (Figu\\fe 8)\\t and the peeks above the mean value (blue ci\\fcle in Figu\\fe 7) co\\f\\fespond to bimanual signs with hands outside the body (Figu\\fe 9) o\\f monomanual signs with the hand fa\\f f\\fom the body (Figu\\fe 10).  Figu\\fe 6: L and H cu\\fves fo\\f the f\\fontal view.   Figu\\fe 7: The ho\\fse is falling down (TS)  Figu\\fe 8: [FIELD]LSF  Figu\\fe 9: [STO\\bY]LSF   Figu\\fe 10: The bi\\fd is taking a fi\\fst-aid kit (TS)","","A second obse\\fvation conce\\fns the st\\fuctu\\fes of iconicity annotated by the linguists. Some of the nume\\fical data\\t in pa\\fticula\\f in the top and close-up views\\t seems \\felevant to detect ce\\ftain types of t\\fansfe\\fs."]},{"title":"H L L L 1998","paragraphs":["Thus\\t the fi\\fst time a cha\\facte\\f is int\\foduced in the sto\\fy\\t a pe\\fsonal t\\fansfe\\f (TP) is often pe\\ffo\\fmed du\\fing a significant pe\\fiod. These cha\\facte\\fs a\\fe located in the signing space on the left- o\\f \\fight-hand side of the signe\\f. Fo\\f example\\t in the cow sto\\fy\\t the cow is located on the \\fight (Figu\\fe 1) o\\f on the left (Figu\\fe 11) in the signing space\\t depending on the signe\\f.  Figu\\fe 11: TP ‘cow’ with the signe\\f #2.","","The displacement of the signe\\f’s body is pe\\fceptible on the X cu\\fve of the top view. In Figu\\fe 12\\t the low value of X in the \\fed box co\\f\\fesponds to the signe\\f’s body shifts on the \\fight\\t while the othe\\f cu\\fves keep a stable value.  Figu\\fe 12: Detection of a \\fight TP on the top view  The cu\\fves of the face view have also stable values","du\\fing the same pe\\fiod (Figu\\fe 13)."]},{"title":"4. Concl\\bsion","paragraphs":["All the \\fesults we p\\fesent he\\fe must be \\fefined and confi\\fmed by extending the study on the whole co\\fpus. In a second step\\t data that is mo\\fe local\\t fo\\f example on the face and hands of the signe\\f\\t should be added to the global data we used in this fi\\fst study. Detection and classification would then be mo\\fe accu\\fate.","  Figu\\fe 13: Detection of a TP on the close-up view","","Fo\\f this fi\\fst attempt in co\\f\\felating linguistic and nume\\fical annotations\\t even if the \\fesults a\\fe only outlined\\t they a\\fe p\\fomising and should help to develop automatic tools fo\\f annotation and classification in the field of SL video co\\fpo\\fa based on visual cues. This study consolidates us in ou\\f multidisciplina\\fy app\\foach of annotation including image p\\focessing and automatic analysis. Ou\\f fi\\fst \\fesults must be consolidated and extended on the whole co\\fpus. When the \\felevant t\\featments will be sufficiently defined and validated\\t they will be integ\\fated in the annotation softwa\\fe dedicated to video SL co\\fpo\\fa (B\\faffo\\ft\\t 2004)."]},{"title":"5. R\\tf\\t\\f\\tnc\\ts","paragraphs":["Cuxac C. et al. (2001) P\\fojet LS-COLIN. Quel outil de notation pou\\f quelle analyse de la LS ? \\bLSF’01.","B\\faffo\\ft A.\\t Choisie\\f A.\\t Collet C. et al. (2004) Towa\\fd an annotation softwa\\fe fo\\f video of Sign Language\\t including image p\\focessing tools and signing space modelling. L\\bEC 2004.","Cassel \\b.\\t Collet C.\\t Ghe\\fbi \\b. “\\beal-Time Ac\\fobatic Gestu\\fe Analysis”\\t 6th Inte\\fnational Wo\\fkshop on Gestu\\fe in Human-Compute\\f Inte\\faction and Simulation\\t 2005\\t Vannes\\t F\\fance.","Cuxac C. (2000) La Langue des Signes F\\fançaise (LSF) – Les voies de l’iconicité. In: “Faits de Langues” 15-16\\t Oph\\fys.","Hanke\\t T. (2002) iLex - A tool fo\\f sign language lexicog\\faphy and co\\fpus analysis. L\\bEC 2002.","Kipp M. (2001) Anvil - A Gene\\fic Annotation Tool fo\\f Multimodal Dialogue. In Eu\\fospeech’01\\t 1367-1370.","Neidle\\t C. (2002)\\t SignSt\\feamTM: A Database Tool fo\\f \\besea\\fch on Visual-Gestu\\fal Language. In B. Be\\fgman\\t P. Boyes-B\\faem\\t T. Hanke\\t and E. Pizzuto\\t eds.\\t “Sign T\\fansc\\fiption and Database Sto\\fage of Sign Info\\fmation\\t a special issue of Sign Language and Linguistics” 4:1/2\\t 203-214.","Salland\\fe M.-A. (2003) “Les unités du discou\\fs en Langue des Signes F\\fançaise. Tentative de catégo\\fisation dans le cad\\fe d’une g\\fammai\\fe de l’iconicité.” PhD thesis\\t Pa\\fis 8 unive\\fsity.","Wittenbu\\fg P.\\t B\\fugman H.\\t Levinso\\t St.\\t Kita S. (2002). Multimodal Annotations in Gestu\\fe and Sign Language Studies. L\\bEC 2002."]},{"title":"1999","paragraphs":[]}]}