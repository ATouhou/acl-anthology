{"sections":[{"title":"Bilingual speech corpus in two phonetically similar languages Vicente Alabau","paragraphs":["∗"]},{"title":", Carlos D. Martı́nez","paragraphs":["∗","∗","Departament de Sistemes Informàtics i Computació","Universitat Politècnica de València Camı́ de Vera, s/n. 46071 València, Spain","{valabau,cmartine}@dsic.upv.es","Abstract As Speech Recognition Systems improve, they become suitable for facing new problems. Multilingual speech recognition is one such problems. In the present work, the case of the Comunitat Valenciana multilingual environment is studied. The official languages in the Comunitat Valenciana (Spanish and Valencian) share most of their acoustic units, and their vocabularies and syntax are quite similar. They have influenced each other for many years. A small corpus on an Information System task was developed for experimentation purposes. This choice will make it possible to develop a working prototype in the future, and it is simple enough to build semi-automatic language models. The design of the acoustic corpus is discussed, showing that all combinations of accents have been studied (native, non-native speakers, male, female, etc.)."]},{"title":"1. Introduction","paragraphs":["The quality of Automatic Speech Recognition (ASR) has improved greatly in recent years (Gorin et al., 1997; Chu-Carroll and Carpenter, 1999; Billi et al., 1998). Some commercial products have appeared for real-world tasks, such as speech transcription systems in restricted domains and automatic call centres. However, some problems arise in these real-world tasks: recognition performance is low under adverse circumstances, and the models are very noise sensitive (Furui, 1992; Huang, 1991). In this paper, we design and acquire a corpus to research one of these problems: multilingual interoperability. The problem of multilingual interoperability presents several is-sues related to the components of a classical ASR system, like acoustic or language models. With respect to acoustic models, ASR systems are very language-dependent, because the phone sets are different in each language. Moreover, coarticulation effects of the same phonemes may differ in each language, and even the articulation of a phoneme may have its own singularities. Some work, for example the introduction of contextual acoustic models (triphones), has already been done to find more robust acoustical units under these conditions (Eklund and Lindström, 2001). Language models are also very language-dependent, because of their vocabulary and gramatical issues. Furthermore, vocabulary transcription is dialect-dependent as well. For example, Spanish utterances from South America and Spain differ in a noticeable way. Language determination is also an important issue. In some tasks, the speaker’s language is unknown. Thus, the system has to find the best way to determine which language it is. Moreover, when the system has to answer the speaker, the identification of the language is needed in order to be able to answer in the same language. In multilingual environments, other difficulties are added to","Work supported by the “Agència Valenciana de Ciència i Tecnologia” under grant GRUPOS03/031, the Spanish project TIC2003-08681-C02-02 and the “Programa d’Incentiu a la Investigació 2004 UPV”. speech recognition, even in monolingual ASR. Languages are usually influenced by other languages that are present in the environment and by the speaker’s mother tongue (e.g., the perception distortion of a non-native Dutch speaker is equivalent to a reduction of the signal-to-noise ratio of 3-4 dB for non-native Dutch speakers (van Wijngaarden, 2001)). This interference is demonstrated by mispronunciation and the use of syntactical structures and vocabulary from the mother tongue. For anyone who has studied foreign languages, it is easy to understand that phonemes that are not present in the mother tongue are hard to pronounce. It is even possible to identify the nationality of some people by their accent. Some syntactical and vocabulary mistakes are produced by the lack of knowledge of the foreign language. In this work, the case of the Comunitat Valenciana is studied. In Comunitat Valenciana, two official languages coexist: Spanish and Valencian. Valencian is the name for the Catalan language dialect that is spoken in the Comunitat Valenciana. Catalan is one of the most widely spoken minor languages in Europe. About 6.5 million people speak it actively (on a daily basis), and about 12 million people are potential speakers (they know the language but use Spanish on a daily basis). Furthermore, the Catalan government is making an important effort to promote the use of the Catalan language in all spheres. Therefore, there is great interest in the speech recognition technologies for Catalan. As official languages, every citizen has the right to know and use both Spanish and Valencian in the Comunitat Valenciana. However, the repression of the use and learning of Valencian in the Franco period (1939-1977)(also called Catalan Negationism) and other historical reasons, have caused that currently only 85% of the population of Comunitat Valenciana understand Valencian, and only 48% are active speakers(Ins, 2001). This has also caused the Valencian phone set to be reduced by the extensive use of Spanish, which is true even for Valencian native speakers (a situation which has not occurred in other Catalan dialects). Thus, nowadays the Valencian phone set differs very little from the Spanish phone set. In the following sections, we describe the design of a mul-"]},{"title":"1624","paragraphs":["tilingual corpus for Spanish and Valencian, and we summarize the most common multilingual approaches presented in the literature. Conclusions and future work are presented in the last section."]},{"title":"2. Multilingual corpus design","paragraphs":["As stated above, the Valencian dialect has special phonetic features with respect to standard Catalan. Thus, although there are a few speech recognition resources for the Catalan language there was no resource for Valencian, and a Valencian language corpus had to be acquired. For this reason, we had to acquire a specific Valencian speech corpus and a similar Spanish one. Although Spanish speech corpora are available (Diaz-Verdejo et al., 1998), it was important to have Spanish and Valencian corpora with the same features to be able to compare them more faithfully. Thus, we decided to acquire our own multilingual corpus specifically for experimentation purposes (i.e., not for real system development). We planned to acquire a small, simple corpus and decided to design a set of 120 mediumlength sentences (60 for each language) for 20 speakers, which corresponds to approximately 1 hour of speech per language. This amount of speech signal should be enough for the experimental purposes that the corpus is going to be used for. We chose an Information System task to design the corpus. This was done because this task is complex enough for demostration purposes, and it is simple enough to semiautomatically generate the task sentences. As there are few syntactic differences between Spanish and Valencian (especially for this task), the semi-automatic sentences could be easily translated. Dictionary translation for single words and some minor modifications were sufficient to accomplish the translation task. The goal of this Information System was to provide information about the staff of a department by phone (Mas et al., 2004). The possible information items the system could be asked for included timetables, office hours, phone numbers, e-mail addresses, or office locations. Some example sentences are shown in Figure 1. This task was tested in a previous work (Mas et al., 2004) with acoustic models that were designed for other tasks. This work showed promising results in bilingual Valencian-Spanish ASR and has encouraged us to continue research in this field."]},{"title":"3. Language Modelling","paragraphs":["Language modelling is crucial in an ASR system. Language models define which kind of sentences are allowed in the system. Therefore, any sentence said by a speaker will not be recognized correctly if it does not belong to the language model. Indeed, this sentence will be recognized as the one that is closest to one that exists in the language model. The language model of this corpus was designed to suit our experimentation needs. That is, it should be able to model Valencian and Spanish separatedly, but it should also be able to model a mixture of both languages. The latter is due to the fact that non-native speakers may use words of their native language when the correct word is unknown. This Spanish","• Por favor, quiero saber el e-mail de Álvaro Rodrı́guez, adiós.","• Buenas noches, querı́a la extensión de la señorita Silvia Abrahao, muchas gracias.","• Buenos dı́as, ¿cuál es el horario de consultas del doctor Vicente?, gracias. Valencian","• Per favor, vull saber l’e-mail d’ Álvaro Rodrı́guez, adeu.","• Bona nit, volia saber l’extensió de la senyoreta Silvia Abrahao, moltes gràcies.","• Bon dia, quin és l’horari de consultes del doctor Vicente?, gràcies. English","• Please, I want to know the e-mail of Álvaro Rodrı́guez, goodbye.","• Good evening, I wanted to know the extension of Miss Silvia Abrahao, thank you very much.","• Good morning, what are the office hours of the Dr. Vicente?, thanks. Figure 1: This is a selection of sentences that are representative of the corpus. The English sentences are provided for a better understanding of the examples. fact is known as barbarism. The modelling of barbarism is not only relevant to multilanguage environments but also to communities with a large number of immigrants. In order to provide barbasism tolerance to some extent, the sentences were divided into six blocks, each of which represents a concept in the sentence. As we will see below, this allowed us to construct an automaton that could switch between languages (block-combined language models). The blocks were: greeting, question, information, title, person, and farewell. A set of frequently used phrases was used to build an acceptor automaton for each block. An acceptor automaton accepts only a set of given sentences, in this case, the phrases of the block. Samples of these phrases for the sentences in Figure 1 are shown in Table 1. Finally, these block-oriented automata were used to build the final automata. Two methods were applied in this task:","• Separate language models: an automaton was build for each language. It was made by joining the block-oriented automata in a series. For every two consecutive automata, the final states of the first automaton were merged with the initial states of the second one. Figure 2 shows an example of the serialization process.","• Block-combined language models: a single automaton was built by joining two automata. The automata"]},{"title":"1625","paragraphs":["block greeting Spanish por favor, buenas noches, buenos dı́as Valencian per favor, bona nit, bon dia English please, good evening, good morning block question Spanish quiero saber, querı́a saber, cuál es Valencian vull saber, volia saber, quin és English i want to know, i wanted to know, what is block information Spanish el e-mail, la extensi ón,","el horario de consultas Valencian l’e-mail, l’extensi ó, l’horari de consultes English the e-mail, the extension, the office hours block title Spanish señorita, doctor Valencian señoreta, doctor English Miss, Dr. block person All Álvaro Rodrı́guez, Àlvar Rodrı́guez, languages Álvaro, Àlvar, Rodrı́guez, Silvia Abrahao,","Silvia, Abrahao,Vicente, Vicent block farewell Spanish gracias, muchas gracias, adiós Valencian gràcies, moltes gràcies, adeu English thanks, thank you very much, goodbye Table 1: This table shows examples of phrases belonging to the blocks for Valencian and Spanish. English phrases are provided for a better understanding of the examples. were joined in parallel on a block-basis manner. Thus, the initial states (and the final states) of each language were merged for each block. Figure 3 shows an example of the parallelization process. Afterwards, the joint blocks were also joined in series. Figure 4 shows an example of the parallelization process for the joint automata. Figure 2: Illustration of the serialization process. The automaton corresponding to the block ’person’ was, in both cases, the list of all the people in the two languages. This reflects the natural tendency of speakers to call people the way they are used to doing so. Moreover, the names and Figure 3: Illustration of the parallelization process. Figure 4: Illustration of the combined parallelization and serialization process. surnames were allowed separately as well."]},{"title":"4. Corpus acquisition","paragraphs":["The corpus should have about 1 hour per language in order to make a quick acquisition and to be long enough to train reliable acoustic models in future experiments. As-suming that the average length of an utterance is 3 seconds, we decided to design a set of 120 sentences (60 for each language) for 20 speakers. This provides approximately 1 hour of speech signal per language. The separate language models were used to generate the corpus. However, a human reviewer was needed to correct the syntactic inconsistencies introduced by the block-oriented automata development, such as gender and number agreement. The corpus acquisition was developed on the telephone line. Half of the volunteer speakers were native Spanish speakers and the other half were native Valencian speakers. Both languages were acquired from all the participants; thus, non-native speech was recorded for both languages."]},{"title":"1626","paragraphs":["Male and female speakers were equally distributed in these groups. In the final design of the corpus, there were five groups of people with four people per group. Each group contained people of all types (men/women, Spanish/Valencian). With this distribution, we ensured a balanced distribution of native and non-native utterances, along with male and female utterances, for both languages. The Spanish phone set was formed by 26 phonemes in the phonetical scheme that we used. Transcriptions were automatically performed following the rules described in (Quilis, 1999) for the SAMPA phonetic alphabet (UCL, 1993). However, Valencian pronounciation does not follow clear, simple rules as Spanish does. No studies have been done to help us transcribe the sentences automatically. Therefore, the Valencian transcriptions were performed manually for each word of the vocabulary, including all the known phonetic variations. The Valencian phone set we used differs by only one phoneme from the Spanish set. The Spanish phoneme /c/ (as in zapato /capato/) is not present in Valencian, but / ∫ / (as in roig /ro ∫","/) is. The remaining phonemes are shared between the two languages. Each acquisition session lasted an average of 50 minutes. Although literal reading was compulsory, the speakers were allowed to pronounce Valencian and Spanish as they normally do. Nearly 2 hours of speech signal were actually acquired (in-cluding the silences) for each language. The signal was recorded with a GSM encoding at 8000 Hertz using a 3COM U.S. Robotics modem (USR, 1993). Although the GSM encoding signal provides worse quality than a-law or mu-law encoding, the fact is that the GSM encoding is currently being widely used in mobile telephony. As the mobile phone market is rising sharply, most of the potential users of these systems will use mobile phones and, other encoding schemes will not improve the signal quality. The ambient noise was the typical noise found in a computer laboratory with the occasional mobile phone intefering with the phone line. Silences at the beginning and end of the speech signal were not removed."]},{"title":"5. Future Work","paragraphs":["After the corpus acquisition, its exploitation would basically consist of using it for several test purposes on different multilingual ASR for Spanish and Valencian in order to assess the performance of the different options (e.g., using shared or separated acoustic models, using language identification before the recognition process, etc.). Specifically, experiments will focus on two goals. The first one is to evaluate the corpus in a coupled multilingual speech recognizer which is expected to perform similarly or better than a separate recognizer. The second goal is to obtain a good ratio in speaker-language identification. The purpose of this corpus was to acquire a corpus to assess the viability of this research line. The acquisition of an acoustic corpus is a tedious task, and therefore, we decided to acquire a minimal corpus which may be a drawback for larger experiments. However, huge Spanish acoustic resources are widely available in the community. The Valencian acoustic signal of this corpus could be used for adaptation purposes, e.g., to adapt good Spanish acoustic models to the Valencian dialect by means of speaker adaptation techniques (Leggeter and Woodland, 1995). Finally, further experiments are planned for a larger corpus if promising results are obtained in the corpus presented in this work."]},{"title":"Acknowledgements","paragraphs":["The authors wish to thank the volunteer speakers who participated in the multilingual corpus acquisition, as well as the reviewers for their comments and suggestions."]},{"title":"6. References","paragraphs":["R. Billi, F. Canavesio, and C. Rullent. 1998. Automation of telecom italia directory assistance service: Field trials results. In Proc. IVTTA 1998, pages 11–16, Turin.","J. Chu-Carroll and R. Carpenter. 1999. Vector-based natural language call-routing. Computational Linguistics, 25(3):361–388.","J.E. Diaz-Verdejo, A.M. Peinado, A.J. Rubio, E. Segarra, N. Prieto, and F. Casacuberta. 1998. Albayzin: a task-oriented spanish speech corpus. In Proceedings of LREC, volume 1, pages 497–501.","R. Eklund and A. Lindström. 2001. Xenophones: An in-vestigation of phone set expansion in swedish and implications for speech recognition and speech systhesis. Speech Communication, 35:81–102.","S. Furui. 1992. Toward robust speech recognition under adverse conditions. In Proceedings ESCA Workshop on Speech Processing in Adverse Conditions, pages 31–41, Nov.","A. L. Gorin, G. Ricardi, and J. H. Wright. 1997. How may i help you? Speech Communication, 35:113–127.","H. G. Huang. 1991. Speech recognition in adverse environments. Computer Speech and Language, 5:275–294.","Institut Valencià d’Estadı́stica, Comunitat Valenciana, 2001. Població en vivendes familiars de 3 i més anys, segons el coneixement del valencià, l’edat i el sexe.","C.J. Leggeter and P. Woodland. 1995. Maximum likelihood linear regression for speaker adaptation of continuous density hidden markov models. Computer Speech and Language, 9:171–185.","F. Mas, J. Vicedo, and C.D. Martı́nez-Hinarejos. 2004. Development of a voice-based telephone information system. In Actas de las III Jornadas de Tecnologı́as del Habla, Valencia, Spain, November.","A. Quilis. 1999. Tratado de fonologı́a y fonética españolas. Madrid (Gredos), second edition.","UCL, 1993. SAMPA computer readable phonetic alphabet.","USRobotics, 1993. 3Com U.S. Robotics 56K Message Modem Users Guide and Reference.","Sander J. van Wijngaarden. 2001. Intelligibility of native and non-native dutch speech. Speech Communication, 35:103–113."]},{"title":"1627","paragraphs":[]}]}