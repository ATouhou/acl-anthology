{"sections":[{"title":"An Answer Bank for Temporal Inference Sanda Harabagiu and Cosmin Adrian Bejan","paragraphs":["Human Language Technology Research Institute The University of Texas at Dallas Richardson, TX 75083-0688, USA sanda,ady@hlt.utdallas.edu","Abstract Answering questions that ask about temporal information involves several forms of inference. In order to develop question answering capabilities that benet from temporal inference, we believe that a large corpus of questions and answers that are discovered based on temporal information should be available. This paper describes our methodology for creating AnswerTime-Bank, a large corpus of questions and answers on which Question Answering systems can operate using complex temporal inference."]},{"title":"1. Introduction","paragraphs":["TimeML (Hobbs and Pustejovsky, 2003) is a corpus annotated with: (a) time expressions; (b) events and (c) links between them. These annotations enable several forms of temporal inference (Boguraev and Ando, 2005), (Moldovan et al., 2005), (Harabagiu and Bejan, 2005). However, additional forms of temporal inference are involved when answering questions. For example, in TimeML, the passage illustrated in Figure 1 has annotations that relate (a) the temporal expression “May 22, 1995” to the verb phrase “made a brigadier general” and (b) the temporal expression “the following year” to the verb phrase “appointed military attache” . This passage is answering the question “ Q1: How long it took Frakas to become military attache at the Hungarian embassy in Washington after his promo-tion to brigadier general ?” On May 22, 1995, Frakas was made a brigadier general, and the following year he was appointed military attache at the Hungarian embassy in Wa− shington. Figure 1: Example of passage from TimeML. Automatic Question Answering (Q/A) involves (1) the question processing; (2) the passage retrieval; and (3) the answer extraction. When processing question Q1, three goals must be achieved: GOAL 1: As reported in (Harabagiu et al., 2001) the expected answer type (EAT) of the question must be determined. In the case of Q1, the EAT is a TIME DURATION. This EAT is typically associated with question stems of the form “How long” and with idiomatic expressions like “it takes” . GOAL 2: Second, question processing involves the discovery of dependencies between the EAT and the other concepts from the question. When we apply shallow semantic parsing on Q1, we discover the dependencies illustrated in Figure 2. The semantic information is produced by a semantic parser trained on the PropBank annotations (www.cis.upenn.edu/ ace), which was reported in (Moschitti and Bejan, 2004). The semantic parser is able to recognize predicate-argument structures in which the predicates are lexicalized by (a) verb or (b) nominalizations. For the case when predicates are nominalizations, the seman-ARGM−TMP at the Hungarian embassy military attache Farkas ARG2 ARG1 ARGM−LOC in Washington","E1becomeEAT = TIME_DURATION (How long it took)","brigadier generalhisARG1 ARG2 Coreference E2promotion after Figure 2: Temporal and semantic dependencies in a question. tic parser relies on its classiers trained on the NomBank annotations (http://nlp.cs.nyu.edu/meyers/NomBank.html). For example, in Figure 2, the predicate-argument structure E1 is generated due to the data available from PropBank, whereas the recognition of E2 is enabled by data available from NomBank. Furthermore, the two predicate-argument structures are connected by a temporal relation made explicit by the signal “after” . This dependency needs to be interpreted as: (i) the beginning of the time duration sought by the EAT is simultaneous with the event illustrated as E1 in Figure 2 and (ii) the end of the time duration sought by the EAT is simultaneous with the event illustrated as E2 in Figure 2. GOAL 3: Keywords from the question need to be selected. The semantic dependencies resulting from the fulllment of GOAL 2 help selecting the best keywords. The keywords are grouped in two classes, each corresponding to a different predicate-argument structure that needs to be retrieved. The rst class of keywords KC1 includes KC1=fK1=“F arkas” , K2=“military” , K3=“attac he” , K4=“Hungarian” , K5=“embassy” , K6=“W ashington” g, whereas KC2=fK′ 1=“F arkas” , K′ 2=“brigadier” , K′ 3=“g eneral” g. Moreover, the keywords and the EAT","are expected to establish meaningful semantic relations in","the passages that are retrieved.","The passage retrieval module for our Q/A system is using","the keyword classes to express semantic constraints that are","expected to be met by the relevant passages. Some of the","semantic constraints are using temporal inference. The two","queries that are generated based on KC1 and KC2 are: QUERY1=[ARG1(K1), ARG2(K2; K3), ARGM-LOC(K4,","K5; K6), ARGM-TMP(END(EAT))] QUERY2=[ARG1(K′","1), ARG2(K′","2; K′","3), ARGM-TMP","(START(EAT))]"]},{"title":"741","paragraphs":["The passage retrieval component of our Q/A system returns a ranked list of passages to each of the queries. The answer extraction module needs to select the partial answers and to infer the correct answer. If it selects the passage illustrated in Figure 1, the answer is “ar ound one year” . In the passage, the time duration is not explicit, but a temporal expression is linked to each of the events. However, two more problems hinder the answer inference process: (1) the events from the question do not match the events from the passage, thus the condence that they are paraphrases needs to be assessed; and (2) there is no temporal signal like “after” connecting the two events in the passage, thus other form of temporal inference needs to be used. The rst problem is addressed by acquiring paraphrases of events, whereas the second problem is solved by having access to temporal normalizations. For example, the normalization of temporal expression T E1=“the following year” from the passage illustrated in Figure 1, is 1996DDMM (where DD represent the day of the MM, which is the month), because the reference to the implicit current year is resolved to 1995, which was derived from T E2=“May 22, 1995” . The two temporal expressions have the roles T E1=END(EAT(Q1)) and T E2=START(EAT(Q1)). When computing the TIME DURATION from the normalizations of expressions T E1 and T E2, the answer extractor cannot generate an exact answer, but only the approximation “ar ound one year” . This is because of the unknown month and day from the normalization of T E1. If the MM digits are between 01 and 05 the TIME DURATION is less than a year, whereas if it is larger than 05, it becomes more than a year. To enable Question Answering systems to operate with complex temporal inference, there is need of a large corpus of questions and answers on which Q/A systems can be trained. We created such a corpus, that we call AnswerTime-Bank, in which the answers are selected and benet from the TimeML annotations. We aimed at producing a large set of complex questions, that are answered by different forms of temporal inference. (Saquete et al., 2004) has illustrated the need for such resources. Our annotations mark: temporal normalizations, paraphrases, as well as inference that justies the answer. Additionally, temporal inference interacts with other forms of textual inference, that may benet the Q/A task. The recent PASCAL RTE evaluation (Dagan et al., 2005) as well as the AQUAINT inference evaluations have shown need for capabilities to infer and draw entailments constrained by temporal information. Textual entailment has been dened as the task of deciding, given two text fragments, whether the meaning of one of the texts can be inferred from the other text. The AQUAINT KB evaluations have also considered the case when one of the texts is a question, the other text is a background to the question, and the textual inference enables the answering to the question. For example, Figure 3 illustrates the question QKB that is entailed by the passage PKB because the prediction of a further increase presupposes a past increase. To be able to infer the answer AKB, we need to recognize:","1. Two events in PKB: e1 = the predicting event and e2 = the","increasing event, in which e2 is temporally constrained to","KBP : The Russian Emergencies Ministry predicts a further increase in\\ 1999 of the concentration of the toxic agents in marine burials of chemical weapons.","chemical weapons increased prior to 1999? A : Yes.KB Q : Has the concentration of toxic agents in marine burials of KB Figure 3: Answering temporal questions with entailment. happen DURING 1999;","2. The event e2 = the increasing event in QKB which this time is constrained to happen BEFORE 1999;","3. The factive relation between event e1 and e2 in PKB; and most importantly","4. The interpretation of the modier “further” for event e2, which indicates that there is a CONTINUATION of e2 from a previous time. Based on this information, the answer AKB may be inferred. Figure 4(a) illustrates the events, modiers and temporal expressions from Figure 3. We represent events as e1 m2 e2 CONTINUATIONFACTIVE t1 DURING PKB Yes/No EAT Q KB e2 t1 BEFORE YesKBA","CONTINUATION DURING e tm BEFORE e t (a) (b) INFERENCE RULE Figure 4: Inference rule that enables the entailment from Figure 3. circles, their modiers as diamonds and temporal expressions as squares. The EAT is represented as well. For example, if the modier m indicates that the event e shall be in a CONTINUATION process, and the event e takes place DURING the time period t, we infer that the event e was also happening before the time period t. Inference rules, like the one illustrated in Figure 4(b), are based on possible relations that exist between (a) events; (b) time expressions and (c) modiers of events. Example of such temporal relations were introduced in (Allen, 1991). Temporal relations, when discovered, may lead to other questions than QKB which was illustrated in Figure 3. Two examples of additional questions that are answered by PKB are: Q : What did the Russian Emergencies Ministry predict in 1999 ? KB1 KB2 Q : When did the increase of the concetration of the toxic agents i\\n","marine burials of chemical weapons happen ? All these questions and their answers are useful for Q/A system developers. Question QKB tests the ability to use temporal inference, whereas question Q1","KB or Q2","KB test the ability to locate information that is constrained temporally. The reminder of the paper is organized as follows. Section 2 describes the methodology employed for selecting questions and answers in our TimeAnswer-Bank. Section 3 details the bootstrapping of new data. Section 4 reports on the usage of semantic and pragmatic knowledge required by temporal inference in Q/A. Section 5 summarizes the conclusions."]},{"title":"742 2. Question and Answer Selection Based on TimeML Annotations","paragraphs":["Time expressions anchor events and states in narratives. They do the same anchoring in questions. We have used human-generated questions and annotated them in the same way as narratives are annotated in TimeML. There are three types of objects that are annotated:","Time expressions, annotated through TIMEX3 tags;","Event expressions, corresponding to EVENT tags;","LINK tags that encode various relations that hold be-","tween temporal elements. There are three types of TIMEX3 expressions: (a) fully specied temporal expressions, e.g. “A ugust 14, 1990” ; (b) underspecied temporal expressions, e.g. “Monday” , “ne xt month” , “last year” , “two days ago” ; and (c) durations, e.g. “two months” , “a week” . In addition, a TIMEX3 expression can provide a temporal anchor for other temporal expressions in the document. In TimeML, seven types of events are considered:","1 occurence, e.g. \"die\", \"crash\".","state, e.g. \"on board\", \"kidnapped\", \"loved\".","reporting, e.g. \"say\", \"report\", \"announce\".","immediate−action, e.g. \"attempt\", \"try\".","immediate−state, e.g. \"believe\", \"intend\".","aspectual, e.g. \"begin\", \"finish\", \"stop\".","perception, e.g. \"see\", \"hear\", \"feel\". 2 3 4 5 6 7 In TimeML texts, there are annotations of two types of relations:","binary relations, that are established between (i) pairs","of events or (ii) events and temporal expressions; and","signaled relations, which link events and/or temporal","expressions through temporal signals. Temporal signals are: (a) temporal prepositions, e.g. “dur - ing” , “on” , (b) temporal connectors, e.g. “when” , “while” and (c) temporal subordinates, e.g. “if ” , “then” . To capture all temporal relations in text and to provide means for disambiguating them, TimeML uses a set of three LINK tags: 1 . TLink or Temporal Link1",", representing temporal rela-","tions holding between events or between an event and","a time; 2 . SLink or Subordination Link2",", used for contexts intro-","ducing relations between two events; and 3 . ALink or Aspectual Link3","representing the relationship","between an aspectual event and its argument event. Additionally, we have marked up modiers that entail temporal information, similarly to the adjective “further” in Figure 3. We have used a new LINK tag, that we called MLink, for Modier Link. The relations made explicit by MLink overlap with relations made explicit by TLink, SLink and ALink.","1","The TLink makes explicit the following relations: (1) BEFORE; (2) AFTER; (3) INCLUDES; (4) IS INCLUDED; (5) DURING; (6) SIMULTANEOUS; (7) IMMEDIATELY AFTER; (8) IMMEDIATELY BEFORE; (9) IDENTITY; (10) BEGINS; (11) ENDS; (12) BEGUN BY and (13) ENDED BY.","2","The SLinks are one of the following sorts: (1) MODAL; (2) NEGATIVE; (3) EVIDENTIAL; (4) NEGATIVE EVIDENTIAL; (5) FACTIVE; (6) COUNTER-FACTIVE and (7) CONDITIONAL.","3","The ALink relations are (1) INITIATES; (2) CULMINATES; (3) TERMINATES; (4) CONTINUES and (5) REINITIATES. The annotations available from TimeML can be used for selecting answers for which we can generate multiple questions. In Section 1 we have exemplied an answer originating in TimeML (Figure 1) and we have discussed how it can answer question Q1. Our search for answers available from TimeML starts with the discovery of two temporal expressions T1 and T2. The Answer Selection Procedure is: Discover T1 and T2, temporal expressions in the sameStep 1: Step 2: Step 3: Step 4: Step 5: sentence or in adjacent sentences. Find events E1 and E2 linked to T1 and T2 respectively. Find link chains CE1 between E1 and other events. Find link chains CE2 between E2 and other events. Use implicit temporal inference on CE1 and CE2. When applying the Answer Selection Procedure to the example illustrated in Figure 5 we discover: (1) temporal expressions t1 and t2 (Step 1); (2) events e1 and e4 linked to t1 and t2 with TLink:IS INCLUDED (Step 2); and (3) the event chain fe1, e2, e3g (Step 3). Because t1 and t2 are linked (by an ANCHORTIME(t2) = t1) we conclude that fe1, e2, e3g and e4 are simultaneous (Step 5). Some 1,500 ethnic Albanians marched Sunday in downtown Istanbul, CREATION TIME: 03/08/1998 e1 burning Serbian flags to protest the killings of the ethnic Albanians by Serb police in southern Serb Kosovo province. Meanwhile in the capital, Ankara, a few hundred ethnic Albanians laid t1 e2 e3 t2 e4 TLink: IS_INCLUDED ANCHOR_TIME(t2) = t1 TLink: SIMULTANEOUS SLink: FACTIVE TLink: IS_INCLUDED a black wreath at the gate of Yugoslavian embassy. Figure 5: Example of TimeML annotation. Figure 6 illustrates three forms of temporal inference that are dictated by the types of links in event chains. In Figure 6(a), the fact that the anchor of t2 is t1 indicates that events e1 and e2 must be simultaneous. Therefore, the conclusion of the temporal inference rule illustrated in Figure 6(a) creates a new TLink:SIMULTANEOUS relation between the two events. In Figure 6(b), the event chain created from e1 fe1, e3g has a TLink:BEFORE, indicating that e3 happened before e1. If the anchor of t2 is t1, the temporal inference rule has two conclusions: (1) that between e3 and e2 there is a TLink:BEFORE and (b) that between e1 and e2 there is a TLink:SIMULTANEOUS. For the example illustrated in Figure 5, the temporal inference rule that applies (Step5 of Answer Selection Procedure) is illustrated in Figure 6(c). There are three conclusions of the temporal inference rule illustrated in Figure 6(c) because there were three events in the event chain connected to t1 and only one event connected to t2. Figure 6 illustrates the format of our implicit temporal inference rules. The left-hand side of the rule represents the possible relations between events (chains) and temporal expressions whereas the right-hand side represents one or more conclusions which are expressed by pairs of events connected by new TLink expressions."]},{"title":"743","paragraphs":["(a) e1 t1 t2 e2 e1 e2","(b) e1 e2 e1 t1 t2 e2e3 e3 e2 t2 e4e1 e2t1 e3 (c) e1 e4 e2 e4 e3 e4 TLink: SIMULTANEOUS TLink: SIMULTANEOUSTLink: IS_INCLUDEDTLink: IS_INCLUDED ANCHOR_TIME(t2) = t1 TLink: IS_INCLUDEDTLink: BEFORE TLink: IS_INCLUDED TLink: BEFORE SLink: FACTIVE ANCHOR_TIME(t2) = t1 TLink: IS_INCLUDEDTLink: SIMULTANEOUS TLink: IS_INCLUDED TLink: SIMULTANEOUS TLink: SIMULTANEOUS TLink: SIMULTANEOUS ANCHOR_TIME(t2) = t1 Figure 6: Inference rules based on TimeML links. When the answer is selected and implicit inference has been discovered, we can generate questions that require temporal inference. For the answer illustrated in Figure 5, since all events are simultaneous (as indicated by the implicit inference rule from Figure 6(c)), we can refer to all events with the generic expression (e.g. “actions” ) on a specic time (e.g. “Sunday March 8, 1998” ). Furthermore, the predicate-argument structures derived from the two sentences illustrated in Figure 5 indicate that all events have as actors ethnic Albanians. Thus, we may associate this paragraph with the generic question QG","1 . 1G Q : What actions were taken by ethnic Albanians in Turkey, on Sunday,","March 8, 1998 ? In order to create the AnswerTime-Bank, we also need a Question Suggestion Procedure which employs (a) the answers selected as well as (b) the forms of temporal inference that are available on them. This procedure also uses 40 different possible EATs to produce question suggestions. The Question Suggestion Procedure is:","Step 1: Step 2: Step 3: place them in [All−EATs] For every EAT from [All−EATs] suggest the question dependencies. Find EATs compatible with the selected answers and Use the semantic dependencies from the answer to Map the dependencies on a set of question patterns. a paraphrase having the same semantic dependencies.Ask the linguist researcher to suggest a question by using Validate the question. Step 5:Step 4: Step 6: (End loop) (Begin loop) For example, the EAT of QG","1 is a list of actions carried by the same agent:“ethnic Albanians” and in the same location:“T urkey” on the same date:“Mar ch 8, 1998” . Also, the factive relationship between e2:“b urning” and e3:“pr otest” indicates that the actions that were referred to in QG","1 can be specialized, as “forms of protest” and enable the generation of QG","2 . The other questions that were generated had either the time as the expected answer (QG","3 ) or some of the entities involved in the events constrained by time (for example QG","4 , QG","5 ). When between two events we nd an SLink:FACTIVE relation, since such relations introduce a presupposition or entailment between the events, we can generate a question that requests causal information (QG","6 ). The questions QG","1 , QG","2 , QG","3 , QG","4 , QG","5 and QG","6 , illustrated in Figure 7, were created by humans such that Q/A system developers can test their ability to answer them when employing (i) textual inference and (ii) relations between events and temporal expressions. Not all questions that humans generated were factual and related to a single date. For example, for the passage illustrated in Figure 1, we generated the question Q1, introduced in section 1, which asks about a time interval that is not explicit in the passage. To be able to create a TimeAnswer-Bank that encodes a large variety of questions that require temporal inference we needed to recognize automatically the temporal expressions, events and their interconnecting links such that we could nd many examples that use the same form of inference. With the annotations from TimeML, we were able to detect 4125 answers, to which we applied 120 implicit temporal inference rules similar to those illustrated in Figure 6. Because we found that event chains can have lengths from 1 to 6, we believed that it would be useful to have all the possible combinations of such links available such that we can generate questions that exploit the implicit temporal inference. In the rst phase of our work we have used event chains with the maximum length of 4. 3 4G Q : Who were the protesters in Turkey, in 1998?Q : When did the ethnic Albanians protest in Turkey, in March 1998?GQ : What forms of protest took place in Turkey, on Sunday, March 8, 199\\8? 2G G Q : Why did the ethnic Albanians protest in Turkey, in March 1998? 6Q : How many Albanians protested in Turkey, in March 1998? 5G Figure 7: Example of questions generated for the text illustrated in Figure 5."]},{"title":"3. Bootstrapping the AnswerTime-Bank","paragraphs":["The Answer Selection Procedure, together with the Question Suggestion Procedure, enabled us to assemble 3472 questions that require temporal inference and to have available answers for them as well as annotations that inform the temporal inference. However, in this form, AnswerTime-Bank has several limitations . First, we could not assemble examples for all the forms of questions that require temporal inference that were listed in (Harabagiu and Bejan, 2005). Second, for each type of question, we did not have a very large number of examples. Third, due to the limitations of the Answer Selection Procedure, we did not have any instance of answers that originated in different documents. In order to address these issues, we have started to bootstrap the AnswerTime-Bank by selecting answers from the AQUAINT corpus. In the bootstrapping procedure, we have modied the Answer Selection such that the pair of time expressions do not necessarily belong to the same or adjacent sentences. The bootstrapping procedure requires the discovery of (1) time expressions; (2) events; (3) temporal signals and (4) links between them. To discover time expressions, we relied on the TIMEX3 annotations produced for us by the TASER time recognition and normalization system (Aarseth et al., 2005). We considered as events only the verbs, which are part of predicate-argument structures recognized by our semantic parser (Moschitti and Bejan, 2004), ltering out all the forms of the verb “be” and several form of generics as well, as is described in (Sauri et"]},{"title":"744","paragraphs":["al., 2006). To classify events in text we implemented similar methods as the ones described in (Sauri et al., 2005). Temporal signals were recognized based on lexicons. We also needed to discover the three types of links. For this reason, we have developed and implemented four link detection methods that are illustrated in Figures 8, 9, 10, 11. Since TLink relations need to be identied in the AQUAINT corpus, we have implemented a method for automatically recognizing such relations by extending the method reported in (Lapata and Lascarides, 2004), which aimed the discovery of temporal constraints between two clauses from the same sentence. Predicate-argument structures discovered by semantic parsers enable us to detect relations between events expressed as verbs and temporal expressions. But such predicate-argument structures do not indicate what type of TLink exist. Thus, we rst generated a classier, of which features are illustrated in Figure 8, that enabled us to detect TLinks between such events and temporal expressions. TLink Detection Method 1 We have trained a decision tree classifier that considers the following features: −verb lemma −the temporal signal that begins the ARGM−TMP (if it exists) −the temporal signal that ends the ARGM−TMP (if it exists) −the temporal signals that are in the clause containing the verb −distance in words between ARG−TMP and the verb −position of the ARG−TMP with respect to the verb −presence in ARGM−TMP of words like: later, past, future, recently, late, previously, over, ago −verb tense earlier, next, last Output: − TLink (Y/N) and TLink class− TIMEX3 expressionInput: − Predicate−argument structure with ARGM−TMP Figure 8: Method 1 for discovering TLink relations. For discovering temporal relations between events in free text, we used an event graph-based representation. Specically, the nodes in the graph are represented by events and the edges between the nodes are either TLink, SLink or ALink relations. We have extended the model proposed in (Lapata and Lascarides, 2004) for classifying the TLink relations between events in two consecutive sentences and we also have enhanced the model with additional features. Concretely, for each pair of events from the same sentence or from consecutive sentences we used an SVM classier that predicts and classies a possible TLink relation. The features used for training the classier are illustrated in Figure 9. For discovering TLink relations at the discourse level, we observed that transitional words introducing sentences or clauses play an important role. For example, transitional words expressing addition like “in addition” , “additionally” , “mor eover” introduce SIMULTANEOUS TLink relations, result transitional words like “as a result of” , “in consequence” introduce AFTER and BEFORE relations, while time transitional words like “meanwhile” , “immediately” , “in the meantime” , “in the past” , “in the future” , “finally” , “then” , “ne xt” , “afterwar d” may introduce all the types of TLink relations. All these TLink relations represent the edges in the event graph built over the entire text for which the method is applied. However, we cannot rely entirely on the method presented above and therefore we have to check the con-TLink Detection Method 2 We have trained an SVM classifier that considers the following features: −all the features described in (Lapata and Lascarides, 2004) −the temporal signals between the two verbs −the temporal signals that are in the clauses containing the verbs −distance in words between the two verbs Output: − TLink (Y/N) and TLink classsecutive sentencesInput: − a pair of events in the same sentence or in two con− since they perform well in discovering temporal relations between events in the same sentence −transitional words introducing sentences or clauses of the verbs Figure 9: Method 2 for discovering TLink relations. sistency of the event graph and to remove all contradictory relations between two events in the graph. For this, we inferred all the possible temporal relations between two events in the graph following all possible paths that connect these two events. If we nd contradictions in the inferred temporal relations, we discard all the temporal relations that connect these two events. An example of a contradiction in an event graph is: if we have event E1 TLink:AFTER event E2 and E2 TLink:SIMULTANEOUS E3, then we cannot have in the event graph E1 TLink:BEFORE E3. We also discard all the TLink relations in the event graph that can be replaced by an ALink or SLink relation discovered by the next two methods. ALink relations represent the temporal relations introduced by aspectual events. We observed in TimeML corpus that different aspectual events trigger different types of aspectual relations. For example, the most frequent aspectual events for each type of the ALink relation in TimeML are:","initiation: “open”, “begin”, “become”, “start”, “trigger”.","termination: “end”, “suspend”, “stop”, “abandon”.","continuation: “extend”, “reinsate”, “remain”, “continue”.","reinitiation: “resume”, “restore”, “return”.","culmination: “finish”, “complete”, “reach”. Starting from this observation, we derived the method illustrated in Figure 10 that identify aspectual relations. ALink Detection Method Input: − a pair of events in the same sentence Output: − ALink (Y/N) and ALink class The method for identifying aspectual relations is described in the following steps: 1. Build aspectual event clusters from TimeBank with the most frequent events that introduce ALink relations. 2. Bootstrap the clusters with aspectual events that require se− mantic processing. To accomplish this task, we used WordNet relations for determining if a event is in relation with events from the aspectual event clusters constructured at Step 1. For exam− ple, we classify \"graduate\" as an event that introduce culmination relation, because it has \"culminates\" in its WordNet gloss. 3. Identify an ALink relation between two events inside a sentence if: (a) the first event is an aspectual event that belongs in one of the five aspectual event clusters and (b) the second event is situa−\\ ted in the same verbal phrase structure with the first event. Label relation with the cluster label of the aspectual event. Figure 10: Method for discovering ALink relations.","In general, the SLink relations are introduced by particu-","lar classes of events. Some of these classes are presented","below: events expressing presuppositions and beliefs: “think”, “be-","lieve”, “try”, “predict”, “want”, “able to”, “hope”. perception events: “see, “look”, “hear”, “perceive”. reporting events: “say”, “tell”, “report”, “quote”. events expressing negative polarity: “deny”, “reject”."]},{"title":"745","paragraphs":["We build these semantic classes of events form TimeML and, in a similar way as in ALink method, we used WordNet to enrich the semantic classes with additional events. Not only this classication of events help in identifying the SLink relations, but also they are used as features in a multiclass classier for identifying the SLink relation types as illustrated in Figure 11. For example, reporting and perception events introduce EVIDENTIAL SLink relations and events expressing negative polarity introduce NEGATIVE EVIDENTIAL SLink relations. Other features we used for classifying the SLink relations are illustrated in Figure 11. SLink Detection Method","Input: − a pair of events in the same sentence Output: − SLink (Y/N) and SLink class We have trained an SVM classifier that considers the following features: −the temporal signals that are present in the event clauses −obligation: presence of modals like \"must\", \"ought\", \"should\" −verb lemma −verb tense −lexical features and the part of speeches for the words surrounding the two events −the semantic class of the events (if the case) −the type of the events −possibility: presence of modals like \"can\", \"could\" −ability: presence of modals like \"might\", \"may\" −future: presence of modals like \"will\", \"shall\", \"would\" −negation: presence of words like \"not\", \"n’t\" Figure 11: Method for discovering SLink relations. Many complex questions do not have the entire answer in the same document; they require answer fusion. In view of this condition, we have included new documents, annotated them in the same way as TimeML and then decided on the partial answers before creating the complex question. Our resource characterizes both question decomposition and the answer fusion in terms of types of links between events or events and time expressions. One key aspect of the bootstrapping process is the identication of answer types for questions created by humans. They enable us to propose new questions and answers. For example, given an answer type FORMS-OF-PROTEST that is constrained by a given date (for QG","2 ), we acquired a set of patterns that represent forms of protest with the method reported in (Thelen and Riloff, 2002) and determined which events occurred in the same time and location. Then we replaced the date to generate questions like QG","7 .","7Q : Who were the protesters during the Scotland Summit in 2004?G This is an example of complex question, where we employed the temporal connector “during” to express the temporal constrains."]},{"title":"4. Inference with Semantic and Pragmatic Knowledge","paragraphs":["One important property of the AnswerTime-Bank is the semantic and pragmatic variation between questions and answers. We have carefully used (1) paraphrases of the answer and (2) generalizations such that we could allow for semantic and pragmatic inference while processing temporal questions. Consequently, we have also annotated the forms of semantic knowledge that are required and suggested possible sources of such knowledge. For example, often domain knowledge was required. For the sentence,","In fiscal1989, Elco earned $7.8 million, or $1.65 a share. to produce the question","What was Elco’s revenue in 1989? we relied on semantic glossing of the concept “r evenue” as the money earned by a company during a given year. Such a gloss is available from WordNet, and we have encoded the mappings between the question and answer concepts using the WordNet glosses. An important factor is the bootstrapping of such lexico-semantic resources that account for the inference of temporal answers. The resource is important as well for studying paraphrases under temporal constraints."]},{"title":"5. Conclusions","paragraphs":["We have described the methodology we employed to date for generating a corpus of questions and answers that require temporal inference. AnswerTime-Bank was built using the annotations from TimeBank. We have described as well our method of bootstrapping the resource by discovering automatically TimeBank-like expressions and links. We believe that AnswerTime-Bank shall be a valuable resource for researchers interested in Question Answering. Acknowledgments This material is based upon work funded in whole or in part by the U.S. Government and any opinions, ndings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reect the views of the U.S. Government."]},{"title":"6. References","paragraphs":["Paul Aarseth, Murat Deligonul, John Lehmann, Luke Nezda, and Andrew Hickl. 2005. ACE 2005 TERN System Description: TASER. In Proceedings of ACE 2005 Workshop.","James F. Allen. 1991. Time and time again: The many ways to represent time. International Journal of Intelligent Systems, 6(4):341356.","Branimir Boguraev and Rie Kubota Ando. 2005. TimeML-Compliant Text Analysis for Temporal Reasoning. In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-2005).","Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The PASCAL recognizing textual entailment challenge. In Proceedings of the PASCAL Challenges Workshop Recognizing Textual Entailment.","Sanda Harabagiu and Cosmin Adrian Bejan. 2005. Question Answering Based on Temporal Inference. In Proceedings of the AAAI-2005 Workshop on Inference for Textual Question Answering.","Sanda M. Harabagiu, Dan I. Moldovan, Marius Pasca, Rada Mihalcea, Mihai Surdeanu, Razvan C. Bunescu, Roxana Girju, Vasile Rus, and Paul Morarescu. 2001. The Role of Lexico-Semantic Feedback in Open-Domain Textual Question-Answering. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics (ACL-2001), pages 274281.","Jerry Hobbs and James Pustejovsky. 2003. Annotating and Reasoning about Time and Events. In Proceedings of the AAAI Spring Symposium on Logical Formalizations of Commonsense Reasoning.","Mirella Lapata and Alex Lascarides. 2004. Inferring Sentence-internal Temporal Relations. In In Proceedings of the North American Chapter of the Assocation of Computational Linguistics, 153-160. Boston.","Dan Moldovan, Christine Clark, and Sanda Harabagiu. 2005. Temporal Context Representation and Reasoning. In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-2005).","Alessandro Moschitti and Cosmin Adrian Bejan. 2004. A Semantic Kernel for Predicate Argument Classication. In Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004), Boston, MA,USA.","E. Saquete, P. Mart·nez-Barco,R. Munoz, and J.L. Vicedo. 2004. Splitting Complex Temporal Questions for Question Answering systems. In Proceedings of the 42th Annual Conference of the Association for Computational Linguistics (ACL-04), pages 567574.","Roser Sauri, Robert Knippen, Marc Verhagen, and James Pustejovsky. 2005. Evita: A Robust Event Recognizer for QA Systems. In Proceedings of HLT/EMNLP.","Roser Sauri, Jessica Littman, Bob Knippen, Robert Gaizauskas, Andrea Setzer, and James Pustejovsky. 2006. TimeML Annotation Guidelines. http://www.timeml.org.","Michael Thelen and Ellen Riloff. 2002. A Bootstrapping Method for Learning Semantic Lexicons Using Extraction Pattern Contexts. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing."]},{"title":"746","paragraphs":[]}]}