{"sections":[{"title":"A Differential Semantics Approach to the Annotation of Synsets in WordNet  Dan Tufiş, Dan Ştefănescu","paragraphs":["Research Institute for Artificial Intelligence, Romanian Academy 13, “Calea 13 Septembrie”, Bucharest 050711, Romania","tufis@racai.ro, danstef@racai.ro Abstract We describe a new method for sentiment load annotation of the synsets of a wordnet, along the principles of Osgood’s “Semantic Differential” theory and extending the Kamp and Marx calculus, by taking into account not only the WordNet structure but also the SUMO/MILO (Niles & Pease, 2001) and DOMAINS (Bentivogli et al., 2004) knowledge sources. We discuss the method to annotate all the synsets in PWN2.0, irrespective of their part of speech. As the number of possible factors (semantic oppositions, along which the synsets are ranked) is very large, we developed also an application allowing the text analyst to select the most discriminating factors for the type of text to be analyzed. Once the factors have been selected, the underlying wordnet is marked-up on the fly and it can be used for the intended textual analysis. We anticipate that these annotations can be imported in other language wordnets, provided they are aligned to PWN2.0. The method for the synsets annotation generalizes the usual subjectivity mark-up (positive, negative and objective) according to a user-based multi-criteria differential semantics model. "]},{"title":"1. Introduction","paragraphs":["Recent developments of WordNet Affect (Valitutti et al., 2004), SentiWordNet (Esuli & Sebastiani, 2006), and the hot topic of subjectivity analysis, (Wiebe et al., 2004), (Polanyi & Zaenen, 2006), (Andreevskaia & Bergler, 2006), (Mihalcea et al., 2007) to name just a few relevant papers, try to remedy the lack of explicit information regarding the sentiment load of the words recorded in a dictionary.  The pioneering work of Osgood et al. (1957) on the theory of semantic differentiation gives strong evidence that affective meanings can be outlined and measured by using a semantic differential technique. Essentially, what this psycholinguistic procedure does is to ask subjects to rate the meaning of a word, phrase or text on different scales defined in terms of pairs of bipolar adjectives (good-bad, active-passive, strong-weak, optimistic-pessimistic, beautiful-ugly, etc.). Each pair of bipolar adjectives is a factor in the semantic differential technique. The very interesting fact found out by (Osgood et al. 1957) was that most of the variance in text affect judgment could be explained by only three major factors. These are: the evaluative factor (e.g. good-bad), the potency factor (e.g. strong-weak) and the activity factor (e.g. active-passive). Out of these three factors, according to Osgood et al. (1957), the most discriminative is the evaluative one.  Starting from the semantic differential techniques (Kamp and Marx, 2002) developed algorithmic methods to assess the subjectivity of arbitrary texts. These algorithms rely on the structure and content of the WordNet semantic lexicon (version 1.7). In their approach, a text unit is regarded as a bag of words and the overall scoring of it is obtained by combining the scores for the individual words of the text. They describe their approach elaborating on the method along the evaluative factor (good-bad). By applying the method (described in the next section) they identified 5410 adjectives related to “good” and “bad”. Then, they applied the same method for the next two best discriminative factors as identified by Osgood and his colleagues, namely the potency factor (strong-weak) and the activity factor (active-passive). Given that WordNet incorporated all adjective pairs that Charles Osgood and his colleagues had used to develop the semantic differential, the set of adjectives related to the bipolar adjectives from the three factors mentioned above represented the same cluster of 5410 adjectives. The scores for the 5410 adjectives computed (in WordNet 1.7) with respect to the three factors were, as expected, different, but this finding provides algorithmic evidence in support of the empirical claims of (Osgood et al. 1957) that the semantic differential approach is an effective way of detecting subjective meanings linguistically expressed in arbitrary texts. As the authors remark, this is valid at least for the case of English. These adjectives appear to have a special status: they are the important modifiers expressing, in English, emotive or affective meanings. These words are named by (Kamp and Marx, 2002) “words with attitude”.  The inspiring work of Kamp and Marx may be extended in several ways to overcome the present limitations: - the bag of words approach can easily be fooled in the","presence of valence shifters (Polanyi & Zaenen,","2006), the scope of which requires minimal syntactic","structuring; - although the adjectives make the major class of","attitude bearing words, the other open class","categories have significant potential of expressing","subjective meanings;"]},{"title":"3173","paragraphs":["- the majority of the domain researchers agrees that the subjectivity load of a given word is dependent on the senses of the respective word; yet, in Kamp and Marx’s approach the sense distinctions for the literals defining a path (between the bipolar adjectives of a given factor) that contain a word of interest are lost making it impossible to assign different scores to different senses of the respective word.","","In our research we have tried to solve, at least partially,","these limitations by: - considering a shallow structure of the sentences in order to figure out the plausible scope of the valence shifters (negations, diminishers or intensifiers) and taking into account their effect on the words with attitude under their scope; - considering all open-class grammar categories in WordNet taking into account word senses.  In this paper we will address the necessary extensions of the Kamp and Marx’s model and its associated calculus so that it should work for all word classes considering also word-sense distinctions.  Our aim is to associate each synset with an attitude mark-up. We deliberately avoid the concept of subjectivity prior since we consider subjectivity a particular case of what Kamp and Marx named attitude. In our opinion, attitude is closer to the notions of connotation and/or evocation. For instance, the word cancer with the sense “any malignant growth or tumor caused by abnormal and uncontrolled cell division” objectively denotes a terrible disease, but it also has a definitely bad connotation, evoking suffering, fear, and other negative sentiments.  In (Tufiş, 2008, 2009) we presented a system named CONAN (CONnotation ANalyzer) which is able to compute not only the subjectivity score of a (tagged, lemmatized and parsed) sentence, but also to detect its potential for connotation shifts, on the basis of attitude mark-ups associated to WordNet synsets.  All the discussions below will be related to Princeton WordNet2.0 (PWN2.0). As the Romanian wordnet (ROWN) is fully aligned to this version of Princeton WordNet and given that the structures of the two aligned wordnets are identical, the annotations computed for PWN2.0 are automatically transferred to ROWN. In a future paper we will describe our experiments on the bilingual version (EN-RO) of the SEMCOR which was manually word sense disambiguated for the English part, annotations imported into the Romanian word-aligned translation. Both parts of the bilingual corpus were also chunked and dependency linked (Ion, 2007).  "]},{"title":"2. Kemp and Marx Model for the Lexical Attitude Mark-up","paragraphs":["Let us begin with some definitions, slightly modified, from Kemp and Marx (2002). We will progressively introduce new definitions to serve our extended approach. Definition 1: Two words wα and wβ are related if there exists a sequence of words (wα w1 w2 ... wi ... wβ ) so that each pair of adjacent words in the sequence belong to the same synset. If the length of such a sequence is n+1 one says that wα and wβ are n-related. For example, the words good and proper are related, more specifically are 2-related since the sequence (good right proper) observes the above definitions: synset1","0161119-a: (good:14 right:13 ripe:3) synset 00140845a: (right:6 proper:3 suitable:3) Two words may not be related at all or may be related by many different sequences, of various lengths. In the latter case, one would be interested in their minimal path-length: Definition 2: Let MPL(wi, wj) be the partial function : MPL(wi, wj)= n if n is the smallest number such that wi and wj are n-related and undefined if wi and wj are not related","MPL(wi, wj) has the following properties: a) MPL(wi, wj) = 0 iff wi, = wj b) MPL(wi, wj) = MPL(wj, wi)","c) MPL(wi, wj) + MPL(wj, wk) ≥ MPL(wi, wk) and thus MPL is a distance measure that can be used as a metric for the semantic relatedness of two words. Taking the example from (Kamp and Marx, 2002), “good” and “bad” are 4-related (good, sound, heavy, big, bad)2",": synset 01130226-a: (good:20 sound:4) synset 00663845-a: (sound:8 heavy:28) synset 02316892-a: (heavy:16 big:7) synset 01459996-a: (big:5, bad:2)  Using the properties a), b) and c) of the MPL distance, and observing that MPL(bad, good) = 4, one can easily demonstrate the following relation for any word x which is n-related to good: n - 4 ≤ MPL (bad, x) ≤ n + 4. Similar relations can be established for MPLs computed with respect to other bipolar words α-β:  MPL(α,x)–MPL(α,β)≤MPL(β,x)≤MPL(α,x)+ MPL(α,β)  This is an important observation since it gives the limits  1 We use here the synset unique identifiers from WordNet 2.0; the numbers following a literal in a synset represents the sense number of that literal: the sense number 14 of the literal good is synonymous with the sense number 13 of the literal right and with the sense number 3 of the literal ripe. 2 This is not the only path sequence of length 5 between good and bad."]},{"title":"3174","paragraphs":["for a recursive algorithm computing the MPL of a certain word to one of the bipolar words when the MPL to the other bipolar word was found. In the case of the good-bad pair and the word proper, if one computed MPL(good, proper)=2, then according to the observation above (since MPL for different arguments is strictly positive) we know that: 1 ≤ MPL (bad, proper) ≤ 6 Observing the properties of the MPL partial function, one can quantify the relatedness of an arbitrary word x to one or the other word of a bipolar pair. To this end (Kemp and Marx, 2002) introduced another partial function as in Definition 3. Definition 3: Let TRI (wi, wαααα, wββββ), with wαααα ≠ wββββ be: TRI(wi, wα, wβ) = (MPL(wi,wα)-MPL(wi,wβ))/MPL(wα,wβ) when all MPL are defined = undefined otherwise When defined, TRI (wi, wαααα, wββββ) is a real number in the interval [-1, 1]. The words wα and wβ are the reference words - the bipolar words of a factor, while wi is the word of interest for which TRI is computed. If one takes the negative values returned by the partial function TRI (wi, wαααα, wββββ) as an indication of wi being more similar to wα than to wβ, and the positive values as an indication of wi being more similar to wβ than to wα, a zero value could be interpreted as wi being neutrally related with respect to wα and wβ. This is different from being unrelated 3","and therefore, if αααα-ββββ specifies the bipolar words (the factor) used for the computation of relatedness of wi, one could define a proper function TRIαααα-ββββ (wi)*","as follows:","TRIα-β (wi)* = TRI(w i,α,β) iff TRI(wi,α,β) is defined","= 2 otherwise","Depending on the reference words (of the selected factor)","for the major factors identified by (Osgood et al.,1957)","namely the evaluative factor (good-bad), the potency","factor (strong-weak) and the activity factor","(active-passive), one gets:",")()( *","ibadgoodi wTRIwEVA −=",")()( *","iweakstrongi wTRIwPOT −=",")()( *","ipassiveactivei wTRIwACT −= Now, we can proceed with the generalization of the Kemp and Marx Model (KMM) described in this section."]},{"title":"3. A Sense-based Computational Model for the Lexical Factorial Mark-up","paragraphs":["In the KMM approach the bipolar words of a factor were defined based on the lexical relation of antonymy. We want to generalize the notion of a factor to a pair of  3 For instance a neutral word with respect to a factor might get a non-null value for the respective factor due to a valence shifter. A word unrelated to a given factor, i.e. objective with respect to that factor, should not have its factor objectiveness affected by a possible governing valence shifter. synsets.","Definition 4: An S-factor is a pair of synsets (Sα, Sβ) for","which there exist",":","","","and \\b : \\b","\\b","so that","",":","and \\b : \\b","are antonyms and \\tPL\\f",", \\b","is","defined. Sα and","Sβ have opposite meanings, but only"," : ","and \\b",": \\b","are antonyms. For these situations we","consider that \\tPL\\f, \\b \\tPL",", \\b",".We should","mention that not any pair of synsets with opposite","meanings represents a factor since it is not the case that","MPL is always defined4",". Let < , \\b> be an S-factor for which the pair of antonyms is A & B. Each word w in WordNet that can be reached on a path from A to B is given a score number which is a function of the distances from w to A and to B. The set of these words defines the coverage of the <A, B> factor – COV(<A,B>). The set of all synsets containing the words defines the semantic coverage of the corresponding S-factor – SCOV(<, \\b>). The major deviation from Kamp and Marx comes from our notion of an n-scoped synset: Definition 5: A synset is n-scoped relative to an S-factor <, \\b> if its SUMO/MILO label L is a node in the tree-like structure having as root the n-th parent of the lowest common ancestor of the SUMO/MILO labels of the two synsets \\b. We say that n defines the depth of the scoped coverage SCOVn< , \\b>) and that every synset in this coverage is n-scoped. If the root synset is Sγ we will use also use the notation SCOV<, \\b>) Sγ Every synset in SCOVn(<, \\b>) can be characterized by the <, \\b> S-factor. The characterization power of the S-factor <, \\b> is maximum for the synsets belonging to SCOV0(<, \\b>). For the synsets in SCOVn(<, \\b>) that cannot be found in SCOVn-1(< , \\b>) the characterization power of the S-factor is decreased5",". We say that SCOV0(<, \\b>) is the main “semantic field” which the S-factor is representative for. A higher value for n extends the field but the factor’s impact in the extended area is diminished. The original definition of n-related words from Kamp and Marx can be obtained from the one above when the value of n is increased so that to reach the top of the ontology. An identical definition may be formulated using instead of SUMO/MILO labels the DOMAINS labels and its hierarchy or even the WordNet hierarchy.   4 This might be explained in various ways: incomplete synsets, limited structuring for adverbial synsets or by the limitation of the current path constructing algorithm. For instance, between a pair of opposite synsets <A, B> when one of A or B contains a single literal and this is monosemous, no path can be established between A and B. This issue is subject to further research. 5 The power of an S-factor in characterizing a given synset is inversely proportional to the depth of the coverage at which the respective synset gets a relevance value for the S-factor. For instance, a synset which is not in the SCOV0(<, \\b>) but appears only in SCOVn-1(<, \\b>) will have the figure of merit for the S-factor <, \\b> penalized with a factor of n."]},{"title":"3175","paragraphs":["For the previous example with the words good and proper, their SCOV0 root is the NormativeAttribute concept since the semantic scope of the synset 0161119-a (good:14 right:13 ripe:3) is SubjectiveAssessmenAttribute, the semantic scope of the synset 00140845a (right:6 proper:3 suitable:3) is NormativeAttribute and SubjectiveAssessmenAttribute ISA NormativeAttribute (see Figure 1). Figure 1: Relations between the scoping concepts  We computed the coverage of the factors for the adjectives and adverbs, nouns and verbs. Our target is to associate each synset (not literal) of a wordnet with a factorial mark-up, namely an n-tuple <F1, F2... Fn> where each Fi represents a relevant factor and its value for the respective synset.  Definition 6: Let <Sα, Sβ> be an S-factor; then TRIS (Si, Sα, Sβ) is defined as the average of the TRI values associated to the literals making the synset.","TRIS\\f, α, β ∑ TRI, α",", \\b","","   where m is the number of literals in Si, wj are the literals in Si, and <α",", \\b","> is the factor determining the <Sα, Sβ> S-factor. Due to the nature of TRI function, TRIS has values in the [-1,1] interval. If TRI, α",", \\b","is not defined, we assign TRIS a value outside the considered interval - TRIS\\f, α, β 2.  The same comment referring to making a distinction between neutrality and unrelatedness applies here. The value 2 in the definition of TRIS signifies that the synset Si is unrelated to Sα and Sβ or, put it otherwise, the synset Si has no attitude load with respect to the S-factor.  The scoping of an S-factor can be achieved at various granularities, depending on available classifications of synsets in the backing wordnet. For the Princeton WordNet two distinct synsets annotations are available: Domains labels (animals, biology, geography, plants, psychological features, etc.) and SUMO/MILO concepts (Animal, BiologicalProcess, FieldOfStudy, Plant, SubjectiveAssessmentAttribute, etc).  The DOMAINS (Bentivogli et al., 2004), labeling (http://wndomains.itc.it/) uses Dewey Decimal Classification codes and the 115425 PWN synsets are classified into 168 distinct classes (domains).  The SUMO&MILO ontology (Niles & Pease, 2001) (http://www.ontologyportal.org/) is the largest freely available ontology today. It is accompanied by more than 20 domain ontologies and altogether they contain about 20,000 concepts and 60,000 axioms. They are formally defined and do not depend on a particular application. Its attractiveness for the NLP community comes from the fact that SUMO, MILO and associated domain ontologies are mapped onto Princeton WordNet.  The hierarchical structures of the Domains and SUMO/MILO classification systems allows one to define the scope of an S-factor in terms of a wordnet synset, a domain category (Lowest Common Ancestor Domain) or a SUMO/MILO concept (Lowest Common Ancestor Concept).  For instance, the S-factor:","({fairness:1 equity:3 } {unfairness:2 inequity:2}) has its scope defined by the synset {quality:1}, by the domain label factotum or by the concept SubjectiveAssessmentAttribute  A scoped S-factor is represented by indexing the S-factor with its scope (of a desired granularity), as in the examples below:  ({fairness:1 equity:3} {unfairness:2 inequity:2}){quality:1} ({fairness:1 equity:3} {unfairness:2 inequity:2}){factotum} ({fairness:1 equity:3} {unfairness:2 inequity:2}){SubjAssAtt}  For the sake of brevity we will say that a synset Si is a sibling of a Domains scope Dj and of a SUMO&MILO concept scope SMK, if the Domains label and the SUMO&MILO concept marking up the synset Si, be they Di and SMi, are siblings of Dj and SMk respectively.  Since each synset is characterized by a part-of-speech (POS), the notions of factor, scoping and semantic coverage are POS specific.  As a consequence, the POS coverage is partitioned in various ways depending on the considered factors. Although maximum POS coverages are very relevant, we found that for fine-grained textual analysis (Tufiş, 2009) a value of 2 for the n-scoping is extremely discriminative.  In the following, if not otherwise specified, by S-factors we will understand scoped S-factors but by coverage of an S-factor we will mean the maximum semantic coverage of the respective S-factor. Unless ambiguous, the scope of a scoped S-factor will be omitted."]},{"title":"4. Determining the S-Factors","paragraphs":["According to the differential semantic theory, the words of a lexical stock can be qualitatively and quantitatively differentiated along the scale defined by an antonymic pair of words (a factor). The synonyms of the antonymic words, pairwise taken, definitely express a semantic"]},{"title":"3176","paragraphs":["opposition. Take for instance the antonymic pair <rise:1 fall:2>. These two words belong to the synsets {rise:1, lift:4, arise:5, move up:1, go up:1, come up:6, uprise:6} and {descend:1, fall:2, go down:1, come down:1}. The pair <rise:1 fall:2> is explicitly encoded as antonymic (i.e. there is an antonymy relation between these word forms). However, there is a conceptual opposition between the synsets to which the two words belong, so between any pair of the Cartesian product: {rise:1, lift:4, arise:5, move up:1, go up:1, come up:6, uprise:6}⊗{descend:1, fall:2, go down:1, come down:1}. This semantic opposition is exploited in our model of synset factorial annotation.  For the noun part of the WordNet 2.0 lexical ontology we identified 85 S-factors, all of them covering the same set of 11,109 noun literals (9.59%) with their senses encoded into 11,007 synsets (13.81%).  For the verb part of the WordNet2.0 lexical ontology we identified 254 S-factors, all of them covering the same set of 6,467 verb literals (57.19%) with their senses encoded into 8,589 synsets (64.58%).  For the adjective part of the WordNet2.0 lexical ontology we identified 335 S-factors, all of them covering the same set of 5,307 literals (24.68%) with their senses encoded into 5,291 synsets (29.50%). The same factors were used for the adverbs derived from adjectives. This way, a number of 1,943 adverbs (41.69%) clustered into 1,571 synsets (42.87%) were successfully annotated. These results are summarized in the table below.  Word Class Factors Coverage (literals) Coverage (synsets)","Adjectives 335 5,307 (24.68%)","5,291 (28.50%) Adverbs (factors & scores imported from adjectives)","335 1,943 (41.69%)","1,571 (42.87%)","Nouns 85 11,109 ( 9.59%)","11,007 (13.81%)","Verbs 254 6,467 (57.19%)","8,589","(64.58%)","Table 1: Multifactorial annotation of the PWN2.0","","As one may note, we found a different coverage for the","adjectives than the one found by Kamp and Marx (5410","literals) and this might be explained by the fact that we","use a newer version of the Princeton WordNet. For each of the scoped S-factors <Sα, Sβ> and for each synset Si in their respective semantic coverage SCOV<Sα, Sβ>Sγ we computed the TRIS\\f, α, βTRISscore. Each synset from the coverage of each POS category is associated with a vector of scores, the dimension of which is equal to the number of factors for that category. For instance, each noun synset (in the noun coverage) is associated with an 85 cell-vector, the i-th cell containing the score of the synset with respect to the i-th factor. The cell-values in a synset vector have very different values showing that factors have discriminative power for a given word-sense. As all the factors have the same coverage, but different values for different word meanings, selecting only a few, the most discriminating from a specific text analysis point of view, is a user significant decision for making the results easy to perceive/interpret. We experimented with different values for n in the definition of n-scoped coverage and, obviously, for lower values of n, the number of synsets characterized by a given factor decreases, which means a smaller (but better characterized) semantic coverage for the respective factor.","For a given synset Sx, the cell values corresponding to","those factors the coverages of which do not include the","synset Sx are filled-in with a conventional value outside","the interval [-1,1]. Thus we have defined three annotation","situations:","a) a synset of a certain POS is not in the","POS-coverage; that case signifies that the synset","cannot be characterized in terms of the differential","semantics methodology and we conventionally say","that such a synset is “objective” (insensitive to any","S-factor for the considered part of speech); that","situation would require a factor vector the cells of","which would have the same value; as such a vector","would be completely uninformative, we decided to","leave the “objective” un-unnotated.","b) any synset of certain POS in the POS-coverage","will have associated a factor vector. We may have","the sub-cases:","b1) all cell values are in the [-1,1] interval meaning that all factors are relevant for the synset with such a factor vector; it means that from any word in the synset one could construct a path to any of the words making a factor, irrespective of the considered factor. We say that the synset has an “attitude” with respect to all the factors. A negative value in the ith","cell of the factor value signifies that the synset is more semantically related to w than to antonym(w). A positive value in the ith","cell of the factor value signifies that the synset is more semantically related to antonym(w) than to w. A zero value in the ith","cell of the factor value signifies that the synset has a neutral attitude with respect to the <w, antonym(w)> factor.","b2) several cell values are not in the interval [-1, 1], say FV[i1]=FV[i2] ... =FV[ik]=2. This signifies that all factors <wi1 antonym(wi1)>, <wi2, antonym(wi2)>, ... <wik, antonym(wik)> are irrelevant for the respective synset; it means that from any word in the synset one could NOT construct a path to any of the words wi1, wi2,...,wik or to any of their respective antonyms. We say that the synset is “objective” with respect to the irrelevant factors and has an “attitude” with respect to the rest of the factors. From the definitions in the previous sections, one could easily observe that the factor values depend on the order in which the antonymic pairs are considered, thus making the synsets ordering in the factors a major decision for consistently judging the factor vector annotations. We used a default ordering of antonyms in all factors, yet this ordering can be modified by a text analyst. For each POS, from the set of factors we selected a representative factor for which the synsets order, from a subjective point of view, was very intuitive. For instance for the adjective factors we selected the factor <good:1 bad:1>, for noun factors we selected the factor <order:5 disorder:2> and for"]},{"title":"3177","paragraphs":["verb factors we selected the factor <succeed:1 fail:2>, the first word sense in each of the representative factors having a clear positive connotation. Then for each POS factor <S1 S2> we computed the distance of its constituent synsets to the synsets of the representative factor of the same POS. The one which was closer to the “positive” side of the reference factor was also considered “positive” and the order of the synsets was established accordingly. This empirical approach proved to be successful for most of the factors, except for a couple of them which were manually ordered. Figure 2: Selecting the factors (those marked with a ‚+’) We developed an application that allows a text analyst to choose the interesting S-factors he/she would like to work with. In Figure 2, the selected factors are shown with a ‘+’ sign on their right. An interface allows the user to automatically arrange the factors’ synsets according to the reference factors he/she would select (as described above). If it is not clear what S-factors would be the most discriminative ones for a specific analysis, the user may select those S-factors which are marked by SUMO/MILO concepts and/or DOMAINS categories consistent with the envisaged applications and domains. For instance, for traditional subjectivity analysis very relevant would be those S-Factors the scope of which are SUMO/MILO concepts: SubjectiveAssessmentAttribute, TraitAttribute PsychologicalAttribute, PsychologicalProcess, Social Interaction, IntentionalProcess, etc. Once the user decided on the relevant S-factors for his/her application and domain, the synsets are marked-up on-the-fly according to the selected S-factors. This version of the WordNet can be saved and used as needed in the planned application. Depending on the application, the selected factors may be linearly interpolated with the weights established, provided some training data is available, by automatic means (e.g. a MERT-like algorithm). In Figure 3 there is a snapshot from the visualization tool for the values of the selected factors exemplified in Figure 2 with respect to the noun criminal belonging to the synset no. 09339986.  Let us exemplify our approach for the noun and verb synsets.  Figure 3: The scoring for the selected factors  As shown before, there are 85 noun S-factors and 254 verb S-factors. Let us suppose that we would like to differentiate the WordNet noun synsets according to three factors: ({comfort:1 ...} – {discomfort:1 ...})status:2-StateOfMind, ({pleasure:1 ...} – {pain:2 ...})feeling:1-Entity and ({trust:3 ...} – {distrust:2 ...})trait:1-TraitAttribute  and the WordNet verb synsets according to other three factors: ({get well:1...}– {get worse:1...}change state:1-OrganismProcess, ({enjoy:4... }– {suffer:1...})experience:1-Entity, ({believe:1...} – {disbelieve:1 ...})judge:2-Entity"," Let us further suppose that we want to analyze various sentences along these factors. The values assigned to each factor vary between [-1,1] (the extreme values corresponding to the left and right synsets respectively). If instead of the whole description of a factor we use only one of the synsets defining it, a positive value would mean closeness to that synset of the factor, while a negative one would mean farness. For instance <{comfort:1,...}: -0.5> means a great lack of comfort (discomfort), while <{believe:1,...}: 0.66> means a high level of confidence. For reading simplicity, in the following examples we will use as notation only a representative literal of the synset followed by the corresponding value (i.e. <comfort: -0.5>). A sentence like “His lies will be dealt with in the court and his immorality will be proved.” would get the following annotations: His lies:1 <comfort:-0.11 pleasure:-0.23 trust:-0.11> will be dealt:2 <get well:0.42 enjoy:0 believe:0.62> within the court:1 <comfort:-0.11 pleasure:-0.07 trust:-0.11> and his immorality:2 <comfort:-0.22 pleasure:-0.07 trust:-0.11> will be proved:3 <get well:0.14 enjoy:-0.2 believe:0.25>. So, a grosser analysis suggests that we have a subjectively loaded sentence which expresses lack of confort (i.e discomfort (average score: -0.14), lack of pleasure (i.e pain (average score: -0.12), lack of trust (i.e distrust (average score -0.11), getting well (average score: 0.28), not enjoying (i.e. suffering (average score: -0.1) and believing (average score: 0.43). If one decides to put"]},{"title":"3178","paragraphs":["everything in terms of the good-bad dichotomy, this sentence is conveying a rather negative connotation: discomfort, pain, distrust and suffering are definitely bad things. On the other hand, the “bad” things are taken care of and so, because of the verbs, getting well and believing are positive.  Certainly, the proper judgment of a sentence depends on the chosen S-factors. For instance, replacing the S-factor ({pleasure:1 ...} – {pain:2 ...})feeling:1- Entity with ({fairness:1 ...} – {unfairness:2 ...})quality:1-NormativeAttribute one would get different scores, but essentially the same polarity (even more accentuated – unfairness:0.4) versus the good-bad dichotomy:  His lies:1 <comfort:-0.11 fairness:0.07 trust:-0.11> will be dealt:2 <get well:0.42 enjoy:0 believe:0.62> within the court:1 <comfort:-0.11 fairness:-0.42 trust:-0.11> and his immorality:2 <comfort:-0.22 fairness:-0.85 trust:-0.11> will be proved:3 <get well:0.14 enjoy:-0.2 believe:0.25>.  If one compares this with the <P,N,O> mark-up in SentiWordNet (Esuli & Sebastiani, 2006) he/she would get for the same nouns the annotations:  His lies:1 <P:0 N:0 O:1> will be dealt:2<P:0.125 N:0 O:0.875> within the court:1 <P:0 N:0 O:1> and his immorality:2 <P:0.75 N:0 O:0.25> will be proved:3<P:0 N:0 O:1>.  In terms of <P, N, O> triad, one would eventually obtain an almost objective statement (average score 0.825) with a significant load of positivism (average score 0.175) and no negativity at all. One should observe that unlike the mark-up in SentiWordNet where the three values of the subjectivity annotation sum up to one, in our approach this is not true, as the S-factors are considered to be independent. This makes text analysis more complicated in our case, since, as mentioned above, the interpretation crucially depends on the chosen S-factors.  With an inappropriate selection of S-factors, the results may be confusing. For instance, let us consider that the same sentence as above is to be evaluated in terms of the following arbitrary noun S-factors:","({increase:3... }<->{decrease:2...)proces:2-QuantityChange,","({balance:1}<->{imbalance:1 ...})situation:1-equal,","({demand:1}<->{supply:2})economic process:1-Entity  His lies:1 <increase:0 balance:0.55 demand:0> will be dealt:2 <get well:0.42 enjoy:0 believe:0.62> within the court:1 <increase:0.33 balance:0.66 demand: -0.15> and his immorality:2 <increase:0.11 balance:0.44 demand:0> will be proved:3 <get well:0.14 enjoy:-0.2 believe:0.25>.  The scoring of the sentence is more confusing than informative: one cannot articulate a reasonable judgment of the sentence in terms of these S-factors: average increase: 0.14, average balance: 0.55, average demand: -0.05, average getting well: 0.28, average enjoying: -0.1 and average believing: 0.43. "]},{"title":"5. Conclusions and Further Work","paragraphs":["We proposed another method for the lexical annotation of the synsets of a wordnet which generalizes the SentiWordNet subjectivity mark-up according to a user-based multi-criteria differential semantics model. We discussed the method to annotate all the synsets in PWN2.0, irrespective of their part of speech. We anticipate that these annotations can be imported in other language wordnets, provided they are aligned to PWN2.0. One of the future development issues is implementing an averaging tool for the word attitude mark-up. Instead of using a factor vector, a synset might be associated with a unique subjectivity value (SV) computed as a linearly interpolated sum of the individual factor values:    ∈1,1 FV is the factor vector associated to Synset and N is the length of the factor value (dependent on the POS of Synset).  The values for λi can be set manually by the analyst or can be computed automatically by a supervised machine learning algorithm. For instance, imagine one has a list of words classified into two sets: “positive” and “negative” (according to a differential factor). That would be a very good training data set for an SVM classification engine fed with the factor vectors for all the words in the training set. Word lists (Wiebe, 2000), (Riloff et al., 2003), (Wiebe et al., 2004), etc., ideally human made, are very good candidates for such a scenario. In the same spirit, at the sentence level, one might consider differently the contribution of different POS attitude words and, as such, use different weights for each POS. A MERT like training algorithm run on an attitude marked-up corpus would help to establish the POS weights. This new mark-up is subject to further research. The annotation system does not depend on the language of the wordnet, but requires its alignment to the Princeton WordNet 2.0, from which the SUMO/MILO and DOMAINS mark-up can be automatically imported. The multi-factored annotation vectors for nominal, verbal and adjectival synsets for PWN2.0 can be freely downloaded from www.racai.ro/differentialsemantics/."]},{"title":"6. Acknowledgements","paragraphs":["This research has been supported by by the National Council for Scientific Research (UEFICSU /CNCSIS) under the grant no. ID 1443."]},{"title":"7. References","paragraphs":["Andreevskaia A. and Bergler S. (2006). Mining WordNet For a Fuzzy Sentiment: Sentiment Tag Extraction From WordNet Glosses. In Proceedings of the 11rd Conference of the European Chapter of the Association for Computational Linguistics (EACL-2006), Trento , Italy."]},{"title":"3179","paragraphs":["Bentivogli L, Forner P., Magnini B. and Pianta E. (2004). Revising WordNet Domains Hierarchy: Semantics, Coverage, and Balancing. In Proceedings of COLING 2004 Workshop on \"Multilingual Linguistic Resources\", Geneva, Switzerland, August 28, 2004, pp. 101-108. Esuli A. and Sebastiani F. (2006). SENTIWORDNET: A Publicly Available Lexical Resource for Opinion Mining. Proceedings of the 5th Conference on Language Resources and Evaluation LREC-06, Genoa, Italy, pp. 417-422. Fellbaum C.(1998). WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA. Ide I., Erjavec T., and Tufiş D. (2002). Sense Discrimination with Parallel Corpora. In Proceedings of the ACL 2002 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions, pp. 56-60, Philadelphia, USA. Association for Computational Linguistics. Kamps J., and Marx M. (2002). Words with Attitude, in Proceedings of the 1st International WordNet Conference, Mysore, India, pp. 332-341. Polanyi L. and Zaenen A. (2006). Contextual Valence Shifters. In Computing Attitude and Affect in Text: Theory and Applications, The Information Retrieval Series, Vol. 20, Springer Netherlands, ISBN 978-1-4020-4026-9, pp. 1-10. Mihalcea R., Banea C., and Wiebe J. (2007). Learning Multilingual Subjective Language via Cross-Lingual Projections. Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,.Prague, Czech Republic, June, pp. 976-983. Niles I., and Pease A. (2001). Towards a Standard Upper Ontology. In Proceedings of the 2nd International Conference on Formal Ontology in Information Systems (FOIS-2001), Ogunquit, Maine, October 17-19, 2001. Osgood C.E., Suci G., and Tannenbaum P. (1957). The measurement of meaning. Urbana, IL. Riloff E., Wiebe J., and Wilson, T. (2003). Learning Subjective Nouns using Extraction Pattern Bootstrapping. In Proceedings of The Seventh Conference on Natural Language Learning (CONLL-2003), Edmonton, Canada May 31-June 1, pp. 25-32. Tufiş D. (2008). Mind YourWords! You Might Convey What YouWouldn’t Like To. Int. J. of Computers, Communications & Control, ISSN 1841-9836, E-ISSN 1841-9844, Vol. III (2008), pp. 139-143. Tufiş D. (2009). Playing with Word Meanings. In Lotfi A. Zadeh, Dan Tufiş, Florin Gh. Filip and Ioan Dziţac (eds.) From Natural Language to Soft Computing: New Paradigms in Artificial Intelligence, pp. 211-223. 2009. Editing House of Romanian Academy. ISBN 978-973-27-1678-6. Valitutti A., Strapparava C., and Stock O. (2004). Developing Affective Lexical Resources. PsychNology Journal, Vol. 2, No. 1, pp. 61-83. Wiebe J. (2000). Learning Subjective Adjective from Corpora. In Proceedings of the 17th","National Conference on Artificial Intelligence (AAAI’2000), Austin, Texas. Wiebe J., Wilson T., Bruce R., Bell M. and Martin, M. (2004). Learning subjective language. Computational Linguistics Vol. 30, No. 3, pp. 277-308."]},{"title":"3180","paragraphs":[]}]}