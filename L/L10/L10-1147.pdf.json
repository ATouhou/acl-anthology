{"sections":[{"title":"Czech Information Retrieval with Syntax-based Language Models Jana Strakov á, Pavel Pecina","paragraphs":["Institute of Formal and Applied Linguistics","Charles University in Prague","strakova@ufal.mff.cuni.cz, pecina@ufal.mff.cuni.cz","Abstract In this paper, we deal with information retrieval approach based on language model paradigm, which has been intensively investigated in recent years. We propose, implement, and evaluate an enrichment of language model employing syntactic dependency information acquired automatically from both documents and queries. By testing our model on the Czech test collection from Cross Language Evaluation Forum 2007 Ad-Hoc track, we show positive contribution of using dependency syntax in this context."]},{"title":"1. Introduction","paragraphs":["In recent years, considerable attention has been dedicated to language modeling methods in information retrieval (Ponte and Croft, 1998). Although these approaches generally allow exploitation of any type of language model, most of the published experiments were conducted with a classical n-gram model, usually limited only to unigrams. A few works exploiting syntax in information retrieval can be cited in this context (Lee and Lee, 2005), (Nallapati and Allan, 2002), (Gao et al., 2004), but significant contribution of syntax based language modeling for information retrieval is yet to be proved. Our experiments are conducted on Czech which is a morphologically rich language and has a considerably free word order. Especially, the long distance relations between words are expected to be captured better in a syntactic language model than in a bigram language model based on surface word order. The paper is organized as follows. First, we describe the test collection (Section 2) and the methodology (Section 3) used in our work. Experiments and their results are described in Section 4 and discussed in Section 5. The work is concluded in Section 6."]},{"title":"2. Test collection","paragraphs":["For our experiments, we used Czech test collection from Cross Language Evaluation Forum 2007 Ad-Hoc Track (CLEF, 2007) consisting of 81, 735 documents (news articles) and relevance assessments of 50 topics. The average length of documents is 349.76 words and 15.24 documents in average are assessed as relevant to each topic. The topics are presented in TREC format as a structure of three fields describing each topic by a keyword query (title) and in more detail by a few sentences (narr and desc). For development and evaluation purposes, we randomly divided these 50 topics into a development set of 10 topics and test set of 40 topics. This test collection was used at the CLEF 2007 Ad-Hoc track and some evaluation results using this collection have already been published. An overview of the CLEF 2007 Ad-Hoc results can be found in (Nunzio et al., 2008)."]},{"title":"3. Methodology 3.1. Notation","paragraphs":["Throughout the paper, we will be using the following notation: D stands for a document and C for a collection of documents, which we rank by relevance to a query Q. A query Q consists of terms Q = q1, q2, . . . , qn, thus a bigram of two subsequent terms (by subsequent we mean “subsequent on surface”) is (qi, qi+1). A dependency relation between two words is denoted as (p(qi), qi), where p(qi) is the head word and qi its modifier.1","For an example of a dependency tree, see figure 1. 3.2. Language modeling in information retrieval In language modeling based information retrieval, for each query Q, all documents D from the collection C are ranked by the probability P (D|Q) of being (independently) generated by the query language model. From the Bayes formula and the fact that P (Q) is constant for all documents and P (D) is considered uniform across the collection, we can rank the documents by the “reverted” probability P (Q|D) with the same result. Thus, instead of estimating probability of document D being generated by language model defined by Q, we will consider the probability of query Q being generated from the language model defined by document D. Having introduced our key ranking function, P (Q|D), we will simplify the notation P (D|Q) to PD(Q). Furthermore, since Q = q1, . . . , qi, . . . , qn, the probability of a single term qi is denoted as PD(qi). Similarly, PD(qi, qi+1) and PD(p(qi), qi) stand for the probability of a surface bigram and dependency bigram (respectively) in a language model of document D.2 In the following formulas, PD stands for document probability, such as PD(Q) is the probability of the whole query","1","We assume the pair (qi, qi+1) to be ordered, therefore the word first appearing in the sentence qi takes the first position in the ordered pair. Similarly, in the dependency bigram (p(qi), qi) the first position in the pair is taken by the head p(qi) and the second one by the modifier qi.","2","Here we should write properly PD((qi, qi+1)) and PD((p(qi), qi)), but we took the liberty of removing the extra pair of brackets as we believe there is no danger of confusion."]},{"title":"1359","paragraphs":["Q given document D and PD(qi) is the probability of single term qi in language model defined by document D. CD stands for raw counts (frequencies) of the corresponding language phenomena, e.g. CD(qi) is the frequency of term qi in document D. |D| denotes the size of the document with respect to the current model, therefore in unigram model, it is a number of unigrams, in surface bigram model, it is number of surface bigrams and finally in dependency bigram model, it denotes the number of dependency relations defined by dependency syntax tree representing the document (sentences), as will be more precisely explained in the next chapter 3.3.. Apart from the well known unigram model P unigram D (Q) = n ∏ i=1 PD(qi) =̂ n ∏ i=1 CD(qi) |D| and surface bigram model P surf.bigram D (Q) = n−1 ∏ i=1 PD(qi, qi+1) =̂ n−1 ∏ i=1","CD(qi, qi+1) |D| we will also use a dependency bigram model described in the following subsection. 3.3. Dependency bigram model In dependency syntax (as it is used in this work), the sentence structure is represented as a tree with nodes formed by words and edges determined by relations between words. Thus, there is a bijection between words of the sentence and nodes of the tree and each word has one parent, except for the root, which is usually the predicate of the sentence (the verb). An example of a dependency tree is shown be-low on Figure 1. Figure 1: An example of a dependency tree for sentence “The American presidential election was followed closely.” For each sentence in query Q = q1, . . . , qn, we build its dependency tree so each word in the query, except for sentence roots, has a parent and define: P dep.bigram D (Q) = ∏ qi:∃p(qi) PD(p(qi), qi) which using MLE can be estimated as P dep.bigram D (Q) =̂ ∏ qi:∃p(qi)","CD(p(qi), qi) |D| In this case, |D| stands for “number of syntactic (dependency) relations” in the document, as opposed to “number of unigrams, bigrams” in unigram or bigram model, respectively. We smoothed all document probabilities by linear interpolation with collection probabilities, which is known as Jelinek-Mercer smoothing (Jelinek and Mercer, 1980): P̃D(qi) = λPD(qi) + (1 − λ)PC(qi), λ ∈ ⟨0, 1⟩ In this formula, PD(qi) is the probability of term qi in language model defined by document D, and similarly, PC(qi) is the probability of term qi in the collection C of all documents."]},{"title":"4. Experimental setup","paragraphs":["As a baseline, we used the plain unigram model. The proposed dependency bigram model is also compared with the classical surface bigram model to prove the hypothesis that more information is captured by dependency bigrams than by surface bigrams. In many information retrieval systems, especially when dealing with morphologically rich languages, some form of stemming is used. In our experiments, we employ lemmatization as a linguistically motivated means of stemming. Lemmatization is a process of mapping a word to its base form (lemma), such as infinitives for verbs. Of course, we could replace the lemmatization step with stemming if we so prefer. In our case, lemmatization was a product of the preprocessing tagging step for the dependency parsing. Thus, by combination of unigram, surface bigram and dependency bigram model and their lemmatized and non-lemmatized versions, there are six models to evaluate. Finally, we combined these six models by means of a simple linear interpolation. The linear coefficients were estimated by grid search with MAP as objective function on a development set of 10 topics. The optimal coefficients for each of the six models are shown in table 1. Morphological analysis (including tagging and lemmatization) was performed with Feature-based tagger (Hajič, 2004) and dependency syntax parsing with MST Parser (McDonald et al., 2005) in TectoMT framework ( Žabokrtský et al., 2008). Since we are depending on syntactic information in our work, we used all three sections of (title, narr and desc) of the TREC-style description of the topics (queries) to be able to benefit from the linguistic information underlying a longer, natural language text. As stopwords set, we used 256 Czech stopwords available at (UniNE, 2005). We also performed pseudo relevance feedback on highly ranked documents as a method of broadening the query with semantically relevant terms (Manning et al., 2008). As evaluation measure, we use common Mean Average Precision (MAP) computed by evaluation tool (trec eval, 2008)."]},{"title":"5. Results and Discussion","paragraphs":["Figure 2 and Table 1 show results of the six models: unigram model with non lemmatized word forms, unigram model with lemmas, surface bigram model with non"]},{"title":"1360","paragraphs":["0 0.1 0.2 0.3 0.4 0.5 unigram-surface-formunigram-surface-lemmabigram-surface-formbigram-surface-lemmabigram-dependency-formbigram-dependency-lemmacombination no-pseudofeedback pseudofeedback Figure 2: MAP for language models and their combination. lemmatized word forms, surface bigram model with lemmas, dependency bigram model with non lemmatized word forms and dependency bigram model with lemmas. The last model is created by a linear interpolation of all models where the coefficients have been estimated by simple grid search on a development set of 10 topics. The results presented in figure 2 and table 1 have been evaluated on test set of 40 topics. As for single models, the unigram model reaches the highest values of MAP. This result is expected, as the higher order n-gram models alone are often too specific for the given task. However, in combination with the unigram model, we observe increased performance of the system. The combination of all language models reaches MAP 0.3890. For comparison purposes, the MAP computed on all 50 topics is 0.4102. This result outperforms most of the models presented in (Nunzio et al., 2008) and is close to the best published result on this test collection, using solely means of language modeling. However, it must be noted that the comparison is somewhat problematic due to the optimiza-tion performed on a subset of 10 topics. Intriguingly, the dependency bigram model outperforms the bigram surface model. The explanation for this is presented in figure 3 which shows MAP for particular topics evaluated in the system for both models. An interesting observa-tion about figure 3 is that rather than improving the results for each topic constantly, the dependency model performs noticeably better on certain topics. To elaborate on that, dependency model seems to pick bigrams with higher information content than the surface bigram model. Let us pick an example, where the difference is particularly remarkable: a topic 7 “Australský premiér (Australian prime minister)”. By inspecting the bigrams participating highly in ranking of the documents, we find surface bigrams “být, v (be, in)”, “být kdo (be, who)”, “australský premiér (australian prime minister)”, “být který (be, who)”, whereas the dependency bigram model employs bigrams “australský primér (australian prime minister)” and “být kdo (be, who)”. Please note that here we are working with lemmatized version of the model, hence the lemma “be”. We assume that the dependency bigram model is more successful in implicitly selecting the correct bigrams and weighting them properly. Apparently, the bigram surface model bigrams can be pruned by good stopword list, but given the flective nature of the Czech language, there were always useless word forms, which even a broadened stoplist did not manage to prune. This might be caused by the very definition of the dependency syntax tree and the fact that bigrams in dependency model are formed of head-modifier word pairs rather than of word pairs brought together by sentence word order."]},{"title":"6. Conclusions","paragraphs":["We have presented a simple dependency bigram language model as an extension of commonly used unigram and bigram surface model. With this language model, we have outperformed most of the results published in (Nunzio et al., 2008). Finally, we have found examples, where the dependency bigram model produced significantly better output than surface bigram model."]},{"title":"7. References","paragraphs":["CLEF. 2007. Cross Language Evaluation Forum (CLEF), http://clef-campaign.org.","Jianfeng Gao, Jian-Yun Nie, Guangyuan Wu, and Guihong Cao. 2004. Dependence language model for information retrieval. In SIGIR ’04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 170– 177, New York, NY, USA. ACM.","Jan Hajič. 2004. Disambiguation of Rich Inflection (Computational Morphology of Czech), volume 1. Charles University Press, Prague.","Frederick Jelinek and Robert L. Mercer. 1980. Interpolated estimation of markov source parameters from sparse data. In Proceedings of the Workshop on Pattern Recognition in Practice, Amsterdam, The Netherlands: North-Holland, May.","Changki Lee and Gary Geunbae Lee. 2005. Probabilistic information retrieval model for a dependency structured indexing system. Inf. Process. Manage., 41(2):161–175.","Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schtze. 2008. Introduction to Information Retrieval. Cambridge University Press.","Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajič. 2005. Non-projective dependency parsing using spanning tree algorithms. In Human Language Technologies and Empirical Methods in Natural Language Processing (HLT-EMNLP), Vancouver, Canada.","Ramesh Nallapati and James Allan. 2002. Capturing term dependencies using a language model based on sentence trees. In CIKM ’02: Proceedings of the eleventh international conference on Information and knowledge management, pages 383–390, New York, NY, USA. ACM.","Giorgio M. Nunzio, Nicola Ferro, Thomas Mandl, and Carol Peters. 2008. Clef 2007: Ad hoc track overview. pages 13–32.","Jay M. Ponte and W. Bruce Croft. 1998. A language modeling approach to information retrieval. In SIGIR ’98: Proceedings of the 21st annual international ACM SIGIR"]},{"title":"1361 model no feedback feedback coefficient","paragraphs":["unigram-surface-form 0, 3046 0, 3116 0.1 unigram-surface-lemma 0, 3392 0, 3731 0.65 bigram-surface-form 0, 1477 0, 1775 0.05 bigram-surface-lemma 0, 1915 0, 2023 0.05 bigram-dependency-form 0, 1654 0, 1826 0.05 bigram-dependency-lemma 0, 2211 0, 2447 0.1 combination 0, 3650 0, 3890 Table 1: MAP for language models and their combination 10 08 23 48 05 13 42 40 19 37 18 32 24 04 17 02 49 06 50 01 16 21 12 47 26 43 46 31 36 38 07 44 03 20 39 35 22 30 09 28 topics MAP 0.0 0.2 0.4 0.6 0.8 Figure 3: Comparison of surface (gray) and dependency (black) lemmatized bigram models on particular topics. conference on Research and development in information retrieval, pages 275–281, New York, NY, USA. ACM.","trec eval. 2008. http://trec.nist.gov/trec eval.","UniNE. 2005. IR multilingual resources at UniNE, http://www.unine.ch/info/clef/.","Zdeněk Žabokrtský, Jan Ptáček, and Petr Pajas. 2008. TectoMT: Highly Modular MT system with tectogrammatics used as a transfer layer. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 167–170. Association for Computational Linguistics, June."]},{"title":"1362","paragraphs":[]}]}