{"sections":[{"title":"","paragraphs":["Computational Linguistics and Chinese Language Processing Vol. 12, No. 2, June 2007, pp. 107-126 107 © The Association for Computational Linguistics and Chinese Language Processing [Received August 2, 2006; Revised March 7, 2007; Accepted March 8, 2007]"]},{"title":"Using a Generative Model for Sentiment Analysis Yi Hu","paragraphs":["∗"]},{"title":", Ruzhan Lu","paragraphs":["∗"]},{"title":", Yuquan Chen","paragraphs":["∗"]},{"title":", and Jianyong Duan","paragraphs":["∗ "]},{"title":"Abstract","paragraphs":["This paper presents a generative model based on the language modeling approach for sentiment analysis. By characterizing the semantic orientation of documents as “favorable” (positive) or “unfavorable” (negative), this method captures the subtle information needed in text retrieval. In order to conduct this research, a language model based method is proposed to keep the dependent link between a “term” and other ordinary words in the context of a triggered language model: first, a batch of terms in a domain are identified; second, two different language models representing classifying knowledge for every term are built up from subjective sentences; last, a classifying function based on the generation of a test document is defined for the sentiment analysis. When compared with Support Vector Machine, a popular discriminative model, the language modeling approach performs better on a Chinese digital product review corpus by a 3-fold cross-validation. This result motivates one to consider finding more suitable language models for sentiment detection in future research. Keywords: Sentiment Analysis, Subjective Sentence, Language Modeling, Supervised Learning."]},{"title":"1. Introduction","paragraphs":["Traditional wisdom of document categorization lies in mapping a document to given topics that are usually sport, finance, politics, etc. Whereas, in recent years there has been a growing interest in non-topical analysis, in which characterizations are sought by the opinions and feelings depicted in documents, instead of just their themes. This method of analysis is defined to classify a document as favorable (positive) or unfavorable (negative), which is called sentiment classification. Labeling documents by their semantic orientation provides succinct summaries to readers and will have a great impact on the field of intelligent information retrieval.   ∗ Department of Computer Science and Engineering, Shanghai Jiao Tong University, 800 Dongchuan Rd, Shanghai, China. Tel: 86-21-3420 4591 E-mail: huyi@cs.sjtu.edu.cn   108 Yi Hu et al.","In this study, the set of documents is rooted in the topic of digital product review, which will be defined in the latter part of this article. Accordingly, the documents can be classified into praising the core product or criticizing it. Obviously, a praising review corresponds to “favorable” and a criticizing one is “unfavorable” (the neutral review is not considered in this study).","Most research for document categorization adopts the “bag of words” representing model that treats words as independent features. On the other hand, utilizing such a representing mechanism may be imprecise for sentiment analysis. Take a simple sentence in Chinese as an example: “柯达 P712 内部处理器作了升级,处理速度应该更快了。(The processor inside Kodak P712 has been upgraded, so its processing speed ought to be faster.)” The term “柯达 (Kodak)” is very helpful for determining its theme of “digital product review”, but words “升 级(update)” and “快(fast)” corresponding to “处理器(processor)” and “处理速度(processing speed)” ought to be the important clues for semantic orientation (praise the product). Inversely, see another sentence in Chinese: “这样电池损耗就很快。(So, the battery was used up quickly.)” The words “损耗 (use up)” and “快 (fast)” become unfavorable features of the term “电池 (battery)”. That is to say, these words probably contribute less to the sentiment classification if they are dispersed into the document vector, because the direct/indirect relationships between ordinary words and the terms within the sentence are lost. Unfortunately, traditional n-gram features cannot easily deal with these long-distance dependencies.","Sentiment classification is a complex semantic problem [Pang et al. 2002; Turney 2002] that needs knowledge for decision-making. The researchers, here, explore a new idea-based language model for the sentiment classification of sentences rather than full document, in which the terms such as “处理器 (processor)”, “处理速度 (processing speed)” are target objects to be evaluated in the context. They are mostly the nouns or noun phrases: “屏幕 (Screen)”, “ 分辨率 (Resolution)”, “ 颜色 (Color)”, etc. If the sentiment classifying knowledge on how to comment on these terms can be obtained by the training data in advance, the goal of sentiment analysis can be achieved by matching the terms in the test documents. Thus, the classifying task for the full document is changed to recognizing the semantic orientation of all terms in accordance with their sentence-level contexts. This can also be considered a positive/negative word counting method for sentiment analysis.","In this study, the authors construct two language models for each term to capture the difference of sentiment context for that term. In these language models, sentences are divided into terms and their contexts. Sentences without the defined terms are ignored since they make no contribution to the document level sentiment classification; hence, they are omitted from training and test documents. This idea of grouping a document under subjective and objective portions is similar to Pang’s work [Pang and Lee 2004].    Using a Generative Model for Sentiment Analysis 109","This work can be divided into three main parts: first, some terms are extracted from a Chinese digital product review corpus [Chen et al. 2005]; second, two language models representing positive and negative classifying knowledge for each term are determined from training a subjective sentence set; third, the two models are applied to the test set and then compared with a popular discriminative classifier, SVM. The experiments demonstrate the better performance of the language modeling approach.","The rest of this paper is structured as follows. Section 2 briefly reviews the related works. Section 3 provides short introductions to SVM and language model. Section 4 describes the model in detail. Section 5 presents the method of estimating model parameters, in which a smoothing technique is utilized. Section 6 shows some experiments to exemplify the availability of the language modeling approach. In section 7, conclusions are given."]},{"title":"2. Related Works","paragraphs":["A considerable amount of research has been done about document categorization other than topic-based classification in recent years. For example, Biber [Biber 1988] concentrated on sorting documents in terms of their source or source style with stylistic variation such as author, publisher, and native-language background. Sentiment classification for documents, though, has attracted tremendous attention for its broad applications in various domains such as movie reviews and customer feedback reviews [Gamon 2004; Pang et al. 2002; Pang and Lee 2004; Turney and Littman 2003]. Many research projects have used positive or negative term counting methods, which automatically determine the positive or negative orientation of a term [Turney and Littman 2002]. Other projects have focused on machine learning algorithms, such as Bayesian Classifier and SVMs, to classify entire reviews in a manner similar to a pattern recognition task.","Some related works focus on categorizing the semantic orientation of individual words or phrases by employing linguistic heuristics [Hatzivassiloglou and McKeown 1997; Hatzivassiloglou and Wiebe 2000; Turney and Littman 2002]. The word’s semantic orientation refers to a real number measure of the positive or negative sentiment expressed by a word or a phrase [Hatzivassiloglou and McKeown 1997]. In previous works, the approach taken by Turney [Turney and Littman 2002] is used to derive such values for selected phrases in the document. The semantic orientation of a phrase is determined based on the phrase’s Pointwise Mutual Information (PMI) with the words “excellent” and “poor”. PMI is defined by Church and Hanks [Church and Hanks 1989] as follows: 12 12 2 12 (& ) (& )log ()( )pw w PMI w w pw pw ⎛⎞","= ⎜⎟ ⎝⎠, (1)    110 Yi Hu et al. where p(w1&w2) is the probability that w1 and w2 co-occur. The orientation for a phrase is the difference between its PMI with the word “excellent” and the PMI with the word “poor”. The final orientation is: ()(,\" \")(,\"\")SO phrase PMI phrase excellent PMI phrase poor= − . (2)","This yields values above zero for phrases having greater PMI with the word “excellent” and below zero for greater PMI with “poor”. An SO value of zero denotes a neutral semantic orientation. This approach is simple but effective. Moreover, it is neither restricted to words of a particular part of speech (e.g. adjectives), nor restricted to a single word, but can be applied to multiple-word phrases. The semantic orientation of phrases can be used to determine the sentiment of complete sentences and reviews. In Turney’s work, 410 reviews were taken and the accuracy of classifying the documents was found when computing the polarity of phrases for different kinds of reviews. Results ranged from 84% for automobile reviews to as low as 66% for movie reviews.","Another method of classifying documents into positive and negative is to use a learning algorithm to classify the documents. Several algorithms were compared in [Pang et al. 2002], where it was found that SVMs generally give better results. Unigrams, bigrams, part of speech information, and the position of the terms in the text are used as features, where using only unigrams is found to produce the best results. Pang et al. further analyzed the problem to discover how difficult sentiment analysis is. Their findings indicate that, generally, these algorithms are not able to generate accuracy in the sentiment classification problem in comparison with the standard topic-based categorization. As a method to determine the sentiment of a document, Bayesian belief networks are used to represent a Markov Blanket [Bai 2004], which is a directed acyclic graph where each vertex represents a word and the edges are dependencies between the words.","Methods for extracting subjective expressions from collections are presented in [Pang and Lee 2004]. Subjectivity clues include low-frequency words, collocations, and adjectives and verbs identified using distribution similarity. In [Riloff and Wiebe 2003], a bootstrapping process learns linguistically rich extraction patterns for subjective expressions. Classifiers define unlabeled data to automatically create a large training set, which is then given to an extraction pattern learning algorithm. The learned patterns are then used to identify more subjective sentences. A method to distinguish objective statements from subjective statements is also presented in [Pang and Lee 2004]. This method is based on the assumption that objective and subjective sentences are more possibly to appear in groups. First, each sentence is given a score indicating if the sentence is more likely to be subjective or objective using a Naive Bayes classifier trained on a subjectivity data set. The system then adjusts the subjectivity of a sentence based on how close it is to other subjective or objective sentences.   Using a Generative Model for Sentiment Analysis 111 This method obtains amazing results with up to 86% accuracy on the movie review set. A similar experiment is presented in [Yu and Hatzivassiloglou 2003].","Past works on sentiment-based categorization of entire texts also involve using cognitive linguistics [Hearst 1992; Sack 1994] or manually constructing discriminated lexicons [Das and Chen 2001; Tong 2001]. These works enlighten researchers on the research on learning sentiment models for terms in the given domain.","It is worth referring to an interesting study conducted by Koji Eguchi and Victor Lavrenko [Eguchi and Lavrenko 2006]. In their contribution, they do not pay more attention to sentiment classification itself, but propose several sentiment retrieval models in the framework of generative modeling approach for ranking. Their research assumes that the polarity of sentiment interest is specified in the users’ need in some manner, where the topic dependence of the sentiment is considered."]},{"title":"3. SVMs and Language Model 3.1 SVMs","paragraphs":["Support Vector Machine (SVM) is highly effective on traditional document categorization [Joachims 1998], and its basic idea is to find the hyper-plane that separates two classes of training examples with the largest margin [Burges 1998]. It is expected that the larger the margin, the better the generalization of the classifier.","The hyper-plane is in a higher dimensional space called feature space and is mapped from the original space. The mapping is done through kernel functions that allow one to compute inner products in the feature space. The key idea in mapping to a higher space is that, in a sufficiently high dimension, data from two categories can always be separated by a hyper-plane. In order to implement the sentiment classification task, these two categories are designated positive and negative. Accordingly, if d is the vector of a document, then the discriminant function is given by: () ()fd w d bφ=⋅ +. (3) Here, w is the weight vector in feature space that is obtained by the SVM from the training examples. The “·” denotes the inner product and b is a constant. The function φ is the mapping function. The equation w·φ(d) + b = 0 represents the hyper-plane in the higher space. Its value f(d) for a document d is proportional to the perpendicular distance of the document’s augmented feature vector φ(d) from the separating hyper-plane. The SVM is trained such that f(d) ≥ 1 for positive (favorable) examples and f(x) ≤ -1 for negative (unfavorable) examples.","Joachim’s SVMlight","package [Joachims 1999] was used for training and testing. For more details on SVM, the reader is referred to Cristiani and Shawe-Tailor’s tutorial [Cristianini and   112 Yi Hu et al. Shawe-Taylor 2000] and Roberto Basili’s paper [Basili 2003]."]},{"title":"3.2 Language Models","paragraphs":["A statistical language model is a probability distribution over all possible word sequences in a language [Rosenfeld 2000]. Generally, the task of language modeling handles the problem: how likely would the ith","word occur in a sequence given the history of the preceding i-1 words? In most applications of language modeling, such as speech recognition and information retrieval, the probability of a word sequence is decomposed into a product of n-gram probabilities. Let one assume that L denotes a specified sequence of k words, 12... kLwww= . (4) An n-gram language model considers the sequence L to be a Markov process with probability 1 1","1() ( | )k","i iin","ipL pw w− − + =="]},{"title":"∏","paragraphs":[". (5) When n is 1, it is a unigram language model which uses only estimates of the probabilities of individual words, and when n is equal to 2, it is the bigram model which is estimated using information about the co-occurrence of pairs of words. On the other hand, the value of n-1 is also called the order of the Markov process.","To establish the n-gram language model, probability estimates are typically derived from frequencies of n-gram patterns in the training data. It is common that many possible n-gram patterns would not appear in the actual data used for estimation, even if the size of the data is huge. As a consequence, for a rare or unseen n-gram, the likelihood estimates that are directly based on counts may become problematic. This is often referred to as data sparseness. Smoothing is used to address this problem and has been an important part of various language models."]},{"title":"4. A Generative Model for Sentiment Classification","paragraphs":["In this section, a language modeling approach to detect semantic orientation of document is proposed. This approach is very simple: one must observe the usage of language in contexts of terms appearing in positive and negative documents. “Favorable” and “unfavorable” language models are likely to be substantially different: they are prone to different language habits. This divergence in the language models is exploited to effectively classify a test document as positive or negative.     Using a Generative Model for Sentiment Analysis 113"]},{"title":"4.1 Two Assumptions","paragraphs":["Models usually have their own basic assumptions as foundation of reasoning and calculating, which support their further applications. The researchers also propose two assumptions in this study, and, based on them, employ a language modeling approach to deal with the sentiment classification problem. As mentioned above, ordinary words in a sentence might have correlation with the term in the same sentence. Therefore, this method follows the idea of learning positive and negative language models for each term within sentences. After this, the sentiment classification is transferred into calculating the generation probability of all subjective sentences in a test document by these sentiment models. The following two assumptions are presented:","A1. A subjective sentence contains at least one sentiment term and is assumed to have obvious semantic orientation. A2. A subjective sentence is the processing unit for sentiment analysis.","The first assumption (A1) gives the definition of subjective sentence, and it means a significant sentence for training or testing should contain at least one term. In contrast, a sentence without any term is regarded as an objective sentence because of its “no contribution” to sentiment. It also assumes that a subjective sentence has complete sentiment information to characterize its own orientation.","The second assumption (A2) allows one to handle the classification problem of sentence-level processing. Therefore, the authors pay more attention to construct models within the given sentence in terms of this assumption. A2 is an intuitive idea in many cases.","Previous work has rarely integrated sentence-level subjectivity detection with document-level sentiment polarity. Yu and Hatzivassiloglou [Yu and Hatzivassiloglou 2003] provide methods for sentence-level analysis and for determining whether a sentence is subjective or not, but do not consider document polarity classification. The motivation behind the single sentence selection method of Beineke et al. [Beineke et al. 2004] is to reveal a document's sentiment polarity, but they do not evaluate the polarity-classification accuracy of results."]},{"title":"4.2 Document Representation","paragraphs":["Based on these two assumptions, a document d is naturally reorganized into subjective sentences, and the objective sentences are omitted from d. That is to say, the original d is reduced to: {| }dsts∃∈ . (6)    114 Yi Hu et al. Furthermore, a subjective sentence can be traditionally represented by a Chinese word sequence as follows, 12 1, 1 2 ... ... lill l nww w t w w w−++. (7) In this, “ti,l ” indicates one term ti appears in the sentence si, which is usually denoted as the serial number ‘l’ in the sequence. Moreover, the subsequence from w1 to wl-1 is the group of ordinary words on the left side of ti, and the subsequence from wl+1 to wn is the group of ordinary words on the right. In (7), ordinary words in this sentence consist of ti’s context (Cxi). So, a subjective sentence si is simplified to: ,iiis tCx<> . (8) The authors now focus on a special form, by which a document is represented. Let d be defined again, {, }iidtCx<> . (9) Definition (9) means that there also exists an independent assumption between sentences and every word has certain correlation with the term within a sentence. Each sentence has semantic orientation and makes a contribution to the global polarity.","Note that it is possible for there to exist more than one term in a sentence. However, when investigating one of them, the others are to be treated as ordinary words. Each term can create a <t, Cx> structure. That is to say, one sentence may create more than one such structure."]},{"title":"4.3 Sentiment Models of Term","paragraphs":["With respect to each term, each plays an important role in sentiment classification because the pivotal point of this work lies in learning and evaluating its context. This kind of classifying knowledge, derived from the contexts of terms in two subject-sentence collections labeled positive or negative in different contexts, would like to use words with polarity, such as “快 (Fast)” and “慢 (Slow)”. A formalized depiction of classifying knowledge is shown as the following 3-tuple ki:",",, PN iiii ikt tTθθ<>∈ . (10) The character “T” denotes the list of all terms obtained from collections. With respect to ti, its classifying knowledge is divided into two models: P","i"]},{"title":"θ","paragraphs":["and N i"]},{"title":"θ","paragraphs":["which represent the positive and negative models, respectively. The model parameters are estimated from the training data. The contribution of wj to polarity is quantified by a triggered unigram model to express the long distance dependency, which is a language modeling idea explained in next subsection.    Using a Generative Model for Sentiment Analysis 115"]},{"title":"4.4 Language Modeling Approach for Sentiment Classification","paragraphs":["Language models applied to information retrieval [Pone and Croft 1998; Song and Croft 1999] have proven the effectiveness of this approach in an ad-hoc IR task. However, little work has been done in sentiment classification other than considering statistical language modeling. The most important idea in this study is to treat sentiment analysis of a document as the comparison of different generation probabilities in their subjective sentences. The difference is derived from the sentiment language models,"]},{"title":"{}","paragraphs":["P i"]},{"title":"θ","paragraphs":["and"]},{"title":"{}","paragraphs":["N i"]},{"title":"θ","paragraphs":[", of terms.","Up to the present, the unigram model has been widely used in many applications due to its relatively small parameter space and suitability for avoiding data sparseness. The traditional unigram model takes a strict assumption that each word is independent from all others, consequently, the probability of a word sequence transfers into the product of the probabilities of individual words. In the authors’ model, a triggered unigram model based on subjective sentence collection is built. Thus, the sentiment classification of a document becomes a generation process.","It is assumed that each subjective sentence has its own contribution. Therefore, the global document orientation is calculated by the differences between the probabilities of generating every subjective sentence in the document based on the sentiment language models. Thus, the logarithm decision function (11) is defined as:"]},{"title":"()","paragraphs":[", (| ) (; , ) ln (| ) ln ( | , ) ln ( | , ) iii P PN N","PN iii iiitssd pd Fd pd ps t ps t θ θθ θ θθ∈∈ ⎛⎞ ⎜⎟⎜⎟ ⎝⎠ =−"]},{"title":"∑ ","paragraphs":[". (11) Equation (11) means that, to a subjective sentence in the document, if it is more possibly generated by the positive language model of term “ti” than by its negative language model, the sentence gives more weight to positive orientation than the negative. If the opposite is true, the sentence is regarded as more negative. The value of these probabilities is then used to classify the documents: 0 : 0 positive F negative >⎧ ⎨ <⎩ . (12) It is obvious that decision value is the semantic orientation of the whole document. Every subjective sentence will also be calculated by the multiplication of each generation probability of an ordinary word in this sentence except the term itself, i.e.:   116 Yi Hu et al. , , (|,) (|,) (|,) (|,) jiji jiji","PP iii jiiwCxwt","NN iii jiiwCxwt ps t pw t ps t pw t θ θ θ θ ∈≠ ∈≠ ⎧ = ⎪ ⎨","=⎪ ⎩"]},{"title":"∏ ∏","paragraphs":[". (13) Using the logarithm, one can rewrite (13) in its final form: , , ln ( | , ) ln ( | , ) ln ( | , ) ln ( | , ) jiji jiji","P P iii jiiwCxwt","NN iii jiiwCxwt ps t pw t ps t pw t θθ θθ ∈≠ ∈≠ ⎧ =⎪ ⎨","=⎪⎩"]},{"title":"∑ ∑","paragraphs":[". (14) Equations (13) and (14) are both composed of two functions corresponding to positive and negative cases, respectively. Finally, when one substitutes Equation (14) into Equation (11), one gets a new sentiment classifying function: , (|,)","(; , ) ln (|, )ijiji","P jiiPN","sd wCxw t N jii pw t Fd pw t θ θθ θ","∈∈≠⎛⎞ ⎜⎟= ⎜⎟ ⎝⎠"]},{"title":"∑∑","paragraphs":[". (15)"]},{"title":"5. Parameter Estimation","paragraphs":["In equation (15), one has to estimate (|,)P jiipw t θ , and (|,)N","jiipw t θ ."]},{"title":"5.1 MLE for (|,)","paragraphs":["jii"]},{"title":"pw t θ","paragraphs":["The researchers have two available training collections labeled with “positive” and “negative”. The detailed information of this corpus will be described in Section 6.1.","Two methods are used to estimate the unigram probability: <1> the Maximum","Likelihood Estimate (MLE); <2> the Dirichlet Prior Smoothing for language models. The two","estimating methods are compared in sentiment classification. The language models are trained","on the positive collection (CP",") and negative collection (CN","), respectively. The MLE is #( , | )","(|,) #( , | ) #( , | )","(|, ) #( , | ) ji j iPP","mle j i i i","ii ji j iNN","mle j i i i","ii wt w Cx","pwt sC","tCx wt w Cx","pwt sC","tCx θ θ <>∈⎧","=∈⎪ <∗ > ∗∈⎪","⎨ <>∈⎪ =∈⎪ <∗ > ∗∈⎩ , (16)","where #( , | )j ijiwt w Cx<>∈ is the number of times jw co-occurring with it in same","subjective sentences in positive/negative document collection CP","/CN",", while","#( , | )iitCx<∗ > ∗∈ is the total number of any word (*) co-occurring with the term i"]},{"title":"t","paragraphs":["in the same subjective","sentences in CP /CN .   Using a Generative Model for Sentiment Analysis 117","In the probability perspective, if a word wj often co-occurs with ti in sentences in the training corpus with a positive view, it may mean that it contributes more to a positive orientation than negative, and vice-versa.","The training data consists of small document samples. The MLE models are inherently poor representations of the true models for unseen words that will be unreasonably assigned zero probability. Therefore, a smoothing language model is worthy of being tried to approximate their true models."]},{"title":"5.2 Dirichlet Prior Smoothing","paragraphs":["Dirichlet Prior smoothing [Zhai and Lafferty 2001; Zhai and Lafferty 2002] is a general smoothing method for the problem of zero probabilities and is suitable for unigram smoothing. It belongs to a type of linearly interpolated method. The purpose of the Dirichlet Prior smoothing is to address the estimation bias due to the fact that a document collection has a relatively small amount of data used to estimate a unigram model. More specifically, it is designed to discount the MLE appropriately and assign non-zero probabilities to n-gram, which are not observed in the collection. This is the normal role of language model smoothing.","The sentence generation is now taken into account. The basic models are the unigram","models {}iθ (includes {}P","iθ and{}N","iθ , respectively), which will result in models with the Dirichlet Prior smoothing. That is, ( | , ) { } (|,) (|) ii i dir i i mle pwt w Cx pwt pwCotherwise γ θ θ α ∈⎧⎪","= ⎨ ⎪⎩ , (17) where (|,)iipwtγ θ indicates the smoothed probability of w seen in the positive/negative subjective sentence collection of ti. The probability (|)mlepwC denotes the whole corpus ( C ) language model based on MLE, and"]},{"title":"α","paragraphs":["is a coefficient controlling the probability mass assigned to unseen words, so that all probabilities sum to one. In general, α may depend on all (|,)iipwtγ θ . In this study, the authors exploit the following smoothing formalizations: #( , | , ) ( | )  #( , | , ) (|,) #( , | , ) ( | )  #( , | , ) P","Piii mle","iP","iii","ii N","Niii mle","iN","iii wt w Cx s C p w C to tCxsC pwt wt w Cx s C p w C to tCxsC γ μ θ μ θ μ θ μ ⎧ <>∈ ∈+ ⎪","<∗ > ∗∈ ∈ +⎪ = ⎨","<>∈ ∈+⎪ ⎪","<∗ > ∗∈ ∈ +⎩ , (18) and ||Cμ α μ = + , (19)   118 Yi Hu et al. where μ is a controlling parameter that needs to be set empirically.","In particular, Dirichlet Prior smoothing may play two different roles in the sentence likelihood generation method. One is to improve the accuracy of the estimated document language model, while the other is to accommodate generation of non-informative common words. The following experiment results further suggest that this smoothing measure is useful in the estimation procedure."]},{"title":"6. Experiment Results and Discussions","paragraphs":["This study is interested in the subject of “digital product review”, and all documents are obtained from digital product review web sites. In terms of evaluating the results of sentiment classification, the researchers employ average accuracy based on 3-fold cross validation over the polarity corpus in the following several experiments."]},{"title":"6.1 Document Set and Evaluating Measure","paragraphs":["The datasets select digital product reviews where the author rating is expressed either with thumbs “up” or thumbs “down”. For the works described in this study, the dataset only concentrates on discriminating between positive and negative sentiment.","To avoid domination of the corpus by a small number of prolific reviewers, the corpus imposes a limit of fewer than 25 reviews per author per sentiment category, yielding a corpus of 900 negative and 900 positive reviews, with a total of more than a hundred reviewers represented. Some statistics about the corpus are shown in Table 1."]},{"title":"Table 1. The two collections from the same domain (digital product reivew).","paragraphs":["Collections # of Documents Average # of Subjective Sentences Sizes (KB) Positive 900 28.3 462.99 Negative 900 25.9 453.82 Note that these 1800 documents in the corpus have obvious semantic orientations to their products: favorable or unfavorable. Furthermore, in terms of positive documents, they contain an average of 28.3 subjective sentences, while negative document collections contain an average of 25.9. All these digital product reviews downloaded from several web sites are about electronic products, such as DV, mobile phones, and cameras. On the other hand, all of these Chinese documents have been pre-processed in a standard manner: they are segmented into words and Chinese stop words are removed. All of these labeled documents are to be naturally divided into three collections in every process of 3-fold cross validation, which are used either for training or for testing.","In evaluating processes, a document may be grouped into positive or negative. That is to say, there exist two kinds of classification errors called “false negative” and “false positive”.   Using a Generative Model for Sentiment Analysis 119 Thus, the authors could build the following Contingency Table."]},{"title":"Table 2. Contingency Table.","paragraphs":["Tagged Positive Tagged Negative True Positive A B True Negative C D In the table A, B, C and D respectively indicate the number of every case. When the system classifies a true positive document into “positive” or classifies a true negative document into “negative”, these two are correct, yet the other two cases are wrong. Therefore, the accuracy is defined as a global evaluation mechanism: ()/( )Accuracy A D A B C D=+ +++. (20) Obviously, the larger the accuracy value is, the better the system performance is. In the following experiments, the 3-fold cross validation based average accuracy is the major evaluating measure in the following experiments."]},{"title":"6.2 Term Extraction","paragraphs":["The researchers extract term candidates using a term extractor from the previous work of the authors [Chen et al. 2005]. Following this study, the hybrid method for automatic extraction of terms from domain-specific un-annotated Chinese corpus is used through means of linguistic knowledge and statistical techniques. Then, hundreds of terms applied in the sentiment analysis are extracted from the digital product review documents. They are ranked by their topic-relativity scores.","The main idea in [Chen et al. 2005] lies in finding the two neighboring Chinese characters with high co-occurrence, called “bi-character seeds”. These seeds can only be terms or the components of terms. For instance, the seed “分辨” is the left part of the real term “分 辨率 (Resolution)”. So the system has to determine the two boundaries by adding characters one by one to these seeds in both directions to acquire multi-character term candidates. Apparently, there exist many non-terms in these candidates, so one must take a dual filtering strategy and introduce a weighting formula to filter these term candidates via a large background corpus.","Although the authors have adopted the dual filtering strategy in this system to improve performance, it cannot separate the terms and non-terms completely. Therefore, it also needs manual selection of the suitable terms that strictly belong to the digital product domain. The terms were chosen from the candidate list one by one via their topic-relativity scores.","It is worth noting that all the selected terms are nouns/noun phrases that represent concepts that are usually evaluated in real-life contexts. For example, “数码相机 (digital   120 Yi Hu et al. camera, one of the digital products)”, “处理器 (processor, a key part of some digital products)”."]},{"title":"6.3 Experiments and Discussions","paragraphs":["Three experiments were designed to investigate the proposed method as compared to SVM. The first was to select the most suitable number of terms given their topic-relativity to the domain. The second was to select a suitable kernel from linear, polynomial, RBF and sigmoid kernels for sentiment classification. The last was to compare the performance between the language modeling approach and SVM.","With respect to these three experiments, the 1800 digital product reviews were split into three parts: 1000 training samples (500 positive and 500 negative); 600 test samples (300 positive and 300 negative); and the remaining 200 samples (100 positive and 100 negative) that were prepared for choosing a suitable number of terms.","Table 3 shows a series of contrastive results by testing on the 200 samples after training models of terms ranging from 20 to 200 given their topic-relativity ranks. This is a method for selecting a suitable term set. In this experiment, unigram models are employed by MLE. Here, all of the Chinese words occurring are used as unigrams to learn the language models, and this is different from selecting a portion of them in the following experiments (see Section 6.4)."]},{"title":"Table 3. Average accuracy based on the number of terms from 20 to 200 according to their topic-relativity ranking scores. In this experiment, we employ the unigram model by MLE.","paragraphs":["# of terms 20 40 60 80 100 120 140 160 180 200","Avg. Accuracy 48.31 50.50 57.11 58.78 70.83 74.27 79.31 77.04 76.78 73.50","The experiment proves that it is not clear whether or not one ought to use a large term set for achieving better system performance, because redundant terms may bring “noise” to semantic polarity decision. As seen in Table 3, experimental results achieve the greatest accuracy when keeping 140 terms by topic-relativity ranking scores in the term set. According to this result, the authors use the 140 terms next for smoothing of sentiment language models and comparison with SVM."]},{"title":"6.4 Comparison with SVM","paragraphs":["Unigrams are extracted as input feature sets for SVM. The following experiments compare the performance of SVM using linear, polynomial, RBF and sigmoid kernels, the four conventional learning methods commonly used for text categorization. The SVMlight","package [Joachims 1999] was used for training and testing on the document-level, and other   Using a Generative Model for Sentiment Analysis 121 parameters of different kernel functions were set to their default values in this package. This experiment aims at exploring which method is more suitable for the sentiment detection problem (See Table 4).","To make sure that the results for the four kernels are not biased by an inappropriate choice of features, all four methods are run after selecting unigrams (Chinese words) appearing at least three times in the whole 1800 document collection. Finally, the total number of features in this study is 5783 for SVM, including those “terms” used in the language modeling approach."]},{"title":"Table 4. Comparison of four kernel functions on the digital product review training and test corpus and average performance over two categories. Linear kernel achieves highest performance on unigram feature set.","paragraphs":["Features # of features Linear Polynomial Radial Basis Function Sigmoid unigrams 5783 80.17 61.25 53.09 51.26 The result with the best performance in the test set is the linear kernel. Thus, the language model based method is compared with the SVM using linear kernel. The next table gives the results achieved by the language modeling approach and the control group. In this experiment, the 5783 single word forms (i.e. vocabulary) are also used as the features for language models."]},{"title":"Table 5. Comparison between language model based method and SVM using linear kernel. ","paragraphs":["# of features AvgAccuracy % change over SVM SVM (Linear Kernel) 5783 80.17 — Uni-MLE 5783 83.10 +3.65 Uni-Smooth ("]},{"title":"=1100μ","paragraphs":[") 5783 85.33 +6.44","Seen from table 5, Uni-MLE performs better on the unigrams features set than SVM, which achieved an average significant improvement of 3.65% compared with the best SVM result. As to the model smoothing, Dirichlet Prior smoothes unigram language model with parameter μ set to 1100 (In this experiment, the best result appears when 1100μ = in Dirichlet Prior smoothing). It makes a contribution to estimating a better unigram language model leading to a significantly better result than SVM (+6.44%). The effect of the smoothing method in sentiment analysis is just like its effect on most language model based applications in NLP. In practice, the unigram model built up from the two limited collections by simple MLE has not enough reasonability in terms of the unseen words. The smoothing method gives the unobserved ordinary words of every term a suitable non-zero probability and improves the system performance. The better results obtained by this generative model may be due to the sentiment   122 Yi Hu et al. description within sentences, which proves that the two assumptions in Section 4.1 may be reasonable. The authors use the triggered unigram models to describe the classifying contribution of features of every term, and then construct sentiment language models. Accordingly, the motivation to further explore the refinement of sentiment language models based on learning higher order models and introduce more powerful smoothing methods in future is acquired."]},{"title":"7. Conclusions","paragraphs":["In this paper, the authors have presented a new language modeling approach for sentiment classification. To this generative model, the terms of a domain are introduced as counting terms, and their contexts are learnt to create sentiment language models. It was assumed that sentences have complete semantic orientation when they contain at least one term. This assumption allows one to design models to learn positive and negative language models from the subjective sentence set with polarity. The approach is then used to test a real document in steps: first to generate all the subjective sentences in the document, and then to generate each ordinary word in turn depending on the terms by positive and negative sentiment models. The difference between the generation probabilities by the two models is used as the determining rule for sentiment classification.","The authors have also discussed how the proposed model resolves the sentiment classification problem by refining the basic unigram model through smoothing. When the language model based method is compared with a popular discriminative model, i.e., SVM, the experiment shows the potential power of language modeling. It was demonstrated that the proposed method is applicable for learning the positive and negative contextual knowledge effectively in a supervised manner.","The difficulty of sentiment classification is apparent: negative reviews may contain many apparently positive unigrams even while maintaining a strongly negative tone and vice-versa. In terms of the Chinese language, it is a language of concept combination, allowing the usage of words to be more flexible than in Indo-European languages, which makes it more difficult to acquire statistic information than other languages. All classifiers will face this difficulty. Therefore, the authors plan to improve the language model based method in the following three possibilities:","Future works may focus on finding a good way to estimate better language models, especially the higher order n-gram models and more powerful smoothing methods.","The authors have assumed an independent condition among sentences so far. It is also possible to introduce a suitable mathematic model to group the close sentences. Constructing an enlarged sentiment analyzing area may utilize more linking information between words.   Using a Generative Model for Sentiment Analysis 123","The conceptual analysis of Chinese words may be helpful to sentiment analysis because this theory pays more attention to counting the real sense of concepts. In future works, the authors may integrate more conceptual features into the models."]},{"title":"Acknowledgement","paragraphs":["This work is supported by NSFC Major Research Program 60496326: Basic Theory and Core Techniques of Non Canonical Knowledge."]},{"title":"References","paragraphs":["Bai, X., R. Padman, and E. Airoldi, “Sentiment extraction from unstructured text using tabu search-enhanced markov blanket,” In Proceedings of the International Workshop on Mining for and from the Semantic Web, 2004, Seattle, WA, USA.","Basili, R., “Learning to Classify Text Using Support Vector Machines: Methods, Theory, and Algorithms by Thorsten Joachims,” Computational Linguistics, 29(4), 2003, pp. 655-661.","Beineke, P., T. Hastie, C. Manning, and S. Vaithyanathan, “Exploring sentiment summarization,” In AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications (AAAI tech report SS-04-07), 2004. Biber, D., Variation across Speech and Writing, The Cambridge University Press, 1988.","Burges, C., “A Tutorial on Support Vector Machines for Pattern Recognition,” Data Mining and Knowledge Discovery, 2(2), 1998, pp. 121-167.","Chen, X., X. Li, Y. Hu, and R. Lu, “Dual Filtering Strategy for Chinese Term Extraction,” In Proceedings of FSKD(2), Changsha, China, 2005, pp. 778-786.","Church, K. W., and P. Hanks, “Word association norms, mutual information and lexicography,” In Proceedings of the 27th","Annual Conference of the ACL, 1989, Vancouver, BC, Canada.","Cristianini, N., and J. Shawe-Taylor, An Introduction to Support Vector Machines and other Kernel-based Learning Methods, The Cambridge University Press, 2000.","Das, S., and M. Chen, “Yahoo! for Amazon: Extracting market sentiment from stock message boards,” In Proceedings of the 8th","Asia Pacific Finance Association Annual Conference, 2001, Bangkok, Thailand.","Eguchi, K., and V. Lavrenko, “Sentiment Retrieval using Generative Models,” In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2006, Sydney, Australia, pp. 345-354.","Gamon, M., “Sentiment classification on customer feedback data: noisy data, large feature vectors, and the role of linguistic analysis,” In Proceedings the 20th","International Conference on Computational Linguistics, 2004, Switzerland.   124 Yi Hu et al.","Hatzivassiloglou, V., and K. McKeown, “Predicting the semantic orientation of adjectives,” In","Proceedings of the 35th","ACL/8th","EACL, 1997, Madrid, Spain, pp. 174-181.","Hatzivassiloglou, V., and J. Wiebe, “Effects of Adjective Orientation and Gradability on Sentence Subjectivity,” In Proceedings the 18th","International Conference on Computational Linguistics, 2000, Germany, pp. 299-305.","Hearst, M., “Direction-based text interpretation as an information access refinement,” Text-based intelligent systems: current research and practice in information extraction and retrieval, ed. by Paul Jacobs, Lawrence Erlbaum Associates, 1992, pp. 257-274.","Joachims, T., “Text categorization with support vector machines: Learning with many relevant features,” In Proceedings of the European Conference on Machine Learning, 1998, Chemnitz, pp. 137-142.","Joachims, T., “Making large-scale SVM learning practical”, Advances in Kernel Methods-Support Vector Learning, ed. by Bernhard Scholkopf and Alexander Smola, The MIT Press, 1999, pp. 44-56.","Pang, B., and L. Lee, “A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts,” In Proceedings of the 42nd","ACL, 2004, Barcelona, Spain, pp. 271-278.","Pang, B., L. Lee, and S. Vaithyanathan, “Thumbs up? Sentiment Classification using Machine Learning Techniques,” In Proceedings of The Conference on Empirical Methods in Natural Language Processing, 2002, Philadelphia, USA.","Pone, J., and W. B. Croft, “A language modeling approach to information retrieval,” In Proceedings of the 21st","Annual Int’l ACM SIGIR Conference on Research and Development in Information Retrieval, 1998, Melbourne, Australia.","Riloff, E., and J. Wiebe, “Learning extraction patterns for subjective expressions,” In Proceedings of the 41st","Conference on Empirical Methods in Natural Language Processing, 2003, Sapporo, Japan, pp. 105-112.","Rosenfeld, R., “Two decades of statistical language modeling: where do we go from here?” In Proceedings of the IEEE, 88(8), 2000.","Sack, W., “On the computation of point of view,” In Proceedings of the Twelfth AAAI, Student abstract, 1994, Seattle, WA, USA, pp. 1488.","Song, F., and W. B. Croft, “A general language model information retrieval,” In Proceedings of the 22nd","Annual Int’l ACM SIGIR Conference on Research and Development in Information Retrieval, 1999, Berkeley, CA, USA.","Tong, R.M., “An operational system for detecting and tracking opinions in on-line discussion,” Workshop Notes, SIGIR Workshop on Operational Text Classification, 2001, New Orleans.","Turney, P.D., “Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews,” In Proceedings of the ACL, 2002, Philadelphia, Pennsylvania, USA, pp. 417-424.   Using a Generative Model for Sentiment Analysis 125","Turney, P.D., and M. L. Littman, “Measuring praise and criticism: Inference of semantic orientation from association,” ACM Transactions on Information Systems (TOIS), 21(4), 2003, pp. 315-346.","Turney, P.D., and M. L. Littman, “Unsupervised learning of semantic orientation from a hundred-billion-word corpus,” Technical Report EGB-1094, National Research Council, Canada, 2002.","Yu, H., and V. Hatzivassiloglou, “Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences,” In Proceedings of the 41st","Annual Meeting of the Association for Computational Linguistics, 2003, Sapporo, Japan.","Zhai, C. and J. Lafferty, “A study of smoothing methods for language models applied to ad","hoc information retrieval,” In Proceedings of SIGIR, 2001, New Orleans, USA.","Zhai, C. and J. Lafferty, “Two Stage Language Models for Information Retrieval,” In","Proceedings of S IGIR, 2002, Tampere, Finland.   126 Yi Hu et al. "]}]}