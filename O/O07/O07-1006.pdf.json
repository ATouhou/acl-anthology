{"sections":[{"title":"改善以最小化音素錯誤為基礎的鑑別式聲學模型訓練於中文連續 語音辨識之研究 ","paragraphs":["劉士弘, 朱芳輝, 陳柏琳","國立臺灣師範大學資訊工程學系","{ g93470185, g94470144, berlin}@ntnu.edu.tw",""]},{"title":"摘要","paragraphs":["本論文探討改善最小化音素錯誤為基礎的鑑別式聲學模型訓練於中文大詞彙連續語音 辨識之研究。首先,本論文提出一個新的音框層次音素正確率函數來取代最小化音素錯 誤訓練的原始音素正確率函數,此新的音素正確率函數在某種程度上能充分地懲罰刪除 錯誤。其次,本論文提出一個以音框層次正規化熵值為基礎的嶄新資料選取方法來改進 鑑別式訓練,其正規化熵值是由訓練語料所產生之詞圖中高斯分布之事後機率所求得。 此資料選取方法可以讓鑑別式訓練更集中在那些離決定邊界較近的訓練樣本所收集的 統計值,以達到較佳的鑑別力。所使用的實驗題材是公視新聞外場記者語料。初步的實 驗結果顯示,結合時間音框層次的資料選取方法和新的音素正確率函數在前幾次的迭代 訓練中確實有些微且一致的進步。 關鍵詞:最小化音素錯誤訓練,鑑別式訓練,資料選取方法,大詞彙連續語音辨識"]},{"title":"一、緒論","paragraphs":["語音,是人與人之間最自然的溝通橋樑,倘若語音能夠成為資訊產品的主要輸入形式, 那麼人與機器之間的溝通就會變得簡單許多,並且可以盡量避免文明病的產生。因此自 動語音辨識(Automatic Speech Recognition, ASR)的研究已變得非常重要,這也是目前語 音與語言處理領域中熱門的研究議題之一。","大詞彙連續語音辨識(Large Vocabulary Continuous Speech Recognition, LVCSR)所 使用的鑑別式訓練法則是不以最大化訓練語料的相似度為目標,而以最小分類錯誤為目 標,進而增進辨識率。傳統在聲學模型之訓練上,大都使用最大化相似度(Maximum Likelihood, ML)法則,配合波氏重估演算法(Baum-Welch algorithm)來進行聲學模型的訓 練,但此種訓練方法並沒有考慮語音辨識時聲學模型彼此間的關係,在調整聲學模型參 數之後,可以使得相關的語音特徵落在此聲學模型的相似度(Likelihood)變大,卻也可能 同時讓非相關的語音特徵落在此聲學模型的相似度更大,造成辨識上的混淆。因此,近 來有不少研究針對此項缺點,提出鑑別式訓練(Discriminative Training)法則來加以改 進。故本文著重於探討以最小化音素錯誤(Minimum Phone Error Training, MPE)為基礎的 鑑別式訓練法則,藉著提出一個新的音框層次音素正確率函數來改善原始音素正確率函 數之缺點,同時也提出一個以音框層次正規化熵值為基礎的嶄新資料選取方法來改進最 小化音素錯誤訓練。","本論文接下來的安排如下:第二章將介紹貝氏風險與全面風險;第三章則介紹最 小化音素錯誤聲學模型訓練;第四章探討最小化音素錯誤訓練之改進;第五章則探討資  料選取方法於改進最小化音素錯誤聲學模型訓練;第六章為實驗與討論;第七章為結論 與未來展望。"]},{"title":"二、貝氏風險與全面風險","paragraphs":["語音辨識的過程可視為一個分類的動作,將每句可能的詞序列都視為一類,語音辨識即 是要從所有可能類別(詞序列)中找出最佳的一類(一句)。若 為一語句的語音特徵向量 序列,將 歸類至詞序列W 時,可以用函數 代表此歸類行為的風險(Risk); 而語音辨識則可視為找出此風險最低的詞序列。 可定義如下[1]: zO zO )|( zOWR |( OWR )z ∈′ WW zz"]},{"title":"∑","paragraphs":["′′= OWPWWlOWR )|(),()|( (1) 其中 W 為所有可能詞序列所成的集合; )|( zOWP ′ 表示給定語音特徵向量序列 時,詞 序列W 的事後機率(Posterior Probability);","zO","′ ),( WWl ′ 為一減損函數(Loss Function),用以","表示詞序列W 與W 之間差異所造成的損失(Loss), 為將 歸類至 時的期望","損失(Expected Loss),又稱為貝氏風險(Bayes Risk)或條件風險(Conditional Risk)。在語 音辨識或解碼上,需要最小化此貝氏風險來找最佳的詞序列W ,即: ′ )|( zOWR zO W ˆ"]},{"title":"∑","paragraphs":["∈′∈∈ ′′== WWW W z W z W OWPWWlOWRW )|(),(minarg)|(minargˆ allR"]},{"title":"∫","paragraphs":["= POWR ()|( (2) 目前有許多辨識器根據貝氏決策定理(Bayesian Decision Theorem),即最小化此貝氏風險 (式(2))來設計其搜尋演算法,如標準最大化事後機率解碼方法(Maximum a Posteriori Decoding, MAP)[2]、ROVER(Recognizer Output Voting Error Reduction)[3]、最小化貝氏 風險(Minimum Bayes Risk, MBR)[4]、最小化時間音框錯誤搜尋(Minimum Time Frame Error Search)[5]及詞錯誤最小化(Word Error Minimization) [6]等。","然而,若在聲學模型和語言模型的訓練上,則需要計算全面風險(Overall Risk),並 且最小化此全面風險 [1]: (3) dOO)Rall 其中W 為語音特徵向量序列 O 對應之正確轉譯詞序列, 為 的事前機率(Prior Probability);全面風險 是在語句空間(語音特徵向量序列空間)上作積分,為所有訓練 語句(語音特徵向量序列)的期望條件風險(Expected Conditional Risk)。由於訓練語料有 限,故全面風險可簡化為 )(OP O allR Z 個訓練語句的條件風險總和:"]},{"title":"∑∑","paragraphs":["= Z"]},{"title":"∑","paragraphs":["=∈′= ′= z W zz","zall POWPWlRR 11 ))|()((","W Z )( zP zzz OPOW )()| (4) ′W, zO(","| OW ′ ,= {λ }Γλ 及語言模型 Γ 所決定,令θ若事後機率分布 由聲學模型 ,所以事後 機率我們將之表示為 );|( θzOWP ′"]},{"title":"∑∑∑","paragraphs":["=∈′= ′′== Z zW zzz Z","z zzzall OPOWPWWlOPOWRR 11 )();|(),()()|(","W θ )( zOP z ,則全面風險可改寫成: (5) 若假設 對所有 O 均有一致(Uniform)的機率,且此項與模型參數 λ 及 Γ 無 關,則 可 將此項省略: "]},{"title":"∑∑","paragraphs":["=∈′ ′′= Z zW zzall OWPWWlR 1 );|(),( W θ (6) 在估測聲學模型和語言模型時,希望估測之模型θ 能將全面風險降至最低:"]},{"title":"∑∑","paragraphs":["′ ′′= Z","zz OWPWWl );|(),(minarĝθθ","θ =∈zW1 W (7) 在此所表示的減損函數是一般化減損函數(Generalized Loss Function),並沒有明確定義 要如何計算,這也因此成為一個開放的研究議題(亦即要如何去設計一個減損函數以期 望訓練出較佳的模型θ ,進而提高辨識率)。目前有許多的模型訓練的方法都是以風險 最小化(Risk Minimization)為基礎,並搭配其設計的減損函數來達成鑑別式之模型訓 練,如最大化交互資訊估測(Maximum Mutual Information Estimation, MMIE) [7]、全面 風險估測法則(Overall Risk Criterion Estimation, ORCE) [8]、最小化貝氏風險鑑別式訓練 (Minimum Bayes Risk Discriminative Training, MBRDT) [9]、最小化音素錯誤訓練 (Minimum Phone Error Training, MPE) [10]等。"]},{"title":"三、最小化音素錯誤之聲學模型訓練","paragraphs":["新近劍橋大學提出的最小化音素錯誤(Minimum Phone Error, MPE)聲學模型訓練,是以 全面風險為出發,以辨識出詞序列的原始音素正確率(Raw Phone Accuracy) 函數","來取代其中減損函數 。因此,它的目標函數變成是最大化語音辨識 器對所有訓練語句( 語音特徵向量序列) 的可能辨識出候選詞序列","( )的期望音素正確率(也就是最小化語音辨識器對所有訓練 語句可能辨識出候選詞序列 的期望錯誤率),最小化音素錯誤的目標函數可表示如下: ),( zi WWA iW Wi ∈ W ),( zi WWl"]},{"title":"}","paragraphs":["zO"]},{"title":"{","paragraphs":["L,,, 321 WWWz = iW"]},{"title":"∑∑","paragraphs":["= Z"]},{"title":"∑∑","paragraphs":["=∈=∈ = z zi W z iiz Z z zi W","zi WWA Op WPWOp","WWAOWp zizi 11 ),( )( )()|(","),()|() WW","λ MPEF (λ (8) 其中 可用語音辨識器產生的詞圖 來近似[11],因此目標函數可進一步表示 成: )( zOp latticez ,W"]},{"title":"∑∑ ∑","paragraphs":["∈ ∈ z zi W W kkz ii WWA WPWOp WP latticezi latticezk ),( )()|( )() , , W W λ i k zO z ≈ )(λ","z WOp |(λ MPEF (9) 其中W 與W 分別表示詞圖 上任兩條候選詞序列(假設 對應的正確詞序列"]},{"title":"W","paragraphs":["亦包含在詞圖裡)。 latticez ,W","為了對目標函數 )λ(MPEF 進行最佳化,Povey 等人提出最小化音素錯誤的弱性 (Weak-sense)輔助函數 ),( λλH 為[12]: MPE"]},{"title":"( )","paragraphs":[")|(log )|(log ),( 1 , qOp qOpF z Z zq z MPE latticez λλλ λ λ λλ"]},{"title":"∑∑","paragraphs":["=∈","= ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ ∂ ∂ = W"]},{"title":"()","paragraphs":["H MPE (10) 其中 λλ λ","λ","=","∂ ∂",")|(log qOpF z MPE"]},{"title":"()","paragraphs":["qz z avg 的值可為正或負,取決於詞圖上通過此音素的候選詞序列的期望正 確率 c 是否大於詞圖上所有候選詞序列的期望正確率 c 。也就是: "]},{"title":"() ()()","paragraphs":["z avgz z q","zMPE","cqc qOpF −= ∂ ∂ = γ λ λλ λ  )|(log (11) 其中:"]},{"title":"∑∑","paragraphs":["∈","∈∈","= klatticezi W kkz","WqW kkz z q WPWOp WPWOp , )()|( )()|(: W W λ","λ","γ (12) latticezk , 為詞圖上通過音素段落 q 的候選詞序列的事後機率和,而"]},{"title":"() ∑∑","paragraphs":["WWAWPWOp ),()()|( ∈∈ ∈∈ = klatticezk ilatticezi WqW kkz WqW ziiiz z WPWOp qc : , , , )()|(W W λ λ (13) 為詞圖上通過此音素段落的候選詞序列的期望正確率,而"]},{"title":"∑ ∑","paragraphs":["∈ ∈ = latticezk latticezi W kkz","W ziiiz z avg WPWOp WWAWPWOp c , , )()|( ),()()|( W W λ λ (14)","為詞圖上所有候選詞序列的期望正確率。 、z qγ"]},{"title":"( )","paragraphs":["qcz 與 的統計量可在詞圖上使用波 氏重估演算法來求得[12]。 z avgc"]},{"title":"( )","paragraphs":["qOp |log另一方面,針對對數機率函數 ,必需透過一個強性輔助函數zλ ), qQML ,,( zλλ 來估測新的模型參數值,因此弱性輔助函數 ),( λλMPEH 可表示成:"]},{"title":"( )","paragraphs":["),,,( qzML λλ"]},{"title":"()","paragraphs":[")|(log ),( 1 , Q qOpF H Z zq z MPE MPE latticez","λ","λλ λλ λ"]},{"title":"∑∑","paragraphs":["=∈","= ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ ∂ ∂ =′ W (15)","若以 來表示MPE z qγ λλλ","=","∂ )|( qOp z","MPE∂ logF ),,,( qzQ 可表示如下: ML λλ,且"]},{"title":"∑∑","paragraphs":["= Σ= q qstm qmqmz z qML toNtqzQ ),);((log)(),,,( μγλλ e"]},{"title":")","paragraphs":["z t ,;( qmqmN (16) 其中 為 O 的第 個語音特徵向量;"]},{"title":"(","paragraphs":["toz )⋅ μ Σ 是音素段落 q 的第 個高斯分布, m qmμ 與 Σ 分別是它的平均值向量與共變異矩陣。因此弱性輔助函數 )MPEH ,( λλqm 可進一 步表示成:","),);((log)(),( , qmqmz z qm MPE z q","mstqzMPE toNtH qlatticez Σ=′"]},{"title":"∑∑∑∑","paragraphs":["=∈ μγγλλ W","qs qe )(tz qmγ"]},{"title":"()","paragraphs":["toz q m eqt= (17) 其中 與 分別為音素段落 q 的開始與結束時間, 為語音特徵向量 在音素段 落 上的高斯分布 的佔有機率。若把平滑函數 ),( λλSMH 加入弱性輔助函數 ),( λλMPEH ′ ,則 ),( λλMPEH ′ 可進一步表示成[12]: "]},{"title":"[]","paragraphs":[")()()(|)log(| 2 ),),((log)(),( 11 , , −− = =∈ ΣΣ+−Σ−+Σ− Σ=′′"]},{"title":"∑ ∑∑∑∑","paragraphs":["qmqmqmqmqm T qmqmqm qm mq qmqmz z qm MPE z q m et stq zMPE tr D toNtH q qlatticez μμμμ μγγλλ","W","(18) 而平滑函數"]},{"title":"),( λλ","paragraphs":["SM"]},{"title":"H","paragraphs":["表示為:"]},{"title":"[]","paragraphs":[")()()(|)log(| 11 2 −− ΣΣ+−Σ−+Σ qmqmqmqmqm T qmqmqm qm tr D μμμμ ,="]},{"title":"∑","paragraphs":["mqSMH (19) 其中 qmμ"]},{"title":"),( λλ","paragraphs":["MPE"]},{"title":"H ′","paragraphs":["qmΣ與 為舊有模型的平均值向量與共變異矩陣。我們可以對 使用延 伸波式(Extended Baum-Welch ,EBW)演算法得到聲學模型參數估測更新公式(當假設語 音特徵向量維度間為無關時,亦即共變異矩陣為對角矩陣)[12]: 22 }{ qmd qmd den qm num qm qmdqmdqmdqmdqmd qmd D μ","γγσ − +− = MPE z qγ MPE z qγ"]},{"title":"∑","paragraphs":["= −= st z z q z qm den qmd","lattice q totO 22 )(),0max()()( γγθ qmdD","2222 )()}()({ }{ )}()({ dennum qmd den qm num qm qmdqmd den qmd num qmd qmd DOO D DOO μσθθ γγ μθθ μ ++− +− +− = (20)","其中統計值資訊可分為兩類,亦即 num(numerator)與 den(denominator)兩類,num 代表 為正時的統計值資訊,而 den 則代表 為負時的統計值資訊,詳細統計資訊可 分別表示如下:"]},{"title":"∑∑∑","paragraphs":["=∈ = = Z zq e st z q z qm num qm latticez q q MPE t 1 , ),0max()( W γγγ"]},{"title":"∑∑∑","paragraphs":["=∈ = = Z zq e st z q z qm num qmd latticez q q MPE","tO","1 , ,0max()()( W γγθ"]},{"title":"∑∑∑","paragraphs":["=∈ = = Z zq e st z q z qm num qmd latticez q","q tO 1 2",", ,0max()()( W γγθ"]},{"title":"∑∑∑","paragraphs":["=∈ = −= Z zq e st z q z qm den qmd latticez q q MPE t 1 , ),0max()( W γγγ"]},{"title":"∑∑∑","paragraphs":["=∈ = −= Z zq e st z q z qm den qmd latticez q q MPE","tO","1 , ),0max()()( W γγθ Z eq MPE (21) (22) (23) (24) (25) (26) z to )() z MPE to )() z to )( 2"]},{"title":"∑∑","paragraphs":["=∈zqz1 ,W qmdD其中式(20)中的 是一個常數,需要用來確保每一維度的變異數必須要是正數,同時 它也會影響收斂速度。一般而言, 的值都設為最小確保變異數為正數的兩倍。另 外,為了要增加正確詞序列的對於模型參數訓練時的貢獻,可以引入所謂的 I-Smoothing 技術[12],其公式如下:  qm num qm num qm ML qmML","qm","qmnum qmd num qmd ML qmdML","qm","qmnum qmd num qmd OOO OOO τγγ θ γ τ θθ θ γ τ θθ +=′ +=′ +=′ )()()( )()()( 222 (27)","其中 、 及 為使用傳統最大化相似度訓練法所求得的統計值資訊,ML qmdγ )(OML","qmdθ )( 2 O ML qmdθ qm"]},{"title":"τ","paragraphs":["為訓練時設定之常數。最後,對於詞圖 上候選詞序列正確率可以以每一候選詞 序列所組成音素的正確率加總來代表,原始最小化音素錯誤(MPE)聲學模型訓練的計算 候選詞序列中每一個組成音素 q 正確率的公式是: latticez ,W ⎭⎬⎫","⎩⎨⎧ +− +− = phonesdifferent are and if ),(1 phone same are and if ),(21 max)( quuqe quuqe qA u (28) 其中 為音素 q 與正確詞序列中音素 u 的重疊比例(根據正確音素 的長度),如 果 與 u 為同一音素則套用計算式 ,反之套用計算式),( uqe u","), u","q","),(21 uqe+− (1 qe+− ,最後 取","與所有重疊的正確詞序列中音素 計算式值最大者為音素 正確率(介於-1 與 1 之間),","圖 1 為計算原始音素正確率的一個範例。而 則可以由前向後向演算法 (Forward-Backward Algorithm)求得[12]。 )(qA","u q MPE z γ q b的音素正確率為取最大=1","a b c正確轉譯 音素序列","b time辨識之音素 -1+3/3=0 -1+3/3=0-1+2*(3/3)=1 a b c b的音素正確率為取最大=1 正確轉譯 音素序列","b time辨識之音素 -1+3/3=0 -1+3/3=0-1+2*(3/3)=1"," 圖 1 最小化音素錯誤訓練之原始音素正確率函數的範例"]},{"title":"四、最小化音素錯誤訓練之改進","paragraphs":["最小化音素錯誤(MPE)訓練主要有兩個缺點:","1. 最小化音素錯誤中的原始音素正確率函數(Raw Phone Accuracy Function)並沒有給予 刪除錯誤(Deletion Errors)適當的懲罰,只有對於插入錯誤(Insertion Errors)和取代錯誤 (Substitution Errors)給予適當的懲罰。","2. 原始音素正確率函數是以音素為單位(Phone-by-Phone)來做計算,如式(28)所示,且 其值域範圍為-1 到+1,這樣的範圍可能過於狹窄。每個音素段落(Phone Arc)所收集 到的正確率統計值最大為 1,因此遇到訓練語料不足的任務時,模型訓練所收集到的 統計值會不夠強健。","為了克服上述之問題,吾人提出了時間音框音素正確率(Time Frame Phone Accuracy Function, 記作 TFA)函數來取代原始音素正確率函數[13]:"]},{"title":"( )","paragraphs":["1 ),( )( +− ="]},{"title":"∑","paragraphs":["= qq e st se tuq qccuracyTimeFrameA q q δ (29) "]},{"title":"a","paragraphs":["正確轉譯音素"]},{"title":"c","paragraphs":["b"]},{"title":"a () () ()","paragraphs":["⎩⎨⎧ ≠ = = ,, ),( ρ , tqif tqif tuq","⎭⎬⎫ < 1 e <0 s − 1 ρ δ u u (30) 其中 q 為詞圖中某一音素段落, q 和 q 分別為音素段落 q 的開始時間及結束時間, )(t 為正確音素段落 u 在時間 t 時的音素標記(Phone Label), u","ρ 為刪除錯誤的懲罰權重 (Deletion Penalty Weight),用來懲罰某不完全正確音素段落 q 的正確率,因此某一音素 段落在某個時間點 t 的正確率值域範圍 介於為 ρ− 到 1 之間。時間音框音素正確率公式 是看每一個音框的音素標記是否與正確音素標記一致來計算音素段落的正確率,因此對 於一個完整的語句所對應的詞序列,就只要計算是否擊中(Hit)或取代(Substitution),而 不用考慮插入(Insertion)或刪除(Deletion),因此在音素段落比對時比計算編輯距離(Edit or Levenshtein Distance)有效率,且時間音框音素正確率與我們要做評估的音素正確率有 很大的正相關[5],所以使用時間音框音素正確率的確可以去近似某個音素段落的音素 正確率。圖 2 即為計算時間音框音素正確率(TFA)的一個例子,假設某個語句有 30 個音 框,此語句的正確轉譯音素共有三個,即 a、b 和 c;而此語句的辨識音素只有兩個, 即 a 和 c,那麼 b 就是刪除錯誤。在圖 2 中灰色部份代表出現刪除錯誤,此刪除錯誤發 生在第 11 個到第 20 個時間音框,我們理當給予這些錯誤的時間音框一些刪除錯誤的懲 罰。而在詞圖中一整條路徑(詞序列) iW 的時間音框音素正確率為:"]},{"title":"∑","paragraphs":["∈ = iWqi qccuracyTimeFrameAWccTimeFrameA )()( (31) 將式(31)取代式(28),即本論文所提出的最大化時間音框音素正確率(Maximum Time Frame Phone Accuracy, 記作 MTFA)的目標函數:"]},{"title":"∑∑","paragraphs":["=∈ = Z zW i z iiz latticezi WccTimeFrameA Op WPWOp 1 , )( )( )()|(  W λ"]},{"title":"∑∑","paragraphs":["=∈ = Z z i W ziMTFA","latticezi WccTimeFrameAOWpF","1 , )()|()( W λ (32) 另外,為了更充分地懲罰刪除錯誤且使其值域與原始音素正確率同為介於-1 到 1 之間, 本論文使用了 S 型函數(Sigmoid Function)來正規化時間音框音素正確率函數(式(29))的 分子項,稱之為 S 型時間音框音素正確率函數(Sigmoid Time Frame Phone Accuracy, 記 作 STFA): 1",")exp(1 2",")( − +⋅−+ = βα netqmeAccuracySigTimeFra (33) 0 5 10 15 20 25 30"]},{"title":"c","paragraphs":["辨識之音素 MPE之原始音 = 2 MTFA之時間音框音素正確率"]},{"title":"c","paragraphs":["b"]},{"title":"a","paragraphs":["正確轉譯音素"]},{"title":"a","paragraphs":["0 5 10 15 20 25 素正確率 = ( )( ) ()1.0.1","305102","=≈ 27−⋅+⋅"]},{"title":"c","paragraphs":["辨識之音素 MPE之原始音素正確率 = 2 MTFA之時間音框音素正確率 = 30","( ρρ ( )) ()1.0.1","305102","=≈( 27−(⋅+⋅","ρρ ))","MTFA之時間音框音素正確率 = ()1.0.1","305102","=≈⋅ + ⋅ − 27ρ ρ  圖 2 最小化音素錯誤訓練之原始音素正確率及時間音框音素正確率對於刪除錯誤的影響  其中"]},{"title":"( )∑","paragraphs":["== qe st tuqnet ),(δ q (34) 其 )(⋅δ 的定義同式(30),α 及 β 為 S 型函數中可調整的參數,α 控制 S 型函數的曲度,β 則控制 S 型函數的平移。故式(33)的值域範圍介於-1 到+1 之間。而在詞圖中一整條路徑 (詞序列) 的 S 型時間音框音素正確率為: iW"]},{"title":"∑","paragraphs":["= qmeAccuracySigTimeFraWmeAccSigTimeFra )()( ∈ iWqi (35) 將式(35)取代式(28),則本論文所提出的最大化 S 型時間音框音素正確率(Maximum Sigmoid Time Frame Phone Accuracy, 記作 MSTFA)的目標函數為:"]},{"title":"∑∑","paragraphs":["=∈ = Z zW i z iiz latticezi WmeAccSigTimeFra Op WPWOp 1 , )( )( )()|(  W λ"]},{"title":"∑∑","paragraphs":["=∈ = Z z i W ziMTFA","latticezi WmeAccSigTimeFraOWpF","1 , )()|()( W λ (36)","其本論文所提出的時間音框音素正確率函數主要並非去逼近編輯距離,而只是有 考量給予刪除錯誤一些適當懲罰,以改進最小化音素錯誤(MPE)鑑別式聲學模型訓練。 至於有關如何在詞圖中正確地計算編輯距離,可以參考[14]。"]},{"title":"五、資料選取方法於改進最小化音素錯誤聲學模型訓練","paragraphs":["近年來,由於最大邊際分類器(Large Margin Classifier)[15]在機器學習(Machine Learning) 的領域中已有高度的發展,且在分類(Classification)任務中都已達到非常不錯的分類效 果。其設計理念就在於提升分類器的一般化能力(Generalization Ability),以致能夠在未 知的測試樣本中達到較好的分類效果。在觀念上,我們以二元類別且可分離的(Separable) 訓練樣本為例,因訓練樣本通常與測試樣本會有不一致(Mismatch)的現象,要提升分類 器的一般化能力,就要使得訓練樣本在某種定義域中( 如相似度定義域(Likelihood Domain))離此定義域的決定邊界(Decision Boundary)越遠越好,訓練樣本到決定邊界的 最近距離我們一般會稱之為邊際(Margin),而此邊際越大且邊際內沒有其他的訓練樣本 代表一般化能力及容錯能力會越好[16]。","最大邊際估測法(Large Margin Estimation, LME)[17]是以相似度(Likelihood)為基礎 的分離邊際(Separation Margin)來選取距離決定邊界(Decision Boundary)較近的語音特徵 向量序列,依其選取門檻(Threshold),可以定義出支持向量集合(Support Vector Set),再 利用最大邊際估測法則進而調整聲學模型。對於那些不在支持向量集合裡的訓練樣本 (訓練語句),因為距離決定邊界較遠,所以較不具鑑別力,因此就沒有拿來調整聲學模 型的參數。所以我們可以視最大邊際估測法為以相似度作為選取準則的資料選取方法, 選出較為重要的語音特徵向量序列( 訓練語句) 。在柔性邊際估測法(Soft Margin Estimation, SME)[18]中,也是以相似度作為選取準則,藉由定義不同的門檻值,進而選 取出較有影響力的訓練語句,而且從選取出來的訓練語句中,更進一步地用類別比對 (Label Matching)的方式選取出重要的時間音框(Frame)。所以我們也可以視柔性邊際估 測法(SME)為以相似度和類別比對為基礎的進階資料選取方法。 最大邊際估測法與柔性邊際估測法所使用的資料選取方法都是在相似度定義域  (Likelihood Domain)中來執行資料的選取。在本論文中,吾人提出以熵值(Entropy)為基 礎的時間音框資料選取(Data Selection)方法來改進最小化音素錯誤聲學模型訓練。其中 是以給定在某語音特徵向量序列(訓練語句) zO ,某個狀態中的某個高斯分布出現的事後 機率(Posterior Probability,此事後機率有考慮到詞與詞之間的轉移機率,即語言模型機 率)來求得熵值,再利用事先所設定的門檻值來選取資料,故可視為在事後機率定義域 中來取選資料。因其熵値的計算是在事後機率定義域(Posterior Domain)中,故有別於以 相似度定義域為基礎的傳統資料選取方法。然而傳統熵値的值域為 0 到 ,其 中 為參與熵値計算的樣本個數,但為了方便決定門檻值進而選取時間音框,故在此我們使 用正規化熵值(Normalized Entropy)來使其值域介於 0 到 1 之間,其公式如下: N2log N )(1 log)( log1",")( 2","12 tt","NtE z qm Q qqm z qmz γ γ ⋅="]},{"title":"∑∑","paragraphs":["=∈ (37) 其中 為在第 句訓練語句時間 t 時的正規化熵値, 為在第 句訓練語句時間 t 時,在音素段落 中之高斯模型 的事後機率, 為在時間 時所有的音素段落個數,N 為在時間 t 中所有事後機率不為零的高斯模型 。",")(tEz z )(tz qmγ t z","q m Q m"]},{"title":"∑∑ ∑","paragraphs":[">⋅= zzz q z qm num qmd tEItotO 22","))(()(),0max()()( ργγ","然而在資料選取方法中,資料(或樣本)可以定義在不同的單位上,以語音辨識為 例,訓練樣本(Training Sample)可以定義在語音特徵向量序列(訓練語句(Sentence or Utterance))、詞圖中的某詞段(Word Arc)、音素段落(Phone Arc)或時間音框(Frame)等。 在語音辨識的任務中,鑑別式訓練收集統計值時是以時間音框(Frame)為最小單位,所 以本論文將著重在時間音框之選取(Frame Selection),並將每一個時間音框視為一個訓 練樣本(Training Sample)。鑑別式訓練時是將所有的時間音框所收集到的統計值都用來 調整模型的參數,事實上有些時間音框對於鑑別式訓練是沒有幫助的,例如那些已經可 以被分類器(在語音辨識中,通常使用連續密度隱藏式馬可夫模型(CDHMM)來當成分類 器)很正確分類或很錯誤分類的時間音框,故本論文提出的以熵値(Entropy)為基礎的時 間音框選取方法(Frame Selection)旨在找出哪些時間音框是會被很正確或很錯誤地分 類,哪些是不容易被分類正確,進而丟棄那些被很正確分類和被很錯誤分類之時間音框 所收集到的統計值,且只利用這些被收集到的統計值來調整模型參數,以幫助鑑別式聲 學模型訓練。因此使用此資料選取方法可以適用於所有的鑑別式聲學模型訓練,不僅能 夠保持鑑別式訓練最小化訓練樣本分類錯誤率,還可以增進分類器的一般化能力。以最 小化音素錯誤(MPE)訓練的統計值收集為例,每個時間音框要先算正規化熵値,再由其 門檻值決定是否累加統計值,則其數學式可表示為(以 num 類為例):"]},{"title":"[] [] [] ∑∑ ∑ ∑∑∑","paragraphs":["=∈ = =∈ = >⋅= >⋅= Z e Z zq z e st z z q z qm num qmd z Z zq e st z q z qm num qm","q MPE latticez q q MPE latticez q q MPE tEItotO tEIt 1 1 , , ))(()(),0max()()( ))((),0max()( W W ργγθ ργγγ (38) θ =∈ =zq stlatticez q1 ,W ρ 為事先定義的門檻值(Threshold),其値介於 0 到 1 之間, ))(( ρ>tEI z ⎩⎨⎧ ≤ > => ρ ρ ρ )(,0 )(,1 ))(( tEif tEif tEI z z z   可表示為: 其中 (39)  式(39)使用的是指示函數,其值非 0 即 1,故我們可將它視為是一種硬性選取(Hard Selection)的資料選取方法。另一方面,我們亦可將每個時間音框所計算出的正規化熵值 作為權重(Weight),用來強調(Emphasized)或非強調(Deemphasized)此時間音框的重要 性,我們將此方法視為另一種柔性選取(Soft Selection)的資料選取方法,其數學式如下 所示:"]},{"title":"(","paragraphs":[")(1)()( tEtt zz qm z qm ⋅+= ωγγ"]},{"title":")","paragraphs":["(40) ω 為一比例控制參數。 其中"]},{"title":"六、實驗與討論 (一)實驗架構與設定","paragraphs":["本論文所使用的大詞彙連續語音辨識器為臺灣師大目前所發展的新聞語音辨識系統 [19],主要包括前端處理、詞彙樹複製搜尋(Tree-Copy Search)及詞圖搜尋(Word Graph Rescoring)[11]等部分。","在前端處理方面,本論文所採用的是異質性線性鑑別分析(Heteroscedastic Linear Discriminant Analysis, HLDA)[20]。且在做完鑑別分析之後還額外使用最大化相似度現 性轉換(Maximum Likelihood Linear Transform, MLLT)[21],其目的是為了配合目前我 們在連續密度隱藏式馬可夫模型所使用的對角化(Diagonal)之共變異矩陣。同時,為了 降低通道效應對語音辨識的影響,在此使用倒頻譜正規化法(Cepstral Normalization, CN)。","在聲學模型方面,我們採用 151 個連續密度隱藏式馬可夫模型作為中文 INITIAL-FINAL 的統計模型,而每個模型的狀態數分別為 3 至 6 個不等,每個狀態皆 為高斯混合分布,其中每個高斯混合分布的分布個數分別為 1 至 128 個不等,本論文 總共使用到約 14,396 個高斯分佈。另一方面,本論文所使用的詞典約含有七萬二千個 一至十字詞,並以從中央通訊社(Central News Agency, CNA) 2001 與 2002 年所收集到 的約一億七千萬(170M)個中文字語料作為背景語言模型訓練時的訓練資料[22]。在本 文中的語言模型使用了 Katz 語言模型平滑技術[23],在訓練時是採用 SRL Language Modeling Toolkit (SRILM)[24]。在詞彙樹搜尋時,本系統採用詞雙連語言模型;在詞 圖搜尋時,則採用詞三連語言模型。"]},{"title":"(二)實驗語料","paragraphs":["本論文實驗使用的訓練與測試語料為 MATBN 電視新聞語料庫[25],是由中央研究院 資訊所口語小組[26]耗時三年與公共電視台[27]合作錄製完成。我們初步地選擇採訪記 者語料作為實驗語材,其中包含 25.5 小時的訓練集(5,774 句),供聲學模型訓練之用, 其中男女語料各半;1.5 小時的評估集(292 句,共 26,219 字),供辨識評估之用。訓練 集由 2001 及 2002 年的新聞語料所篩選出來的;評估集則均為 2003 年的語料,由中 研院的評估語料篩選出來,只選擇了採訪記者語料並濾掉了含有語助詞之語句。"]},{"title":"(三)實驗評估方式","paragraphs":["本論文採用美國國家標準與技術中心(National Institute of Standards and Technology, NIST)所訂立的評估標準來進行正確轉譯詞序列與辨識詞序列的比較。此評估標準需  要使用動態規畫(Dynamic Programming)來做詞序列比對。然而因在中文中存在著斷詞 不一致的問題,故在本文的實驗中皆是以字為比對單位。令 H 為正確轉譯詞序列與辨 識詞序列比對後相同(Match)的字元個數、I 為辨識詞序列多餘插入(Insertion)的字元個 數、 為正確轉譯詞序列的字元總數,則語音辨識系統之正確率(Accuracy)的計算方 式為 N %100× − NH I ,錯誤率(Error Rate)則為 1-正確率。本文的實驗數據中,皆是以字錯 誤率(Character Error Rate, CER)來呈現實驗結果。"]},{"title":"(四)基礎實驗結果","paragraphs":["於基礎實驗中,先利用最大化相似度(ML)估測法訓練 10 次,所得到的字錯誤率(CER) 為 23.64% (記作 Baseline)。接著進行最小化音素錯誤(MPE)訓練 10 次,最後所得到的 字錯誤率(CER)為 20.77%。故於接下來的實驗中,皆以這組實驗為比較對象。 20 20.5 21 21.5 22 22.5 23 23.5 24字錯誤率(%)","012345678910 訓練次數 MPE MSTFA Lo=0.1 alpha=0.5 MTFA Lo=0.5  圖 3 時間音框正確率函數與最小化音素錯誤之比較結果"]},{"title":"(五)改進最小化音素錯誤之實驗結果","paragraphs":["本小節呈現本論文針對最小化音素錯誤訓練(MPE)的缺點而改進的最大化時間音框正 確率函數(MTFA)訓練之實驗數據。事實上,本論文所提出的時間音框正確率函數並 不是要減少刪除錯誤的個數(但實際上於共 26,219 字的評估集中,MPE 在第 10 次迭 代訓練上有 359 個刪除錯誤,然而 MSTFA 則稍微減為成 345 個),而是去考量詞圖中 某詞段受到刪除錯誤的影響,而減少其收集到的正確率統計値,以利聲學模型訓練之 強健。實驗結果可參考表 1,其中刪除錯誤的懲罰權重(Penalty Weight)以 Lo( ρ )表示。 由實驗數據顯示得知,在前幾次的迭代訓練中,時間音框正確率函數都會稍比最小化 音素錯誤來得好。不同的刪除錯誤懲罰權重設定會有不同的刪除錯誤懲罰之效果。由 表 1 的數據顯示,太大( ρ =0.8)或太小( ρ =0.1)的刪除錯誤懲罰權重設定,在一開始的 迭代訓練上並無法得到明顯的效果,但都比最小化音素錯誤訓練來得佳,不過在第 10 次的迭代訓練上卻比最小化音素錯誤訓練的字錯誤率要高一點。最好的刪除錯誤懲罰 權重設定(Lo=0.5)的時間音框正確率函數在第 10 次的迭代訓練上比最小化音素錯誤 (MPE)訓練的辨識字錯誤率好 0.05%,相對字錯誤率將低約 0.1%,訓練次數 1 到 10 次的字錯誤率曲線圖請參考圖 3。","本論文亦使用一個常見的 S 型函數來平滑時間音框正確率函數,記作 MSTFA。 其中 S 型函數有兩個參數可調整,在本實驗中只調整α (alpha),而 β 設為零(0=β )。  實驗結果同樣參考表 1,實驗數據顯示出 MSTFA 在每次迭代訓練中都會比最小化音 素錯誤(MPE)訓練來得好,最好的設定( =ρ 0.1, 5.0=α )在第 10 次的迭代訓練上可以 比最小化音素錯誤的辨識字錯誤率好 0.31%,相對字錯誤率降低約 1.5%。","表 1 時間音框正確率函數之實驗結果 CER(%) MPE MTFA ρ =0.1 MTFA ρ =0.3 MTFA ρ =0.5 MTFA"]},{"title":"(六)資料選取方法之實驗結果","paragraphs":["本小節呈現資料選取方法於最小化音素錯誤(MPE)訓練之實驗結果。其中最小化音素 錯誤的 I-平滑技術參數設定為 10[28]。所使用的時間音框資料選取方法分為硬性選取 (HS)和軟性選取(SS),其實驗結果皆可參考表 2。在軟性選取部分,所得到的結果跟 基礎實驗結果不相上下,而其硬性選取最佳門檻值(記作 Thr)之設定為 0.05(其時間音 框總數為 4,214,360 個,佔所有時間音框總數的 45.88%)。如實驗數據所顯示,資料選 ρ =0.8 MSTFA ρ =0.1","0.5 MSTFA ρ =0.5","=α 0.5 MSTFA ρ =0.1","=α 1 MSTFA ρ =0.5","=α 1 =α","Baseline 23.64 Itr01 22.82 22.85 22.73 22.74 22.80 22.88 22.82 22.83 22.77 Itr02 22.44 22.35 22.33 22.36 22.39 22.37 22.34 22.37 22.38 Itr03 22.28 22.07 22.13 22.14 22.19 22.06 22.10 22.02 22.05 Itr04 21.79 21.65 21.50 21.56 21.69 21.52 21.58 21.41 21.56 Itr05 21.48 21.26 21.14 21.26 21.34 21.23 21.47 21.3 21.52 Itr06 21.24 20.98 20.97 21.09 21.23 21.05 21.27 21.06 21.32 Itr07 21.10 20.91 20.87 21.09 21.19 20.89 21.11 20.80 21.19 Itr08 21.06 20.87 20.81 20.82 20.93 20.50 20.97 20.54 20.98 Itr09 20.97 20.84 20.74 20.85 20.90 20.58 20.82 20.57 21.03 Itr10 20.77 20.82 20.80 20.72 20.93 20.46 20.87 20.65 21.10 表 2 資料選取方法之實驗結果 CER(%) MPE MPE Random MPE HS Thr=0.05 MPE HS Thr=0.08 MPE SS ω =1.0 MPE SS ω =0.5 Baseline 23.64 Itr01 22.82 23.02 22.63 22.43 22.84 22.88 Itr02 22.44 22.62 22.05 21.80 22.40 22.43 Itr03 22.28 22.22 21.60 21.45 22.21 22.25 Itr04 21.79 22.16 21.40 21.34 21.65 21.73 Itr05 21.48 21.76 21.19 20.94 21.34 21.31 Itr06 21.24 21.66 20.92 20.82 21.33 21.18 Itr07 21.10 21.74 20.91 20.73 21.29 21.29 Itr08 21.06 21.62 21.22 20.74 21.00 21.06 Itr09 20.97 21.78 21.08 20.65 21.02 20.93 Itr10 20.77 21.84 21.29 20.63 20.94 20.89  取方法應用在最小化音素錯誤(MPE)訓練確實可以加快收斂速度,但在第 10 次的訓練 上沒有明顯比最小化音素錯誤的字錯誤率來得低,其效果是差不多的。特別注意的是 在 Thr=0.08 的這組實驗中,我們嘗試把門檻值隨著迭代訓練次數而遞減以企圖避免過 度訓練之現象,所得結果亦符合我們所期望。故可以得知資料選取方法具有加快收斂 速度之能力同時在第 10 次迭代訓練上與最小化音素錯誤訓練擁有差不多之結果。同 時更說明了以正規化熵值為基礎的資料選取方法確實能選出在事後機率定義域中離 決定邊界較近的時間音框樣本,受惠於這些時間音框樣本本身比較具有鑑別力,故資 料選取方法對於鑑別式訓練特別有幫助。","另一方面,吾人使用隨機選取(Random Selection)方法進行比較驗證以正規化熵值 為基礎的資料選取方法的確有效用的,而非亂選。實驗結果同樣參考表 2,其中隨機 選取( 記作 MPE Random) 方法在每一次的迭代都隨機選取所有時間音框總數的 45.88%(與 MPE HS Thr=0.05 這組實驗的時間音框總數一致)。"]},{"title":"(七)資料選取方法結合時間音框正確率函數之實驗結果","paragraphs":["最後本小節將呈現資料選取方法於最大化 S 型時間音框正確率函數(MSTFA)之實驗結 果。其最大化 S 型時間音框正確率函數的 I-平滑技術參數最佳化設定為 10。所使用的 時間音框資料選取方法為硬性選取(HS)、軟性選取(SS)以及結合硬性和軟性選取 (HS+SS),實驗結果可參考表 3。其中最大化 S 型時間音框正確率函數的參數設定為","=ρ 0.1、 5.0=α ;而各資料選取方法之參數設定皆列於表 3 中。由數據顯示得知,資 料選取方法應用在最大化 S 型時間音框正確率函數依然保有加快收斂速度之成效,但 在第 10 次迭代訓練上卻沒能比最大化 S 型時間音框正確率函數的字錯誤率來得低。 此外,軟性資料選取方法比硬性選取效果來得好,在第 10 次迭代訓練上跟最大化 S 型時間音框正確率函數的字錯誤率差不多。最後,結合硬性與軟性選取(HS+SS)的實 驗結果卻並沒有達到我們所預期的加成性效果。","表 3 資料選取方法結合時間音框正確率函數之實驗結果 CER(%) MPE MSTFA ρ =0.1","=α 0.5 MSTFA","HS Thr=0.05 MSTFA","SS ω =1.0 MSTFA HS+SS Thr=0.1 ω =0.5","Baseline 23.64 Itr01 22.82 22.88 22.46 22.75 22.53 Itr02 22.44 22.37 21.87 22.25 21.72 Itr03 22.28 22.06 21.40 21.83 21.45 Itr04 21.79 21.52 21.38 21.45 21.38 Itr05 21.48 21.23 21.08 21.27 21.03 Itr06 21.24 21.05 21.03 20.94 20.90 Itr07 21.10 20.89 21.02 20.65 21.14 Itr08 21.06 20.50 21.15 20.78 21.14 Itr09 20.97 20.58 20.86 20.56 21.07 Itr10 20.77 20.46 21.43 20.86 21.37  "]},{"title":"七、結論與未來展望","paragraphs":["鑑別式聲學模型訓練在大詞彙連續語音辨識的研究上一直扮演著重要的角色。本論文旨 在改善最小化音素錯誤之聲學模型訓練,相關研究內容與成果可從下面兩個面向來作探 討: (1) 首先,本論文提出了新的時間音框正確率函數來取代最小化音素錯誤訓練的原始音 素正確率函數,進而充分地給予刪除錯誤適當的懲罰。在實驗結果上,最大化 S 型時 間音框正確率函數(MSTFA)能達到比最小化音素錯誤(MPE)訓練約有 1.5%的相對字錯 誤率降低。 (2) 其次,本論文提出以正規化熵值為基礎之新的資料選取方法來改善鑑別式聲學模型 訓練,由於正規化熵值是以給定某訓練語句的語音特徵向量序列中,某個狀態中的某 個高斯分布出現的事後機率來求得的,所以可以視為是在事後機率定義域中來選取訓 練樣本,且所選出來的訓練樣本是比較混淆的,對鑑別式訓練來說,這些混淆的訓練 樣本是較具有鑑別力的。根據初步的實驗結果顯示,此資料選取方法可以加快收斂速 度,在前幾次的迭代訓練中,比最小化音素錯誤訓練有很大且一致的字錯誤率降低。 最好的結果在第 6 次的迭代訓練上,比最小化音素錯誤訓練約有 1.5%的相對字錯誤率 降低。","以全面風險為基礎的鑑別式聲學模型訓練中,減損函數的設計一直都是一個重要 的議題,如最流行的最小化音素錯誤訓練目標函數中,以類別比對為基礎的原始音素正 確率函數就還存在著改進的空間。已有學者提出以聲學模型間的關係來計算正確率以取 代以類別為基礎的正確率函數。類別比對為基礎的音素正確率函數和聲學模型彼此間關 係的減損函數皆各有其優缺點,未來吾人想要嘗試將這兩種不同的資訊結合,企圖改進 鑑別式聲學模型訓練。","同時,吾人未來也想嘗試將以正規化熵值為基礎的資料選取方法應用到其他的鑑 別式訓練,如最小化分類錯誤、最小化貝氏風險鑑別式訓練等,以驗證此方法的一般性。 事實上,由加最小化音素錯誤訓練的收斂速度來看,此以正規化熵值為基礎之新的資料 選取方法的確為鑑別式聲學模型訓練提供了一個新的方向。"]},{"title":"參考文獻","paragraphs":["[1] R. O. Duda, P. E. Hart and D. G. Stork, Pattern Classification, Second Edition. New York: John & Wiley, 2000.","[2] Lalit R. Bahl, F. Jelinek and Robert L. Mercer, A Maximum Likelihood Approach to Continuous Speech Recognition, IEEE Trans. Pattern Analysis and Machine Intelligence, vol. PAMI-5, no.2, March 1983.","[3] J. Fiscus, A Post-processing System to Yield Reduced Word Error Rates: Recognizer Output Voting Error Reduction (ROVER), in Proc. ASRU 1997.","[4] V. Goel and W. Byrne, Minimum Bayes-Risk Automatic Speech Recognition, Computer Speech and Language, Vol. 14, pp.115-135, 2000.","[5] F. Wessel, R. Schluter, K. Macherey and H. Ney, Explicit Word Error Minimization Using Word Hypothesis Posterior Probability, in Proc. ICASSP 2001.","[6] L. Mangu, E. Brill and A. Stolcke, Finding Consensus in Speech Recognition: Word Error Minimization and Other Applications of Confusion Networks, Computer Speech and Language, Vol. 14, pp.373-400, 2000.","[7] Y. Normandin, Hidden Markov Models, Maximum Mutual Information Estimation, and the Speech Recognition Problem, Ph.D Dissertation, McGill University, Montreal, 1991.  ","[8] J. Kaiser, B. Horvat and Z. Kacic, Overall Risk Criterion Estimation of Hidden Markov Model Parameters, Speech Communication, Vol. 38, pp.383-398, 2002. [9] V. Doumpiotis, S. Tsakalidis and W. Byrne, Lattice Segmentation and Minimum Bayes Risk Discriminative","Training, in Proc. Eurospeech 2004. [10] D. Povey and P. C. Woodland, Minimum Phone Error and I-smoothing for Improved Discriminative Training, in Proc. ICASSP 2002. [11] S. Ortmanns, H. Ney and X Aubert, A Word Graph Algorithm for Large Vocabulary Continuous Speech Recognition, Computer Speech and Language, Vol. 11, pp.11-72, 1997.","[12]D. Povey, Discriminative Training for Large Vocabulary Speech Recognition. Ph.D Dissertation, Peterhouse, University of Cambridge, July 2004.","[13] Shih-Hung Liu, Fang-Hui Chu, Shih-Hsiang Lin and Berlin Chen, Investigating Data Selection for Minimum Phone Error Training of Acoustic Models, in Proc. ICME 2007. [14] G. Heigold et al, Minimum Exact Word Error Training, in Proc. ASRU 2005","[15] A. J. Smola, P. Bartlett, B. Scholkopf and D. Schuurmans, Advances in Large Margin Classifiers, The MIT Press. [16] V. Vapnik, The Nature of Statistical Learning Theory, Springer-Verlag, New York, 1995.","[17] Xinwei Li, Hui Jiang and Chaojun Liu, Large Margin HMMs for Speech Recognition, in Proc. ICASSP 2005.","[18] Jinyu Li, Ming Yuan and Chin-Hui Lee, Soft Margin Estimation of Hidden Markov Model Parameters, in Proc. ICSLP 2006.","[19] B. Chen, J. W. Kuo and W. H. Tsai, Lightly Supervised and Data-Driven Approaches to Mandarin Broadcast News Transcription, in Proc. ICASSP 2004.","[20] N. Kumar, Investigation of Silicon-Auditory Models and Generalizaion of Linar Discriminant Analysis for Improved Speech Recognition, Ph.D. Thesis, John Hopkins University, Baltimore, 1997. [21] R. A. Gopinath, Maximum Likelihood Modeling with Gaussian Distributions, in Proc. of ICASSP 1998. [22] LDC: Linguistic Data Consortium, http://www.ldc.upenn.edu","[23] S. M. Katz, Estimation of Probabilities from Sparse Data for Other Language Component of a Speech Recognizer, IEEE Trans. Acoustics, Speech and Signal Processing, Vol. 35, No.3, pp. 400-401, 1987. [24]A. Stolcke, SRI language Modeling Toolkit, version 1.3.3, http://www.speech.sri.com/projects/srilm/","[25] H. M. Wang, B. Chen, J.-W. Kuo, and S.S. Cheng. MATBN: A Mandarin Chinese Broadcast News Corpus, International Journal of Computational Linguistics and Chinese Language Processing, Vol. 10, No. 2, pp. 219-236, 2005.","[26] SLG: Spoken Language Group at Chinese Information Processing Laboratory, Institute of Information Science, Academia Sinica. http://sovideo.iis.sinica.edu.tw/SLG/index.htm [27] PTS: Public Television Service Foundation. http://www.pts.org.tw","[28] 郭人瑋, 最小化音素錯誤鑑別式聲學模型學習於中文大詞彙連續語音辨識之初步研究, Master Thesis, NTNU, 2005. [29] 劉士弘, 改善鑑別式聲學模型訓練於中文連續語音辨識之研究, Master Thesis, NTNU, 2007."]}]}