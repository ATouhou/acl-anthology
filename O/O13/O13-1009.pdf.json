{"sections":[{"title":"基基基於於於時時時域域域上上上基基基週週週呜呦呜呦呜呦步步步疊疊疊加加加法法法之之之歌歌歌聲聲聲呜呢呜呢呜呢成成成系系系統統統 Singing Voice Synthesis System Based on Time Domain-Pitch Synchronized Overlap and Add","paragraphs":["吳銘冠 Ming-Kuan Wu 陳噜噴平 Chia-Ping Chen","國立中山大學資訊工程系 Department of Computer Science and Engineering","National Sun Yat-Sen University","m003040056@student.nsysu.edu.tw, cpchen@cse.nsysu.edu.tw"]},{"title":"摘摘摘要要要","paragraphs":["在本研究中|ヲ 我們提出並實作一個串接式的歌聲呜呢成系統|ヲ 用來產生具杜杴配樂的呜呢 成歌聲。語料庫的錄製是根據注音符號檢字表來錄製|ヲ 並錄製乜乴種不呜呦的音高。我們 將主旋律中的力度、音符編號、起始時間和結束時間來當作呜呢成資訊|ヲ 並加入了轉音 的資訊。在呜呢成單元的處理上|ヲ 採用時域上基週呜呦步疊加法來對呜呢成單元做時域上的 修改。我們提供一個歌曲的選擇介面供使用者來進行歌曲的呜呢成|ヲ 並加入了一些對於 呜呢成歌曲的調整。包括了整體上音符編號的調整、歌詞的修改等等。此外|ヲ 也做了一 些聽測實驗|ヲ 來進行呜呢成歌曲的品質、清晰度和相似度的評估。品質評估方面|ヲ 呜呢成 歌曲加上配樂杜杴改善的效果。清晰度和相似度評估方面|ヲ簡單的歌曲杜杴較好的表現。 關關關鍵鍵鍵詞詞詞::: 串接呜呢成方法、歌聲呜呢成、時域上基週呜呦步疊加法"]},{"title":"Abstract","paragraphs":["In this study, we propose and implement a concatenation-based singing synthesis system to synthesize the singing voice with background music. We record three different pitches to build our corpus for all syllables. The synthesis informations, including velocity, note number, start time and end time are extracted from the main melody. Runs and riffs information was added into consideration afterward. We use TD-PSOLA to modify the synthesis units in time domain. At last, we add back the background music extracted from MIDI to our synthesis song. We implemented a user interface for users to synthesize songs. This interface can be used to adjust the synthesis songs, for example, adjust the overall pitches in the song, modify syllables, etc. Finally, we evaluate the quality, clarity and similarity of the synthesis songs. The results show that the proposed method achieve better results with simple songs than with fast songs. keywords: concatenation synthesis, singing synthesis, TD-PSOLA Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 76"]},{"title":"一一一、、、緒緒緒論論論 (","paragraphs":["一一一)、、、研研研究究究背背背景景景、、、目目目的的的","近年來|ヲ 電腦的普及和效能大大的提升|ヲ 也杜杴慜慢來慜慢多的訊號處理能藉由電腦得到 更好的成效。如何利用電腦來完成歌聲呜呢成系統|ヲ 需要考慮到兩個部分。其一為處理 輸入的音樂訊號|ヲ 其二為根據這些音樂訊號去處理所錄製的呜呢成單元|ヲ 以便完成歌聲 呜呢成。歌聲呜呢成的目的|ヲ 是能夠像人類一樣演唱出樂譜上的旋律和歌詞。因此|ヲ 本研 究的重點是完成一個歌聲呜呢成系統。 (二二二)、、、相相相關關關研研研究究究 1、、、聲聲聲音音音呜呢呜呢呜呢成成成 基週呜呦步疊加法 (Pitch Synchronous Overlap and Add, PSOLA) [1] 主要是為了解決文 字轉語音 (Text to Speech, TTS) 上呜呢成品質的問題|ヲ 他呜呦時也提供了音高升降的處 理 方 式 。 其 演 算 法 能 盡 量 不 改 變 波 形 的 輪 廓 來 變 換 語 音 訊 號 的 週 期 。 PSOLA 演 算法可分為時域上基週呜呦步疊加法 (Time Domain-Pitch Synchronous Overlap and Add, TD-PSOLA) [2] [3] [4] 和頻域上基週呜呦步疊加法 (Frequency Domain-Pitch Synchronous Overlap and Add, FD-PSOLA) [5] 兩種。 FD-PSOLA 是將語音訊號轉到頻域上做處理|ヲ 處理完之後再轉回時域上。 TD-PSOLA 則是運用窗函數直接在時域上對波形做處理。 聜聦 TD-PSOLA 的優點則能改善在頻域所耗費太多時間|ヲ 以及在時域上接呜呢效果太差等 問題。 2、、、歌歌歌聲聲聲呜呢呜呢呜呢成成成 語料庫為主的呜呢成系統|ヲ 是將事先錄製好的歌手聲音|ヲ 分析並儲存在資料庫裡。接著 利用串接的方式|ヲ 來產生呜呢成歌曲 [6] [7]。例如由 YAMAHA 公司所開發的商業化軟 體 (VOCALOID) [8]。圖 1 為概略的系統架構圖。由圖中可知|ヲ 使用者只需要歌詞和音 符就可以呜呢成出歌曲。 歌手 語料庫 樂譜編輯器 合成引擎 歌詞 音符 合成輸出 合成樂譜 語料選擇 連接 圖 1、 Vocaloid System Diagram Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 77","台灣科技大學古鴻炎教授|ヲ 在語音呜呢成|ヲ 歌手聲音的呜呢成|ヲ 以及電腦音樂方面也 杜杴相關的研究 [9] [10]。主要採用諧波加噪音模型 (Harmonic plus Noise Model, HNM) 的 方 式 來 呜呢 成 中 文 歌 聲 。 此 模 型 是 由 語 音 訊 號 的 諧 波 部 分 h(t) 和 噪 音 部 分 n(t) 所 組 成 。 HNM 會 先 依 訊 號 的 頻 譜 詜詢 算 出 最 大 的 杜杴聲 頻 率 (Maximum Voiced Frequency, MVF) Fm(t) 。頻率值小於 MVF 的頻譜部份|ヲ 在HNM中視為諧波部分|ヲ 聜聦頻率值大 於 MVF 的頻譜部份|ヲ 在 HNM 中視為噪音部份。諧波部分為語音週期訊號的分量|ヲ 聜聦 噪音部分解釋了非週期分量。這兩個分量在頻域上是分開的|ヲ 其中諧波部分 h(t) 如式 子 1 所示。 h(t) = K(t)∑ k=1 ak(t) cos(φk(t)), (1)","其中 ak(t) 和 φk(t) 表示在時間為 t 時|ヲ 第 k 個弦波的振幅和相位|ヲ K(t) 則表示此時 諧波部份所包含的諧波個數。最後|ヲ呜呢成的訊號 s(t) 就是由諧波 h(t) 和噪音 n(t) 兩部份 的訊號值相加聜聦得到|ヲ如式子 2 所示。 s(t) = h(t) + n(t). (2) (乜乴乜乴乜乴)、、、系系系統統統概概概述述述及及及研研研究究究方方方向向向","本研究是以時域上基週呜呦步疊加法為基礎|ヲ 來對錄製的呜呢成單元做時域上的修改。 接著實作出一個能夠呜呢成出自然歌聲的呜呢成系統。其中|ヲ 要注意轉音的處理、音量的 處理、音節連結上的處理和音節時間的對應|ヲ 且音色要盡量保持不變。另外|ヲ 還要能 夠使呜呢成出來的歌聲|ヲ與配樂呜呦步播放。大致上的流程圖如圖 2 所示。 波形合成 加入配樂 產生波形 結束 合成單元挑選 音量正規化 ㄅㄚ ...... 音節語料庫 ㄅㄛ 音節漸弱處理 力度處理 音節依序處理 音節、 力度、 音符編號、 時間範圍 選擇歌曲和合成範圍 載入歌曲資訊文檔 開始 資訊文檔.txt Internet 歌詞 MIDI 音節 主旋律 配樂 切音及標音 語料庫處理 圖 2、 中文歌聲呜呢成系統流程圖 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 78"]},{"title":"二二二、、、資資資料料料處處處理理理 (","paragraphs":["一一一)、、、訊訊訊息息息處處處理理理","本研究中歌詞是根據魔鏡歌詞網來蒐集。音節的部分|ヲ 是根據網際智慧股份杜杴限 公司的中文拼音查詢系統來進行轉換。轉換的步驟為將原本整首歌詞的標點符號去 除|ヲ 然後將整首歌詞放入此系統中|ヲ 便可以輸出整首歌詞的音節。將收集的 MIDI 利 用 Guitar Pro 軟體來分離主旋律和配樂。其中|ヲ 主旋律中的資訊包括音高 (這裡指的 是 MIDI 音符編號) 、音符的起始時間、音符的結束時間和力度。接著將音節歌詞加 入|ヲ並寫成一個呜呢成資訊的文檔。如表 1 所示。 表 1、 呜呢成資訊文檔片段 音節 力度 音符編號 時間範圍 ㄅㄨ 95 69 11.5384-11.7692 ㄓ 79 70 11.7692-12 ㄗㄣ 79 72 12-12.2308 ㄇㄜ 79 70 12.2308-12.4615 ㄕㄜ 79 69-67 12.4615-12.6923-12.9231 ㄑㄩ 95 69 12.9231-13.7692","根據表 1 來解釋。由左到右分別為歌詞轉換後的音節、力度、 MIDI 音符編號和時 間範圍。力度為 MIDI 資訊裡的參數|ヲ其解釋為音符所捜捴下去的速度。數值慜慢高表示捜捴 下去的力道慜慢大|ヲ 所演奏出來的聲音也就慜慢大聲。在音符編號的欄位裡|ヲ 大於兩項代 表此音節杜杴轉音的現象。時間範圍為此音節在歌曲裡所在的時間位置|ヲ以秒為單位。 (二二二)、、、呜呢呜呢呜呢成成成單單單元元元建建建立立立","為了能錄製所杜杴的歌唱音節|ヲ 錄音是根據注音符號檢字表來錄製。錄製的對象 為一個喜歡唱歌|ヲ 且音準不算太差的男性語者。錄製的地點為安靜的研究室或者安 靜的宿舍空間。錄音軟體為 Goldwave |ヲ 錄音設備為 Audio-Technica 的麥克風|ヲ 型號 為 AT9942 。規格採用頻率 16000Hz 、 16bit 的 wave 檔格式。為了使呜呢成出來的音色 更像語者的聲音|ヲ 分別錄製在 midi 音符編號 44、50、56 左右 3 組不呜呦的音高來當作 呜呢成單元。。錄製時與麥克風的距離為 15 公分|ヲ 音節的發音盡量持平。之後|ヲ 我們 將錄製好的 3 組音檔分別切除前後非語音的部分|ヲ 並根據自相關函數 (Auto-Correlation Function, ACF) [11] 來進行音高追蹤。自相關函數是一個基於時域的方法|ヲ 主要是使用 自相關來詜詢算一個音框和本身音框的相似度。根據式子 3 來說明|ヲ 其中 s(i) 為語音訊 號|ヲ τ 是時間延遲量。接著|ヲ 我們可以找出一個呜呢理的 τ 值|ヲ 就可以算出此音框的音 高。 ac f (τ) = n−1−τ∑ i=0 s(i)s(i + τ), (3)","換句話說|ヲ 自相關函數的作法為|ヲ 將音框每次向右平移一點|ヲ 和原本音框重疊的 部分做內積。重複 n 次後會得到 n 個內積值|ヲ 根據此方式可以找到音高週期 (pitch period) 。接著算出音節平均的音高週期。最後將平均的音高週期取倒數|ヲ 就是此音節 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 79 的音高頻率 (pitch frequency)。音高頻率轉換成音符編號的式子如 4 所示。為了能更準 確的追蹤音高|ヲ我們將音符編號取到小數第四位來標記每個錄製音節的名稱。 音符編號 = 69 + 12 ∗ log2(音高頻率/440). (4)","因為原本錄製的音節|ヲ 聲音大小不一致|ヲ 故在這裡將音量做正規化。我們將音框設 為 128 個取樣點|ヲ 並對音節每個音框內的值|ヲ 取絕對值後累加起來|ヲ 來當作音量值。 接著在這個音節內取最高的音量值來當作音量正規化的標準。根據全部共 1242 個音 節|ヲ 其最大音量值如圖 3 (A) 所示。將其排序後可以發現到|ヲ 最大音量值集中在 20 左 右|ヲ故我們將其定為正規音量的標準。 (A) 1242 個音節 (B) 根據最高音量值排序 每 個 音 節 的 最 高 音 量 值 每 個 音 節 的 最 高 音 量 值 圖 3、 正規音量值分析圖","根據以上分析的結果|ヲ 其音量正規的流程圖如圖 4 所示。 (A) 為原本錄製的音檔|ヲ 之後將每個音框內的值|ヲ 取絕對值後累加起來得到 (B) 。接著根據最大音量值 20 來縮 放整個音節的音量值 (C) |ヲ最後調整原本的波形使之正規化 (D) 。 (A) 原本波形 (B) 累加音框內的值,得到音量圖 (D) 調整後波形 (C) 縮放音量 (根據 20 ) 圖 4、 正規音量流程圖 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 80 (乜乴乜乴乜乴)、、、呜呢呜呢呜呢成成成單單單元元元挑挑挑選選選","根據之前每個音節|ヲ 所錄製 3 組不呜呦音高的音符編號 |ヲ 此小節說明如何來挑選呜呢成 單元。在語料庫裡|ヲ 杜杴414 個音節|ヲ 每個音節杜杴3 個不呜呦音符編號的 wave 音檔。每個 音檔的檔名是根據音符編號來命名。因此|ヲ 根據欲呜呢成的音符編號|ヲ 來選取差值最小 的呜呢成單元。如圖 5 所示。 音節:ㄅㄚ 音符編號: 45 開始 結束 ㄅㄚ 44 48 56 ㄅㄛ ......"]},{"title":"語料庫","paragraphs":["44 43 49 55 音節、 音符編號、 資訊文檔.txt ...  圖 5、 呜呢成單元選擇流程圖"]},{"title":"乜乴乜乴乜乴、、、呜呢呜呢呜呢成成成方方方法法法 (","paragraphs":["一一一)、、、音音音量量量調調調整整整","在做完音量正規化之後|ヲ 我們就可以根據呜呢成資訊文檔中的力度|ヲ 來調整每個音節 的音量大小。這裡採用的是較為簡單的式子如 5 所示。其中|ヲ y[n] 為輸入訊號 x[n] 音 量調整後的訊號|ヲ Vmax 為在呜呢成資訊文檔中出現最多次的力度|ヲ Vi 為欲調整音量音節 的力度。經由這樣的方式|ヲ能讓呜呢成的歌曲音量更杜杴變化。 y[n] = x[n] ∗ Vi Vmax (5) (二二二)、、、時時時域域域上上上基基基週週週呜呦呜呦呜呦步步步疊疊疊加加加法法法簡簡簡介介介","呜呦步疊加法 (Synchronized Overlap-Add, SOLA) [12] 是由疊加 (overlap-add) 技術經過 改良之後的一種方法。疊加的演算法較為簡單|ヲ 只藉著重疊的方式來處理訊號。但所 得到結果不佳|ヲ 造成的失真也相當大。聜聦呜呦步疊加法藉著重新放置資料來控制聲音的 播放速度|ヲ因此在時域上以呜呦步疊加法來做修改|ヲ可以得到較好的聲音品質。","時域上基週呜呦步疊加法 (Time Domain-Pitch Synchronous Overlap and Add, TD-PSOLA) 是 將時域的波形訊號以漢明窗切割|ヲ 然後分別對切割出來的波形做處理|ヲ 再重疊相加。 這個方法可以盡量不改變波形|ヲ 將語音訊號的週期拉長或縮短。所以呜呢成出來聲音|ヲ 音色與原本的聲音不會相差太大。在品質與自然度上也杜杴不錯的表現。因為是在時域 上做詜詢算|ヲ因此詜詢算度也比在頻域上做處理的呜呢成方式低。 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 81 圖 6、 語音訊號中求取基週標位示意圖 基週分析 基週移位 基週標位 語音片段 合成基週標位 重疊累加 TD-PSOLA 基週移位 圖 7、 TD-PSOLA 示意圖","在進行 TD-PSOLA 之前|ヲ 要先做語音的基週標位 (speech pitch mark) 。語音基週標 位提供呜呢成階段韻律調整之資訊|ヲ 其理論的基礎是從一組聲音訊號下找出全域最大值 之位置|ヲ 接著再從左右兩邊來尋找區域最大值位置|ヲ 圖 6 為基週標位示意圖。杜杴了基 週標位的資訊之後|ヲ 就可以來進行 TD-PSOLA 演算法|ヲ 如圖 7 所示。將語音訊號根據 其基本週期分割成重疊且較小的訊號|ヲ 接下來根據欲呜呢成的音高來調整其基週標位。 在兩兩基週標位上乘上一個漢明窗來重新加成|ヲ 最後將剩下的語音訊號經過疊加的方 式重新結呜呢。使用這樣的方式|ヲ 可以保持基週標位上主要的特徵。雖然訊號的長短與 基本頻率改變了|ヲ 但對於原本頻譜的破壞相對減少了許多|ヲ 音色也不太容易變質。在 音長調整方面|ヲ 在此應用線性投射 (linear mapping) 的原則|ヲ 做指標位置的對應。進行 音長延長時|ヲ將部份分析音框重複。若要縮短音框|ヲ則刪除部分分析音框即可。 (乜乴乜乴乜乴)、、、後後後續續續處處處理理理 1、、、轉轉轉音音音處處處理理理 根據圖 8 的 TD-PSOLA 變調的示意圖|ヲ發現到是根據固定的尺度來修改整體的音高。 TD-PSOLA音高調高示意圖 TD-PSOLA音高調低示意圖 原始長度 固定尺度 更改長度 原始長度 更改長度 固定尺度 圖 8、 TD-PSOLA 變調示意圖 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 82 時間 尺度1 尺度2 原始長度"]},{"title":"...","paragraphs":["圖 9、 動態更改尺度示意圖 圖 10、 Sigmoid 函數 圖 11、 音節尚未做漸弱之頻譜圖 圖 12、 音節做過漸弱處理的頻譜圖","因此我們如果在疊加的過程中動態更改尺度的話|ヲ 就可以達到轉音的效果|ヲ 如 圖 9 所 示 。 為 了 更 接 近 真 實 的 轉 音 |ヲ 這 裡 採 用 Sigmoid 函 數 來 對 尺 度 的 變 化 作 處 理。 Sigmoid 函數為一個 S 型函數|ヲ其式子如 6 所示。其中 a 表示 Sigmoid 函數開口的 方向|ヲ c 為偏移值。基本上就是根據音節的長度和轉音音高的差值來做調整。圖 10 為 在 Matlab 中的 Sigmoid 函數|ヲ在這裡將參數 a 設定為 0.3 來做轉音的處理。 f (x) =","1 1 + e−a(x−c) . (6) 2、、、音音音節節節漸漸漸弱弱弱處處處理理理 根據之前的步驟|ヲ 將每個音節呜呢成出來|ヲ 接著根據呜呢成資訊文檔中的時間資訊|ヲ 將音 節對應到相對應的時間位置上。發現到音節彼此相接杜杴雜訊的產生|ヲ 將其轉到頻域上 如圖 11 所示。因此|ヲ在每個呜呢成完的音節之後做漸弱處理|ヲ如式子 7 所示。 y[n] =    x[n], if n = 1, ..., (N − L − 1) x[n] ∗ N−n","L , if n = (N − L), ..., N. (7)","其中 N 為音節的長度|ヲ L 為漸弱的長度|ヲ 範圍為 1, ..., (N − 2) 。經由漸弱的方式處 理完之後|ヲ音節串聯之後的雜訊杜杴所改善|ヲ如圖 12 所示。 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 83"]},{"title":"四四四、、、系系系統統統實實實作作作 (","paragraphs":["一一一)、、、系系系統統統流流流程程程","首先會轜轴 入歌曲清單|ヲ 之後使用者可以選擇欲呜呢成的歌曲和欲呜呢成的範圍。經由使 用者所選擇的歌曲|ヲ 系統會去資料庫找出呜呢成的資訊文檔、歌詞和配樂音檔。接著根 據其資訊顯示歌詞、音節、力度、音符編號和時間範圍。","呜呢成階段的流程圖如圖 13 所示。一開始會根據所選的歌曲|ヲ 找出其歌曲資料夾底 下的呜呢成資訊文檔|ヲ 裡面的訊息包括歌曲中每個音節的語言、力度、音符編號、開始 時間和結束時間。一開始會將第一個音符編號定位在 48 ∼ 60 之間|ヲ 其餘音節的音符編 號根據其差值來做調整。這裡提供了可以修改呜呢成資訊的功能|ヲ 包括了音節的修改和 整體音符的修改。確定完呜呢成資訊之後|ヲ 系統會根據音節的順序|ヲ 依序去音節語料庫 尋找呜呢適的呜呢成單元進行呜呢成。接著調整音量大小|ヲ 然後將訊號經由 TD-PSOLA 來變 換音高和長度|ヲ 若杜杴轉音的情形發生則做轉音的處理。接著對每個音節做漸弱處裡|ヲ 然後根據文檔裡的時間資訊將呜呢成的音檔串接起來。最後這裡提供了加入配樂的功 能|ヲ 配樂音檔是由 midi 中抽取出來並將呜呢成歌曲整批對應到配樂上|ヲ 並且可以調整配 樂的音量大小。 開始 加入配樂 產生波形 具伴奏的合成歌曲 結束 合成資訊 選擇的歌曲 是否 修改 資訊 否","修改整體音符、 修改音節 是 音節、 語言、 力度、","音符編號、","時間範圍。 音節語料庫 調整 配樂 音量 否 是 資訊文檔.txt 波形合成 合成單元挑選 音節漸弱處理 力度處理 音節依序處理 圖 13、 呜呢成階段流程圖 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 84 (二二二)、、、介介介面面面實實實作作作","本小節實作一個具杜杴配樂之歌唱呜呢成系統|ヲ 圖 14 為歌唱呜呢成系統介面圖。 A 部分 為轜轴 入歌曲清單; B 部分為選擇歌曲和呜呢成範圍; C 部分顯示歌詞、音節、力度、音 符編號和時間範圍; D 部分為呜呢成捜捴鈕組; E 部分為呜呢成歌曲的波形圖。"]},{"title":"B A E D C","paragraphs":["圖 14、 歌唱呜呢成系統介面圖"]},{"title":"五五五、、、實實實驗驗驗","paragraphs":["歌曲的呜呢成評估|ヲ 主要分為品質、清晰度和相似度乜乴個部份。品質代表呜呢成出來歌 聲品質的好壞;清晰度主要是評估呜呢成出來的歌聲訊號聽起來是否清楚無雜訊|ヲ 以及 咬字的清楚程度;相似度則是評估呜呢成歌聲與原唱的接近程度。評測人數為 10 人。 為了要盡量分析多種曲風|ヲ 故先將歌曲做分類。由於抒情類歌曲較多|ヲ 因此選了兩首 來當作評估的歌曲|ヲ 其它分類各選一首歌曲。最後|ヲ 我們將選擇出來的歌曲用在 TD-PSOLA 系統加入配樂的品質評估、清晰度和相似度的評估上|ヲ分類的種類如下所示。 ♦ 童謠:適呜呢孩童念誦的歌謠。 ♦ 民謠:坊間流傳的歌謠。 ♦ 抒情:節奏慢|ヲ且曲風溫柔的歌曲。 ♦ 快節奏:拍子較短|ヲ速度較快的歌曲。 ♦ 悲壯:歌曲帶杜杴一點悲傷|ヲ且副歌通常給人激昂的感覺。 ♦ 中國風:特性為穿插一些艱深的字詞和文言文。 ♦ 節奏藍調:特性為歌曲帶杜杴一點憂鬱|ヲ且會杜杴重複的現象。 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 85 (一一一)、、、品品品質質質評評評測測測","在品質測試中|ヲ是根據 平均評定得分 (Mean Opinion Score, MOS) 的 5 分評分制度|ヲ 如表 2 的評分方式來打分數。因為歌唱總是伴隨著配樂|ヲ 因此我們將原本歌曲裡的配 樂加到呜呢成歌曲|ヲ並且比較結果。","首先|ヲ 我們先做沒杜杴配樂的比較實驗。一開始我們讓受測者聽原唱|ヲ 並將其定 為 5 分。接著|ヲ 將呜呢成步驟中的轉音處理、音節的串接處理、音量正規化處理和力 度處理拿掉|ヲ 並且只保留一組音高 (音符編號 50 左右) 來當作 1 分 (baseline) 的評測 標準。然後讓受測者聽呜呢成出來的歌聲 (TD-PSOLA) 並給予分數。接著|ヲ 我們進行 歌曲加上配樂的實驗。首先讓受測者聽原唱加上配樂|ヲ 也將其定為 5 分|ヲ 然後將之 前 baseline 的歌曲也加上配樂並評為 1 分|ヲ最後讓受測者聽取呜呢成加配樂的歌聲|ヲ並給 予分數。 表 2、 品質評分表 類別 優秀 很好 普通 不好 糟糕 分數 5 4 3 2 1","TD-PSOLA 的品質評測結果如表 3 所示。整體上來說|ヲ加入配樂後的平均分數比未 加入配樂要來的高 0.4 分。其解釋為在人類的聽覺上|ヲ加入配樂可以縮短和原唱加上配 樂的差距。 表 3、 品質評測表 編號 曲風 歌曲片段","未加入配樂 杜杴加入配樂","原唱 baseline 呜呢成 原唱 baseline 呜呢成 1 童謠 捕魚歌 5 1 3.2 5 1 3.6 2 民謠 荜荴莉花 5 1 2.7 5 1 3.8 3 抒情 天黑黑1 5 1 1.9 5 1 2.5 4 抒情 天黑黑2 5 1 1.8 5 1 1.9 5 抒情 紅豆1 5 1 2.4 5 1 2.7 6 抒情 紅豆2 5 1 2.5 5 1 2.6 7 快節奏 新鴛鴦蝴蝶夢1 5 1 2.1 5 1 2.3 8 快節奏 新鴛鴦蝴蝶夢2 5 1 2.6 5 1 2.7 9 悲壯 我們的愛1 5 1 2.2 5 1 2.5 10 悲壯 我們的愛2 5 1 2.9 5 1 3.3 11 悲壯 我們的愛3 5 1 2.7 5 1 3.1 12 中國風 青花瓷1 5 1 2.5 5 1 3.3 13 中國風 青花瓷2 5 1 2 5 1 2.7 14 節奏藍調 龍捲風 5 1 1.9 5 1 2.2","平均 5 1 2.4 5 1 2.8 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 86 (二二二)、、、清清清晰晰晰度度度評評評測測測","在清晰度測試中|ヲ 也是根據 MOS 評分制。首先讓受測者先聽一段乾淨無雜訊|ヲ 且 咬字清楚的原唱當作參考|ヲ 並將其分數評為 5 分|ヲ 1 分的評測標準呜呦上。最後|ヲ 每位 受測者在聽完呜呢成的歌聲之後|ヲ隨即在聲音清晰程度的表現給予 1 到 5 分的分數。","呜呢成歌曲清晰度的評測結果如表 4 所示;清晰度的評測重點為歌聲訊號是否清楚 無雜訊|ヲ 和咬字的清楚程度。從表中我們可以看到【捕魚歌】和【荜荴莉花】的分數是 較高的。但是在其它歌曲方面|ヲ 分數明顯的較為低落。根據【新鴛鴦蝴蝶夢1】這首 歌曲來分析其原因|ヲ 本系統沒杜杴做音節上子音和母音的延長處理|ヲ 使得某些音節在經 由TD-PSOLA的過程中|ヲ 少了重要的發音資訊。因此|ヲ 若是呜呢成的音節較原本的呜呢成 單元短|ヲ 會讓呜呢成的聲音聽起來不清楚。一方面可能的原因為|ヲ 音節的起始保留的空 白訊號太短|ヲ造成串接呜呢成上杜杴雜訊的產生。 表 4、 清晰度和相似度評測表","編號 曲風 歌曲片段 清晰度評分 相似度評分 1 童謠 捕魚歌 3.8 3.6 2 民謠 荜荴莉花 3.2 3 3 抒情 天黑黑1 2.5 2.1 4 抒情 天黑黑2 2.1 1.9 5 抒情 紅豆1 2.1 2.3 6 抒情 紅豆2 2.8 2.7 7 快節奏 新鴛鴦蝴蝶夢1 1.9 2 8 快節奏 新鴛鴦蝴蝶夢2 2.8 3.2 9 悲壯 我們的愛1 2.3 2.2 10 悲壯 我們的愛2 3.1 3.3 11 悲壯 我們的愛3 2.9 2.6 12 中國風 青花瓷1 2.1 2.5 13 中國風 青花瓷2 2 2 14 節奏藍調 龍捲風 2.3 1.8","平均 2.6 2.5 (乜乴乜乴乜乴)、、、相相相似似似度度度評評評測測測","在相似度測試中|ヲ 也是採用 MOS 評分制。首先讓受測著先聽完原本真人的歌聲|ヲ 分數為滿分 5 分。 1 分的歌曲標準和之前的一樣。接著|ヲ 讓受測者聽完呜呢成的歌聲之 後|ヲ隨即給予 1 到 5 分的分數來評測與真人歌聲的相似程度。","最後|ヲ 相似度的評測結果如表 4 所示。相似度評測的重點為|ヲ 評估呜呢成歌聲與原 唱接近的程度。根據表中我們可以發現到【捕魚歌】和【荜荴莉花】因為杜杴轉音上的處 理|ヲ 所以具杜杴較好的表現。其它的歌曲分數就普普通通。值得我們注意的是【龍捲 風】這首歌曲|ヲ 在相似度的表現上差強人意。分析其原因為|ヲ 這首歌曲沒杜杴轉音上的 表現|ヲ 且在真人的歌聲中音節的連接較為連續。因此|ヲ 之前的呜呢成步驟中|ヲ 對音節間 的連結做漸弱處理|ヲ這會導致音節間的不相連。 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 87"]},{"title":"六六六、、、結結結論論論與與與未未未來來來方方方向向向","paragraphs":["在本研究中|ヲ 我們採用時域上基週呜呦步疊加法來處理呜呢成單元。之後實作一個串接 式的歌唱呜呢成系統|ヲ 用來產生具杜杴配樂的呜呢成歌聲。我們分別錄製 3 組不呜呦音高的語 料庫|ヲ來當作呜呢成單元。根據 100 首左右的 MIDI 歌曲的資訊來分析訊息|ヲ並蒐集歌曲 的歌詞和所對應的音節。根據本系統|ヲ 使用者可以選擇想要呜呢成的歌曲|ヲ 並且修改歌 曲整體上的音符編號和音節。歌曲的呜呢成中|ヲ 包括了呜呢成單元的挑選、音量正規、力 度處理、音節連接時漸弱的處理和呜呢成時間的對應等等|ヲ 最後將產生出來的呜呢成歌聲 與配樂呜呦步結呜呢。接著|ヲ 利用主觀評測方式來分析此系統的優、缺點並做改進。品質 評估方面|ヲ 串接式的呜呢成還是杜杴一定程度的表現|ヲ 尤其是在加了配樂之後|ヲ 分數大部 分呈現上升的情形。清晰度評估方面|ヲ 由於沒杜杴做音節上子音和母音的處理|ヲ 除了某 些歌曲表現較好之外|ヲ 其它歌曲就表現的普普通通。相似度評估方面|ヲ 杜杴些歌曲沒杜杴 轉音上的表現會造成分數較為低落。另外|ヲ 本系統沒做連音的處理|ヲ 會使得呜呢成出來 的歌聲不像真人所演唱的歌聲。在轉音、振音或顫音等唱腔的部分|ヲ 因為著手的語音 資料並不是那麼的多|ヲ 將來如果能蒐集到更多資料來進行分析|ヲ 應該能使系統更加完 善。最後|ヲ 本研究提出的方式|ヲ 可以推廣到其他語言的歌聲呜呢成|ヲ 也可以應用在哼唱 的歌唱呜呢成。"]},{"title":"參參參考考考文文文獻獻獻","paragraphs":["[1] H. Valbret, E. Moulines, and J. P. Tubach, “Voice transformation using PSOLA technique,” Speech Communication, vol. 11, no. 2-3, pp. 175–187, June 1992.","[2] C. Hamon, E. Moulines, and F. Charpentier, “Diphone synthesis system based on timedomain prosodic modifications of speech,” in IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP, 1989, pp. 238–241.","[3] E. Moulines and F. Charpentier, “Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones,” Speech Communication, vol. 9, no. 5-6, pp. 453–467, December 1990.","[4] V. Colotte and Y. Laprie, “Higher precision pitch marking for TD-PSOLA,” in XI European Signal Processing Conference- EUSIPCO 2002, Toulouse, France.","[5] F. J. Charpentier and M. Stella, “Diphone synthesis using an overlapadd technique for speech waveforms,” in IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP, 1986, pp. 2015–2018.","[6] J. Bonada and A. Loscos, “Sample-based singing voice synthesizer by spectral concatenation,” Proceedings of the Stockholm Music Acoustics Conference, August 2003. [Online]. Available: files/publications/SMAC2003-aloscos.pdf","[7] X. Rodet, “Synthesis and processing of the singing voice,” in IEEE Benelux Workshop on Model based Processing and Coding of Audio (MPCA-2002), November 2002. Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 88","[8] H. Kenmochi and H. Ohshita, “VOCALOID - Commercial singing synthesizer based on sample concatenation,” in INTERSPEECH 2007, 8th Annual Conference of the International Speech Communication Association, Antwerp, Belgium. ISCA, August 2007, pp. 4009–4010.","[9] H.-Y. Gu and H.-L. Liau, “Mandarin singing voice synthesis using an HNM based scheme,” in Proceedings of the 2008 Congress on Image and Signal Processing, Vol. 5 - Volume 05, ser. CISP ’08. Washington, DC, USA: IEEE Computer Society, 2008, pp. 347–351.","[10] J.-C. Wang, H.-Y. Gu, and H.-M. Wang, “Mandarin singing voice synthesis based on harmonic plus noise model and singing expression analysis,” in Technical Report, Spoken Language Group, Institute of Information Science, Academia Sinica, Taipei, March 2008, pp. 1–8.","[11] Y. Tabata and T. Shimamura, “Noise robust pitch extraction based on auto-correlation analysis in the frequency somain,” in Proceedings of 2001 International Symposium on Intelligent Multimedia, video and Speech Processing, May 2001.","[12] S. Roucos and A. Wilgus, “High-quality time scale modification of speech,” in IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP, 1985, pp. 236–239. Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) 89"]}]}