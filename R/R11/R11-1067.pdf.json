{"sections":[{"title":"","paragraphs":["Proceedings of Recent Advances in Natural Language Processing, pages 487–494, Hissar, Bulgaria, 12-14 September 2011."]},{"title":"Parallel Suffix Arrays for Linguistic Pattern Search Johannes Goller Macmillan, Digital Science Chiyoda Bldg., 2-37 Ichigayatamachi Shinjuku-ku, Tokyo jogojapan@gmail.com Abstract","paragraphs":["The paper presents the results of an analysis of the merits and problems of using suffix arrays as an index data structure for annotated natural-language corpora. It shows how multiple suffix arrays can be combined to represent layers of annotation, and how this enables matches for complex linguistic patterns to be identified in the corpus quickly and, for a large subclass of patterns, with greater theoretical efficiency than alternative approaches. The results reported include construction times and retrieval times for an annotated corpus of 1.9 billion characters in length, and a range of example patterns of varying complexity."]},{"title":"1 Introduction","paragraphs":["Empirical linguistic studies require access to large corpora of text, and they benefit greatly when the text is stored in a form that enables the efficient retrieval of specific elements, such as sentences that match a pattern defined by a linguist. The size and contents of the corpus, the type and structure of its annotations, and the form of patterns involved vary greatly; the present paper deals with the requirements of only a subset of linguistic studies, which are characterized as follows:","• The corpus is large (hundreds of millions of words), but not extremely large (hundreds of millions of documents);","• Annotations exist in any number of layers, for example a layer of part-of-speech (POS) annotations and a layer of semantic role labels, but the annotations on each individual layer are non-overlapping and non-ambiguous;","• A pattern is essentially a regular expression, made up of literals (to be matched against the text), annotations (each with a specification of the layer it is expected to be found in) and wildcard elements (“gaps”);","• The retrieval results are expected to be delivered within seconds or minutes (that is, not necessarily as fast as web search), and to be comprehensive (that is, to contain all matches, not only the top-N defined by some relevancy ranking);","• New patterns are generated constantly, perhaps by many different users or automated programs in parallel, while the text is largely static.","Corpus search engines that respond to a similar, albeit not identical, set of requirements include the Corpus Workbench1",", WebCorp Linguist’s Search Engine2","and Manatee/Bonito (Rychlý, 2007). The implementation of all of these systems relies on the principle of inverted files, which is the main alternative to the suffix arrays presented here3",". Both approaches are described and briefly compared in section 2, a direct comparison is also available in (Puglisi et al., 2006). Sections 3 and 4 introduce the concept of parallel suffix arrays and describe how it enables annotations and complex pattern search, including patterns equivalent to finite state machines. Section 5 describes results obtained using an actual implementation of parallel suffix arrays."]},{"title":"2 The Two Main Approaches to Indexing 2.1 Inverted Files","paragraphs":["The concept of inverted files requires the text to","be tokenized, that is, to be segmented into tokens 1 http://cwb.sourceforge.net/ 2 http://www.webcorp.org.uk/ 3 Suffix arrays are frequently used for n-gram analyses","(e.g. Yamamoto and Church (1998)), but without the ability","to process complex search patterns. 487 (usually roughly equivalent to words). The index consists of a searchable dictionary of the tokens (e.g. a hash table or sorted list), and a link connect-ing each token with its inverted list, i.e. the list of positions where the token is found (where the position of a token is defined as the token offset, i.e. the number of tokens to its left).","The match result for a search pattern that consists of a single token t is then readily retrieved by determining the dictionary entry corresponding to t (which if hashing is used typically takes O(|t|) time, where |t| is the length of t in characters) and returning the entire inverted list It. The length of the list corresponds to the number of occurrences of t, occ(t). If the pattern is a sequence of tokens P := t1, . . . , tr, the retrieval strategy is to determine all inverted lists in O(|t1|) + . . . + |tr|) time, to then identify the inverted list of the least frequent token, i.e. Itμ such that μ = argmini occ(ti), and to finally check for each of the positions p ∈ Itμ whether it lies in a match for the entire pattern P . That requires, for each p a look-up in the remaining r − 1 inverted lists, specifically, for each 1 ≤ k < μ, a look-up to check whether p − k ∈ Itμ−k , and for each 1 ≤ k < (r − μ) to check whether p + k ∈ Itμ+k . Since inverted lists are usually stored as sorted lists of integers, a look-up in Iti requires O(log occ(ti)) time, hence the total time taken to identify all matches for P is O (∑ k |ti| + occ(tμ) ∑ k̸=μ log occ(tk)) (1) Storing annotations in the index is straightforward: Modify the inverted lists so as to store positions as character offsets (rather than token offsets), and the length of t in characters along with each occurrence of t. Annotations can then be indexed in the same way as ordinary tokens, with character offset and length, and the procedure above can be modified so as to take into account the length of each ti when computing the positions of adjacent tokens. This enables patterns using a mix of text and annotations, i.e. with some of the ti referring to text, others to annotation. The time bound of (1) is unchanged. 2.2 Suffix Arrays A suffix array is any representation of the lexicographically sorted list of all suffixes of a text, where suffix is defined as any substring beginning 1 2 3 4 5 6 7 8 9"]},{"title":"a b x a b d a e $ lcp= a b d a e $ a b x a b d a e $ a e $ b d a e $ b x a b d a e $ d a e $ e $ x a b d a e $ T= SA= 9 4 1 7 5 2 6 8 3 x $ d a a b a bebwt= 0 0 2 1 0 1 0 0 0 $","paragraphs":["Figure 1: Suffix array SA for the string T =abxabdae$, along with auxiliary data structures bwt, lcp and “brackets” indicating the match ranges for substrings ab, a and b. somewhere in the text and ending at the end of the text, i.e. there are n suffixes in a text of lengthn. Rather than storing copies of all the substrings, the suffix array is usually represented as a list of n integers, each indicating the starting position of a suffix. An example of this is shown in Fig. 1: The suffix array itself consists only of the integer list SA; the lower part of Fig. 1 shows the strings corresponding to each position, written vertically. Suffix arrays have an important property related to substring searches: Given a text T , its suffix array SA and a search pattern P , the set of starting positions of matches for P in T forms a continuous range in SA, as each match is the initial part of a suffix of T . Because of the lexicographical sort-ing, these suffixes must be adjacent to each other in the suffix array. For example, the set of matches for substring ab in Fig. 1 is the range [2; 3] of SA (corresponding to positions 4 and 1 of T ). This shall be called the range property of suffix arrays.","Recent improvements in search algorithms for suffix arrays, cf. Navarro and Mäkinen (2007), make it possible to identify the match range for P in O(|P |) time4",", and since no tokenization is required, recombining matches for individual tokens as in the case of inverted files is unnecessary. However, it is impossible to store annotation-related information in the suffix array. The follow-","4","Strictly speaking, the time is bound by O(|P |(1 + log |Σ|/ log log n)), where |Σ| is the size of the alphabet. However that is asymptotically equivalent to O(|P |) when the alphabet is as much smaller than the text as it is the case for large-scale natural-language corpus search. See Navarro and Mäkinen (2007, 42) for details. 488 ing two sections describe a new concept, parallel suffix arrays, and how it enables annotations and more powerful search patterns."]},{"title":"3 Parallel Suffix Arrays","paragraphs":["The first step is to allow annotations to enter the index. In the following it is assumed that a text T ∈ Σ∗","of length n is given, and one layer of q annotations A = ((a1, p1, l1), (a2, p2, l2), . . . , (aq, pq, lq)) such that each annotation (ai, pi, li) consists of a label ai ∈ Σ∗",", a starting position p","i < n and a length li. pi indicates where in T the substring annotated with ai starts, li indicates the number of T -characters it covers. For example, given T = is but a dream within a dream and POS-annotations V, Conj etc., the annotation layer might look like this: A = ((V, 1, 2), (Conj, 4, 3), (Det, 8, 1), (N, 10, 5), (Prep, 16, 6), (Det, 23, 1), (N, 25, 5)) . There are two ways to bring these annotations into the suffix-array-based index forT :","Method 1: Single-integer annotations. Three steps need to be performed: (1) Each distinct annotation label is mapped to a unique integer (e.g. using a hash table), that is, a new annotation alphabet Λ is created, in which each annotation is represented as one integer. (2) An extra integer is introduced in Λ, below represented by ∅, which is used as a dummy annotation for all areas of T that are not covered by any element of A (in the example above, this applies to the space characters between words). (3) A is replaced by a string A′","∈ Λ∗","containing the new annotation symbols in the order of the T -positions they refer to, and a bitvector BT ↔A","of length n indicating the starting positions of annotations relative to T . The example above now becomes: A′ =1∅2∅3∅4∅5∅3∅4","BT ↔A =10110011110000110000011110000 , where V has been mapped to 1, Conj to 2, and so forth. The next step is to construct a suffix array SAA′ from the Λ-string A′",", along with auxiliary data structures required for fast searches, cf. Navarro and Mäkinen (2007). That enables fast searches for sequences consisting solely of annotations. It will later be shown how the bitvector is used to accomplish searches for mixed patterns, that is, patterns that contain both, T -sequences and A-sequences.","Method 2: Complex annotations. In some situations annotations are themselves complex and one would like to be able to search inside them, rather than mapping them to atomic integers. This is accomplished by appending a new character ♯ /∈ Σ to every label ai as a separation mark, and then concatenating all labels to a new string A′",":","A′ = V♯Conj♯Det♯N♯Prep♯Det♯N♯","In addition, two bitvectors BT ↔A","and BA↔A","are","defined, the former in the same way as in method","1, while the latter is of length |A′","| and has a 1","wherever a new annotation starts in A′",":","BA↔A = 101000010001010000100010 Again, a suffix arraySAA′ for A′","enables search-ing for substrings of annotations as well as sequences of annotations. The ♯-symbols prevent undesired matches across annotation-boundaries.","How the bitvectors are used for mixed T /A′ patterns. Both the bitvector of the first, and the bitvectors of the second method need to undergo an indexing process, during which a rank index and a select index are generated for each bitvector, defined as follows: LetB be a bitvector of length b and i, j < b, then rankB(i) := the total number of 1s in B[1..i] selectB(j) := i s.t. there are j 1s in B[1..i] . Using techniques described by Jacobson (1989), it is possible to construct, in O(b) time, data structures that implement these functions, such that a lookup can be performed in O(1) time and no more than b + o(b) bits of space are consumed in total (including the bitvector itself). In the case of single-integer annotations (method 1), rankBT↔A and selectBT↔A are constructed; in the case of complex annotations, these and rankBA↔A and selectBA↔A are constructed. In addition, in both cases the inverse suffix arrays for T and A′","must be computed and stored in memory: Given a suffix array SA, its inverse is defined as invSA[j] := i such that SA[i] = j , 489 and invSA can be generated from SA in linear time. To see how these data structures work to-gether, consider a mixed pattern σλ, where σ ∈ Σ∗","is a substring match against T and λ is a substring match against the annotations. We first as-sume that method 1 was used, hence that λ ∈ Λ∗ is a sequence of annotations mapped to integers. The next step is to search the suffix arrays and determine the match ranges (lσ, rσ) for σ in SAT and (lλ, rλ) for λ in SAA′. Clearly, the number of occurrences of σ in T is occ(σ) = rσ − lσ, the number of matches for λ is occ(λ) = rλ − lλ. We must now check, for each σ-match, whether it is followed by a λ-match. Let lσ ≤ x < rσ one of the σ-matches. It begins at position p = SAT [x] of T and it is |σ| characters in length. Hence it is followed by a λ-match if and only if an A-annotation starts at p + |σ| and that annotation corresponds to a λ-match in A′",", which is the case iff the corresponding position in A′","is a suffix in the match range (lλ, rλ). We therefore verify, for the candidate offset q := p + |σ|:","A-element exists: BT ↔A","[q] = 1 (2)","Location in A′",": q′",":= rankBT↔A(q) (3)","Is q′ a λ-match: lλ ≤ invSAA[q′","] < rλ (4) If SA and invSA are available for random access, all of the above can be tested in O(1) time, hence it takes O( occ(σ)) time to compute the set of σλ-matches from the two individual match ranges. Moreover, the procedure works in the reverse direction, too, starting from the λ-matches and determining those among them that are preceded by a σ-match (using select instead of rank; the time consumption becomes O( occ(λ))). Hence it is possible to choose the matching direction according to whichever part of the pattern has fewer matches, i.e. let occμ := min( occ(σ), occ(λ)), then the match combination can be computed in O( occμ) time.","Without giving a detailed proof, we note that this result can be extended to general sequential patterns t1 · · · tr, ti ∈ Σ∗",", Λ∗",": The match combination time depends only on the least frequent (i.e. most specific) element tμ, that is, including the time taken to determine the match range for each ti, the total asymptotic time is O (∑ k","|tk| + occ(tμ)) , (5) which is obviously better than with inverted files, where the match combination time depends on the frequency of all elements, as shown in (1). This shall be called the least-frequency property of parallel suffix arrays5",". It should also be noted that for subsequences te · · · tf such that all elements refer to the same layer, i.e. ∀ti ∈ Σ∗","or ∀ti ∈ Λ∗",", no match combination is required at all, since the suffix arrays do not rely on tokenization, hence t′",":= t","e · · · tf can be searched for as a single element in O(|t′","|) time.","Moreover, it is possible to define gaps of fixed length (measured in terms of number of T -characters, or alternatively, as number of A-annotations) between the individual elements, e.g. a pattern like σ","A:3","▷◁ λ, indicating a distance of 3 arbitrarily A-annotated elements between σ and λ, can be evaluated in the same asymptotic time (because the length l of the three wildcard elements following σ can be computed for each match candidate using rank and select, and then added to the candidate position, q := p + |σ| + l used in (2) and (3) before the match range check for λ).","The property also holds when complex annotations and method 2 are used, at least when search-ing for prefixes of annotations, rather than arbitrary substrings of them. The distance calculations must then be made using the rank/select indexes for BT ↔A","to map positions between T and A, and those for BA↔A","to compute the string length of annotations in A′",". If arbitrary substring matching in annotations is required, the match process is delayed by a factor related to the length of λ, as every position inside the annotation must be checked for being a possible match continuation."]},{"title":"4 Complex Patterns 4.1 General patterns Multiple annotation layers","paragraphs":["It is straightforward to add further layers of annotation, e.g. semantic or morphological information, constituent classes etc. Each layer A1, A2, . . . is represented by an annotation string A′","i, a bitvector BT ↔Ai",", and BAi↔Ai","if it is complex. Direct mappings between layers Ai, Aj are unnecessary, as they can be emulated using BT ↔Ai","and BT ↔Aj",". Hence, total space consumption of the index grows in an additive manner as layers are added. 5 The name parallel suffix arrays refers to the view of SAT","and SAA′","as parallel layers, both related to the same under-","lying text. 490 Branching patterns An important step towards more powerful search patterns is the ability to process branching patterns, that is, patterns that specify multiple alternatives. This shall be denoted using a new operator ⊕, such that a pattern ⊕(e1, e2, . . . , em) is defined as matching all substrings of T that match any of the subexpressions ei. If all ei are distinct Σ-strings, the individual match sets for each ei are disjoint, and the final result corresponds to the union set of the match ranges for the ei.","But if some of the ei refer to annotations or are themselves complex, i.e. sequential patterns or ⊕- expressions, the individual match sets might not be disjoint, causing the end result to contain duplicate matches, which makes it difficult to read and might cause frequency counts to be wrong. Hence, duplicate elements must be detected and removed from the individual match sets. This can be done either by creating a searchable result set representation, such as a hash table or tree, and in-serting the matches one by one, rejecting matches that were inserted before; or, it can be done by creating a simpler, non-searchable result list and checking for each match for any ei whether it is also a match for one of the other ej, j < i. Both these methods are available when inverted files are used instead of suffix arrays, too, but if the second method is used, suffix arrays often have an advantage because the member check for the ej, if it is a Σ- or Λ-string, involves only an O(1) range check, whereas it would be logarithmic in an inverted file. Sequences of complex elements In section 3, the least-frequency property was established for sequential patterns, consisting of atomic elements and fixed-length-gaps, i.e. expressions like e1 Q 1:x1 ▷◁ e2 Q 2:x2 ▷◁ · · · Q m−1:xm−1","▷◁ em , where ei ∈ Σ∗",", Λ∗","; Qi ∈ {Σ, Λ}; xi integers. For even more powerful search patterns, it is important that the above can also be processed if the ei are themselves complex, i.e. sequences or branching elements. This is indeed possible; the pattern then becomes a graph, and determining the least-frequent element, at which the matching should start, becomes a non-trivial problem. The number of matches of a sequence or branching subelement cannot be calculated accurately before the entire matching process has finished, but an upper bound can be determined: For a sequence, it is the frequency of its least-frequent subelement, for a branching element it is the sum of the frequencies of its branches. Based on this, it is possible to recursively determine the estimated best atomic subelement of the graph for the match combination process to begin. Once it has begun, the least-frequency property takes full effect during the processing of sequential substructures, and the range property accelerates the duplicate-checks where branching substructures are involved, as described above. Both is not true of inverted files, hence the theoretical performance of parallel suffix arrays is, generally, superior even for the most complex patterns. Iteration Another useful operator in powerful linguistic search patterns is the iteration operator, which is denoted by ⊛(e) for any atomic or complex expression e. It corresponds to a sequence e T:0 ▷◁ e T:0 ▷◁ · · · T:0 ▷◁ e of undetermined length. Since all its elements are identical, the least-frequency property is preserved, even if the matching simply starts on the left end, or alternatively on the right end, and continues as long as new matches are found. There-fore, iteration elements can itself become part of complex patterns, and the three operations","Q:x","▷◁ , ⊕ and ⊛ establish a pattern syntax with the power of regular expressions, over an annotated text with any number of annotation layers, and including fixed-length gaps (wildcards). 4.2 Gap-filling In order to analyse linguistic patterns in specific contexts, it is desirable that not only substrings matching the entire pattern are identified, but that selected parts of the patterns, especially matches for gaps or annotation elements, can be extracted and separately returned as frequency lists. For example, if one wants to investigate the syntactic environment of “discussion”, i.e. usages like “discussion on”, “discussion with” etc., one might use a pattern like","discussionT:0 ▷◁ <Prep><Det> } {{ }","(∗) T:0 ▷◁ <N> and then obtain a frequency list of the content that matched the part marked by (∗). Parallel suf-491 fix arrays are particularly well-suited for this purpose: Firstly, it is easy to keep track of the beginning and ending offsets of the desired subexpressions during the matching processing; secondly, frequency lists are easy to generate: Given starting positions p1, p2 of two matches for (∗), a comparison of invSA[p1] and invSA[p2] in O(1) time suffices to determine their lexicographic order. Once the matches are in lexicographic order, identifying duplicates and counting the frequencies of distinct strings is easy. 4.3 Look-betweens and negation Another feature related to gaps is the ability to define some of their content partially. The three types of patterns below are examples of this: (a) e1 Q:x:y ▷◁ e2 (b) e1 Q:x:y ▷◁ [?e3]e2 (c) e1 Q:x:y ▷◁ [!e3]e2 (a) represents a gap of length x ≤ l ≤ y elements on the annotation level Q; (b) requires that somewhere inside the gap there must be a match for e3 (positive look-between); (c) means there must be no match for e3 in the gap (negative look-between). Without going into further detail, it should be noted that these types of patterns can be incorporated into the matching process using match combination techniques similar to those described in section 3. There is, however, a specific disadvantage of suffix arrays when processing variable-length gaps e1","Q:x:y","▷◁ e2: Assuming that occ(e1) ≤ occ(e2), let (p, l) be the position and length of a match for e1. Let (qi, pi, li) be a Q-annotation located at pi = p + l, and (qi+1, pi+1, li+1), . . . , (qi+y, pi+y, li+y) the following y Q-annotations. Then we need to check whether a match for e2 is found at any of the positions pi+x, . . . , pi+y, which requires δ := y − x + 1 look-ups in invSAQ. Hence, the gap length variability δ becomes a factor in the time complexity of the match combination process. That is not the case when inverted files are used: It then suffices to check for matches atpi+x and pi+y stored in the inverted list for e2. Since the inverted list is sorted, all other relevant matches must be located between these too and can be retrieved in one step."]},{"title":"5 Implementation and Results 5.1 Index construction and operation","paragraphs":["The system has been implemented as a C++ program that takes as input a file containing the text T with three layers of annotations in XML: APOS (POS-annotations); Alem (baseforms of words, indexed using method 1 (see section 3); AcPOS (POS along with morphological information; indexed using method 2).","The index construction is performed by first establishing the parallel layers and bitvectors and then creating SAQ, invSAQ and, as an auxiliary data structure used to enable faster suffix array search, the wavelet tree WVTQ (Grossi et al., 2003) for each layer Q ∈ {T, APOS, Alem, AcPOS}. For the construction of SAQ, a multi-threaded version of the DC-algorithm (Kärkkäinen et al., 2006) is used, invSAQ is computed in a trivial way in one pass over SAQ, and the wavelet tree WVTQ is constructed using a simple multi-threaded method (for details see Goller (2011)). The only highly time-consuming steps are the constructions of SAQ and WVTQ. Their running times are given in Table 1.","For efficient pattern search, it is necessary to keep all data structures in main memory at all times. Compression methods for SA, invSA and WVT are available, cf. Navarro and Mäkinen (2007), but unfortunately, using them causes the time complexity of pattern search to be increased by a factor of Ω(log n), eliminating the advantage it has over inverted files. As a result, using parallel suffix arrays requires a large amount of RAM. The implementation used to obtain the results described above was found to require ≈ (0.06 · N )/1024 MB for a corpus of N characters with the three annotation layers described above. Hence, on a 32-bit desktop computer with about 3 GB of memory available, a corpus of ≈ 52 million characters (≈ 7 million words) can be processed efficiently. Therefore, although optimizing the implementation’s use of RAM is certainly possible, it is quite clear that possibilities to use the described approach in linguistic practice depend on whether servers with sufficiently large RAM are available, and affordable. 5.2 Pattern Search Table 2 presents response times for various kinds of patterns and illustrates, as expected, that the performance varies greatly depending on the complexity of the pattern; more specifically, it de-492 Threads Used Hard drive Available RAM SAT WVTT SAPOS WVTPOS SAlem WVTlem SAcPOS WVTcPOS A 10 NFS 128 GB 3:17 3:48 1:30 1:13 1:27 11:46 3:03 2:03 B 20 Direct 512 GB 2:00 3:06 0:50 1:05 0:49 8:05 2:00 1:57 C 45 Direct 512 GB 2:00 2:37 0:51 0:54 0:55 6:16 1:49 1:43 Table 1: Construction times on three different system configurations. The text is 1.97 billion characters (375 million words) in length and contains approx. 27,000 distinct baseforms of words. Test A was performed on a server with AMD-Opteron CPUs 8356 (total 16 threads) and the hard drive mounted through NFS, tests B and C were conducted on a server with Intel Xeon X7560 processors (total 64 threads) and the hard drive installed locally. Time durations are given in the format h:mm.","Pattern #results Search time (ms)","Extraction","time","(ms) P1 millions 5,857 106 200 P2 thousands of 7,526 74 399 P3 #thousand# of 7,696 168 343 P4 discussion⟨IN⟩⟨NN⟩ 1,296 213 80 P5 discussion$pr$$n$ 1,894 372 118 P6 discussion[$pr$$n$] 1,894 530 111","P7 #preparation#APOS:0:2 ▷◁ ⟨IN⟩T:0","▷◁ ⊕ (⟨NN⟩, ⟨NNS⟩) 752 191 28","P8 ⟨JJ⟩⟨NN⟩⟨NN⟩APOS:0:2 ▷◁ ⟨IN⟩T:0","▷◁ ⊕ (⟨NN⟩, ⟨NNS⟩) 13,229 4,065 621","P9 ⟨NN⟩⟨NN⟩APOS:0:2 ▷◁ ⟨IN⟩T:0","▷◁ ⊕ (⟨NN⟩, ⟨NNS⟩) 129,723 36,711 5,178 Table 2: Pattern processing times using hardware configuration A (see Table 1). Search time (identifying the set of match positions) and extraction time (extracting matches, but not including result printing). #..#-elements refer to Alem, ⟨..⟩ to APOS, $..$ to AcPOS. Elements enclosed in [..] are marked for separate extraction and frequency counting (gap-filling). Times are in milliseconds. 493 pends on the “most specific atomic element” of the pattern. An element is atomic, if it refers to one layer (text or annotation) exclusively and contains no gaps. For example, the POS sequence ⟨JJ⟩⟨NN⟩⟨NN⟩ in P8, which would consist of three tokens in a standard inverted-file configuration, is atomic, as all three sub-elements refer to the same layer APOS and can therefore be matched against SAAPOS in a single step. In accordance with the least-frequency property, the overall response time for the entire pattern depends on the number of occurrences of the most specific atomic element, which in this case is ⟨JJ⟩⟨NN⟩⟨NN⟩, rather than such high-frequency individual tokens as ⟨JJ⟩ or ⟨NN⟩. If the most specific atom is modified to be less specific, as in P9, the search time is increased by a factor of ≈ 9. 5.3 Discussion and Conclusion The approach presented appears to be effective, especially for complex patterns that contain at least one relatively specific element. It provides efficient solutions for special tasks like context-specific pattern matching and frequency-list generation (described as gap-filling above), and it does not require any kind of tokenization, neither on the level of the main text, nor on the level of annotations and is hence suitable for corpora that involve annotations on the morpheme level, or across token boundaries, as well as for languages or writing systems that are hard to tokenize. Its biggest disadvantage is its high memory consumption, which however is likely to be less important in the future, as ever larger RAM hardware becomes available at increasingly low cost.","Although this has not been discussed in detail in previous sections, it is important to point out that the approach is not suitable in situations that call for frequent updates to the text or the annotations. The index structures described above, especially rank and select indexes for bit vectors as well as the suffix arrays themselves cannot be updated efficiently. Although data structures for suffix arrays that can be searched as well as dynamically updated are known, cf. (Russo et al., 2008; González and Navarro, 2008), using them would cause delays in the order of O(log n) (where n is the length of the text) in lookups of select, rank and SA, hence rendering the system considerably less efficient the corresponding version of an inverted file based system.","There are plans to release an open-source version of the implementation used for the tests described above as a corpus exploration tool for linguists before the end of the year."]},{"title":"References","paragraphs":["Johannes Goller. 2011. Exploring text corpora using index structures. PhD thesis. To appear, Centrum für Informations- und Sprachverarbeitung, Ludwig-Maximilians-Universität München.","Rodrigo González and Gonzalo Navarro. 2008. Improved dynamic rank-select entropy-bound structures. In LNCS 4957/2008, LATIN 2008: Theoretical Informatics, pages 374–386, Berlin / Heidelberg. Springer.","Roberto Grossi, Ankur Gupta, and Jeffrey Scott Vitter. 2003. High-order entropy-compressed text indexes. In SODA ’03: Proceedings of the 14th an-nual ACM-SIAM symposium on discrete algorithms, pages 841–850, Philadelphia, PA, USA. Society for Industrial and Applied Mathematics.","Guy Jacobson. 1989. Space-efficient static trees and graphs. In Proc. of the 30th IEEE Symposium on Foundations of Computer Science (FOCS), pages 549–554.","Juha Kärkkäinen, Peter Sanders, and Stefan Burkhardt. 2006. Linear work suffix array construction. J. ACM, 53(6):918–936.","Gonzalo Navarro and Veli Mäkinen. 2007. Compressed full-text indexes. ACM Comput. Surv., 39(1):2.","Simon Puglisi, W. Smyth, and Andrew Turpin. 2006. Inverted files versus suffix arrays for locating patterns in primary memory. In Fabio Crestani, Paolo Ferragina, and Mark Sanderson, editors, String Processing and Information Retrieval, volume 4209 of Lecture Notes in Computer Science, pages 122–133. Springer Berlin / Heidelberg.","Luı́s M. Russo, Gonzalo Navarro, and Arlindo L. Oliveira. 2008. Dynamic fully-compressed suffix trees. In CPM ’08: Proceedings of the 19th an-nual symposium on Combinatorial Pattern Match-ing, pages 191–203, Berlin, Heidelberg. Springer-Verlag.","P. Rychlý. 2007. Manatee/bonito – a modular corpus manager. In P. Sojka and A. Horák, editors, First Workshop on Recent Advances in Slavonic Natural Language Processing 2007, Faculty of Informatics, Masaryk University, Botanická 68a, 60200 Brno, Czech Republic.","Mikio Yamamoto and Kenneth W. Church. 1998. Using suffix arrays to compute term frequency and document frequency for all substrings in a corpus. Computational Linguistics, 27:28–37. 494"]}]}